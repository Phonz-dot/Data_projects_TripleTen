{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi Alphonso, thank you for submitting the project! üòä I can see your code now. For further clarity or improvements, consider scheduling a 1:1 session with your tutor for personalized guidance. Keep up the great effort!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hi Alphonso,Thank you for submitting the project! üòä I am unable to see the results of your code snippets. Please ensure that all the cells are run, resolve any errors if they occur, and then resubmit. All the best with your revisions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello Alphonso,\n",
    "\n",
    "You‚Äôve submitted another project‚Äîgreat work! Your commitment to pushing through the challenges of this program is admirable.\n",
    "\n",
    "After reviewing your submission, I‚Äôve returned it with some feedback to help you make the necessary improvements. You can find my general feedback on the platform, with more detailed notes within your project file in the ‚ÄòComments‚Äô section.\n",
    "\n",
    "What Was Great:\n",
    "\t‚Ä¢\tYou‚Äôve shown good progress in handling data preprocessing and feature preparation.\n",
    "\t‚Ä¢\tYour approach to model training, including tracking training and prediction time, is a valuable step for model efficiency evaluation.\n",
    "\n",
    "Areas to Improve:\n",
    "\n",
    "\t1.\tData Preprocessing / EDA:\n",
    "\t‚Ä¢\tDuplicate Check: Great job on dropping duplicates to ensure clean data.\n",
    "\t‚Ä¢\tNull Check: Dropping rows with missing values works, but consider imputation for categorical features (e.g., mode imputation) if missing data is non-trivial.\n",
    "\t‚Ä¢\tOutlier Detection: Your visual inspection of features like price and mileage is helpful. You may want to test your models with and without extreme outliers to assess their impact.\n",
    "\t‚Ä¢\tColumn Drop: Dropping unnecessary columns (e.g., datecrawled) is crucial for reducing noise.\n",
    "    \n",
    "\t2.\tFeature Preparation:\n",
    "    \n",
    "\t‚Ä¢\tEncoding Categorical Variables: You‚Äôre using pd.get_dummies to one-hot encode categorical variables, which is suitable for models like Random Forest and XGBoost. For models like CatBoost and LightGBM, you can leave categorical features as is, as they handle them natively.\n",
    "\t‚Ä¢\tScaling Numeric Features: Scaling with StandardScaler is important for linear models but may not be necessary for tree-based models like Random Forest or XGBoost.\n",
    "    \n",
    "\t3.\tModel Training:\n",
    "\t‚Ä¢\tTraining and Prediction Timing: You‚Äôre correctly tracking the training and prediction time, which is important for assessing the efficiency of your models.\n",
    "\t‚Ä¢\tEvaluation with RMSE: You‚Äôre using RMSE correctly for evaluating model performance on validation and test sets.\n",
    "\t4.\tModeling with Various Algorithms:\n",
    "\t‚Ä¢\tLinear Regression (LR): Great baseline model to start with, though it might not perform as well with complex relationships.\n",
    "\t‚Ä¢\tRandom Forest (RF): Hyperparameter tuning using RandomizedSearchCV is spot on. Keep an eye on overfitting with higher n_estimators or max_depth values.\n",
    "\t‚Ä¢\tLightGBM (LGBM): Excellent for large datasets. Ensure thorough hyperparameter tuning.\n",
    "\t‚Ä¢\tCatBoost: A good choice for categorical data, but make sure to fine-tune its parameters to improve model performance.\n",
    "\t‚Ä¢\tXGBoost: Efficient and performs well with hyperparameter tuning, similar to the other models.\n",
    "    \n",
    "\t5.\tSuggestions:\n",
    "\t‚Ä¢\tCross-validation: Implement cross-validation (e.g., cross_val_score or KFold) to ensure your models generalize well and don‚Äôt overfit to the training data.\n",
    "\t‚Ä¢\tFeature Engineering: Consider exploring advanced feature engineering techniques, such as interaction terms or polynomial features, to enhance model performance.\n",
    "\t‚Ä¢\tEnsemble Methods: Combining predictions from multiple models (e.g., stacking, boosting) could provide better generalization, especially if you combine models like Random Forest, LightGBM, and XGBoost.\n",
    "\t‚Ä¢\tModel Selection: After tuning all models, evaluate their performance on the test set and choose the one with the best balance between performance and speed.\n",
    "\t6.\tFinal Model Evaluation:\n",
    "Once you‚Äôve completed hyperparameter tuning for all models, select the one with the best RMSE on the test set. Ensure that the chosen model‚Äôs prediction speed meets the app‚Äôs performance requirements\n",
    "\n",
    "Next Steps:\n",
    "Please run all cells in your notebook to ensure everything is functioning correctly and then resubmit the project after addressing the points above. I‚Äôm confident you can refine the project and make it even better! Keep going‚Äîyou‚Äôre doing great! \n",
    "üèÑ\n",
    "\n",
    "\n",
    "\n",
    "<b>Project Owner Questions:<b>\n",
    "- 1. Do you want me to address the points under your 'suggestions' section or both the 'suggestions' & 'Areas to improve' sections?\n",
    "    \n",
    "- 2. For your suggestion under 'Ensemble Methods', where you suggest 'Combining predictions from multiple models', is this a boosting technique? if so, I thought that's what the Light GBM, Catboost and XGBoost models did on their own?\n",
    "    \n",
    "- 3. For your suggestion under 'Final Model Evaluation', the project description didn't include explicit app performance requirements. The instructions reads to 'analyze the speed and quality of the models'. If there are explicit instructions, where would I need to look in order to find them?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "---\n",
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You need to build the model to determine the value using historical data: technical specifications, trim versions, and prices. \n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training\n",
    "\n",
    "### Stages:\n",
    "1. Data Preprocessing: Clean and organize the data, ensuring it's ready for analysis.\n",
    "2. Exploratory Data Analysis (EDA): Perform an initial analysis to understand the data distribution and identify key trends.\n",
    "3. ID Target/Feature Variables: Find out exactly what variable is being tested.\n",
    "4. Split Dataset: Split dataset up into training, validating & test sets.\n",
    "5. Scale Numeric Features: Set all of the feature variables on equal fields.\n",
    "6. Determine Best Model: Train, fine tune, & evaluate the appropriate models for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display first 5 rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/03/2016 11:52</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>07/04/2016 03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/03/2016 10:58</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>07/04/2016 01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/03/2016 12:52</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>05/04/2016 12:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/03/2016 16:54</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>17/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>17/03/2016 17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2016 17:25</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>31/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>06/04/2016 10:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  24/03/2016 11:52    480         NaN              1993  manual      0   \n",
       "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
       "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
       "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
       "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf   150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN   125000                  5  gasoline        audi         yes   \n",
       "2  grand   125000                  8  gasoline        jeep         NaN   \n",
       "3   golf   150000                  6    petrol  volkswagen          no   \n",
       "4  fabia    90000                  7  gasoline       skoda          no   \n",
       "\n",
       "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
       "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
       "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
       "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
       "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
       "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display column data types & count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "cars_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display descriptive stats of numerical variables within dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Power</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.000000</td>\n",
       "      <td>354369.0</td>\n",
       "      <td>354369.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4416.656776</td>\n",
       "      <td>2004.234448</td>\n",
       "      <td>110.094337</td>\n",
       "      <td>128211.172535</td>\n",
       "      <td>5.714645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50508.689087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4514.158514</td>\n",
       "      <td>90.227958</td>\n",
       "      <td>189.850405</td>\n",
       "      <td>37905.341530</td>\n",
       "      <td>3.726421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25783.096248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30165.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2700.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6400.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price  RegistrationYear          Power        Mileage  \\\n",
       "count  354369.000000     354369.000000  354369.000000  354369.000000   \n",
       "mean     4416.656776       2004.234448     110.094337  128211.172535   \n",
       "std      4514.158514         90.227958     189.850405   37905.341530   \n",
       "min         0.000000       1000.000000       0.000000    5000.000000   \n",
       "25%      1050.000000       1999.000000      69.000000  125000.000000   \n",
       "50%      2700.000000       2003.000000     105.000000  150000.000000   \n",
       "75%      6400.000000       2008.000000     143.000000  150000.000000   \n",
       "max     20000.000000       9999.000000   20000.000000  150000.000000   \n",
       "\n",
       "       RegistrationMonth  NumberOfPictures     PostalCode  \n",
       "count      354369.000000          354369.0  354369.000000  \n",
       "mean            5.714645               0.0   50508.689087  \n",
       "std             3.726421               0.0   25783.096248  \n",
       "min             0.000000               0.0    1067.000000  \n",
       "25%             3.000000               0.0   30165.000000  \n",
       "50%             6.000000               0.0   49413.000000  \n",
       "75%             9.000000               0.0   71083.000000  \n",
       "max            12.000000               0.0   99998.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df = cars_df.rename(columns=lambda x: x.lower()) # Convert column names to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing/EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df = cars_df.drop_duplicates()  # Drop duplicate rows\n",
    "cars_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datecrawled              0\n",
       "price                    0\n",
       "vehicletype          37484\n",
       "registrationyear         0\n",
       "gearbox              19830\n",
       "power                    0\n",
       "model                19701\n",
       "mileage                  0\n",
       "registrationmonth        0\n",
       "fueltype             32889\n",
       "brand                    0\n",
       "notrepaired          71145\n",
       "datecreated              0\n",
       "numberofpictures         0\n",
       "postalcode               0\n",
       "lastseen                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datecrawled          0\n",
       "price                0\n",
       "vehicletype          0\n",
       "registrationyear     0\n",
       "gearbox              0\n",
       "power                0\n",
       "model                0\n",
       "mileage              0\n",
       "registrationmonth    0\n",
       "fueltype             0\n",
       "brand                0\n",
       "notrepaired          0\n",
       "datecreated          0\n",
       "numberofpictures     0\n",
       "postalcode           0\n",
       "lastseen             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df = cars_df.dropna()  # Drop rows with missing values\n",
    "cars_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns/features that don't contribute to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the main goal behind a machine learning model is to produce the most accurate predictions, only the most relevant columns/features need to be considered that directly help in that prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>vehicletype</th>\n",
       "      <th>registrationyear</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registrationmonth</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>brand</th>\n",
       "      <th>notrepaired</th>\n",
       "      <th>postalcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>91074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>60437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>650</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1995</td>\n",
       "      <td>manual</td>\n",
       "      <td>102</td>\n",
       "      <td>3er</td>\n",
       "      <td>150000</td>\n",
       "      <td>10</td>\n",
       "      <td>petrol</td>\n",
       "      <td>bmw</td>\n",
       "      <td>yes</td>\n",
       "      <td>33775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2200</td>\n",
       "      <td>convertible</td>\n",
       "      <td>2004</td>\n",
       "      <td>manual</td>\n",
       "      <td>109</td>\n",
       "      <td>2_reihe</td>\n",
       "      <td>150000</td>\n",
       "      <td>8</td>\n",
       "      <td>petrol</td>\n",
       "      <td>peugeot</td>\n",
       "      <td>no</td>\n",
       "      <td>67112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1980</td>\n",
       "      <td>manual</td>\n",
       "      <td>50</td>\n",
       "      <td>other</td>\n",
       "      <td>40000</td>\n",
       "      <td>7</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>19348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  vehicletype  registrationyear gearbox  power    model  mileage  \\\n",
       "3   1500        small              2001  manual     75     golf   150000   \n",
       "4   3600        small              2008  manual     69    fabia    90000   \n",
       "5    650        sedan              1995  manual    102      3er   150000   \n",
       "6   2200  convertible              2004  manual    109  2_reihe   150000   \n",
       "7      0        sedan              1980  manual     50    other    40000   \n",
       "\n",
       "   registrationmonth  fueltype       brand notrepaired  postalcode  \n",
       "3                  6    petrol  volkswagen          no       91074  \n",
       "4                  7  gasoline       skoda          no       60437  \n",
       "5                 10    petrol         bmw         yes       33775  \n",
       "6                  8    petrol     peugeot          no       67112  \n",
       "7                  7    petrol  volkswagen          no       19348  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df = cars_df.drop(columns=['datecrawled', 'datecreated', 'lastseen', 'numberofpictures'])  # Drop specific columns\n",
    "cars_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the columns that don't seem to add any value to the quality or level of predicting the price of a car. The columns left within the dataframe that contain null values are: 'vehicletype', 'gearbox', 'model', 'fueltype', & 'notrepaired' columns. Looking at a snippet of the dataframe now, it appears the variables/features that are categorical are 'vehicletype', 'gearbox', 'model', 'fueltype', 'brand', 'notrepaired'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAABMCklEQVR4nO3deXwU9f0/8Nfm2pybC3MSQgRMuCNQ0ihnjYTvN6Wm2HKlSG0EtQkF+RYRv4qgWAREBAsi9Feh1AOpYpVLYziCEAMEAuFIuKKcm8iR3SSY+/37g2+m2ZwbMrmY1/Px2AfMzHs/85nJTvaV2c/s6EREQERERKRBNm3dASIiIqK2wiBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmmXX1h1ozyorK3H16lW4ublBp9O1dXeIiIjICiKCgoICBAQEwMam4XM+DEINuHr1KoKCgtq6G0RERHQXLl26hM6dOzdYwyDUADc3NwB3dqTBYGjj3hAREZE1zGYzgoKClPfxhjAINaDq4zCDwcAgRERE1MFYM6yFg6WJiIhIsxiEiIiISLMYhIiIiEizGISIiIhIsxiEiIiISLMYhIiIiEizGISIiIhIsxiEiIiISLMYhIiIiEizGISIiIhIsxiEiIiISLMYhIiIiEizeNNVIiKV/FT+E/b/cAo/lVY0WFdSUowrly62SB8Cg7pAr3dssMbJwRYPB/eCk51Ti/SBqCNhECIiUsn+H07huW9/37aduGld2XKsR1S3gS3bF6IOgEGIiEglnvadUZQzHX9+9AEEeTnXW9eWZ4Qu3byNN5POwHNk5xZZP1FHwyBERKQSva0jKosDMazrg+gT6N5wcXirdKmWE1dMWFJcBL1twx+fEWkFB0sTERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjU5CKWkpGDMmDEICAiATqfD559/Xm/tM888A51Oh7ffftti/s2bNxEXFweDwQAPDw/Ex8ejsLDQoub48eMYOnQoHB0dERQUhCVLltRqf/PmzQgLC4OjoyP69u2L7du3WywXEcybNw/+/v5wcnJCVFQUzp4929RNJiIiontUk4NQUVER+vfvj1WrVjVYt2XLFnz33XcICAiotSwuLg4nT55EUlIStm7dipSUFEybNk1ZbjabMWrUKAQHByM9PR1Lly7F/PnzsXbtWqXmwIEDmDhxIuLj43H06FHExsYiNjYWJ06cUGqWLFmClStXYs2aNUhLS4OLiwuio6NRXFzc1M0mIiKie5E0AwDZsmVLrfmXL1+WwMBAOXHihAQHB8vy5cuVZadOnRIAcujQIWXejh07RKfTyZUrV0REZPXq1eLp6SklJSVKzZw5cyQ0NFSZHjdunMTExFisNyIiQp5++mkREamsrBQ/Pz9ZunSpsjw/P1/0er189NFHVm2fyWQSAGIymayqJyJty7ycL8Fztkrm5fy27kq9OkIfiZqrKe/fqo8RqqysxOTJkzF79mz07t271vLU1FR4eHhg0KBByryoqCjY2NggLS1NqRk2bBgcHByUmujoaGRnZ+PWrVtKTVRUlEXb0dHRSE1NBQDk5OTAaDRa1Li7uyMiIkKpqamkpARms9niQURERPcu1YPQ4sWLYWdnhz/96U91LjcajfDx8bGYZ2dnBy8vLxiNRqXG19fXoqZqurGa6surP6+umpoWLVoEd3d35REUFNTo9hIREVHHpWoQSk9Px4oVK7B+/XrodDo1m24Vc+fOhclkUh6XLl1q6y4RERFRC1I1CO3btw95eXno0qUL7OzsYGdnhx9++AH/8z//g65duwIA/Pz8kJeXZ/G88vJy3Lx5E35+fkpNbm6uRU3VdGM11ZdXf15dNTXp9XoYDAaLBxEREd27VA1CkydPxvHjx5GRkaE8AgICMHv2bHz11VcAgMjISOTn5yM9PV153q5du1BZWYmIiAilJiUlBWVlZUpNUlISQkND4enpqdQkJydbrD8pKQmRkZEAgJCQEPj5+VnUmM1mpKWlKTVERESkbXZNfUJhYSHOnTunTOfk5CAjIwNeXl7o0qULvL29Lert7e3h5+eH0NBQAEDPnj0xevRoTJ06FWvWrEFZWRkSExMxYcIE5VL7SZMmYcGCBYiPj8ecOXNw4sQJrFixAsuXL1fanTFjBoYPH45ly5YhJiYGH3/8MQ4fPqxcYq/T6TBz5kwsXLgQPXr0QEhICF5++WUEBAQgNja2yTuKiIiI7j1NDkKHDx/GyJEjlelZs2YBAKZMmYL169db1cYHH3yAxMREPPLII7CxscHjjz+OlStXKsvd3d3x9ddfIyEhAQMHDkSnTp0wb948i+8aeuihh/Dhhx/ipZdewosvvogePXrg888/R58+fZSa559/HkVFRZg2bRry8/MxZMgQ7Ny5E46Ojk3dbCIiIroH6URE2roT7ZXZbIa7uztMJhPHCxFRo05cMeGX73yLrdOHoE+ge1t3p04doY9EzdWU92/ea4yIiIg0i0GIiIiINItBiIiIiDSLQYiIiIg0i0GIiIiINItBiIiIiDSLQYiIiIg0i0GIiIiINItBiIiIiDSLQYiIiIg0i0GIiIiINItBiIiIiDSLQYiIiIg0i0GIiIiINItBiIiIiDSLQYiIiIg0i0GIiIiINItBiIiIiDSLQYiIiIg0i0GIiIiINItBiIiIiDSLQYiIiIg0i0GIiIiINItBiIiIiDSLQYiIiIg0y66tO0BEdK/4qawCAHDiikm1NovLKnD51k/o7OkER3vbZrd3Lq9QhV4R3TsYhIiIVHL+/0LGC59ltnFPGuei569/IoBBiIhINaN6+wEAuvm4wkmFszfAnTM4Mzdl4O3x4eju46pKmy56O4R0clGlLaKOjkGIiEglXi4OmDC4S4u03d3HFX0C3VukbSIt42BpIiIi0iwGISIiItIsBiEiIiLSLAYhIiIi0iwGISIiItKsJgehlJQUjBkzBgEBAdDpdPj888+VZWVlZZgzZw769u0LFxcXBAQE4IknnsDVq1ct2rh58ybi4uJgMBjg4eGB+Ph4FBZafsnX8ePHMXToUDg6OiIoKAhLliyp1ZfNmzcjLCwMjo6O6Nu3L7Zv326xXEQwb948+Pv7w8nJCVFRUTh79mxTN5mIiIjuUU0OQkVFRejfvz9WrVpVa9nt27dx5MgRvPzyyzhy5Ag+++wzZGdn41e/+pVFXVxcHE6ePImkpCRs3boVKSkpmDZtmrLcbDZj1KhRCA4ORnp6OpYuXYr58+dj7dq1Ss2BAwcwceJExMfH4+jRo4iNjUVsbCxOnDih1CxZsgQrV67EmjVrkJaWBhcXF0RHR6O4uLipm01ERET3ImkGALJly5YGaw4ePCgA5IcffhARkVOnTgkAOXTokFKzY8cO0el0cuXKFRERWb16tXh6ekpJSYlSM2fOHAkNDVWmx40bJzExMRbrioiIkKefflpERCorK8XPz0+WLl2qLM/Pzxe9Xi8fffSRVdtnMpkEgJhMJqvqiYjUlnk5X4LnbJXMy/lt3RWiDqMp798tPkbIZDJBp9PBw8MDAJCamgoPDw8MGjRIqYmKioKNjQ3S0tKUmmHDhsHBwUGpiY6ORnZ2Nm7duqXUREVFWawrOjoaqampAICcnBwYjUaLGnd3d0RERCg1NZWUlMBsNls8iIiI6N7VokGouLgYc+bMwcSJE2EwGAAARqMRPj4+FnV2dnbw8vKC0WhUanx9fS1qqqYbq6m+vPrz6qqpadGiRXB3d1ceQUFBTd5mIiIi6jhaLAiVlZVh3LhxEBG8++67LbUaVc2dOxcmk0l5XLp0qa27RERERC2oRe41VhWCfvjhB+zatUs5GwQAfn5+yMvLs6gvLy/HzZs34efnp9Tk5uZa1FRNN1ZTfXnVPH9/f4ua8PDwOvut1+uh1+uburlERETUQal+RqgqBJ09exbffPMNvL29LZZHRkYiPz8f6enpyrxdu3ahsrISERERSk1KSgrKysqUmqSkJISGhsLT01OpSU5Otmg7KSkJkZGRAICQkBD4+flZ1JjNZqSlpSk1REREpG1NDkKFhYXIyMhARkYGgDuDkjMyMnDx4kWUlZXhN7/5DQ4fPowPPvgAFRUVMBqNMBqNKC0tBQD07NkTo0ePxtSpU3Hw4EHs378fiYmJmDBhAgICAgAAkyZNgoODA+Lj43Hy5Els2rQJK1aswKxZs5R+zJgxAzt37sSyZcuQlZWF+fPn4/Dhw0hMTAQA6HQ6zJw5EwsXLsQXX3yBzMxMPPHEEwgICEBsbGwzdxsRERHdE5p6Sdru3bsFQK3HlClTJCcnp85lAGT37t1KGzdu3JCJEyeKq6urGAwGefLJJ6WgoMBiPceOHZMhQ4aIXq+XwMBAeeONN2r15ZNPPpEHHnhAHBwcpHfv3rJt2zaL5ZWVlfLyyy+Lr6+v6PV6eeSRRyQ7O9vqbeXl80TU1nj5PFHTNeX9Wyci0iYJrAMwm81wd3eHyWSyGOdERNRaTlwx4ZfvfIut04egT6B7W3eHqENoyvs37zVGREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESa1eQglJKSgjFjxiAgIAA6nQ6ff/65xXIRwbx58+Dv7w8nJydERUXh7NmzFjU3b95EXFwcDAYDPDw8EB8fj8LCQoua48ePY+jQoXB0dERQUBCWLFlSqy+bN29GWFgYHB0d0bdvX2zfvr3JfSEiIiLtanIQKioqQv/+/bFq1ao6ly9ZsgQrV67EmjVrkJaWBhcXF0RHR6O4uFipiYuLw8mTJ5GUlIStW7ciJSUF06ZNU5abzWaMGjUKwcHBSE9Px9KlSzF//nysXbtWqTlw4AAmTpyI+Ph4HD16FLGxsYiNjcWJEyea1BciIiLSMGkGALJlyxZlurKyUvz8/GTp0qXKvPz8fNHr9fLRRx+JiMipU6cEgBw6dEip2bFjh+h0Orly5YqIiKxevVo8PT2lpKREqZkzZ46EhoYq0+PGjZOYmBiL/kRERMjTTz9tdV8aYzKZBICYTCar6omI1JZ5OV+C52yVzMv5bd0Vog6jKe/fdmqGqpycHBiNRkRFRSnz3N3dERERgdTUVEyYMAGpqanw8PDAoEGDlJqoqCjY2NggLS0Nv/71r5Gamophw4bBwcFBqYmOjsbixYtx69YteHp6IjU1FbNmzbJYf3R0tPJRnTV9qamkpAQlJSXKtNlsbvY+ISIi6ghu376NrKysRuuKyypw+dZtdPZ0hqO9baP1YWFhcHZ2VqOLLULVIGQ0GgEAvr6+FvN9fX2VZUajET4+PpadsLODl5eXRU1ISEitNqqWeXp6wmg0NrqexvpS06JFi7BgwQLrNpaIiOgekpWVhYEDB6rebnp6OgYMGKB6u2pRNQh1dHPnzrU4y2Q2mxEUFNSGPSIiImodYWFhSE9Pb7TuXF4BZnycgRUTwtHdx82qdtszVYOQn58fACA3Nxf+/v7K/NzcXISHhys1eXl5Fs8rLy/HzZs3lef7+fkhNzfXoqZqurGa6ssb60tNer0eer3e6u0lIiK6Vzg7O1t15sbhign6PYXo1TccfQLdW6FnLUvV7xEKCQmBn58fkpOTlXlmsxlpaWmIjIwEAERGRiI/P98ide7atQuVlZWIiIhQalJSUlBWVqbUJCUlITQ0FJ6enkpN9fVU1VStx5q+EBERkbY1OQgVFhYiIyMDGRkZAO4MSs7IyMDFixeh0+kwc+ZMLFy4EF988QUyMzPxxBNPICAgALGxsQCAnj17YvTo0Zg6dSoOHjyI/fv3IzExERMmTEBAQAAAYNKkSXBwcEB8fDxOnjyJTZs2YcWKFRYfW82YMQM7d+7EsmXLkJWVhfnz5+Pw4cNITEwEAKv6QkRERBrX1EvSdu/eLQBqPaZMmSIidy5bf/nll8XX11f0er088sgjkp2dbdHGjRs3ZOLEieLq6ioGg0GefPJJKSgosKg5duyYDBkyRPR6vQQGBsobb7xRqy+ffPKJPPDAA+Lg4CC9e/eWbdu2WSy3pi8N4eXzRNTWePk8tTcd4TXZlPdvnYhIG+awds1sNsPd3R0mkwkGg6Gtu0NEGnTiigm/fOdbbJ0+5J4Yj0EdX0d4TTbl/Zv3GiMiIiLNYhAiIiIizWIQIiIiIs1iECIiIiLNYhAiIiIizWIQIiIiIs1iECIiIiLNYhAiIiIizWIQIiIiIs1iECIiIiLNYhAiIiIizWIQIiIiIs1iECIiIiLNYhAiIiIizWIQIiIiIs2ya+sOEBFpze3bt5GVlWVV7bm8ApQYz+FUpitKc90arQ8LC4Ozs3Nzu0ikGQxCREStLCsrCwMHDmzSc8ZvsK4uPT0dAwYMuIteEWkTgxARUSsLCwtDenq6VbXFZRW4fOs2Ons6w9He1qq2ich6DEJERK3M2dmZZ22I2gkOliYiIiLNYhAiIiIizWIQIiIiIs1iECIiIiLNYhAiIiIizWIQIiIiIs1iECIiIiLNYhAiIiIizWIQIiIiIs1iECIiIiLNYhAiIiIizWIQIiIiIs1iECIiIiLNYhAiIiIizbJr6w4QEVHddDpdrXki0gY9Ibp3qX5GqKKiAi+//DJCQkLg5OSEbt264bXXXrM4eEUE8+bNg7+/P5ycnBAVFYWzZ89atHPz5k3ExcXBYDDAw8MD8fHxKCwstKg5fvw4hg4dCkdHRwQFBWHJkiW1+rN582aEhYXB0dERffv2xfbt29XeZCIi1dUVghqaT0R3R/UgtHjxYrz77rv461//itOnT2Px4sVYsmQJ3nnnHaVmyZIlWLlyJdasWYO0tDS4uLggOjoaxcXFSk1cXBxOnjyJpKQkbN26FSkpKZg2bZqy3Gw2Y9SoUQgODkZ6ejqWLl2K+fPnY+3atUrNgQMHMHHiRMTHx+Po0aOIjY1FbGwsTpw4ofZmExGpprGwwzBEpCJRWUxMjPzhD3+wmDd27FiJi4sTEZHKykrx8/OTpUuXKsvz8/NFr9fLRx99JCIip06dEgBy6NAhpWbHjh2i0+nkypUrIiKyevVq8fT0lJKSEqVmzpw5EhoaqkyPGzdOYmJiLPoSEREhTz/9tFXbYjKZBICYTCar6omImguAxcPaZUStJfNyvgTP2SqZl/Pbuiv1asr7t+pnhB566CEkJyfjzJkzAIBjx47h22+/xX/9138BAHJycmA0GhEVFaU8x93dHREREUhNTQUApKamwsPDA4MGDVJqoqKiYGNjg7S0NKVm2LBhcHBwUGqio6ORnZ2NW7duKTXV11NVU7WemkpKSmA2my0eRERtRWqMB6o5TUTNp/pg6RdeeAFmsxlhYWGwtbVFRUUFXn/9dcTFxQEAjEYjAMDX19fieb6+vsoyo9EIHx8fy47a2cHLy8uiJiQkpFYbVcs8PT1hNBobXE9NixYtwoIFC+5ms4mIiKgDUv2M0CeffIIPPvgAH374IY4cOYINGzbgzTffxIYNG9Relermzp0Lk8mkPC5dutTWXSIiIqIWpPoZodmzZ+OFF17AhAkTAAB9+/bFDz/8gEWLFmHKlCnw8/MDAOTm5sLf3195Xm5uLsLDwwEAfn5+yMvLs2i3vLwcN2/eVJ7v5+eH3Nxci5qq6cZqqpbXpNfrodfr72aziYhUp9PpLD4O4yBpIvWpfkbo9u3bsLGxbNbW1haVlZUAgJCQEPj5+SE5OVlZbjabkZaWhsjISABAZGQk8vPzkZ6ertTs2rULlZWViIiIUGpSUlJQVlam1CQlJSE0NBSenp5KTfX1VNVUrYeIqL2pOQ5Ip9Mpj4bqiOjuqB6ExowZg9dffx3btm3D999/jy1btuCtt97Cr3/9awB3DuqZM2di4cKF+OKLL5CZmYknnngCAQEBiI2NBQD07NkTo0ePxtSpU3Hw4EHs378fiYmJmDBhAgICAgAAkyZNgoODA+Lj43Hy5Els2rQJK1aswKxZs5S+zJgxAzt37sSyZcuQlZWF+fPn4/Dhw0hMTFR7s4mIVNNYyGEIIlKR2pesmc1mmTFjhnTp0kUcHR3l/vvvl//93/+1uMy9srJSXn75ZfH19RW9Xi+PPPKIZGdnW7Rz48YNmThxori6uorBYJAnn3xSCgoKLGqOHTsmQ4YMEb1eL4GBgfLGG2/U6s8nn3wiDzzwgDg4OEjv3r1l27ZtVm8LL58noraEGpfLt8CvbKImu9cun9eJ8E+L+pjNZri7u8NkMsFgMLR1d4iIiNrciSsm/PKdb7F1+hD0CXRv6+7UqSnv37zpKhEREWkWgxARERFpFoMQERERaRaDEBEREWkWgxARERFpFoMQERERaRaDEBEREWkWgxARERFpFoMQERERaZbqd58nIiKi9iPnehGKSspVa+9cXqHFv2px0dshpJOLqm1ag0GIiIjoHpVzvQgj39zTIm3P3JShepu7/zyi1cMQgxARUTul0+lqzePtIakpqs4EvT0+HN19XFVps7isApdv/YTOnk5wtLdVpc1zeYWYuSlD1TNX1mIQIiJqh+oKQVXzGYaoqbr7uKp6g9RBXVVrqs1xsDQRUTtTXwiydjkRWY9BiIioHakZckREeTRUR0R3h0GIiKidqhl++JEYkfoYhIiIiEizGISIiIhIsxiEiIjaqZrjgDguiEh9vHyeiKgdERGLwFNf+OF4ISJ18IwQEVE701jIYQgiUg+DEBFRO1Rf2GEIIlIXPxojImqnGHqIWh7PCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFm8RYbRETtVF13nudtN4jU1SJnhK5cuYLf/e538Pb2hpOTE/r27YvDhw8ry0UE8+bNg7+/P5ycnBAVFYWzZ89atHHz5k3ExcXBYDDAw8MD8fHxKCwstKg5fvw4hg4dCkdHRwQFBWHJkiW1+rJ582aEhYXB0dERffv2xfbt21tik4mIVFVXCGpoPhHdHdWD0K1bt/Dwww/D3t4eO3bswKlTp7Bs2TJ4enoqNUuWLMHKlSuxZs0apKWlwcXFBdHR0SguLlZq4uLicPLkSSQlJWHr1q1ISUnBtGnTlOVmsxmjRo1CcHAw0tPTsXTpUsyfPx9r165Vag4cOICJEyciPj4eR48eRWxsLGJjY3HixAm1N5uISDWNhR2GISIVicrmzJkjQ4YMqXd5ZWWl+Pn5ydKlS5V5+fn5otfr5aOPPhIRkVOnTgkAOXTokFKzY8cO0el0cuXKFRERWb16tXh6ekpJSYnFukNDQ5XpcePGSUxMjMX6IyIi5Omnn7ZqW0wmkwAQk8lkVT0RUXMBsHhYu4yoLpmX8yV4zlbJvJzf1l1pkNr9bMr7t+pnhL744gsMGjQIv/3tb+Hj44MHH3wQ69atU5bn5OTAaDQiKipKmefu7o6IiAikpqYCAFJTU+Hh4YFBgwYpNVFRUbCxsUFaWppSM2zYMDg4OCg10dHRyM7Oxq1bt5Sa6uupqqlaT00lJSUwm80WDyKitiI1xgPVnCai5lM9CF24cAHvvvsuevToga+++grPPvss/vSnP2HDhg0AAKPRCADw9fW1eJ6vr6+yzGg0wsfHx2K5nZ0dvLy8LGrqaqP6OuqrqVpe06JFi+Du7q48goKCmrz9RERE1HGoHoQqKysxYMAA/OUvf8GDDz6IadOmYerUqVizZo3aq1Ld3LlzYTKZlMelS5fauktERETUglQPQv7+/ujVq5fFvJ49e+LixYsAAD8/PwBAbm6uRU1ubq6yzM/PD3l5eRbLy8vLcfPmTYuautqovo76aqqW16TX62EwGCweRERtpeagaA6SJlKf6kHo4YcfRnZ2tsW8M2fOIDg4GAAQEhICPz8/JCcnK8vNZjPS0tIQGRkJAIiMjER+fj7S09OVml27dqGyshIRERFKTUpKCsrKypSapKQkhIaGKleoRUZGWqynqqZqPURE7U3NcUA6nU55NFRHRHdH9SD03HPP4bvvvsNf/vIXnDt3Dh9++CHWrl2LhIQEAHcO6pkzZ2LhwoX44osvkJmZiSeeeAIBAQGIjY0FcOcM0ujRozF16lQcPHgQ+/fvR2JiIiZMmICAgAAAwKRJk+Dg4ID4+HicPHkSmzZtwooVKzBr1iylLzNmzMDOnTuxbNkyZGVlYf78+Th8+DASExPV3mwiItU0FnIYgohUpMp1ajV8+eWX0qdPH9Hr9RIWFiZr1661WF5ZWSkvv/yy+Pr6il6vl0ceeUSys7Mtam7cuCETJ04UV1dXMRgM8uSTT0pBQYFFzbFjx2TIkCGi1+slMDBQ3njjjVp9+eSTT+SBBx4QBwcH6d27t2zbts3q7eDl80TUllDjcvkW+pVN9zBePt/4+7dOhH9a1MdsNsPd3R0mk4njhYiIqMM5ccWEX77zLbZOH4I+ge5t3Z16qd3Pprx/86arREREpFkMQkRERKRZDEJERESkWQxCREREpFkMQkRERKRZDEJERESkWQxCREREpFkMQkRERKRZDEJERESkWQxCREREpFl2bd0BIiKqW807zgO84SqR2nhGiIioHaorBDU0n4juDoMQEVE701jYYRgiUg8/GiMiakdqhpzqH4VVX6bT6fgxGTWqpKIYNo5XkGPOho2ja1t3p1455kLYOF5BSUUxgObffb4pGISIiNqpmkFHRHg2iJrkatEPcAl5By8ebOueNM4lBLhaFI6B8G3V9TIIERER3aMCXIJRlDMdK8aHo5tP+z0jdD6vEDM2ZSBgZHCrr5tBiIiI6B6lt3VEZXEgQgyh6OXduh85NUVlsQmVxT9Cb+vY6uvmYGkionaq5sdg/FiMSH08I0RE1I7UHAdUX/jhQGkidfCMEBFRO9NYyGEIIlIPgxARUTtUX9hhCCJSFz8aIyJqpxh6iFoezwgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWYxCBEREZFmMQgRERGRZjEIERERkWbxXmNERO2UTqerNY/3HyNSV4ufEXrjjTeg0+kwc+ZMZV5xcTESEhLg7e0NV1dXPP7448jNzbV43sWLFxETEwNnZ2f4+Phg9uzZKC8vt6jZs2cPBgwYAL1ej+7du2P9+vW11r9q1Sp07doVjo6OiIiIwMGDB1tiM4mIVFVXCGpoPhHdnRYNQocOHcJ7772Hfv36Wcx/7rnn8OWXX2Lz5s3Yu3cvrl69irFjxyrLKyoqEBMTg9LSUhw4cAAbNmzA+vXrMW/ePKUmJycHMTExGDlyJDIyMjBz5kw89dRT+Oqrr5SaTZs2YdasWXjllVdw5MgR9O/fH9HR0cjLy2vJzSYiapbGwg7DEJGKpIUUFBRIjx49JCkpSYYPHy4zZswQEZH8/Hyxt7eXzZs3K7WnT58WAJKamioiItu3bxcbGxsxGo1KzbvvvisGg0FKSkpEROT555+X3r17W6xz/PjxEh0drUwPHjxYEhISlOmKigoJCAiQRYsWWbUNJpNJAIjJZGraxhMR3SUAFg9rlxHVJfNyvgTP2SqZl/PbuisNUrufTXn/brEzQgkJCYiJiUFUVJTF/PT0dJSVlVnMDwsLQ5cuXZCamgoASE1NRd++feHr66vUREdHw2w24+TJk0pNzbajo6OVNkpLS5Genm5RY2Njg6ioKKWmppKSEpjNZosHEVFbkRrjgWpOE1Hztchg6Y8//hhHjhzBoUOHai0zGo1wcHCAh4eHxXxfX18YjUalpnoIqlpetayhGrPZjJ9++gm3bt1CRUVFnTVZWVl19nvRokVYsGCB9RtKREREHZrqZ4QuXbqEGTNm4IMPPoCjo6PazbeouXPnwmQyKY9Lly61dZeIiIioBakehNLT05GXl4cBAwbAzs4OdnZ22Lt3L1auXAk7Ozv4+vqitLQU+fn5Fs/Lzc2Fn58fAMDPz6/WVWRV043VGAwGODk5oVOnTrC1ta2zpqqNmvR6PQwGg8WDiKit1BwUzUHSROpTPQg98sgjyMzMREZGhvIYNGgQ4uLilP/b29sjOTlZeU52djYuXryIyMhIAEBkZCQyMzMtru5KSkqCwWBAr169lJrqbVTVVLXh4OCAgQMHWtRUVlYiOTlZqSEiam9qjgPS6XTKo6E6Iro7qo8RcnNzQ58+fSzmubi4wNvbW5kfHx+PWbNmwcvLCwaDAdOnT0dkZCR+/vOfAwBGjRqFXr16YfLkyViyZAmMRiNeeuklJCQkQK/XAwCeeeYZ/PWvf8Xzzz+PP/zhD9i1axc++eQTbNu2TVnvrFmzMGXKFAwaNAiDBw/G22+/jaKiIjz55JNqbzYRkWpEpMGzPwxBROppk2+WXr58OWxsbPD444+jpKQE0dHRWL16tbLc1tYWW7duxbPPPovIyEi4uLhgypQpePXVV5WakJAQbNu2Dc899xxWrFiBzp07429/+xuio6OVmvHjx+PHH3/EvHnzYDQaER4ejp07d9YaQE1E1N7UF4YYgojUpRMeVfUym81wd3eHyWTieCEiIupwTlwx4ZfvfIut04egT6B7W3enXmr3synv37zpKhEREWkWgxARERFpFoMQERERaRaDEBEREWkWgxARERFpFoMQERERaRaDEBEREWkWgxARERFpFoMQERERaRaDEBEREWlWm9xrjIiIGsd7jRG1PJ4RIiJqh+q7+3xDd6UnoqbjGSEionamsbCj0+l4Zois8lNZBYA7NzVVS3FZBS7f+gmdPZ3gaG+rSpvn8gpVaeduMAgREbUjNUNQ9cBTfRnDEFnj/P8FjBc+y2zjnljHRd/6sYRBiIionaoZdESEH41Rk4zq7QcA6ObjCicVz97M3JSBt8eHo7uPqyptAndCUEgnF9XasxaDEBER0T3Ky8UBEwZ3aZG2u/u4ok+ge4u03Zo4WJqIiIg0i0GIiKidqvkxGD8WI1IfPxojImpHao4Dqi/8cKA0kTp4RoiIqJ1pLOQwBBGph0GIiKgdqi/sMAQRqYsfjRERtVMMPUQtj2eEiIiISLMYhIiIiEizGISIiIhIsxiEiIiISLMYhIiIiEizGISIiIhIsxiEiIiISLMYhIiIiEizGISIiIhIsxiEiIiISLMYhIiIiEizeK+xDk6n09Wax/sTUVuqqKjAvn37cO3aNfj7+2Po0KGwtbVt6251SDy+iVqe6meEFi1ahJ/97Gdwc3ODj48PYmNjkZ2dbVFTXFyMhIQEeHt7w9XVFY8//jhyc3Mtai5evIiYmBg4OzvDx8cHs2fPRnl5uUXNnj17MGDAAOj1enTv3h3r16+v1Z9Vq1aha9eucHR0REREBA4ePKj2JreZun5JNjSfqKV99tln6N69O0aOHIlJkyZh5MiR6N69Oz777LO27lqHw+ObqHWoHoT27t2LhIQEfPfdd0hKSkJZWRlGjRqFoqIipea5557Dl19+ic2bN2Pv3r24evUqxo4dqyyvqKhATEwMSktLceDAAWzYsAHr16/HvHnzlJqcnBzExMRg5MiRyMjIwMyZM/HUU0/hq6++Umo2bdqEWbNm4ZVXXsGRI0fQv39/REdHIy8vT+3NbnWN/TLkL0tqbZ999hl+85vfoG/fvkhNTUVBQQFSU1PRt29f/OY3v2EYagIe30StSFpYXl6eAJC9e/eKiEh+fr7Y29vL5s2blZrTp08LAElNTRURke3bt4uNjY0YjUal5t133xWDwSAlJSUiIvL8889L7969LdY1fvx4iY6OVqYHDx4sCQkJynRFRYUEBATIokWLrOq7yWQSAGIymZq41S0LgNUPotZQXl4uXbt2lTFjxkhFRYXFsoqKChkzZoyEhIRIeXl5G/Ww42joGObxTe1B5uV8CZ6zVTIv57d1V+rVlPfvFh8sbTKZAABeXl4AgPT0dJSVlSEqKkqpCQsLQ5cuXZCamgoAyl+Rvr6+Sk10dDTMZjNOnjyp1FRvo6qmqo3S0lKkp6db1NjY2CAqKkqpqamkpARms9niQUSN27dvH77//nu8+OKLsLGx/LViY2ODuXPnIicnB/v27WujHnZMUmM8UM1pImq+Fg1ClZWVmDlzJh5++GH06dMHAGA0GuHg4AAPDw+LWl9fXxiNRqWmegiqWl61rKEas9mMn376CdevX0dFRUWdNVVt1LRo0SK4u7srj6CgoLvbcCKNuXbtGgCgT58+KC0txdtvv43p06fj7bffRmlpqXL8V9UREbUXLXrVWEJCAk6cOIFvv/22JVejmrlz52LWrFnKtNlsZhgisoK/vz8A4JlnnsGmTZssLmyYPXs2xo0bZ1FHRNRetNgZocTERGzduhW7d+9G586dlfl+fn4oLS1Ffn6+RX1ubi78/PyUmppXkVVNN1ZjMBjg5OSETp06wdbWts6aqjZq0uv1MBgMFg8iatzQoUPh7u6ODz74AF5eXli3bh2uXbuGdevWwcvLCx9++CHc3d0xdOjQtu5qh1JzUDQHSROpT/UgJCJITEzEli1bsGvXLoSEhFgsHzhwIOzt7ZGcnKzMy87OxsWLFxEZGQkAiIyMRGZmpsXVXUlJSTAYDOjVq5dSU72NqpqqNhwcHDBw4ECLmsrKSiQnJys1RKSOiooKFBQUAAAGDRqEzMxMvPLKK8jMzMSgQYMAAAUFBaioqGjLbnYINccB6XQ65dFQHRHdJbVHaj/77LPi7u4ue/bskWvXrimP27dvKzXPPPOMdOnSRXbt2iWHDx+WyMhIiYyMVJaXl5dLnz59ZNSoUZKRkSE7d+6U++67T+bOnavUXLhwQZydnWX27Nly+vRpWbVqldja2srOnTuVmo8//lj0er2sX79eTp06JdOmTRMPDw+Lq9EawqvGiKyzfPlyASDh4eF1vg779esnAGT58uVt3dUOg8c1tVf32lVjqo8RevfddwEAI0aMsJj//vvv4/e//z0AYPny5bCxscHjjz+OkpISREdHY/Xq1Uqtra0ttm7dimeffRaRkZFwcXHBlClT8Oqrryo1ISEh2LZtG5577jmsWLECnTt3xt/+9jdER0crNePHj8ePP/6IefPmwWg0Ijw8HDt37qw1gJqImuf8+fMAgIyMDPj6+mLy5Mm4//77ceHCBWzcuBHHjx+3qKPGiQi/WZqoFagehKw5SB0dHbFq1SqsWrWq3prg4GBs3769wXZGjBiBo0ePNliTmJiIxMTERvtERHcvODgYAGAwGHD27FnMnTsXn3/+OXr06IGzZ88iMDAQBQUFSh1Zh6GHqOXxXmPt1O3bt5GVldXsdo4cOVJrXlhYGJydnZvdNlFNRUVFFhcZfP3111i1ahXvNUZE7RaDUDuVlZWFgQMHNrudutpIT0/HgAEDmt02UZUffvgBAJTB0KNHj8bLL7+M1157DTt37lTmV9UREbUXDELtVFhYGNLT0+tc1pSAVFcbYWFhd90vorpUfd9W1ZiWnTt3YufOnQDufLO0iEBE+L1cRNTuMAi1U87OzvWetalvEGVddUSt4cKFCwDufG2Fr68vLl68qCzr3LkzjEYjSktLlToiovaixe81Ri2jsZDDEEStKScnB8Cd+/UZjUbMmTMHZ86cwZw5c5QQVL2OiKi94BmhDoyX11J70a1bNwCAh4cHCgoKsHjxYixevBgAYGdnBw8PD+Tn5yt1RETtBc8IdXAigszL+QiesxWZl/MZgqhNPPbYYwCAwsJC3LhxAwkJCRg1ahQSEhJw/fp1FBYWWtQREbUXPCNERM128+ZNAEB5eTk8PDyU+VWXz9esIyJqL3hGiIiazdq7yvPu80TU3jAIEVGzPfTQQ7CxufPrRK/XWyyrmraxscFDDz3U6n0jImoIgxARNdu+fftQWVkJ4M6VY9VVTVdWVmLfvn2t3reOrPqd5+u6Az0RNR+DEBE1265du5T/13yzrj5dvY4aVl/oYRgiUheDEBE12/fffw/gzg2Va357dFBQEBwdHS3qqGGNhR2GISL1MAgRUbPl5eUBAIqLi5X/V19WXFxsUUf1qxlyqm5PUvOrMRiGiNTBIEREzebs7Kz8v+pbpOuarl5HjasZfvg9YUTqYxAiomarfll81aDpuqZ5+TwRtTcMQkTUbNW/RFGNOiKi1sIgRETNdvnyZVXr6I6GrsAjInXwFhtERO1IzZsp1xd+OF6ISB08I0REzda5c2fl/7/4xS/g6uoKW1tbuLq64he/+EWddVS/xkIOQxCRenhGqA3kXC9CUUm5au2dyyu0+FcNLno7hHRyUa09ureZzWbl/9W/NLGwsNBiunodNazmmaHq84lIPQxCrSznehFGvrmnRdqeuSlD1fZ2/3kEwxBZxdqxKxzjQkTtDYNQK6s6E/T2+HB093FVpc3isgpcvvUTOns6wdHettntncsrxMxNGaqetaJ7G+8+r76GbrHBs0JE6mEQaiPdfVzRJ9BdtfYGdVWtKaIme++996yue+mll1q4Nx2fNbfYYBgiUgcHSxNRs+Xm5qpap2W8xQZR62IQIqJmq7qpqlp1dAdvsUHU8vjRGBE129ixY7FhwwYAdy6f9/T0xK1bt5R/q64cGzt2bFt2k4ioFgYhImo2X19f5f/VL5dvqI6IqD1gECJC3eMt+DGE9a5evapqHd1Rc1A0xwURqY9BqJWVVBTDxvEKcszZsHFU5/J5teWYC2HjeAUlFcUA1Luyrb3iZcrNZ+03RvObpRvHW2wQtS4GoVZ2tegHuIS8gxcPtnVPGuYSAlwtCsdA3NsfZfAyZXV4enqqWqd19X2rdPXlRKQOBqFWFuASjKKc6VgxPhzdVPpCRbWdzyvEjE0ZCBgZ3NZdaVF1XaZc1zKGocZt27bN6rrnn3++hXtzb+AtNohaB4NQK9PbOqKyOBAhhlD08m6fHztVFptQWfwj9Lbt+1LnqyYTNmWkN1pXVGjG2czadY7B/9m+cc/8GVPeeFmZfmLRS/hkzZvKdPVl1fXoOxAuroYG1+/n7ojYPg/Cyc6p0b52VCkpKarW0R0MPUQtTxNBaNWqVVi6dCmMRiP69++Pd955B4MHD26TvvxUVgEAOHHFpFqbLXGLjY5gU0Y6/v79DOuK67izQ/cF3ZX/H8HnTV4OAEeufw5cb3z1Xi7rEd1jYOOFRETUqu75ILRp0ybMmjULa9asQUREBN5++21ER0cjOzsbPj4+rd6f8/8XMl74LLPV191ULvr2/fIYHz4QwIpG6+o7I1T9jM+4Z/7c5OWA9WeEhoX0arSfRERt6fbt28jKymq07lxeAUqM53Aq0xWluW6N1oeFhcHZ2VmNLrYIndzj514jIiLws5/9DH/9618BAJWVlQgKCsL06dPxwgsvNPhcs9kMd3d3mEwmGAwNv9lZ62ZRKb4+aUQ3H1c4qXD2BvjPTVLVvJGri97unr/zvLVjhGouo9qaclk39yVR+3TkyBEMHKj+mev09HQMGDBA9XYb0pT37/b9J38zlZaWIj09HXPnzlXm2djYICoqCqmpqbXqS0pKUFJSokybzWbV++Tl4oAJg7s0WmdtMgeA0v9L56W5riiVjp/OWwsvU77D2rFWgHXjrRpT13gra86sAdoYb0V3NHcMoBq0NgYwLCwM6emN78s7wzFuo7Ons1XDMcLCwtToXou5p4PQ9evXUVFRUevbbH19fesMGYsWLcKCBQtaq3sNysrKanIyH7/Burq2SOftFS9TbuJYK6DR8VaNqWu8lbVjrQCOt9KK5o4BVIPWxgA6Oztr8r3hng5CTTV37lzMmjVLmTabzQgKCmqTvlibzIF7L523Nq1fpmztWCvAuvFWjalrvFVTzghxvJU2NHcMoBo4BlAb7ukxQqWlpXB2dsa//vUvxMbGKvOnTJmC/Px8/Pvf/27w+S0xRojoXsQxQkTUnjTl/dumlfrUJhwcHDBw4EAkJycr8yorK5GcnIzIyMg27BnRvcXacMMQRETtzT3/0disWbMwZcoUDBo0CIMHD8bbb7+NoqIiPPnkk23dNaJ7CsdbEVFHdM8HofHjx+PHH3/EvHnzYDQaER4ejp07d9YaQE1Ezaf18VZE1PHc02OEmotjhIiIiDoejhEiIiIisgKDEBEREWkWgxARERFpFoMQERERaRaDEBEREWkWgxARERFpFoMQERERaRaDEBEREWkWgxARERFp1j1/i43mqPrSbbPZ3MY9ISIiImtVvW9bc/MMBqEGFBQUAACCgoLauCdERETUVAUFBXB3d2+whvcaa0BlZSWuXr0KNze3Bu+q3dbMZjOCgoJw6dIl3hOtGbgf1cN9qR7uS3VwP6qnI+xLEUFBQQECAgJgY9PwKCCeEWqAjY0NOnfu3NbdsJrBYGi3L8qOhPtRPdyX6uG+VAf3o3ra+75s7ExQFQ6WJiIiIs1iECIiIiLNYhC6B+j1erzyyivQ6/Vt3ZUOjftRPdyX6uG+VAf3o3rutX3JwdJERESkWTwjRERERJrFIERERESaxSBEREREmsUg1IF9//330Ol0yMjIaOuuqKZr1654++2327obivnz5yM8PLytu0H3gD179kCn0yE/Px8AsH79enh4eLRpn1oCj+HW1xbvBa2xztbaLgahDiwoKAjXrl1Dnz592rorqjl06BCmTZtmVa3av3B1Oh0+//xzi3l//vOfkZycrNo6SLseeughXLt2zeoveeuoeAy3rN///veIjY1Vrb2aAV2L+M3SHVRpaSkcHBzg5+fX1l0B8J/+NNd9992nQm/+o6KiAjqdrtGvWK+Pq6srXF1dVe1TWykrK4O9vX1bd+OuqfUaayvt6XitC49h0iyhdmH48OGSkJAgCQkJYjAYxNvbW1566SWprKwUEZHg4GB59dVXZfLkyeLm5iZTpkyRnJwcASBHjx5V2jlx4oTExMSIm5ubuLq6ypAhQ+TcuXPK8nXr1klYWJjo9XoJDQ2VVatWNau/M2bMEG9vbxkxYoRkZmbK6NGjxcXFRXx8fOR3v/ud/Pjjj8pzzGazTJo0SZydncXPz0/eeustGT58uMyYMUOpCQ4OluXLl4uISGVlpbzyyisSFBQkDg4O4u/vL9OnT1fWD8DiISLy/vvvi7u7u/z73/+Wnj17iq2treTk5MjBgwclKipKvL29xWAwyLBhwyQ9Pd1ivdXbCg4OFhGRV155Rfr376/UVVRUyIIFCyQwMFAcHBykf//+smPHDmV51c/k008/lREjRoiTk5P069dPDhw4ICIihYWF4ubmJps3b7bYn1u2bBFnZ2cxm80iInLx4kX57W9/K+7u7uLp6Sm/+tWvJCcnR6lvbHtERADI6tWrZcyYMeLs7CyvvPKKVT/T+l6DN2/elMmTJ4uHh4c4OTnJ6NGj5cyZM8rPqlOnThbb1b9/f/Hz81Om9+3bJw4ODlJUVCQiIrdu3ZL4+Hjp1KmTuLm5yciRIyUjI0Opr9r369atk65du4pOp2uw/61t+PDhkpiYKDNmzBAPDw/x8fGRtWvXSmFhofz+978XV1dX6datm2zfvl1ERHbv3i0A5NatWyLyn9dqdZ9//rk8+OCDotfrJSQkRObPny9lZWXK8mXLlkmfPn3E2dlZOnfuLM8++6wUFBRYtLF27Vrp3LmzODk5SWxsrCxbtqzO9bi6uoqNjY0YDAZxcnKS4cOH8xiWxo/h6n388ssv5YEHHhAnJyd5/PHHpaioSNavXy/BwcHi4eEh06dPl/LycuV5DR1D1dvduXOnhIWFiYuLi0RHR0tkZKQkJCTIz372s1r7bPfu3ZKRkSEAxMXFRWxsbMTGxkZCQ0OVPn///ffyy1/+Ujw8PMTZ2Vl69eol27ZtU7a1+mPKlCkiIrJjxw55+OGHxd3dXby8vCQmJsbivaSp7z+N7XcRkbS0NAkPDxe9Xi8DBw6Uzz77rNY6GnuN3g0GoXZi+PDh4urqKjNmzJCsrCz55z//Kc7OzrJ27VoRuXOQGwwGefPNN+XcuXNy7ty5Wi/Ey5cvi5eXl4wdO1YOHTok2dnZ8ve//12ysrJEROSf//yn+Pv7y6effioXLlyQTz/9VLy8vGT9+vV33d/Zs2dLVlaWfPfdd3LffffJ3Llz5fTp03LkyBF59NFHZeTIkcpznnrqKQkODpZvvvlGMjMz5de//rW4ubnV+0t08+bNYjAYZPv27fLDDz9IWlqasj9u3LghnTt3lldffVWuXbsm165dE5E7v0js7e3loYcekv3790tWVpYUFRVJcnKybNy4UU6fPi2nTp2S+Ph48fX1VYJHXl6eAJD3339frl27Jnl5eSJS+5foW2+9JQaDQT766CPJysqS559/Xuzt7ZVfZlU/k7CwMNm6datkZ2fLb37zGwkODlbe0KZOnSr//d//bbE/f/WrX8kTTzwhIiKlpaXSs2dP+cMf/iDHjx+XU6dOyaRJkyQ0NFRKSkpERBrdHpE7QcjHx0f+/ve/y/nz5+WHH36w6mda32vwV7/6lfTs2VNSUlIkIyNDoqOjpXv37lJaWioiImPHjpWEhAQRufML38HBQdzd3eX06dMiIrJw4UJ5+OGHlfVFRUXJmDFj5NChQ3LmzBn5n//5H/H29pYbN24o+97FxUVGjx4tR44ckWPHjjXY/9Y2fPhwcXNzk9dee03OnDkjr732mtja2sp//dd/ydq1a+XMmTPy7LPPire3txQVFTUahFJSUsRgMMj69evl/Pnz8vXXX0vXrl1l/vz5Ss3y5ctl165dkpOTI8nJyRIaGirPPvussvzbb78VGxsbWbp0qWRnZ8uqVavEy8urzvWEhoaKi4uL/Pa3v5XAwEB56qmneAyLdcdwVR8fffRROXLkiOzdu1e8vb1l1KhRMm7cODl58qR8+eWX4uDgIB9//LGy7saOoap2o6Ki5NChQ5Keni49e/YUHx8fcXV1lT/+8Y8yevRo6devnzg5OcnSpUulpKREoqKiBIB06dJFVq5cKUOGDBFXV1fp0qWLlJWVSUxMjDz66KNy/PhxOX/+vHz55Zeyd+9eKS8vl08//VQASHZ2tly7dk3y8/NFRORf//qXfPrpp3L27Fk5evSojBkzRvr27SsVFRUW+8na95/G9ntBQYHcd999MmnSJDlx4oR8+eWXcv/991us49atW42+Ru8Gg1A7MXz4cOnZs6fy17eIyJw5c6Rnz54icueXS2xsrMVzar4Q586dKyEhIcpBVVO3bt3kww8/tJj32muvSWRk5F3198EHH7RoZ9SoURY1ly5dUg4ws9ks9vb2FmcM8vPzxdnZud5fosuWLZMHHnig3u2pXlvl/fffFwAWZxbqUlFRIW5ubvLll18q8wDIli1bLOpq/hINCAiQ119/3aLmZz/7mfzxj38Ukf/8TP72t78py0+ePCkAlECQlpYmtra2cvXqVRERyc3NFTs7O9mzZ4+IiGzcuFFCQ0MtXgslJSXi5OQkX331VZO2Z+bMmQ3uh+oaeg2eOXNGAMj+/fuVZdevXxcnJyf55JNPRERk5cqV0rt3bxG5c8YhIiJCHnvsMXn33XdF5E7wefHFF0Xkztkhg8EgxcXFFn3o1q2bvPfeeyJyZ9/b29srb2jtzfDhw2XIkCHKdHl5ubi4uMjkyZOVedeuXRMAkpqa2mgQeuSRR+Qvf/mLxTo2btwo/v7+9fZh8+bN4u3trUyPHz9eYmJiLGri4uLqXE/1Y3jjxo3i6urKY1isO4ar+lj9DMnTTz8tzs7OFmfooqOj5emnnxYRseoYqqvdVatWib29vXJsTpkyRR577LFax2b1Pl+/fl0cHR2VPvft29ciUFdX83VZnx9//FEASGZmpsV+svb9p7H9/t5774m3t7f89NNPyvJ3333XYh2Nvc/cLQ6Wbkd+/vOfQ6fTKdORkZE4e/YsKioqAACDBg1q8PkZGRkYOnRoneNAioqKcP78ecTHxyufmbu6umLhwoU4f/78XfV34MCByv+PHTuG3bt3W7QdFhYGADh//jwuXLiAsrIyDB48WHmOu7s7QkND623/t7/9LX766Sfcf//9mDp1KrZs2YLy8vJG++Xg4IB+/fpZzMvNzcXUqVPRo0cPuLu7w2AwoLCwEBcvXrR6e81mM65evYqHH37YYv7DDz+M06dPW8yrvn5/f38AQF5eHgBg8ODB6N27NzZs2AAA+Oc//4ng4GAMGzYMwJ19ee7cObi5uSn70svLC8XFxcrPytrtaew1U1N9r8FTp07Bzs4OERERyjJvb2+EhoYq2z58+HCcOnUKP/74I/bu3YsRI0ZgxIgR2LNnD8rKynDgwAGMGDFC2cbCwkJ4e3tbvGZycnIsXo/BwcGqjzlRU/Wfs62tLby9vdG3b19lnq+vL4D//OwbcuzYMbz66qsW+2Pq1Km4du0abt++DQD45ptv8MgjjyAwMBBubm6YPHkybty4oSzPzs62OMYA1JquWs++ffuQmZmprKewsJDHcDUNHcMA4OzsjG7duinTvr6+6Nq1q8V4JF9fX+U5p0+fbvQYqqtdf39/lJWVNXpsVu+zt7c3evToofT5T3/6ExYuXIiHH34Yr7zyCo4fP97ovjp79iwmTpyI+++/HwaDAV27dgWAevd3Q+8/1uz306dPo1+/fnB0dLTYxuoae5+5Wxws3YG4uLg0uNzJyaneZYWFhQCAdevWWRyIwJ1f4M3tT2FhIcaMGYPFixfXqvP398e5c+ea3H5QUBCys7PxzTffICkpCX/84x+xdOlS7N27t8FBv05OTha/MABgypQpuHHjBlasWIHg4GDo9XpERkaitLS0yf2yRvX+VfWlsrJSmffUU09h1apVeOGFF/D+++/jySefVOoKCwsxcOBAfPDBB7XarQoF1m5PY68ZNfXt2xdeXl7Yu3cv9u7di9dffx1+fn5YvHgxDh06hLKyMjz00EMA7myjv78/9uzZU6ud6peUt2b/70bN16FOp2v0Z1+fwsJCLFiwAGPHjq21zNHREd9//z1++ctf4tlnn8Xrr78OLy8vfPvtt4iPj0dpaSmcnZ2t6nPVej799FP07NkTL730EgAgPj4e3t7eWLJkSa3n8Biu/XNs7GdfNc+an319662+7rt5LnCnz0899RSio6Oxbds2fP3111i0aBGWLVuG6dOn19vWmDFjEBwcjHXr1iEgIACVlZXo06dPvfu7ofcftTT2PnO3GITakbS0NIvp7777Dj169LA6qPTr1w8bNmyo8+ogX19fBAQE4MKFC4iLi1Otz1UGDBiATz/9FF27dlX+Oqnu/vvvh729PQ4dOoQuXboAAEwmE86cOaOcCamLk5MTxowZgzFjxiAhIQFhYWHIzMzEgAED4ODgoJwta8z+/fuxevVq/Pd//zcA4NKlS7h+/bpFjb29fYPtGQwGBAQEYP/+/Rg+fLhF2zX/6m7M7373Ozz//PNYuXIlTp06hSlTpijLBgwYgE2bNsHHxwcGg+Gut+du1Pca7NWrF8rLy5GWlqaEmRs3biA7Oxu9evUCcOcX9tChQ/Hvf/8bJ0+exJAhQ+Ds7IySkhK89957GDRokBJsBgwYAKPRCDs7O+UvTa0bMGAAsrOz0b179zqXp6eno7KyEsuWLVOuoPrkk08sakJDQ3Ho0CGLeTWnq9bj5OQEDw8PZX1DhgzhMdyCevbs2egx1JCqY7Nqn9U8Nqu7ceNGreAaFBSEZ555Bs888wzmzp2LdevWYfr06cqVgtX3W1W/1q1bh6FDhwIAvv322wb719D7jzX7vWfPnti4cSOKi4uVs0LfffedRTuNvc/cLX401o5cvHgRs2bNQnZ2Nj766CO88847mDFjhtXPT0xMhNlsxoQJE3D48GGcPXsWGzduRHZ2NgBgwYIFWLRoEVauXIkzZ84gMzMT77//Pt56661m9z0hIQE3b97ExIkTcejQIZw/fx5fffUVnnzySVRUVMDNzQ1TpkzB7NmzsXv3bpw8eRLx8fGwsbGp9y+e9evX4//9v/+HEydO4MKFC/jnP/8JJycnBAcHA7jzHSQpKSm4cuVKoyGgR48e2LhxI06fPo20tDTExcXV+guma9euSE5OhtFoxK1bt+psZ/bs2Vi8eDE2bdqE7OxsvPDCC8jIyGjSzwkAPD09MXbsWMyePRujRo1C586dlWVxcXHo1KkTHnvsMezbtw85OTnYs2cP/vSnP+Hy5ctWb8/dqO812KNHDzz22GOYOnUqvv32Wxw7dgy/+93vEBgYiMcee0x5/ogRI/DRRx8hPDwcrq6usLGxwbBhw/DBBx9Y/AKMiopCZGQkYmNj8fXXX+P777/HgQMH8L//+784fPhws7ejI5o3bx7+8Y9/YMGCBTh58iROnz6Njz/+WDlj0717d5SVleGdd97BhQsXsHHjRqxZs8aijenTp2P79u146623cPbsWbz33nvYsWOHxTFWtZ7vv/8eN27cUNZTWFjIY7gFWXsM1afq2HRxcUFqaipWrlyJ+Ph4dO3aFY8++igA4OjRo0q71c+QzJw5E1999RVycnJw5MgR7N69Gz179gRw5+NnnU6HrVu34scff0RhYSE8PT3h7e2NtWvX4ty5c9i1axdmzZrVYP8ae/9pbL9PmjQJOp0OU6dOxalTp7B9+3a8+eabFuto7H3mrt316CJS1fDhw+WPf/yjPPPMM2IwGMTT01NefPFFi8vnaw4qrOvyxWPHjsmoUaPE2dlZ3NzcZOjQoXL+/Hll+QcffCDh4eHi4OAgnp6eMmzYMPnss8/uqr/VB0iK3BkM+Otf/1q5NDQsLExmzpypbENdl94OHjxYXnjhBaWN6tu5ZcsWiYiIEIPBIC4uLvLzn/9cvvnmG6U2NTVV+vXrJ3q9vtaltzUdOXJEBg0aJI6OjtKjRw/ZvHlzrX36xRdfSPfu3cXOzq7BS2/nz58vgYGBYm9vX++lt9V/Jrdu3VIuc60uOTlZACgDJau7du2aPPHEE9KpUyfR6/Vy//33y9SpU8VkMlm9Pahj4GhDGnsNVl366+7uLk5OThIdHW1x6a+IyNGjRwWAzJkzR5m3fPlyASA7d+60qDWbzTJ9+nQJCAgQe3t7CQoKkri4OLl48aKI1N737U1dx0Bdx2nVz8Gay+d37twpDz30kDg5OYnBYJDBgwcrV1mJ3Lnyxt/fX9n///jHP2oNdF27dq0EBgYql88vXLjQ4msMqtZjMBjE1tbWYj08hq07huvqY12v16qBzVUaO4bqanfLli0CQDk23dzcxM7OTuzt7WtdPu/q6qq0e/jwYWV5YmKidOvWTfR6vdx3330yefJkuX79urKOV199Vfz8/ESn0ymXzyclJUnPnj1Fr9dLv379ZM+ePRa/U5r6/tPYfhe583ro37+/ODg4SHh4uHJFW/V1NPYavRs6EZG7j1GklhEjRiA8PLxdfTV9SysqKkJgYCCWLVuG+Pj4tu5Oq9u4cSOee+45XL16tV18UaAWX4NaMHXqVGRlZWHfvn2qt631Y7i18NhsWRwjRK3m6NGjyMrKwuDBg2EymfDqq68CgFWnhe8lt2/fxrVr1/DGG2/g6aefbhchiO4db775Jh599FG4uLhgx44d2LBhA1avXq1K2zyG6V7EMULUqt588030798fUVFRKCoqwr59+9CpU6e27larWrJkCcLCwuDn54e5c+e2dXfoHnPw4EE8+uij6Nu3L9asWYOVK1fiqaeeUq19HsN0r+FHY0RERKRZPCNEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESaxSBEREREmsUgRERERJrFIERERESa9f8BQdOgUGbLKW0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cars_df.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the current dataset, there are outliers present, but given the context surrounding it, they should remain. For instance, some used cars may have mileage that are higher than the norm due to the fact that some drivers drive more than others. It is those types of drivers and drivers that rarely drive their vehicle that will consider this app for their car valuation. With that being, these anamolies should be kept for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>registrationyear</th>\n",
       "      <th>power</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registrationmonth</th>\n",
       "      <th>postalcode</th>\n",
       "      <th>vehicletype_convertible</th>\n",
       "      <th>vehicletype_coupe</th>\n",
       "      <th>vehicletype_other</th>\n",
       "      <th>vehicletype_sedan</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_seat</th>\n",
       "      <th>brand_skoda</th>\n",
       "      <th>brand_smart</th>\n",
       "      <th>brand_subaru</th>\n",
       "      <th>brand_suzuki</th>\n",
       "      <th>brand_toyota</th>\n",
       "      <th>brand_trabant</th>\n",
       "      <th>brand_volkswagen</th>\n",
       "      <th>brand_volvo</th>\n",
       "      <th>notrepaired_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>2001</td>\n",
       "      <td>75</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>91074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3600</td>\n",
       "      <td>2008</td>\n",
       "      <td>69</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>60437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>650</td>\n",
       "      <td>1995</td>\n",
       "      <td>102</td>\n",
       "      <td>150000</td>\n",
       "      <td>10</td>\n",
       "      <td>33775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2200</td>\n",
       "      <td>2004</td>\n",
       "      <td>109</td>\n",
       "      <td>150000</td>\n",
       "      <td>8</td>\n",
       "      <td>67112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>50</td>\n",
       "      <td>40000</td>\n",
       "      <td>7</td>\n",
       "      <td>19348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354360</th>\n",
       "      <td>3999</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>81825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354362</th>\n",
       "      <td>3200</td>\n",
       "      <td>2004</td>\n",
       "      <td>225</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>96465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354363</th>\n",
       "      <td>1150</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>26624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354366</th>\n",
       "      <td>1199</td>\n",
       "      <td>2000</td>\n",
       "      <td>101</td>\n",
       "      <td>125000</td>\n",
       "      <td>3</td>\n",
       "      <td>26135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354367</th>\n",
       "      <td>9200</td>\n",
       "      <td>1996</td>\n",
       "      <td>102</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>87439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245567 rows √ó 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  registrationyear  power  mileage  registrationmonth  \\\n",
       "3        1500              2001     75   150000                  6   \n",
       "4        3600              2008     69    90000                  7   \n",
       "5         650              1995    102   150000                 10   \n",
       "6        2200              2004    109   150000                  8   \n",
       "7           0              1980     50    40000                  7   \n",
       "...       ...               ...    ...      ...                ...   \n",
       "354360   3999              2005      3   150000                  5   \n",
       "354362   3200              2004    225   150000                  5   \n",
       "354363   1150              2000      0   150000                  3   \n",
       "354366   1199              2000    101   125000                  3   \n",
       "354367   9200              1996    102   150000                  3   \n",
       "\n",
       "        postalcode  vehicletype_convertible  vehicletype_coupe  \\\n",
       "3            91074                        0                  0   \n",
       "4            60437                        0                  0   \n",
       "5            33775                        0                  0   \n",
       "6            67112                        1                  0   \n",
       "7            19348                        0                  0   \n",
       "...            ...                      ...                ...   \n",
       "354360       81825                        0                  0   \n",
       "354362       96465                        0                  0   \n",
       "354363       26624                        0                  0   \n",
       "354366       26135                        1                  0   \n",
       "354367       87439                        0                  0   \n",
       "\n",
       "        vehicletype_other  vehicletype_sedan  ...  brand_seat  brand_skoda  \\\n",
       "3                       0                  0  ...           0            0   \n",
       "4                       0                  0  ...           0            1   \n",
       "5                       0                  1  ...           0            0   \n",
       "6                       0                  0  ...           0            0   \n",
       "7                       0                  1  ...           0            0   \n",
       "...                   ...                ...  ...         ...          ...   \n",
       "354360                  0                  0  ...           0            0   \n",
       "354362                  0                  1  ...           1            0   \n",
       "354363                  0                  0  ...           0            0   \n",
       "354366                  0                  0  ...           0            0   \n",
       "354367                  0                  0  ...           0            0   \n",
       "\n",
       "        brand_smart  brand_subaru  brand_suzuki  brand_toyota  brand_trabant  \\\n",
       "3                 0             0             0             0              0   \n",
       "4                 0             0             0             0              0   \n",
       "5                 0             0             0             0              0   \n",
       "6                 0             0             0             0              0   \n",
       "7                 0             0             0             0              0   \n",
       "...             ...           ...           ...           ...            ...   \n",
       "354360            0             0             0             0              0   \n",
       "354362            0             0             0             0              0   \n",
       "354363            0             0             0             0              0   \n",
       "354366            1             0             0             0              0   \n",
       "354367            0             0             0             0              0   \n",
       "\n",
       "        brand_volkswagen  brand_volvo  notrepaired_yes  \n",
       "3                      1            0                0  \n",
       "4                      0            0                0  \n",
       "5                      0            0                1  \n",
       "6                      0            0                0  \n",
       "7                      1            0                0  \n",
       "...                  ...          ...              ...  \n",
       "354360                 0            0                0  \n",
       "354362                 0            0                1  \n",
       "354363                 0            0                0  \n",
       "354366                 0            0                0  \n",
       "354367                 1            0                0  \n",
       "\n",
       "[245567 rows x 307 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df_ohe = pd.get_dummies(cars_df, columns=['vehicletype', 'gearbox', 'model', 'fueltype', 'brand', 'notrepaired'], drop_first=True)\n",
    "cars_df_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features & Target/Split Set/Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cars_df[['vehicletype', 'registrationyear', 'registrationmonth', 'gearbox', 'power', 'model', 'fueltype', 'brand', 'notrepaired', 'postalcode','mileage']]\n",
    "y = cars_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ohe = cars_df_ohe['price']\n",
    "x_ohe = cars_df_ohe.drop(columns =['price'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pred_eval(model, x, y, cv_splits=5, **kwargs):\n",
    "    # Initialize the model with optional hyperparameters\n",
    "    model_instance = model(**kwargs)\n",
    "    \n",
    "    # Define K-Fold Cross-Validator\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Cross-Validation\n",
    "    cv_mse_scores = cross_val_score(model_instance, x, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    cv_rmse_scores = np.sqrt(-cv_mse_scores)\n",
    "    print(\"Cross-Validation RMSE Scores:\", cv_rmse_scores)\n",
    "    print(\"Mean Cross-Validation RMSE:\", cv_rmse_scores.mean())\n",
    "    print(\"Standard Deviation of Cross-Validation RMSE:\", cv_rmse_scores.std())\n",
    "\n",
    "    # split data into training and validation sets\n",
    "    train_x, x_rem, train_y, y_rem = train_test_split(x, y, test_size=0.40, random_state=42)\n",
    "    valid_x, test_x, valid_y, test_y = train_test_split(x_rem, y_rem, test_size=0.50, random_state=42)\n",
    "\n",
    "    \n",
    "    # Train the model on the entire training set and measure the training time\n",
    "    start_time = time.time()\n",
    "    model_instance.fit(train_x, train_y)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training time: {training_time} seconds\")\n",
    "    \n",
    "    # Validate the model and measure the prediction time\n",
    "    start_time = time.time()\n",
    "    pred_y_val = model_instance.predict(valid_x)\n",
    "    validation_time = time.time() - start_time\n",
    "    print(f\"Validation prediction time: {validation_time} seconds\")\n",
    "    \n",
    "    # Calculate RMSE for validation\n",
    "    rmse_val = mean_squared_error(valid_y, pred_y_val, squared=False)\n",
    "    print(f\"Validation RMSE: {rmse_val}\")\n",
    "    \n",
    "    # Test the model and measure the prediction time\n",
    "    start_time = time.time()\n",
    "    pred_y_test = model_instance.predict(test_x)\n",
    "    test_prediction_time = time.time() - start_time\n",
    "    print(f\"Test prediction time: {test_prediction_time} seconds\")\n",
    "    \n",
    "    # Calculate RMSE for test\n",
    "    rmse_test = mean_squared_error(test_y, pred_y_test, squared=False)\n",
    "    print(f\"Test RMSE: {rmse_test}\")\n",
    "\n",
    "    return {\n",
    "        'training_time': training_time,\n",
    "        'validation_time': validation_time,\n",
    "        'validation_rmse': rmse_val,\n",
    "        'test_prediction_time': test_prediction_time,\n",
    "        'test_rmse': rmse_test,\n",
    "        'cv_rmse_scores': cv_rmse_scores,\n",
    "        'mean_cv_rmse': cv_rmse_scores.mean(),\n",
    "        'std_cv_rmse': cv_rmse_scores.std()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pred_eval_lgbm(model, x, y, cv_splits=5, categorical_features=None, **kwargs):\n",
    "    # initialize the model\n",
    "    model_instance = model(**kwargs)\n",
    "\n",
    "    # define K-Fold cross-validator\n",
    "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # cross-validation with LightGBM\n",
    "    def lgb_cv(model_instance, x, y, cv_splits, categorical_features):\n",
    "        cv_rmse_scores = []\n",
    "        for train_index, val_index in kf.split(x):\n",
    "            x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            train_data = lgb.Dataset(x_train, label=y_train, categorical_feature=categorical_features)\n",
    "            val_data = lgb.Dataset(x_val, label=y_val, reference=train_data, categorical_feature=categorical_features)\n",
    "\n",
    "            model_instance.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=10, verbose=False, categorical_feature=categorical_features)\n",
    "            y_pred_val = model_instance.predict(x_val, num_iteration=model_instance.best_iteration_)\n",
    "\n",
    "            rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "            cv_rmse_scores.append(rmse_val)\n",
    "        \n",
    "        return np.array(cv_rmse_scores)\n",
    "\n",
    "    cv_rmse_scores = lgb_cv(model_instance, x, y, cv_splits, categorical_features)\n",
    "    print(\"Cross-Validation RMSE Scores:\", cv_rmse_scores)\n",
    "    print(\"Mean Cross-Validation RMSE:\", cv_rmse_scores.mean())\n",
    "    print(\"Standard Deviation of Cross-Validation RMSE:\", cv_rmse_scores.std())\n",
    "\n",
    "    # split data into training and validation sets\n",
    "    train_x, x_rem, train_y, y_rem = train_test_split(x, y, test_size=0.40, random_state=42)\n",
    "    valid_x, test_x, valid_y, test_y = train_test_split(x_rem, y_rem, test_size=0.50, random_state=42)\n",
    "\n",
    "    # train the model & record the training time\n",
    "    start_time = time.time()\n",
    "    model_instance.fit(train_x, train_y, eval_set=[(valid_x, valid_y)], early_stopping_rounds=10, verbose=False, categorical_feature=categorical_features)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training time: {training_time} seconds\")\n",
    "\n",
    "    # validate the model & record the prediction time\n",
    "    start_time = time.time()\n",
    "    pred_y_val = model_instance.predict(valid_x, num_iteration=model_instance.best_iteration_)\n",
    "    validation_time = time.time() - start_time\n",
    "    print(f\"Validation prediction time: {validation_time} seconds\")\n",
    "\n",
    "    # calculate RMSE for validation\n",
    "    rmse_val = np.sqrt(mean_squared_error(valid_y, pred_y_val))\n",
    "    print(f\"Validation RMSE: {rmse_val}\")\n",
    "\n",
    "    # test the model & record the prediction time\n",
    "    start_time = time.time()\n",
    "    pred_y_test = model_instance.predict(test_x, num_iteration=model_instance.best_iteration_)\n",
    "    test_prediction_time = time.time() - start_time\n",
    "    print(f\"Test prediction time: {test_prediction_time} seconds\")\n",
    "\n",
    "    # calculate RMSE for test\n",
    "    rmse_test = np.sqrt(mean_squared_error(test_y, pred_y_test))\n",
    "    print(f\"Test RMSE: {rmse_test}\")\n",
    "\n",
    "    return {\n",
    "        'training_time': training_time,\n",
    "        'validation_time': validation_time,\n",
    "        'validation_rmse': rmse_val,\n",
    "        'test_prediction_time': test_prediction_time,\n",
    "        'test_rmse': rmse_test,\n",
    "        'cv_rmse_scores': cv_rmse_scores,\n",
    "        'mean_cv_rmse': cv_rmse_scores.mean(),\n",
    "        'std_cv_rmse': cv_rmse_scores.std()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Model (used as a sanity check/reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [2720.34965325 2713.89301841 2722.9869927  2709.64935225 2746.13702762]\n",
      "Mean Cross-Validation RMSE: 2722.603208844007\n",
      "Standard Deviation of Cross-Validation RMSE: 12.670724108413575\n",
      "Training time: 5.084500312805176 seconds\n",
      "Validation prediction time: 0.11524057388305664 seconds\n",
      "Validation RMSE: 2712.5318692747637\n",
      "Test prediction time: 0.18185997009277344 seconds\n",
      "Test RMSE: 2716.1342597155726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 5.084500312805176,\n",
       " 'validation_time': 0.11524057388305664,\n",
       " 'validation_rmse': 2712.5318692747637,\n",
       " 'test_prediction_time': 0.18185997009277344,\n",
       " 'test_rmse': 2716.1342597155726,\n",
       " 'cv_rmse_scores': array([2720.34965325, 2713.89301841, 2722.9869927 , 2709.64935225,\n",
       "        2746.13702762]),\n",
       " 'mean_cv_rmse': 2722.603208844007,\n",
       " 'std_cv_rmse': 12.670724108413575}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_eval(LinearRegression, x_ohe, y_ohe, cv_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1592.60517498 1576.62286613 1623.35754347 1581.94323305 1620.2904273 ]\n",
      "Mean Cross-Validation RMSE: 1598.9638489869315\n",
      "Standard Deviation of Cross-Validation RMSE: 19.386226502362558\n",
      "Training time: 171.4957115650177 seconds\n",
      "Validation prediction time: 1.7912344932556152 seconds\n",
      "Validation RMSE: 1619.8383722236697\n",
      "Test prediction time: 1.7741107940673828 seconds\n",
      "Test RMSE: 1635.4340026719017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 171.4957115650177,\n",
       " 'validation_time': 1.7912344932556152,\n",
       " 'validation_rmse': 1619.8383722236697,\n",
       " 'test_prediction_time': 1.7741107940673828,\n",
       " 'test_rmse': 1635.4340026719017,\n",
       " 'cv_rmse_scores': array([1592.60517498, 1576.62286613, 1623.35754347, 1581.94323305,\n",
       "        1620.2904273 ]),\n",
       " 'mean_cv_rmse': 1598.9638489869315,\n",
       " 'std_cv_rmse': 19.386226502362558}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_eval(RandomForestRegressor, x_ohe, y_ohe, cv_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation sets\n",
    "x_train_ohe, x_rem, y_train_ohe, y_rem = train_test_split(x_ohe, y_ohe, test_size=0.40, random_state=42)\n",
    "x_valid_ohe, x_test_ohe, y_valid_ohe, y_test_ohe = train_test_split(x_rem, y_rem, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation sets\n",
    "x_train, x_rem, y_train, y_rem = train_test_split(X, y, test_size=0.40, random_state=42)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_rem, y_rem, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted DataFrame to NumPy array in an attempt to decrease overall model tuning time\n",
    "x_train_array_ohe = x_train_ohe.to_numpy()\n",
    "y_train_array_ohe = y_train_ohe.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=64; total time= 1.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=64; total time= 1.6min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=64; total time= 1.6min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=70; total time= 1.7min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=70; total time= 1.5min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=70; total time= 1.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=136; total time= 2.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=136; total time= 2.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=4, n_estimators=136; total time= 2.0min\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=149; total time= 2.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=149; total time= 2.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=3, min_samples_split=5, n_estimators=149; total time= 2.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=51; total time=  45.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=51; total time=  45.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=51; total time=  46.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=113; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=113; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=113; total time= 1.3min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=107; total time= 1.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=107; total time= 1.8min\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=107; total time= 1.8min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=138; total time= 1.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=138; total time= 1.5min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=138; total time= 1.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=4, n_estimators=91; total time= 1.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=4, n_estimators=91; total time= 1.4min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=4, n_estimators=91; total time= 1.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=96; total time= 1.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=96; total time= 1.4min\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=3, n_estimators=96; total time= 1.4min\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=104; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=104; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=104; total time= 1.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time= 1.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time= 1.6min\n",
      "[CV] END max_depth=None, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time= 1.6min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=88; total time= 1.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=88; total time= 1.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=88; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=109; total time= 1.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=109; total time= 1.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=109; total time= 1.1min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=58; total time=  34.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=58; total time=  34.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=58; total time=  34.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=133; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=133; total time= 1.3min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=3, n_estimators=133; total time= 1.3min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=93; total time= 1.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=93; total time= 1.2min\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=4, n_estimators=93; total time= 1.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=84; total time= 1.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=84; total time= 1.2min\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=4, n_estimators=84; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=99; total time=  58.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=99; total time=  59.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=99; total time=  59.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=103; total time= 1.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=103; total time= 1.0min\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=3, n_estimators=103; total time= 1.0min\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 107}\n",
      "Best Score: -1696.7771\n"
     ]
    }
   ],
   "source": [
    "# define the RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(random_state=42, warm_start=True)\n",
    "\n",
    "# define the parameter distribution using scipy's randint for random sampling\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 150),\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': randint(2, 6),\n",
    "    'min_samples_leaf': randint(1, 5)\n",
    "}\n",
    "\n",
    "# setup RandomizedSearchCV\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Reduced number of iterations\n",
    "    cv=3,  # Reduced number of cross-validation folds\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "rf_random_search.fit(x_train_array_ohe, y_train_array_ohe)\n",
    "\n",
    "# print the best parameters and score\n",
    "print(f\"Best Parameters: {rf_random_search.best_params_}\")\n",
    "print(f\"Best Score: {rf_random_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1591.88843403 1572.90363437 1620.43882457 1582.36203769 1616.71529678]\n",
      "Mean Cross-Validation RMSE: 1596.8616454897162\n",
      "Standard Deviation of Cross-Validation RMSE: 18.75637810608607\n",
      "Training time: 175.51081347465515 seconds\n",
      "Validation prediction time: 1.6134088039398193 seconds\n",
      "Validation RMSE: 1616.4487461999909\n",
      "Test prediction time: 1.6199262142181396 seconds\n",
      "Test RMSE: 1633.4989706293793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 175.51081347465515,\n",
       " 'validation_time': 1.6134088039398193,\n",
       " 'validation_rmse': 1616.4487461999909,\n",
       " 'test_prediction_time': 1.6199262142181396,\n",
       " 'test_rmse': 1633.4989706293793,\n",
       " 'cv_rmse_scores': array([1591.88843403, 1572.90363437, 1620.43882457, 1582.36203769,\n",
       "        1616.71529678]),\n",
       " 'mean_cv_rmse': 1596.8616454897162,\n",
       " 'std_cv_rmse': 18.75637810608607}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_eval(RandomForestRegressor, x_ohe, y_ohe, cv_splits=5, min_samples_leaf=1, min_samples_split=5, n_estimators=107, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78/777906463.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature] = X[feature].astype('category')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1655.65147332 1643.67780903 1673.84234528 1646.88369695 1677.90652697]\n",
      "Mean Cross-Validation RMSE: 1659.5923703100586\n",
      "Standard Deviation of Cross-Validation RMSE: 13.919658250404405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 2.298672676086426 seconds\n",
      "Validation prediction time: 0.38285374641418457 seconds\n",
      "Validation RMSE: 1645.464939464531\n",
      "Test prediction time: 0.3056056499481201 seconds\n",
      "Test RMSE: 1671.1684821667957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 2.298672676086426,\n",
       " 'validation_time': 0.38285374641418457,\n",
       " 'validation_rmse': 1645.464939464531,\n",
       " 'test_prediction_time': 0.3056056499481201,\n",
       " 'test_rmse': 1671.1684821667957,\n",
       " 'cv_rmse_scores': array([1655.65147332, 1643.67780903, 1673.84234528, 1646.88369695,\n",
       "        1677.90652697]),\n",
       " 'mean_cv_rmse': 1659.5923703100586,\n",
       " 'std_cv_rmse': 13.919658250404405}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['vehicletype', 'gearbox', 'model', 'fueltype', 'brand', 'notrepaired']\n",
    "for feature in categorical_features:\n",
    "    X[feature] = X[feature].astype('category')\n",
    "\n",
    "train_pred_eval_lgbm(lgb.LGBMRegressor, X, y, cv_splits=5, categorical_features=categorical_features, objective= 'regression',\n",
    "    metric= 'rmse',\n",
    "    boosting_type= 'gbdt', random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78/3696249856.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[feature] = X[feature].astype('category')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8123620356542087, learning_rate=0.20014286128198325, max_depth=10, n_estimators=121, num_leaves=48, reg_alpha=0.596850157946487, reg_lambda=0.44583275285359114, subsample=0.7299924747454009; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8123620356542087, learning_rate=0.20014286128198325, max_depth=10, n_estimators=121, num_leaves=48, reg_alpha=0.596850157946487, reg_lambda=0.44583275285359114, subsample=0.7299924747454009; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8123620356542087, learning_rate=0.20014286128198325, max_depth=10, n_estimators=121, num_leaves=48, reg_alpha=0.596850157946487, reg_lambda=0.44583275285359114, subsample=0.7299924747454009; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8123620356542087, learning_rate=0.20014286128198325, max_depth=10, n_estimators=121, num_leaves=48, reg_alpha=0.596850157946487, reg_lambda=0.44583275285359114, subsample=0.7299924747454009; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8123620356542087, learning_rate=0.20014286128198325, max_depth=10, n_estimators=121, num_leaves=48, reg_alpha=0.596850157946487, reg_lambda=0.44583275285359114, subsample=0.7299924747454009; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8377746675897602, learning_rate=0.07674172222780437, max_depth=20, n_estimators=201, num_leaves=22, reg_alpha=0.020584494295802447, reg_lambda=0.9699098521619943, subsample=0.9497327922401264; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8377746675897602, learning_rate=0.07674172222780437, max_depth=20, n_estimators=201, num_leaves=22, reg_alpha=0.020584494295802447, reg_lambda=0.9699098521619943, subsample=0.9497327922401264; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8377746675897602, learning_rate=0.07674172222780437, max_depth=20, n_estimators=201, num_leaves=22, reg_alpha=0.020584494295802447, reg_lambda=0.9699098521619943, subsample=0.9497327922401264; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8377746675897602, learning_rate=0.07674172222780437, max_depth=20, n_estimators=201, num_leaves=22, reg_alpha=0.020584494295802447, reg_lambda=0.9699098521619943, subsample=0.9497327922401264; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8377746675897602, learning_rate=0.07674172222780437, max_depth=20, n_estimators=201, num_leaves=22, reg_alpha=0.020584494295802447, reg_lambda=0.9699098521619943, subsample=0.9497327922401264; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7637017332034828, learning_rate=0.04636499344142013, max_depth=-1, n_estimators=210, num_leaves=31, reg_alpha=0.6116531604882809, reg_lambda=0.007066305219717406, subsample=0.7069187275124247; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7637017332034828, learning_rate=0.04636499344142013, max_depth=-1, n_estimators=210, num_leaves=31, reg_alpha=0.6116531604882809, reg_lambda=0.007066305219717406, subsample=0.7069187275124247; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7637017332034828, learning_rate=0.04636499344142013, max_depth=-1, n_estimators=210, num_leaves=31, reg_alpha=0.6116531604882809, reg_lambda=0.007066305219717406, subsample=0.7069187275124247; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7637017332034828, learning_rate=0.04636499344142013, max_depth=-1, n_estimators=210, num_leaves=31, reg_alpha=0.6116531604882809, reg_lambda=0.007066305219717406, subsample=0.7069187275124247; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7637017332034828, learning_rate=0.04636499344142013, max_depth=-1, n_estimators=210, num_leaves=31, reg_alpha=0.6116531604882809, reg_lambda=0.007066305219717406, subsample=0.7069187275124247; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8574323980775167, learning_rate=0.08997219434305109, max_depth=20, n_estimators=269, num_leaves=47, reg_alpha=0.3663618432936917, reg_lambda=0.45606998421703593, subsample=0.935552788417904; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8574323980775167, learning_rate=0.08997219434305109, max_depth=20, n_estimators=269, num_leaves=47, reg_alpha=0.3663618432936917, reg_lambda=0.45606998421703593, subsample=0.935552788417904; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8574323980775167, learning_rate=0.08997219434305109, max_depth=20, n_estimators=269, num_leaves=47, reg_alpha=0.3663618432936917, reg_lambda=0.45606998421703593, subsample=0.935552788417904; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8574323980775167, learning_rate=0.08997219434305109, max_depth=20, n_estimators=269, num_leaves=47, reg_alpha=0.3663618432936917, reg_lambda=0.45606998421703593, subsample=0.935552788417904; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8574323980775167, learning_rate=0.08997219434305109, max_depth=20, n_estimators=269, num_leaves=47, reg_alpha=0.3663618432936917, reg_lambda=0.45606998421703593, subsample=0.935552788417904; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7599021346475079, learning_rate=0.11284688768272232, max_depth=20, n_estimators=298, num_leaves=22, reg_alpha=0.8599404067363206, reg_lambda=0.6803075385877797, subsample=0.8351497755908628; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7599021346475079, learning_rate=0.11284688768272232, max_depth=20, n_estimators=298, num_leaves=22, reg_alpha=0.8599404067363206, reg_lambda=0.6803075385877797, subsample=0.8351497755908628; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7599021346475079, learning_rate=0.11284688768272232, max_depth=20, n_estimators=298, num_leaves=22, reg_alpha=0.8599404067363206, reg_lambda=0.6803075385877797, subsample=0.8351497755908628; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7599021346475079, learning_rate=0.11284688768272232, max_depth=20, n_estimators=298, num_leaves=22, reg_alpha=0.8599404067363206, reg_lambda=0.6803075385877797, subsample=0.8351497755908628; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7599021346475079, learning_rate=0.11284688768272232, max_depth=20, n_estimators=298, num_leaves=22, reg_alpha=0.8599404067363206, reg_lambda=0.6803075385877797, subsample=0.8351497755908628; total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7039794883479599, learning_rate=0.19844035113697056, max_depth=5, n_estimators=291, num_leaves=45, reg_alpha=0.3046137691733707, reg_lambda=0.09767211400638387, subsample=0.905269907953647; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7039794883479599, learning_rate=0.19844035113697056, max_depth=5, n_estimators=291, num_leaves=45, reg_alpha=0.3046137691733707, reg_lambda=0.09767211400638387, subsample=0.905269907953647; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7039794883479599, learning_rate=0.19844035113697056, max_depth=5, n_estimators=291, num_leaves=45, reg_alpha=0.3046137691733707, reg_lambda=0.09767211400638387, subsample=0.905269907953647; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7039794883479599, learning_rate=0.19844035113697056, max_depth=5, n_estimators=291, num_leaves=45, reg_alpha=0.3046137691733707, reg_lambda=0.09767211400638387, subsample=0.905269907953647; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7039794883479599, learning_rate=0.19844035113697056, max_depth=5, n_estimators=291, num_leaves=45, reg_alpha=0.3046137691733707, reg_lambda=0.09767211400638387, subsample=0.905269907953647; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8320457481218804, learning_rate=0.03440764696895577, max_depth=-1, n_estimators=57, num_leaves=34, reg_alpha=0.17336465350777208, reg_lambda=0.3910606075732408, subsample=0.7546708263364187; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8320457481218804, learning_rate=0.03440764696895577, max_depth=-1, n_estimators=57, num_leaves=34, reg_alpha=0.17336465350777208, reg_lambda=0.3910606075732408, subsample=0.7546708263364187; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8320457481218804, learning_rate=0.03440764696895577, max_depth=-1, n_estimators=57, num_leaves=34, reg_alpha=0.17336465350777208, reg_lambda=0.3910606075732408, subsample=0.7546708263364187; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8320457481218804, learning_rate=0.03440764696895577, max_depth=-1, n_estimators=57, num_leaves=34, reg_alpha=0.17336465350777208, reg_lambda=0.3910606075732408, subsample=0.7546708263364187; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8320457481218804, learning_rate=0.03440764696895577, max_depth=-1, n_estimators=57, num_leaves=34, reg_alpha=0.17336465350777208, reg_lambda=0.3910606075732408, subsample=0.7546708263364187; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9266084230952957, learning_rate=0.09503117489824894, max_depth=5, n_estimators=155, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=0.9695846277645586, subsample=0.9325398470083344; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9266084230952957, learning_rate=0.09503117489824894, max_depth=5, n_estimators=155, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=0.9695846277645586, subsample=0.9325398470083344; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9266084230952957, learning_rate=0.09503117489824894, max_depth=5, n_estimators=155, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=0.9695846277645586, subsample=0.9325398470083344; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9266084230952957, learning_rate=0.09503117489824894, max_depth=5, n_estimators=155, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=0.9695846277645586, subsample=0.9325398470083344; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9266084230952957, learning_rate=0.09503117489824894, max_depth=5, n_estimators=155, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=0.9695846277645586, subsample=0.9325398470083344; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9818496824692566, learning_rate=0.18896547008552977, max_depth=5, n_estimators=144, num_leaves=35, reg_alpha=0.3265407688058354, reg_lambda=0.5704439744053994, subsample=0.856250278007747; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9818496824692566, learning_rate=0.18896547008552977, max_depth=5, n_estimators=144, num_leaves=35, reg_alpha=0.3265407688058354, reg_lambda=0.5704439744053994, subsample=0.856250278007747; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9818496824692566, learning_rate=0.18896547008552977, max_depth=5, n_estimators=144, num_leaves=35, reg_alpha=0.3265407688058354, reg_lambda=0.5704439744053994, subsample=0.856250278007747; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9818496824692566, learning_rate=0.18896547008552977, max_depth=5, n_estimators=144, num_leaves=35, reg_alpha=0.3265407688058354, reg_lambda=0.5704439744053994, subsample=0.856250278007747; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9818496824692566, learning_rate=0.18896547008552977, max_depth=5, n_estimators=144, num_leaves=35, reg_alpha=0.3265407688058354, reg_lambda=0.5704439744053994, subsample=0.856250278007747; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9883516073048046, learning_rate=0.1789067697356303, max_depth=-1, n_estimators=131, num_leaves=34, reg_alpha=0.8287375091519293, reg_lambda=0.3567533266935893, subsample=0.7842803529062142; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9883516073048046, learning_rate=0.1789067697356303, max_depth=-1, n_estimators=131, num_leaves=34, reg_alpha=0.8287375091519293, reg_lambda=0.3567533266935893, subsample=0.7842803529062142; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9883516073048046, learning_rate=0.1789067697356303, max_depth=-1, n_estimators=131, num_leaves=34, reg_alpha=0.8287375091519293, reg_lambda=0.3567533266935893, subsample=0.7842803529062142; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9883516073048046, learning_rate=0.1789067697356303, max_depth=-1, n_estimators=131, num_leaves=34, reg_alpha=0.8287375091519293, reg_lambda=0.3567533266935893, subsample=0.7842803529062142; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9883516073048046, learning_rate=0.1789067697356303, max_depth=-1, n_estimators=131, num_leaves=34, reg_alpha=0.8287375091519293, reg_lambda=0.3567533266935893, subsample=0.7842803529062142; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8628088249474745, learning_rate=0.03818484499495253, max_depth=10, n_estimators=94, num_leaves=20, reg_alpha=0.01563640674119393, reg_lambda=0.4234014807063696, subsample=0.8184644554526709; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8628088249474745, learning_rate=0.03818484499495253, max_depth=10, n_estimators=94, num_leaves=20, reg_alpha=0.01563640674119393, reg_lambda=0.4234014807063696, subsample=0.8184644554526709; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8628088249474745, learning_rate=0.03818484499495253, max_depth=10, n_estimators=94, num_leaves=20, reg_alpha=0.01563640674119393, reg_lambda=0.4234014807063696, subsample=0.8184644554526709; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8628088249474745, learning_rate=0.03818484499495253, max_depth=10, n_estimators=94, num_leaves=20, reg_alpha=0.01563640674119393, reg_lambda=0.4234014807063696, subsample=0.8184644554526709; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8628088249474745, learning_rate=0.03818484499495253, max_depth=10, n_estimators=94, num_leaves=20, reg_alpha=0.01563640674119393, reg_lambda=0.4234014807063696, subsample=0.8184644554526709; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7880464524154114, learning_rate=0.012815964543016891, max_depth=10, n_estimators=130, num_leaves=27, reg_alpha=0.7290071680409873, reg_lambda=0.7712703466859457, subsample=0.722213395520227; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7880464524154114, learning_rate=0.012815964543016891, max_depth=10, n_estimators=130, num_leaves=27, reg_alpha=0.7290071680409873, reg_lambda=0.7712703466859457, subsample=0.722213395520227; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7880464524154114, learning_rate=0.012815964543016891, max_depth=10, n_estimators=130, num_leaves=27, reg_alpha=0.7290071680409873, reg_lambda=0.7712703466859457, subsample=0.722213395520227; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7880464524154114, learning_rate=0.012815964543016891, max_depth=10, n_estimators=130, num_leaves=27, reg_alpha=0.7290071680409873, reg_lambda=0.7712703466859457, subsample=0.722213395520227; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7880464524154114, learning_rate=0.012815964543016891, max_depth=10, n_estimators=130, num_leaves=27, reg_alpha=0.7290071680409873, reg_lambda=0.7712703466859457, subsample=0.722213395520227; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8075397185632818, learning_rate=0.03317381190502595, max_depth=10, n_estimators=250, num_leaves=27, reg_alpha=0.4494506741382034, reg_lambda=0.09541011649041131, subsample=0.8112454756594799; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8075397185632818, learning_rate=0.03317381190502595, max_depth=10, n_estimators=250, num_leaves=27, reg_alpha=0.4494506741382034, reg_lambda=0.09541011649041131, subsample=0.8112454756594799; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8075397185632818, learning_rate=0.03317381190502595, max_depth=10, n_estimators=250, num_leaves=27, reg_alpha=0.4494506741382034, reg_lambda=0.09541011649041131, subsample=0.8112454756594799; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8075397185632818, learning_rate=0.03317381190502595, max_depth=10, n_estimators=250, num_leaves=27, reg_alpha=0.4494506741382034, reg_lambda=0.09541011649041131, subsample=0.8112454756594799; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8075397185632818, learning_rate=0.03317381190502595, max_depth=10, n_estimators=250, num_leaves=27, reg_alpha=0.4494506741382034, reg_lambda=0.09541011649041131, subsample=0.8112454756594799; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9006523757990821, learning_rate=0.14318447132349935, max_depth=20, n_estimators=153, num_leaves=41, reg_alpha=0.8872127425763265, reg_lambda=0.4722149251619493, subsample=0.7358782737814905; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9006523757990821, learning_rate=0.14318447132349935, max_depth=20, n_estimators=153, num_leaves=41, reg_alpha=0.8872127425763265, reg_lambda=0.4722149251619493, subsample=0.7358782737814905; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9006523757990821, learning_rate=0.14318447132349935, max_depth=20, n_estimators=153, num_leaves=41, reg_alpha=0.8872127425763265, reg_lambda=0.4722149251619493, subsample=0.7358782737814905; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9006523757990821, learning_rate=0.14318447132349935, max_depth=20, n_estimators=153, num_leaves=41, reg_alpha=0.8872127425763265, reg_lambda=0.4722149251619493, subsample=0.7358782737814905; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9006523757990821, learning_rate=0.14318447132349935, max_depth=20, n_estimators=153, num_leaves=41, reg_alpha=0.8872127425763265, reg_lambda=0.4722149251619493, subsample=0.7358782737814905; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9139734361668984, learning_rate=0.1621570097233795, max_depth=5, n_estimators=296, num_leaves=33, reg_alpha=0.49379559636439074, reg_lambda=0.5227328293819941, subsample=0.8282623055075649; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9139734361668984, learning_rate=0.1621570097233795, max_depth=5, n_estimators=296, num_leaves=33, reg_alpha=0.49379559636439074, reg_lambda=0.5227328293819941, subsample=0.8282623055075649; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9139734361668984, learning_rate=0.1621570097233795, max_depth=5, n_estimators=296, num_leaves=33, reg_alpha=0.49379559636439074, reg_lambda=0.5227328293819941, subsample=0.8282623055075649; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9139734361668984, learning_rate=0.1621570097233795, max_depth=5, n_estimators=296, num_leaves=33, reg_alpha=0.49379559636439074, reg_lambda=0.5227328293819941, subsample=0.8282623055075649; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9139734361668984, learning_rate=0.1621570097233795, max_depth=5, n_estimators=296, num_leaves=33, reg_alpha=0.49379559636439074, reg_lambda=0.5227328293819941, subsample=0.8282623055075649; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7076257380232285, learning_rate=0.031578285398660894, max_depth=10, n_estimators=145, num_leaves=26, reg_alpha=0.47537022318211175, reg_lambda=0.5632755719763837, subsample=0.9086548259278382; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7076257380232285, learning_rate=0.031578285398660894, max_depth=10, n_estimators=145, num_leaves=26, reg_alpha=0.47537022318211175, reg_lambda=0.5632755719763837, subsample=0.9086548259278382; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7076257380232285, learning_rate=0.031578285398660894, max_depth=10, n_estimators=145, num_leaves=26, reg_alpha=0.47537022318211175, reg_lambda=0.5632755719763837, subsample=0.9086548259278382; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7076257380232285, learning_rate=0.031578285398660894, max_depth=10, n_estimators=145, num_leaves=26, reg_alpha=0.47537022318211175, reg_lambda=0.5632755719763837, subsample=0.9086548259278382; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7076257380232285, learning_rate=0.031578285398660894, max_depth=10, n_estimators=145, num_leaves=26, reg_alpha=0.47537022318211175, reg_lambda=0.5632755719763837, subsample=0.9086548259278382; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7417994363217627, learning_rate=0.13088347585556345, max_depth=10, n_estimators=220, num_leaves=48, reg_alpha=0.22879816549162246, reg_lambda=0.07697990982879299, subsample=0.7869254358741303; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7417994363217627, learning_rate=0.13088347585556345, max_depth=10, n_estimators=220, num_leaves=48, reg_alpha=0.22879816549162246, reg_lambda=0.07697990982879299, subsample=0.7869254358741303; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7417994363217627, learning_rate=0.13088347585556345, max_depth=10, n_estimators=220, num_leaves=48, reg_alpha=0.22879816549162246, reg_lambda=0.07697990982879299, subsample=0.7869254358741303; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7417994363217627, learning_rate=0.13088347585556345, max_depth=10, n_estimators=220, num_leaves=48, reg_alpha=0.22879816549162246, reg_lambda=0.07697990982879299, subsample=0.7869254358741303; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7417994363217627, learning_rate=0.13088347585556345, max_depth=10, n_estimators=220, num_leaves=48, reg_alpha=0.22879816549162246, reg_lambda=0.07697990982879299, subsample=0.7869254358741303; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7483663861762013, learning_rate=0.19593953046851464, max_depth=-1, n_estimators=111, num_leaves=44, reg_alpha=0.10549425983027061, reg_lambda=0.45653457048291024, subsample=0.76553213116505; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7483663861762013, learning_rate=0.19593953046851464, max_depth=-1, n_estimators=111, num_leaves=44, reg_alpha=0.10549425983027061, reg_lambda=0.45653457048291024, subsample=0.76553213116505; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7483663861762013, learning_rate=0.19593953046851464, max_depth=-1, n_estimators=111, num_leaves=44, reg_alpha=0.10549425983027061, reg_lambda=0.45653457048291024, subsample=0.76553213116505; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7483663861762013, learning_rate=0.19593953046851464, max_depth=-1, n_estimators=111, num_leaves=44, reg_alpha=0.10549425983027061, reg_lambda=0.45653457048291024, subsample=0.76553213116505; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7483663861762013, learning_rate=0.19593953046851464, max_depth=-1, n_estimators=111, num_leaves=44, reg_alpha=0.10549425983027061, reg_lambda=0.45653457048291024, subsample=0.76553213116505; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8249529843611099, learning_rate=0.18665605178377367, max_depth=20, n_estimators=299, num_leaves=42, reg_alpha=0.8960912999234932, reg_lambda=0.3180034749718639, subsample=0.733015577358303; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8249529843611099, learning_rate=0.18665605178377367, max_depth=20, n_estimators=299, num_leaves=42, reg_alpha=0.8960912999234932, reg_lambda=0.3180034749718639, subsample=0.733015577358303; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8249529843611099, learning_rate=0.18665605178377367, max_depth=20, n_estimators=299, num_leaves=42, reg_alpha=0.8960912999234932, reg_lambda=0.3180034749718639, subsample=0.733015577358303; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8249529843611099, learning_rate=0.18665605178377367, max_depth=20, n_estimators=299, num_leaves=42, reg_alpha=0.8960912999234932, reg_lambda=0.3180034749718639, subsample=0.733015577358303; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8249529843611099, learning_rate=0.18665605178377367, max_depth=20, n_estimators=299, num_leaves=42, reg_alpha=0.8960912999234932, reg_lambda=0.3180034749718639, subsample=0.733015577358303; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7683805487625824, learning_rate=0.09542155772525127, max_depth=20, n_estimators=254, num_leaves=28, reg_alpha=0.30478125815802903, reg_lambda=0.16465585314294173, subsample=0.8602268258126325; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7683805487625824, learning_rate=0.09542155772525127, max_depth=20, n_estimators=254, num_leaves=28, reg_alpha=0.30478125815802903, reg_lambda=0.16465585314294173, subsample=0.8602268258126325; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7683805487625824, learning_rate=0.09542155772525127, max_depth=20, n_estimators=254, num_leaves=28, reg_alpha=0.30478125815802903, reg_lambda=0.16465585314294173, subsample=0.8602268258126325; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7683805487625824, learning_rate=0.09542155772525127, max_depth=20, n_estimators=254, num_leaves=28, reg_alpha=0.30478125815802903, reg_lambda=0.16465585314294173, subsample=0.8602268258126325; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7683805487625824, learning_rate=0.09542155772525127, max_depth=20, n_estimators=254, num_leaves=28, reg_alpha=0.30478125815802903, reg_lambda=0.16465585314294173, subsample=0.8602268258126325; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8454489914076949, learning_rate=0.1484872065780541, max_depth=5, n_estimators=221, num_leaves=43, reg_alpha=0.9429097039125192, reg_lambda=0.32320293202075523, subsample=0.8556371865230098; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8454489914076949, learning_rate=0.1484872065780541, max_depth=5, n_estimators=221, num_leaves=43, reg_alpha=0.9429097039125192, reg_lambda=0.32320293202075523, subsample=0.8556371865230098; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8454489914076949, learning_rate=0.1484872065780541, max_depth=5, n_estimators=221, num_leaves=43, reg_alpha=0.9429097039125192, reg_lambda=0.32320293202075523, subsample=0.8556371865230098; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8454489914076949, learning_rate=0.1484872065780541, max_depth=5, n_estimators=221, num_leaves=43, reg_alpha=0.9429097039125192, reg_lambda=0.32320293202075523, subsample=0.8556371865230098; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8454489914076949, learning_rate=0.1484872065780541, max_depth=5, n_estimators=221, num_leaves=43, reg_alpha=0.9429097039125192, reg_lambda=0.32320293202075523, subsample=0.8556371865230098; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9109056876685533, learning_rate=0.08272592047585879, max_depth=-1, n_estimators=235, num_leaves=39, reg_alpha=0.2468760628386012, reg_lambda=0.6963042728397884, subsample=0.9136811769773325; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9109056876685533, learning_rate=0.08272592047585879, max_depth=-1, n_estimators=235, num_leaves=39, reg_alpha=0.2468760628386012, reg_lambda=0.6963042728397884, subsample=0.9136811769773325; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9109056876685533, learning_rate=0.08272592047585879, max_depth=-1, n_estimators=235, num_leaves=39, reg_alpha=0.2468760628386012, reg_lambda=0.6963042728397884, subsample=0.9136811769773325; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9109056876685533, learning_rate=0.08272592047585879, max_depth=-1, n_estimators=235, num_leaves=39, reg_alpha=0.2468760628386012, reg_lambda=0.6963042728397884, subsample=0.9136811769773325; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9109056876685533, learning_rate=0.08272592047585879, max_depth=-1, n_estimators=235, num_leaves=39, reg_alpha=0.2468760628386012, reg_lambda=0.6963042728397884, subsample=0.9136811769773325; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.74442607898602, learning_rate=0.20954809700978838, max_depth=10, n_estimators=162, num_leaves=21, reg_alpha=0.5026790232288615, reg_lambda=0.05147875124998935, subsample=0.7835939392709834; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.74442607898602, learning_rate=0.20954809700978838, max_depth=10, n_estimators=162, num_leaves=21, reg_alpha=0.5026790232288615, reg_lambda=0.05147875124998935, subsample=0.7835939392709834; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.74442607898602, learning_rate=0.20954809700978838, max_depth=10, n_estimators=162, num_leaves=21, reg_alpha=0.5026790232288615, reg_lambda=0.05147875124998935, subsample=0.7835939392709834; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.74442607898602, learning_rate=0.20954809700978838, max_depth=10, n_estimators=162, num_leaves=21, reg_alpha=0.5026790232288615, reg_lambda=0.05147875124998935, subsample=0.7835939392709834; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.74442607898602, learning_rate=0.20954809700978838, max_depth=10, n_estimators=162, num_leaves=21, reg_alpha=0.5026790232288615, reg_lambda=0.05147875124998935, subsample=0.7835939392709834; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9724797657899961, learning_rate=0.05791237813339449, max_depth=5, n_estimators=102, num_leaves=31, reg_alpha=0.44778316457309164, reg_lambda=0.552893089071328, subsample=0.877809017163818; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9724797657899961, learning_rate=0.05791237813339449, max_depth=5, n_estimators=102, num_leaves=31, reg_alpha=0.44778316457309164, reg_lambda=0.552893089071328, subsample=0.877809017163818; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9724797657899961, learning_rate=0.05791237813339449, max_depth=5, n_estimators=102, num_leaves=31, reg_alpha=0.44778316457309164, reg_lambda=0.552893089071328, subsample=0.877809017163818; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9724797657899961, learning_rate=0.05791237813339449, max_depth=5, n_estimators=102, num_leaves=31, reg_alpha=0.44778316457309164, reg_lambda=0.552893089071328, subsample=0.877809017163818; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9724797657899961, learning_rate=0.05791237813339449, max_depth=5, n_estimators=102, num_leaves=31, reg_alpha=0.44778316457309164, reg_lambda=0.552893089071328, subsample=0.877809017163818; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7242559978998145, learning_rate=0.0839308912122809, max_depth=-1, n_estimators=87, num_leaves=43, reg_alpha=0.4703006344460384, reg_lambda=0.983423140894843, subsample=0.8196473327333659; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7242559978998145, learning_rate=0.0839308912122809, max_depth=-1, n_estimators=87, num_leaves=43, reg_alpha=0.4703006344460384, reg_lambda=0.983423140894843, subsample=0.8196473327333659; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7242559978998145, learning_rate=0.0839308912122809, max_depth=-1, n_estimators=87, num_leaves=43, reg_alpha=0.4703006344460384, reg_lambda=0.983423140894843, subsample=0.8196473327333659; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7242559978998145, learning_rate=0.0839308912122809, max_depth=-1, n_estimators=87, num_leaves=43, reg_alpha=0.4703006344460384, reg_lambda=0.983423140894843, subsample=0.8196473327333659; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7242559978998145, learning_rate=0.0839308912122809, max_depth=-1, n_estimators=87, num_leaves=43, reg_alpha=0.4703006344460384, reg_lambda=0.983423140894843, subsample=0.8196473327333659; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9449295619658151, learning_rate=0.16966902499691025, max_depth=-1, n_estimators=173, num_leaves=46, reg_alpha=0.18651851039985423, reg_lambda=0.040775141554763916, subsample=0.8772678829564725; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9449295619658151, learning_rate=0.16966902499691025, max_depth=-1, n_estimators=173, num_leaves=46, reg_alpha=0.18651851039985423, reg_lambda=0.040775141554763916, subsample=0.8772678829564725; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9449295619658151, learning_rate=0.16966902499691025, max_depth=-1, n_estimators=173, num_leaves=46, reg_alpha=0.18651851039985423, reg_lambda=0.040775141554763916, subsample=0.8772678829564725; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9449295619658151, learning_rate=0.16966902499691025, max_depth=-1, n_estimators=173, num_leaves=46, reg_alpha=0.18651851039985423, reg_lambda=0.040775141554763916, subsample=0.8772678829564725; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9449295619658151, learning_rate=0.16966902499691025, max_depth=-1, n_estimators=173, num_leaves=46, reg_alpha=0.18651851039985423, reg_lambda=0.040775141554763916, subsample=0.8772678829564725; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9032693085526846, learning_rate=0.013317565785571231, max_depth=10, n_estimators=196, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.17436642900499144, subsample=0.9072813214307397; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9032693085526846, learning_rate=0.013317565785571231, max_depth=10, n_estimators=196, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.17436642900499144, subsample=0.9072813214307397; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9032693085526846, learning_rate=0.013317565785571231, max_depth=10, n_estimators=196, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.17436642900499144, subsample=0.9072813214307397; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9032693085526846, learning_rate=0.013317565785571231, max_depth=10, n_estimators=196, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.17436642900499144, subsample=0.9072813214307397; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9032693085526846, learning_rate=0.013317565785571231, max_depth=10, n_estimators=196, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.17436642900499144, subsample=0.9072813214307397; total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8160206038901612, learning_rate=0.19734599774734693, max_depth=-1, n_estimators=60, num_leaves=47, reg_alpha=0.7352161192407721, reg_lambda=0.20907162073771368, subsample=0.8624343921482697; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8160206038901612, learning_rate=0.19734599774734693, max_depth=-1, n_estimators=60, num_leaves=47, reg_alpha=0.7352161192407721, reg_lambda=0.20907162073771368, subsample=0.8624343921482697; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8160206038901612, learning_rate=0.19734599774734693, max_depth=-1, n_estimators=60, num_leaves=47, reg_alpha=0.7352161192407721, reg_lambda=0.20907162073771368, subsample=0.8624343921482697; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8160206038901612, learning_rate=0.19734599774734693, max_depth=-1, n_estimators=60, num_leaves=47, reg_alpha=0.7352161192407721, reg_lambda=0.20907162073771368, subsample=0.8624343921482697; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8160206038901612, learning_rate=0.19734599774734693, max_depth=-1, n_estimators=60, num_leaves=47, reg_alpha=0.7352161192407721, reg_lambda=0.20907162073771368, subsample=0.8624343921482697; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9087353198035246, learning_rate=0.055710004359459935, max_depth=20, n_estimators=139, num_leaves=35, reg_alpha=0.5552008115994623, reg_lambda=0.5296505783560065, subsample=0.7725556872701355; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9087353198035246, learning_rate=0.055710004359459935, max_depth=20, n_estimators=139, num_leaves=35, reg_alpha=0.5552008115994623, reg_lambda=0.5296505783560065, subsample=0.7725556872701355; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9087353198035246, learning_rate=0.055710004359459935, max_depth=20, n_estimators=139, num_leaves=35, reg_alpha=0.5552008115994623, reg_lambda=0.5296505783560065, subsample=0.7725556872701355; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9087353198035246, learning_rate=0.055710004359459935, max_depth=20, n_estimators=139, num_leaves=35, reg_alpha=0.5552008115994623, reg_lambda=0.5296505783560065, subsample=0.7725556872701355; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9087353198035246, learning_rate=0.055710004359459935, max_depth=20, n_estimators=139, num_leaves=35, reg_alpha=0.5552008115994623, reg_lambda=0.5296505783560065, subsample=0.7725556872701355; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7279308303417698, learning_rate=0.18944315159066538, max_depth=-1, n_estimators=209, num_leaves=46, reg_alpha=0.18870710834137938, reg_lambda=0.2788713525921819, subsample=0.9101073489918313; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7279308303417698, learning_rate=0.18944315159066538, max_depth=-1, n_estimators=209, num_leaves=46, reg_alpha=0.18870710834137938, reg_lambda=0.2788713525921819, subsample=0.9101073489918313; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7279308303417698, learning_rate=0.18944315159066538, max_depth=-1, n_estimators=209, num_leaves=46, reg_alpha=0.18870710834137938, reg_lambda=0.2788713525921819, subsample=0.9101073489918313; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7279308303417698, learning_rate=0.18944315159066538, max_depth=-1, n_estimators=209, num_leaves=46, reg_alpha=0.18870710834137938, reg_lambda=0.2788713525921819, subsample=0.9101073489918313; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7279308303417698, learning_rate=0.18944315159066538, max_depth=-1, n_estimators=209, num_leaves=46, reg_alpha=0.18870710834137938, reg_lambda=0.2788713525921819, subsample=0.9101073489918313; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9539983426714918, learning_rate=0.1812648583756185, max_depth=5, n_estimators=169, num_leaves=20, reg_alpha=0.6420316461542878, reg_lambda=0.08413996499504883, subsample=0.7484886142283841; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9539983426714918, learning_rate=0.1812648583756185, max_depth=5, n_estimators=169, num_leaves=20, reg_alpha=0.6420316461542878, reg_lambda=0.08413996499504883, subsample=0.7484886142283841; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9539983426714918, learning_rate=0.1812648583756185, max_depth=5, n_estimators=169, num_leaves=20, reg_alpha=0.6420316461542878, reg_lambda=0.08413996499504883, subsample=0.7484886142283841; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9539983426714918, learning_rate=0.1812648583756185, max_depth=5, n_estimators=169, num_leaves=20, reg_alpha=0.6420316461542878, reg_lambda=0.08413996499504883, subsample=0.7484886142283841; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9539983426714918, learning_rate=0.1812648583756185, max_depth=5, n_estimators=169, num_leaves=20, reg_alpha=0.6420316461542878, reg_lambda=0.08413996499504883, subsample=0.7484886142283841; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9695662565581238, learning_rate=0.131285811931918, max_depth=10, n_estimators=161, num_leaves=49, reg_alpha=0.9401334424577784, reg_lambda=0.9736638367553173, subsample=0.7851762924212397; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9695662565581238, learning_rate=0.131285811931918, max_depth=10, n_estimators=161, num_leaves=49, reg_alpha=0.9401334424577784, reg_lambda=0.9736638367553173, subsample=0.7851762924212397; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9695662565581238, learning_rate=0.131285811931918, max_depth=10, n_estimators=161, num_leaves=49, reg_alpha=0.9401334424577784, reg_lambda=0.9736638367553173, subsample=0.7851762924212397; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9695662565581238, learning_rate=0.131285811931918, max_depth=10, n_estimators=161, num_leaves=49, reg_alpha=0.9401334424577784, reg_lambda=0.9736638367553173, subsample=0.7851762924212397; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9695662565581238, learning_rate=0.131285811931918, max_depth=10, n_estimators=161, num_leaves=49, reg_alpha=0.9401334424577784, reg_lambda=0.9736638367553173, subsample=0.7851762924212397; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.791609158103318, learning_rate=0.10712275071724532, max_depth=10, n_estimators=257, num_leaves=48, reg_alpha=0.22426930946055978, reg_lambda=0.7121792213475359, subsample=0.7711747262490399; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.791609158103318, learning_rate=0.10712275071724532, max_depth=10, n_estimators=257, num_leaves=48, reg_alpha=0.22426930946055978, reg_lambda=0.7121792213475359, subsample=0.7711747262490399; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.791609158103318, learning_rate=0.10712275071724532, max_depth=10, n_estimators=257, num_leaves=48, reg_alpha=0.22426930946055978, reg_lambda=0.7121792213475359, subsample=0.7711747262490399; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.791609158103318, learning_rate=0.10712275071724532, max_depth=10, n_estimators=257, num_leaves=48, reg_alpha=0.22426930946055978, reg_lambda=0.7121792213475359, subsample=0.7711747262490399; total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.791609158103318, learning_rate=0.10712275071724532, max_depth=10, n_estimators=257, num_leaves=48, reg_alpha=0.22426930946055978, reg_lambda=0.7121792213475359, subsample=0.7711747262490399; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7976199094477803, learning_rate=0.15929828102360485, max_depth=20, n_estimators=185, num_leaves=26, reg_alpha=0.7209399242521293, reg_lambda=0.3080607918523892, subsample=0.8627620691664697; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7976199094477803, learning_rate=0.15929828102360485, max_depth=20, n_estimators=185, num_leaves=26, reg_alpha=0.7209399242521293, reg_lambda=0.3080607918523892, subsample=0.8627620691664697; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7976199094477803, learning_rate=0.15929828102360485, max_depth=20, n_estimators=185, num_leaves=26, reg_alpha=0.7209399242521293, reg_lambda=0.3080607918523892, subsample=0.8627620691664697; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7976199094477803, learning_rate=0.15929828102360485, max_depth=20, n_estimators=185, num_leaves=26, reg_alpha=0.7209399242521293, reg_lambda=0.3080607918523892, subsample=0.8627620691664697; total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7976199094477803, learning_rate=0.15929828102360485, max_depth=20, n_estimators=185, num_leaves=26, reg_alpha=0.7209399242521293, reg_lambda=0.3080607918523892, subsample=0.8627620691664697; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.852644223051628, learning_rate=0.1372665236371791, max_depth=5, n_estimators=287, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.3930977246667604, subsample=0.9676139665531339; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.852644223051628, learning_rate=0.1372665236371791, max_depth=5, n_estimators=287, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.3930977246667604, subsample=0.9676139665531339; total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.852644223051628, learning_rate=0.1372665236371791, max_depth=5, n_estimators=287, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.3930977246667604, subsample=0.9676139665531339; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.852644223051628, learning_rate=0.1372665236371791, max_depth=5, n_estimators=287, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.3930977246667604, subsample=0.9676139665531339; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.852644223051628, learning_rate=0.1372665236371791, max_depth=5, n_estimators=287, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.3930977246667604, subsample=0.9676139665531339; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8893415877991788, learning_rate=0.1689622607083297, max_depth=5, n_estimators=146, num_leaves=47, reg_alpha=0.6689240596630996, reg_lambda=0.8641675650719031, subsample=0.7690555804724666; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8893415877991788, learning_rate=0.1689622607083297, max_depth=5, n_estimators=146, num_leaves=47, reg_alpha=0.6689240596630996, reg_lambda=0.8641675650719031, subsample=0.7690555804724666; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8893415877991788, learning_rate=0.1689622607083297, max_depth=5, n_estimators=146, num_leaves=47, reg_alpha=0.6689240596630996, reg_lambda=0.8641675650719031, subsample=0.7690555804724666; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8893415877991788, learning_rate=0.1689622607083297, max_depth=5, n_estimators=146, num_leaves=47, reg_alpha=0.6689240596630996, reg_lambda=0.8641675650719031, subsample=0.7690555804724666; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8893415877991788, learning_rate=0.1689622607083297, max_depth=5, n_estimators=146, num_leaves=47, reg_alpha=0.6689240596630996, reg_lambda=0.8641675650719031, subsample=0.7690555804724666; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8497580139654256, learning_rate=0.12440083984183663, max_depth=20, n_estimators=98, num_leaves=36, reg_alpha=0.994550510797341, reg_lambda=0.46994451399094295, subsample=0.7838681025390275; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8497580139654256, learning_rate=0.12440083984183663, max_depth=20, n_estimators=98, num_leaves=36, reg_alpha=0.994550510797341, reg_lambda=0.46994451399094295, subsample=0.7838681025390275; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8497580139654256, learning_rate=0.12440083984183663, max_depth=20, n_estimators=98, num_leaves=36, reg_alpha=0.994550510797341, reg_lambda=0.46994451399094295, subsample=0.7838681025390275; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8497580139654256, learning_rate=0.12440083984183663, max_depth=20, n_estimators=98, num_leaves=36, reg_alpha=0.994550510797341, reg_lambda=0.46994451399094295, subsample=0.7838681025390275; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8497580139654256, learning_rate=0.12440083984183663, max_depth=20, n_estimators=98, num_leaves=36, reg_alpha=0.994550510797341, reg_lambda=0.46994451399094295, subsample=0.7838681025390275; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9650482066798776, learning_rate=0.1595437547794828, max_depth=-1, n_estimators=73, num_leaves=48, reg_alpha=0.42818414831731433, reg_lambda=0.9666548190436696, subsample=0.9890859931267758; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9650482066798776, learning_rate=0.1595437547794828, max_depth=-1, n_estimators=73, num_leaves=48, reg_alpha=0.42818414831731433, reg_lambda=0.9666548190436696, subsample=0.9890859931267758; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9650482066798776, learning_rate=0.1595437547794828, max_depth=-1, n_estimators=73, num_leaves=48, reg_alpha=0.42818414831731433, reg_lambda=0.9666548190436696, subsample=0.9890859931267758; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9650482066798776, learning_rate=0.1595437547794828, max_depth=-1, n_estimators=73, num_leaves=48, reg_alpha=0.42818414831731433, reg_lambda=0.9666548190436696, subsample=0.9890859931267758; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9650482066798776, learning_rate=0.1595437547794828, max_depth=-1, n_estimators=73, num_leaves=48, reg_alpha=0.42818414831731433, reg_lambda=0.9666548190436696, subsample=0.9890859931267758; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.955902836640208, learning_rate=0.06888977841391714, max_depth=-1, n_estimators=209, num_leaves=42, reg_alpha=0.2684748568901568, reg_lambda=0.4852798742763157, subsample=0.8118060601282148; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.955902836640208, learning_rate=0.06888977841391714, max_depth=-1, n_estimators=209, num_leaves=42, reg_alpha=0.2684748568901568, reg_lambda=0.4852798742763157, subsample=0.8118060601282148; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.955902836640208, learning_rate=0.06888977841391714, max_depth=-1, n_estimators=209, num_leaves=42, reg_alpha=0.2684748568901568, reg_lambda=0.4852798742763157, subsample=0.8118060601282148; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.955902836640208, learning_rate=0.06888977841391714, max_depth=-1, n_estimators=209, num_leaves=42, reg_alpha=0.2684748568901568, reg_lambda=0.4852798742763157, subsample=0.8118060601282148; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.955902836640208, learning_rate=0.06888977841391714, max_depth=-1, n_estimators=209, num_leaves=42, reg_alpha=0.2684748568901568, reg_lambda=0.4852798742763157, subsample=0.8118060601282148; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8184074400428416, learning_rate=0.1788426281452623, max_depth=10, n_estimators=153, num_leaves=33, reg_alpha=0.09717649377076854, reg_lambda=0.6150072266991697, subsample=0.9970161550312789; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8184074400428416, learning_rate=0.1788426281452623, max_depth=10, n_estimators=153, num_leaves=33, reg_alpha=0.09717649377076854, reg_lambda=0.6150072266991697, subsample=0.9970161550312789; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8184074400428416, learning_rate=0.1788426281452623, max_depth=10, n_estimators=153, num_leaves=33, reg_alpha=0.09717649377076854, reg_lambda=0.6150072266991697, subsample=0.9970161550312789; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8184074400428416, learning_rate=0.1788426281452623, max_depth=10, n_estimators=153, num_leaves=33, reg_alpha=0.09717649377076854, reg_lambda=0.6150072266991697, subsample=0.9970161550312789; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8184074400428416, learning_rate=0.1788426281452623, max_depth=10, n_estimators=153, num_leaves=33, reg_alpha=0.09717649377076854, reg_lambda=0.6150072266991697, subsample=0.9970161550312789; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7420252045709572, learning_rate=0.11366593047274735, max_depth=5, n_estimators=267, num_leaves=36, reg_alpha=0.8486697949246744, reg_lambda=0.13662133144202881, subsample=0.9126732990730355; total time=   5.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7420252045709572, learning_rate=0.11366593047274735, max_depth=5, n_estimators=267, num_leaves=36, reg_alpha=0.8486697949246744, reg_lambda=0.13662133144202881, subsample=0.9126732990730355; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7420252045709572, learning_rate=0.11366593047274735, max_depth=5, n_estimators=267, num_leaves=36, reg_alpha=0.8486697949246744, reg_lambda=0.13662133144202881, subsample=0.9126732990730355; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7420252045709572, learning_rate=0.11366593047274735, max_depth=5, n_estimators=267, num_leaves=36, reg_alpha=0.8486697949246744, reg_lambda=0.13662133144202881, subsample=0.9126732990730355; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7420252045709572, learning_rate=0.11366593047274735, max_depth=5, n_estimators=267, num_leaves=36, reg_alpha=0.8486697949246744, reg_lambda=0.13662133144202881, subsample=0.9126732990730355; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8658459930723723, learning_rate=0.06930202872955969, max_depth=5, n_estimators=148, num_leaves=37, reg_alpha=0.8670723185801037, reg_lambda=0.9132405525564713, subsample=0.8534027196582813; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8658459930723723, learning_rate=0.06930202872955969, max_depth=5, n_estimators=148, num_leaves=37, reg_alpha=0.8670723185801037, reg_lambda=0.9132405525564713, subsample=0.8534027196582813; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8658459930723723, learning_rate=0.06930202872955969, max_depth=5, n_estimators=148, num_leaves=37, reg_alpha=0.8670723185801037, reg_lambda=0.9132405525564713, subsample=0.8534027196582813; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8658459930723723, learning_rate=0.06930202872955969, max_depth=5, n_estimators=148, num_leaves=37, reg_alpha=0.8670723185801037, reg_lambda=0.9132405525564713, subsample=0.8534027196582813; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8658459930723723, learning_rate=0.06930202872955969, max_depth=5, n_estimators=148, num_leaves=37, reg_alpha=0.8670723185801037, reg_lambda=0.9132405525564713, subsample=0.8534027196582813; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8504548884061598, learning_rate=0.16965903579335506, max_depth=-1, n_estimators=57, num_leaves=33, reg_alpha=0.795792669436101, reg_lambda=0.8900053418175663, subsample=0.8013985470554607; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8504548884061598, learning_rate=0.16965903579335506, max_depth=-1, n_estimators=57, num_leaves=33, reg_alpha=0.795792669436101, reg_lambda=0.8900053418175663, subsample=0.8013985470554607; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8504548884061598, learning_rate=0.16965903579335506, max_depth=-1, n_estimators=57, num_leaves=33, reg_alpha=0.795792669436101, reg_lambda=0.8900053418175663, subsample=0.8013985470554607; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8504548884061598, learning_rate=0.16965903579335506, max_depth=-1, n_estimators=57, num_leaves=33, reg_alpha=0.795792669436101, reg_lambda=0.8900053418175663, subsample=0.8013985470554607; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8504548884061598, learning_rate=0.16965903579335506, max_depth=-1, n_estimators=57, num_leaves=33, reg_alpha=0.795792669436101, reg_lambda=0.8900053418175663, subsample=0.8013985470554607; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8126748857919832, learning_rate=0.028796387968173805, max_depth=10, n_estimators=240, num_leaves=41, reg_alpha=0.32815266747473193, reg_lambda=0.1550416167277442, subsample=0.9945522664931592; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8126748857919832, learning_rate=0.028796387968173805, max_depth=10, n_estimators=240, num_leaves=41, reg_alpha=0.32815266747473193, reg_lambda=0.1550416167277442, subsample=0.9945522664931592; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8126748857919832, learning_rate=0.028796387968173805, max_depth=10, n_estimators=240, num_leaves=41, reg_alpha=0.32815266747473193, reg_lambda=0.1550416167277442, subsample=0.9945522664931592; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8126748857919832, learning_rate=0.028796387968173805, max_depth=10, n_estimators=240, num_leaves=41, reg_alpha=0.32815266747473193, reg_lambda=0.1550416167277442, subsample=0.9945522664931592; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8126748857919832, learning_rate=0.028796387968173805, max_depth=10, n_estimators=240, num_leaves=41, reg_alpha=0.32815266747473193, reg_lambda=0.1550416167277442, subsample=0.9945522664931592; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.951680050620809, learning_rate=0.18208092366233508, max_depth=-1, n_estimators=229, num_leaves=29, reg_alpha=0.8226005606596583, reg_lambda=0.3601906414112629, subsample=0.7381181537955654; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.951680050620809, learning_rate=0.18208092366233508, max_depth=-1, n_estimators=229, num_leaves=29, reg_alpha=0.8226005606596583, reg_lambda=0.3601906414112629, subsample=0.7381181537955654; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.951680050620809, learning_rate=0.18208092366233508, max_depth=-1, n_estimators=229, num_leaves=29, reg_alpha=0.8226005606596583, reg_lambda=0.3601906414112629, subsample=0.7381181537955654; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.951680050620809, learning_rate=0.18208092366233508, max_depth=-1, n_estimators=229, num_leaves=29, reg_alpha=0.8226005606596583, reg_lambda=0.3601906414112629, subsample=0.7381181537955654; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.951680050620809, learning_rate=0.18208092366233508, max_depth=-1, n_estimators=229, num_leaves=29, reg_alpha=0.8226005606596583, reg_lambda=0.3601906414112629, subsample=0.7381181537955654; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8566729780164413, learning_rate=0.16399871061972218, max_depth=20, n_estimators=157, num_leaves=24, reg_alpha=0.45726516161372854, reg_lambda=0.8420230750119814, subsample=0.7583140101984619; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8566729780164413, learning_rate=0.16399871061972218, max_depth=20, n_estimators=157, num_leaves=24, reg_alpha=0.45726516161372854, reg_lambda=0.8420230750119814, subsample=0.7583140101984619; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8566729780164413, learning_rate=0.16399871061972218, max_depth=20, n_estimators=157, num_leaves=24, reg_alpha=0.45726516161372854, reg_lambda=0.8420230750119814, subsample=0.7583140101984619; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8566729780164413, learning_rate=0.16399871061972218, max_depth=20, n_estimators=157, num_leaves=24, reg_alpha=0.45726516161372854, reg_lambda=0.8420230750119814, subsample=0.7583140101984619; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8566729780164413, learning_rate=0.16399871061972218, max_depth=20, n_estimators=157, num_leaves=24, reg_alpha=0.45726516161372854, reg_lambda=0.8420230750119814, subsample=0.7583140101984619; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8234061715170036, learning_rate=0.1499024421534388, max_depth=20, n_estimators=101, num_leaves=35, reg_alpha=0.9758520794625346, reg_lambda=0.5163003483011953, subsample=0.7968869418823737; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8234061715170036, learning_rate=0.1499024421534388, max_depth=20, n_estimators=101, num_leaves=35, reg_alpha=0.9758520794625346, reg_lambda=0.5163003483011953, subsample=0.7968869418823737; total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8234061715170036, learning_rate=0.1499024421534388, max_depth=20, n_estimators=101, num_leaves=35, reg_alpha=0.9758520794625346, reg_lambda=0.5163003483011953, subsample=0.7968869418823737; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8234061715170036, learning_rate=0.1499024421534388, max_depth=20, n_estimators=101, num_leaves=35, reg_alpha=0.9758520794625346, reg_lambda=0.5163003483011953, subsample=0.7968869418823737; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8234061715170036, learning_rate=0.1499024421534388, max_depth=20, n_estimators=101, num_leaves=35, reg_alpha=0.9758520794625346, reg_lambda=0.5163003483011953, subsample=0.7968869418823737; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9385558584306111, learning_rate=0.06416645025241484, max_depth=20, n_estimators=107, num_leaves=42, reg_alpha=0.2508605273466612, reg_lambda=0.18433367433137005, subsample=0.7242618899851593; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9385558584306111, learning_rate=0.06416645025241484, max_depth=20, n_estimators=107, num_leaves=42, reg_alpha=0.2508605273466612, reg_lambda=0.18433367433137005, subsample=0.7242618899851593; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9385558584306111, learning_rate=0.06416645025241484, max_depth=20, n_estimators=107, num_leaves=42, reg_alpha=0.2508605273466612, reg_lambda=0.18433367433137005, subsample=0.7242618899851593; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9385558584306111, learning_rate=0.06416645025241484, max_depth=20, n_estimators=107, num_leaves=42, reg_alpha=0.2508605273466612, reg_lambda=0.18433367433137005, subsample=0.7242618899851593; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9385558584306111, learning_rate=0.06416645025241484, max_depth=20, n_estimators=107, num_leaves=42, reg_alpha=0.2508605273466612, reg_lambda=0.18433367433137005, subsample=0.7242618899851593; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8284943424820322, learning_rate=0.14769998015307328, max_depth=-1, n_estimators=107, num_leaves=45, reg_alpha=0.15643704267108605, reg_lambda=0.25024289816459533, subsample=0.8647679994118361; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8284943424820322, learning_rate=0.14769998015307328, max_depth=-1, n_estimators=107, num_leaves=45, reg_alpha=0.15643704267108605, reg_lambda=0.25024289816459533, subsample=0.8647679994118361; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8284943424820322, learning_rate=0.14769998015307328, max_depth=-1, n_estimators=107, num_leaves=45, reg_alpha=0.15643704267108605, reg_lambda=0.25024289816459533, subsample=0.8647679994118361; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8284943424820322, learning_rate=0.14769998015307328, max_depth=-1, n_estimators=107, num_leaves=45, reg_alpha=0.15643704267108605, reg_lambda=0.25024289816459533, subsample=0.8647679994118361; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8284943424820322, learning_rate=0.14769998015307328, max_depth=-1, n_estimators=107, num_leaves=45, reg_alpha=0.15643704267108605, reg_lambda=0.25024289816459533, subsample=0.8647679994118361; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9143787768100187, learning_rate=0.14203947534354627, max_depth=-1, n_estimators=178, num_leaves=35, reg_alpha=0.5166962574265667, reg_lambda=0.6571113285001668, subsample=0.8307018696033672; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9143787768100187, learning_rate=0.14203947534354627, max_depth=-1, n_estimators=178, num_leaves=35, reg_alpha=0.5166962574265667, reg_lambda=0.6571113285001668, subsample=0.8307018696033672; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9143787768100187, learning_rate=0.14203947534354627, max_depth=-1, n_estimators=178, num_leaves=35, reg_alpha=0.5166962574265667, reg_lambda=0.6571113285001668, subsample=0.8307018696033672; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9143787768100187, learning_rate=0.14203947534354627, max_depth=-1, n_estimators=178, num_leaves=35, reg_alpha=0.5166962574265667, reg_lambda=0.6571113285001668, subsample=0.8307018696033672; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9143787768100187, learning_rate=0.14203947534354627, max_depth=-1, n_estimators=178, num_leaves=35, reg_alpha=0.5166962574265667, reg_lambda=0.6571113285001668, subsample=0.8307018696033672; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.8249529843611099, 'learning_rate': 0.18665605178377367, 'max_depth': 20, 'n_estimators': 299, 'num_leaves': 42, 'reg_alpha': 0.8960912999234932, 'reg_lambda': 0.3180034749718639, 'subsample': 0.733015577358303}\n",
      "Best Score: -1587.6482\n"
     ]
    }
   ],
   "source": [
    "# Define categorical features\n",
    "categorical_features = ['vehicletype', 'gearbox', 'model', 'fueltype', 'brand', 'notrepaired']\n",
    "\n",
    "# Convert categorical features to 'category' dtype for LightGBM\n",
    "for feature in categorical_features:\n",
    "    X[feature] = X[feature].astype('category')\n",
    "\n",
    "# Define the LightGBM model\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': randint(20, 50),\n",
    "    'max_depth': [-1, 5, 10, 20],\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'subsample': uniform(0.7, 0.3),\n",
    "    'colsample_bytree': uniform(0.7, 0.3),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1)\n",
    "}\n",
    "\n",
    "# Get categorical feature indices\n",
    "categorical_feature_indices = [X.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X, y, categorical_feature=categorical_feature_indices)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(f\"Best Score: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1586.63447663 1579.64530885 1613.42718242 1584.4128766  1607.79900644]\n",
      "Mean Cross-Validation RMSE: 1594.383770186807\n",
      "Standard Deviation of Cross-Validation RMSE: 13.559591626135628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['brand', 'fueltype', 'gearbox', 'model', 'notrepaired', 'vehicletype']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 5.264832973480225 seconds\n",
      "Validation prediction time: 1.0019903182983398 seconds\n",
      "Validation RMSE: 1582.5702330945005\n",
      "Test prediction time: 1.0046632289886475 seconds\n",
      "Test RMSE: 1609.12153926151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 5.264832973480225,\n",
       " 'validation_time': 1.0019903182983398,\n",
       " 'validation_rmse': 1582.5702330945005,\n",
       " 'test_prediction_time': 1.0046632289886475,\n",
       " 'test_rmse': 1609.12153926151,\n",
       " 'cv_rmse_scores': array([1586.63447663, 1579.64530885, 1613.42718242, 1584.4128766 ,\n",
       "        1607.79900644]),\n",
       " 'mean_cv_rmse': 1594.383770186807,\n",
       " 'std_cv_rmse': 13.559591626135628}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_eval_lgbm(lgb.LGBMRegressor, X, y, cv_splits=5, categorical_features=categorical_features, objective= 'regression', metric= 'rmse',\n",
    "                               boosting_type= 'gbdt', colsample_bytree= 0.791609158103318, \n",
    "                               learning_rate= 0.10712275071724532, max_depth= 10, n_estimators= 257, \n",
    "                               num_leaves= 48, reg_alpha= 0.22426930946055978, reg_lambda= 0.7121792213475359, subsample= 0.7711747262490399, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.094301\n",
      "0:\tlearn: 4417.3823914\ttotal: 219ms\tremaining: 3m 38s\n",
      "1:\tlearn: 4154.9584217\ttotal: 389ms\tremaining: 3m 14s\n",
      "2:\tlearn: 3919.1521889\ttotal: 538ms\tremaining: 2m 58s\n",
      "3:\tlearn: 3706.6904612\ttotal: 664ms\tremaining: 2m 45s\n",
      "4:\tlearn: 3516.1064946\ttotal: 809ms\tremaining: 2m 41s\n",
      "5:\tlearn: 3348.3037435\ttotal: 950ms\tremaining: 2m 37s\n",
      "6:\tlearn: 3199.6819246\ttotal: 1.06s\tremaining: 2m 31s\n",
      "7:\tlearn: 3066.1054663\ttotal: 1.2s\tremaining: 2m 28s\n",
      "8:\tlearn: 2949.1767948\ttotal: 1.31s\tremaining: 2m 24s\n",
      "9:\tlearn: 2848.1412674\ttotal: 1.47s\tremaining: 2m 25s\n",
      "10:\tlearn: 2757.8442434\ttotal: 1.62s\tremaining: 2m 25s\n",
      "11:\tlearn: 2676.4617984\ttotal: 1.75s\tremaining: 2m 24s\n",
      "12:\tlearn: 2602.6052853\ttotal: 1.89s\tremaining: 2m 23s\n",
      "13:\tlearn: 2537.1208353\ttotal: 2.03s\tremaining: 2m 23s\n",
      "14:\tlearn: 2475.7565880\ttotal: 2.16s\tremaining: 2m 21s\n",
      "15:\tlearn: 2417.0948455\ttotal: 2.28s\tremaining: 2m 20s\n",
      "16:\tlearn: 2370.9207568\ttotal: 2.37s\tremaining: 2m 17s\n",
      "17:\tlearn: 2325.0364936\ttotal: 2.52s\tremaining: 2m 17s\n",
      "18:\tlearn: 2287.2701489\ttotal: 2.66s\tremaining: 2m 17s\n",
      "19:\tlearn: 2250.4520681\ttotal: 2.78s\tremaining: 2m 16s\n",
      "20:\tlearn: 2218.9011490\ttotal: 2.9s\tremaining: 2m 15s\n",
      "21:\tlearn: 2192.3462540\ttotal: 3.02s\tremaining: 2m 14s\n",
      "22:\tlearn: 2165.8802994\ttotal: 3.12s\tremaining: 2m 12s\n",
      "23:\tlearn: 2142.8347627\ttotal: 3.23s\tremaining: 2m 11s\n",
      "24:\tlearn: 2122.3872238\ttotal: 3.37s\tremaining: 2m 11s\n",
      "25:\tlearn: 2104.5649675\ttotal: 3.51s\tremaining: 2m 11s\n",
      "26:\tlearn: 2086.8395670\ttotal: 3.65s\tremaining: 2m 11s\n",
      "27:\tlearn: 2071.2279083\ttotal: 3.76s\tremaining: 2m 10s\n",
      "28:\tlearn: 2057.0616777\ttotal: 3.87s\tremaining: 2m 9s\n",
      "29:\tlearn: 2046.1211260\ttotal: 3.97s\tremaining: 2m 8s\n",
      "30:\tlearn: 2033.9445225\ttotal: 4.1s\tremaining: 2m 8s\n",
      "31:\tlearn: 2024.3697862\ttotal: 4.21s\tremaining: 2m 7s\n",
      "32:\tlearn: 2013.8579943\ttotal: 4.35s\tremaining: 2m 7s\n",
      "33:\tlearn: 2001.0892423\ttotal: 4.45s\tremaining: 2m 6s\n",
      "34:\tlearn: 1993.4923722\ttotal: 4.59s\tremaining: 2m 6s\n",
      "35:\tlearn: 1986.3551094\ttotal: 4.69s\tremaining: 2m 5s\n",
      "36:\tlearn: 1980.4021674\ttotal: 4.8s\tremaining: 2m 5s\n",
      "37:\tlearn: 1970.9037670\ttotal: 4.91s\tremaining: 2m 4s\n",
      "38:\tlearn: 1963.7630637\ttotal: 5.03s\tremaining: 2m 4s\n",
      "39:\tlearn: 1959.1926572\ttotal: 5.16s\tremaining: 2m 3s\n",
      "40:\tlearn: 1950.7022417\ttotal: 5.26s\tremaining: 2m 2s\n",
      "41:\tlearn: 1945.4895761\ttotal: 5.36s\tremaining: 2m 2s\n",
      "42:\tlearn: 1938.5608807\ttotal: 5.44s\tremaining: 2m 1s\n",
      "43:\tlearn: 1933.7234859\ttotal: 5.53s\tremaining: 2m\n",
      "44:\tlearn: 1929.1675416\ttotal: 5.67s\tremaining: 2m\n",
      "45:\tlearn: 1925.3675325\ttotal: 5.76s\tremaining: 1m 59s\n",
      "46:\tlearn: 1920.8481484\ttotal: 5.91s\tremaining: 1m 59s\n",
      "47:\tlearn: 1917.5952920\ttotal: 6.03s\tremaining: 1m 59s\n",
      "48:\tlearn: 1914.4213912\ttotal: 6.16s\tremaining: 1m 59s\n",
      "49:\tlearn: 1910.4320054\ttotal: 6.27s\tremaining: 1m 59s\n",
      "50:\tlearn: 1907.2789251\ttotal: 6.4s\tremaining: 1m 59s\n",
      "51:\tlearn: 1904.5266446\ttotal: 6.5s\tremaining: 1m 58s\n",
      "52:\tlearn: 1901.1232525\ttotal: 6.58s\tremaining: 1m 57s\n",
      "53:\tlearn: 1897.7055102\ttotal: 6.68s\tremaining: 1m 57s\n",
      "54:\tlearn: 1895.2674715\ttotal: 6.82s\tremaining: 1m 57s\n",
      "55:\tlearn: 1892.4029144\ttotal: 6.95s\tremaining: 1m 57s\n",
      "56:\tlearn: 1889.7874080\ttotal: 7.07s\tremaining: 1m 57s\n",
      "57:\tlearn: 1886.8903150\ttotal: 7.2s\tremaining: 1m 56s\n",
      "58:\tlearn: 1883.8691139\ttotal: 7.28s\tremaining: 1m 56s\n",
      "59:\tlearn: 1880.9507335\ttotal: 7.42s\tremaining: 1m 56s\n",
      "60:\tlearn: 1878.7364161\ttotal: 7.53s\tremaining: 1m 55s\n",
      "61:\tlearn: 1876.5227737\ttotal: 7.64s\tremaining: 1m 55s\n",
      "62:\tlearn: 1874.7733024\ttotal: 7.75s\tremaining: 1m 55s\n",
      "63:\tlearn: 1872.2334241\ttotal: 7.88s\tremaining: 1m 55s\n",
      "64:\tlearn: 1869.6204584\ttotal: 7.97s\tremaining: 1m 54s\n",
      "65:\tlearn: 1866.8071541\ttotal: 8.09s\tremaining: 1m 54s\n",
      "66:\tlearn: 1863.5192141\ttotal: 8.21s\tremaining: 1m 54s\n",
      "67:\tlearn: 1861.6061616\ttotal: 8.31s\tremaining: 1m 53s\n",
      "68:\tlearn: 1859.4814384\ttotal: 8.45s\tremaining: 1m 53s\n",
      "69:\tlearn: 1858.1753089\ttotal: 8.54s\tremaining: 1m 53s\n",
      "70:\tlearn: 1856.7631055\ttotal: 8.69s\tremaining: 1m 53s\n",
      "71:\tlearn: 1854.9302449\ttotal: 8.79s\tremaining: 1m 53s\n",
      "72:\tlearn: 1852.9337025\ttotal: 8.9s\tremaining: 1m 53s\n",
      "73:\tlearn: 1850.4539107\ttotal: 8.99s\tremaining: 1m 52s\n",
      "74:\tlearn: 1848.4804049\ttotal: 9.12s\tremaining: 1m 52s\n",
      "75:\tlearn: 1845.7381408\ttotal: 9.23s\tremaining: 1m 52s\n",
      "76:\tlearn: 1843.9735926\ttotal: 9.35s\tremaining: 1m 52s\n",
      "77:\tlearn: 1842.3412072\ttotal: 9.5s\tremaining: 1m 52s\n",
      "78:\tlearn: 1840.4502210\ttotal: 9.59s\tremaining: 1m 51s\n",
      "79:\tlearn: 1838.1873029\ttotal: 9.73s\tremaining: 1m 51s\n",
      "80:\tlearn: 1836.6081453\ttotal: 9.83s\tremaining: 1m 51s\n",
      "81:\tlearn: 1835.4348557\ttotal: 9.93s\tremaining: 1m 51s\n",
      "82:\tlearn: 1834.1007221\ttotal: 10s\tremaining: 1m 50s\n",
      "83:\tlearn: 1830.9576105\ttotal: 10.2s\tremaining: 1m 50s\n",
      "84:\tlearn: 1828.7991915\ttotal: 10.3s\tremaining: 1m 50s\n",
      "85:\tlearn: 1827.7454030\ttotal: 10.4s\tremaining: 1m 50s\n",
      "86:\tlearn: 1826.4342124\ttotal: 10.5s\tremaining: 1m 50s\n",
      "87:\tlearn: 1824.4700379\ttotal: 10.6s\tremaining: 1m 49s\n",
      "88:\tlearn: 1822.5760735\ttotal: 10.7s\tremaining: 1m 49s\n",
      "89:\tlearn: 1820.8101770\ttotal: 10.9s\tremaining: 1m 49s\n",
      "90:\tlearn: 1819.1029175\ttotal: 11s\tremaining: 1m 49s\n",
      "91:\tlearn: 1817.8747392\ttotal: 11.1s\tremaining: 1m 49s\n",
      "92:\tlearn: 1816.1896186\ttotal: 11.2s\tremaining: 1m 49s\n",
      "93:\tlearn: 1814.7322617\ttotal: 11.3s\tremaining: 1m 49s\n",
      "94:\tlearn: 1813.5880166\ttotal: 11.4s\tremaining: 1m 48s\n",
      "95:\tlearn: 1812.3690002\ttotal: 11.5s\tremaining: 1m 48s\n",
      "96:\tlearn: 1810.6728181\ttotal: 11.6s\tremaining: 1m 48s\n",
      "97:\tlearn: 1808.8617675\ttotal: 11.7s\tremaining: 1m 47s\n",
      "98:\tlearn: 1808.0174594\ttotal: 11.8s\tremaining: 1m 47s\n",
      "99:\tlearn: 1806.7261487\ttotal: 11.9s\tremaining: 1m 47s\n",
      "100:\tlearn: 1805.3860587\ttotal: 12.1s\tremaining: 1m 47s\n",
      "101:\tlearn: 1803.8424073\ttotal: 12.2s\tremaining: 1m 47s\n",
      "102:\tlearn: 1802.9866904\ttotal: 12.3s\tremaining: 1m 47s\n",
      "103:\tlearn: 1801.2291901\ttotal: 12.4s\tremaining: 1m 46s\n",
      "104:\tlearn: 1800.0320020\ttotal: 12.5s\tremaining: 1m 46s\n",
      "105:\tlearn: 1799.1509305\ttotal: 12.6s\tremaining: 1m 46s\n",
      "106:\tlearn: 1798.0171192\ttotal: 12.7s\tremaining: 1m 46s\n",
      "107:\tlearn: 1796.7732986\ttotal: 12.8s\tremaining: 1m 46s\n",
      "108:\tlearn: 1795.8854945\ttotal: 13s\tremaining: 1m 46s\n",
      "109:\tlearn: 1795.0314247\ttotal: 13.1s\tremaining: 1m 46s\n",
      "110:\tlearn: 1794.4810983\ttotal: 13.2s\tremaining: 1m 45s\n",
      "111:\tlearn: 1794.1148554\ttotal: 13.3s\tremaining: 1m 45s\n",
      "112:\tlearn: 1792.9406507\ttotal: 13.5s\tremaining: 1m 45s\n",
      "113:\tlearn: 1790.8013561\ttotal: 13.6s\tremaining: 1m 45s\n",
      "114:\tlearn: 1789.9691440\ttotal: 13.7s\tremaining: 1m 45s\n",
      "115:\tlearn: 1788.9370591\ttotal: 13.8s\tremaining: 1m 45s\n",
      "116:\tlearn: 1787.4607456\ttotal: 13.9s\tremaining: 1m 44s\n",
      "117:\tlearn: 1786.2794875\ttotal: 14s\tremaining: 1m 44s\n",
      "118:\tlearn: 1785.3746862\ttotal: 14.2s\tremaining: 1m 44s\n",
      "119:\tlearn: 1784.3387805\ttotal: 14.3s\tremaining: 1m 44s\n",
      "120:\tlearn: 1783.7370024\ttotal: 14.4s\tremaining: 1m 44s\n",
      "121:\tlearn: 1782.7013827\ttotal: 14.5s\tremaining: 1m 44s\n",
      "122:\tlearn: 1781.5724505\ttotal: 14.6s\tremaining: 1m 44s\n",
      "123:\tlearn: 1780.2314730\ttotal: 14.7s\tremaining: 1m 44s\n",
      "124:\tlearn: 1779.4551578\ttotal: 14.9s\tremaining: 1m 44s\n",
      "125:\tlearn: 1778.8213863\ttotal: 15s\tremaining: 1m 43s\n",
      "126:\tlearn: 1778.2421620\ttotal: 15.1s\tremaining: 1m 43s\n",
      "127:\tlearn: 1777.4333182\ttotal: 15.2s\tremaining: 1m 43s\n",
      "128:\tlearn: 1776.3630041\ttotal: 15.3s\tremaining: 1m 43s\n",
      "129:\tlearn: 1775.6819965\ttotal: 15.5s\tremaining: 1m 43s\n",
      "130:\tlearn: 1775.0147571\ttotal: 15.6s\tremaining: 1m 43s\n",
      "131:\tlearn: 1774.4463707\ttotal: 15.7s\tremaining: 1m 43s\n",
      "132:\tlearn: 1773.9507257\ttotal: 15.8s\tremaining: 1m 43s\n",
      "133:\tlearn: 1772.0296067\ttotal: 15.9s\tremaining: 1m 42s\n",
      "134:\tlearn: 1770.8177437\ttotal: 16s\tremaining: 1m 42s\n",
      "135:\tlearn: 1769.7314274\ttotal: 16.2s\tremaining: 1m 42s\n",
      "136:\tlearn: 1769.0095153\ttotal: 16.3s\tremaining: 1m 42s\n",
      "137:\tlearn: 1768.4865019\ttotal: 16.4s\tremaining: 1m 42s\n",
      "138:\tlearn: 1767.4078279\ttotal: 16.5s\tremaining: 1m 42s\n",
      "139:\tlearn: 1767.0373717\ttotal: 16.6s\tremaining: 1m 41s\n",
      "140:\tlearn: 1766.4085450\ttotal: 16.7s\tremaining: 1m 41s\n",
      "141:\tlearn: 1765.3451666\ttotal: 16.8s\tremaining: 1m 41s\n",
      "142:\tlearn: 1763.5507641\ttotal: 16.9s\tremaining: 1m 41s\n",
      "143:\tlearn: 1762.2202672\ttotal: 17s\tremaining: 1m 41s\n",
      "144:\tlearn: 1761.7084776\ttotal: 17.1s\tremaining: 1m 41s\n",
      "145:\tlearn: 1759.7405034\ttotal: 17.2s\tremaining: 1m 40s\n",
      "146:\tlearn: 1759.1826317\ttotal: 17.3s\tremaining: 1m 40s\n",
      "147:\tlearn: 1758.5620201\ttotal: 17.4s\tremaining: 1m 40s\n",
      "148:\tlearn: 1757.7699511\ttotal: 17.5s\tremaining: 1m 40s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149:\tlearn: 1756.5982823\ttotal: 17.7s\tremaining: 1m 40s\n",
      "150:\tlearn: 1755.8293514\ttotal: 17.8s\tremaining: 1m 39s\n",
      "151:\tlearn: 1754.2757078\ttotal: 17.9s\tremaining: 1m 39s\n",
      "152:\tlearn: 1753.5296968\ttotal: 18s\tremaining: 1m 39s\n",
      "153:\tlearn: 1752.5476762\ttotal: 18.1s\tremaining: 1m 39s\n",
      "154:\tlearn: 1752.0088139\ttotal: 18.2s\tremaining: 1m 39s\n",
      "155:\tlearn: 1751.0816047\ttotal: 18.4s\tremaining: 1m 39s\n",
      "156:\tlearn: 1750.8779104\ttotal: 18.5s\tremaining: 1m 39s\n",
      "157:\tlearn: 1750.3781842\ttotal: 18.6s\tremaining: 1m 39s\n",
      "158:\tlearn: 1749.2610372\ttotal: 18.8s\tremaining: 1m 39s\n",
      "159:\tlearn: 1748.9629941\ttotal: 18.9s\tremaining: 1m 39s\n",
      "160:\tlearn: 1748.3417215\ttotal: 19s\tremaining: 1m 38s\n",
      "161:\tlearn: 1747.8136214\ttotal: 19.1s\tremaining: 1m 38s\n",
      "162:\tlearn: 1747.0330163\ttotal: 19.2s\tremaining: 1m 38s\n",
      "163:\tlearn: 1746.4075760\ttotal: 19.4s\tremaining: 1m 38s\n",
      "164:\tlearn: 1745.5764010\ttotal: 19.5s\tremaining: 1m 38s\n",
      "165:\tlearn: 1745.1061936\ttotal: 19.6s\tremaining: 1m 38s\n",
      "166:\tlearn: 1744.8434702\ttotal: 19.7s\tremaining: 1m 38s\n",
      "167:\tlearn: 1744.1920794\ttotal: 19.9s\tremaining: 1m 38s\n",
      "168:\tlearn: 1743.5625405\ttotal: 20s\tremaining: 1m 38s\n",
      "169:\tlearn: 1743.1775727\ttotal: 20.1s\tremaining: 1m 38s\n",
      "170:\tlearn: 1742.4755726\ttotal: 20.2s\tremaining: 1m 37s\n",
      "171:\tlearn: 1742.0015472\ttotal: 20.3s\tremaining: 1m 37s\n",
      "172:\tlearn: 1741.1473860\ttotal: 20.5s\tremaining: 1m 37s\n",
      "173:\tlearn: 1740.8917800\ttotal: 20.6s\tremaining: 1m 37s\n",
      "174:\tlearn: 1740.3616754\ttotal: 20.7s\tremaining: 1m 37s\n",
      "175:\tlearn: 1739.7436051\ttotal: 20.8s\tremaining: 1m 37s\n",
      "176:\tlearn: 1738.5927960\ttotal: 20.9s\tremaining: 1m 37s\n",
      "177:\tlearn: 1738.2412738\ttotal: 21s\tremaining: 1m 36s\n",
      "178:\tlearn: 1737.3496127\ttotal: 21.1s\tremaining: 1m 36s\n",
      "179:\tlearn: 1736.6124210\ttotal: 21.2s\tremaining: 1m 36s\n",
      "180:\tlearn: 1735.7964926\ttotal: 21.3s\tremaining: 1m 36s\n",
      "181:\tlearn: 1735.4607826\ttotal: 21.4s\tremaining: 1m 36s\n",
      "182:\tlearn: 1735.1123806\ttotal: 21.5s\tremaining: 1m 36s\n",
      "183:\tlearn: 1735.0685010\ttotal: 21.6s\tremaining: 1m 35s\n",
      "184:\tlearn: 1734.2552931\ttotal: 21.7s\tremaining: 1m 35s\n",
      "185:\tlearn: 1733.6022550\ttotal: 21.8s\tremaining: 1m 35s\n",
      "186:\tlearn: 1732.3002216\ttotal: 21.9s\tremaining: 1m 35s\n",
      "187:\tlearn: 1731.9791259\ttotal: 22s\tremaining: 1m 35s\n",
      "188:\tlearn: 1731.3363347\ttotal: 22.1s\tremaining: 1m 35s\n",
      "189:\tlearn: 1730.4280140\ttotal: 22.3s\tremaining: 1m 34s\n",
      "190:\tlearn: 1729.6171649\ttotal: 22.4s\tremaining: 1m 34s\n",
      "191:\tlearn: 1728.9835272\ttotal: 22.5s\tremaining: 1m 34s\n",
      "192:\tlearn: 1728.4904844\ttotal: 22.6s\tremaining: 1m 34s\n",
      "193:\tlearn: 1728.1081788\ttotal: 22.8s\tremaining: 1m 34s\n",
      "194:\tlearn: 1727.4929026\ttotal: 22.9s\tremaining: 1m 34s\n",
      "195:\tlearn: 1726.8876689\ttotal: 23s\tremaining: 1m 34s\n",
      "196:\tlearn: 1726.3977583\ttotal: 23.1s\tremaining: 1m 34s\n",
      "197:\tlearn: 1725.8033264\ttotal: 23.2s\tremaining: 1m 34s\n",
      "198:\tlearn: 1724.9167736\ttotal: 23.4s\tremaining: 1m 34s\n",
      "199:\tlearn: 1723.9960264\ttotal: 23.5s\tremaining: 1m 33s\n",
      "200:\tlearn: 1723.3757431\ttotal: 23.6s\tremaining: 1m 33s\n",
      "201:\tlearn: 1723.0067484\ttotal: 23.7s\tremaining: 1m 33s\n",
      "202:\tlearn: 1722.4767994\ttotal: 23.8s\tremaining: 1m 33s\n",
      "203:\tlearn: 1721.8405892\ttotal: 23.9s\tremaining: 1m 33s\n",
      "204:\tlearn: 1721.2953883\ttotal: 24s\tremaining: 1m 32s\n",
      "205:\tlearn: 1721.0459574\ttotal: 24.1s\tremaining: 1m 32s\n",
      "206:\tlearn: 1720.5387632\ttotal: 24.2s\tremaining: 1m 32s\n",
      "207:\tlearn: 1719.8069775\ttotal: 24.4s\tremaining: 1m 32s\n",
      "208:\tlearn: 1719.4374935\ttotal: 24.5s\tremaining: 1m 32s\n",
      "209:\tlearn: 1718.7522954\ttotal: 24.6s\tremaining: 1m 32s\n",
      "210:\tlearn: 1718.1457156\ttotal: 24.7s\tremaining: 1m 32s\n",
      "211:\tlearn: 1717.4097228\ttotal: 24.8s\tremaining: 1m 32s\n",
      "212:\tlearn: 1716.9168381\ttotal: 24.9s\tremaining: 1m 32s\n",
      "213:\tlearn: 1716.3476404\ttotal: 25.1s\tremaining: 1m 32s\n",
      "214:\tlearn: 1716.1740364\ttotal: 25.2s\tremaining: 1m 31s\n",
      "215:\tlearn: 1715.3587375\ttotal: 25.3s\tremaining: 1m 31s\n",
      "216:\tlearn: 1714.5737774\ttotal: 25.4s\tremaining: 1m 31s\n",
      "217:\tlearn: 1714.1150736\ttotal: 25.5s\tremaining: 1m 31s\n",
      "218:\tlearn: 1713.6972138\ttotal: 25.6s\tremaining: 1m 31s\n",
      "219:\tlearn: 1713.1794409\ttotal: 25.7s\tremaining: 1m 31s\n",
      "220:\tlearn: 1712.7031308\ttotal: 25.9s\tremaining: 1m 31s\n",
      "221:\tlearn: 1712.4589160\ttotal: 26s\tremaining: 1m 30s\n",
      "222:\tlearn: 1712.1387416\ttotal: 26.1s\tremaining: 1m 30s\n",
      "223:\tlearn: 1711.4781719\ttotal: 26.2s\tremaining: 1m 30s\n",
      "224:\tlearn: 1711.2477462\ttotal: 26.3s\tremaining: 1m 30s\n",
      "225:\tlearn: 1710.8228963\ttotal: 26.4s\tremaining: 1m 30s\n",
      "226:\tlearn: 1710.1983546\ttotal: 26.5s\tremaining: 1m 30s\n",
      "227:\tlearn: 1709.7334795\ttotal: 26.6s\tremaining: 1m 30s\n",
      "228:\tlearn: 1708.7017877\ttotal: 26.8s\tremaining: 1m 30s\n",
      "229:\tlearn: 1707.9857882\ttotal: 26.9s\tremaining: 1m 29s\n",
      "230:\tlearn: 1707.6587670\ttotal: 27s\tremaining: 1m 29s\n",
      "231:\tlearn: 1707.5404659\ttotal: 27.1s\tremaining: 1m 29s\n",
      "232:\tlearn: 1707.2558638\ttotal: 27.2s\tremaining: 1m 29s\n",
      "233:\tlearn: 1706.6810267\ttotal: 27.3s\tremaining: 1m 29s\n",
      "234:\tlearn: 1706.3503483\ttotal: 27.4s\tremaining: 1m 29s\n",
      "235:\tlearn: 1705.8813187\ttotal: 27.6s\tremaining: 1m 29s\n",
      "236:\tlearn: 1705.7074326\ttotal: 27.7s\tremaining: 1m 29s\n",
      "237:\tlearn: 1705.2682680\ttotal: 27.8s\tremaining: 1m 29s\n",
      "238:\tlearn: 1704.7020530\ttotal: 27.9s\tremaining: 1m 28s\n",
      "239:\tlearn: 1704.2417859\ttotal: 28s\tremaining: 1m 28s\n",
      "240:\tlearn: 1703.7213698\ttotal: 28.1s\tremaining: 1m 28s\n",
      "241:\tlearn: 1703.4166691\ttotal: 28.2s\tremaining: 1m 28s\n",
      "242:\tlearn: 1703.0867874\ttotal: 28.4s\tremaining: 1m 28s\n",
      "243:\tlearn: 1702.7551294\ttotal: 28.5s\tremaining: 1m 28s\n",
      "244:\tlearn: 1702.2453168\ttotal: 28.6s\tremaining: 1m 28s\n",
      "245:\tlearn: 1701.6234668\ttotal: 28.7s\tremaining: 1m 28s\n",
      "246:\tlearn: 1700.8093258\ttotal: 28.8s\tremaining: 1m 27s\n",
      "247:\tlearn: 1700.1966315\ttotal: 29s\tremaining: 1m 27s\n",
      "248:\tlearn: 1699.6303923\ttotal: 29.1s\tremaining: 1m 27s\n",
      "249:\tlearn: 1698.7789465\ttotal: 29.2s\tremaining: 1m 27s\n",
      "250:\tlearn: 1698.4006498\ttotal: 29.3s\tremaining: 1m 27s\n",
      "251:\tlearn: 1698.0484576\ttotal: 29.4s\tremaining: 1m 27s\n",
      "252:\tlearn: 1697.6859319\ttotal: 29.5s\tremaining: 1m 27s\n",
      "253:\tlearn: 1697.1841635\ttotal: 29.6s\tremaining: 1m 26s\n",
      "254:\tlearn: 1697.0133720\ttotal: 29.7s\tremaining: 1m 26s\n",
      "255:\tlearn: 1696.6994736\ttotal: 29.8s\tremaining: 1m 26s\n",
      "256:\tlearn: 1695.8564620\ttotal: 29.9s\tremaining: 1m 26s\n",
      "257:\tlearn: 1695.2640608\ttotal: 30s\tremaining: 1m 26s\n",
      "258:\tlearn: 1694.7185920\ttotal: 30.1s\tremaining: 1m 26s\n",
      "259:\tlearn: 1694.3701559\ttotal: 30.2s\tremaining: 1m 25s\n",
      "260:\tlearn: 1694.0615774\ttotal: 30.3s\tremaining: 1m 25s\n",
      "261:\tlearn: 1693.7474101\ttotal: 30.5s\tremaining: 1m 25s\n",
      "262:\tlearn: 1693.2441184\ttotal: 30.6s\tremaining: 1m 25s\n",
      "263:\tlearn: 1692.5330350\ttotal: 30.7s\tremaining: 1m 25s\n",
      "264:\tlearn: 1692.3580761\ttotal: 30.8s\tremaining: 1m 25s\n",
      "265:\tlearn: 1691.9888723\ttotal: 30.9s\tremaining: 1m 25s\n",
      "266:\tlearn: 1691.8914846\ttotal: 31.1s\tremaining: 1m 25s\n",
      "267:\tlearn: 1691.6548885\ttotal: 31.1s\tremaining: 1m 25s\n",
      "268:\tlearn: 1691.2466475\ttotal: 31.3s\tremaining: 1m 24s\n",
      "269:\tlearn: 1690.9653766\ttotal: 31.4s\tremaining: 1m 24s\n",
      "270:\tlearn: 1690.7324308\ttotal: 31.5s\tremaining: 1m 24s\n",
      "271:\tlearn: 1690.2918425\ttotal: 31.6s\tremaining: 1m 24s\n",
      "272:\tlearn: 1689.9046706\ttotal: 31.7s\tremaining: 1m 24s\n",
      "273:\tlearn: 1689.6641083\ttotal: 31.8s\tremaining: 1m 24s\n",
      "274:\tlearn: 1689.2790816\ttotal: 31.9s\tremaining: 1m 24s\n",
      "275:\tlearn: 1688.9002515\ttotal: 32.1s\tremaining: 1m 24s\n",
      "276:\tlearn: 1688.6381081\ttotal: 32.2s\tremaining: 1m 24s\n",
      "277:\tlearn: 1688.3196412\ttotal: 32.3s\tremaining: 1m 23s\n",
      "278:\tlearn: 1687.7823043\ttotal: 32.4s\tremaining: 1m 23s\n",
      "279:\tlearn: 1687.2031681\ttotal: 32.5s\tremaining: 1m 23s\n",
      "280:\tlearn: 1686.6216800\ttotal: 32.6s\tremaining: 1m 23s\n",
      "281:\tlearn: 1686.3976121\ttotal: 32.7s\tremaining: 1m 23s\n",
      "282:\tlearn: 1685.8635305\ttotal: 32.8s\tremaining: 1m 23s\n",
      "283:\tlearn: 1685.6239554\ttotal: 33s\tremaining: 1m 23s\n",
      "284:\tlearn: 1684.8971111\ttotal: 33.1s\tremaining: 1m 23s\n",
      "285:\tlearn: 1684.4991411\ttotal: 33.2s\tremaining: 1m 22s\n",
      "286:\tlearn: 1684.2692588\ttotal: 33.3s\tremaining: 1m 22s\n",
      "287:\tlearn: 1683.9837048\ttotal: 33.5s\tremaining: 1m 22s\n",
      "288:\tlearn: 1683.4065994\ttotal: 33.6s\tremaining: 1m 22s\n",
      "289:\tlearn: 1682.7240105\ttotal: 33.7s\tremaining: 1m 22s\n",
      "290:\tlearn: 1682.3324979\ttotal: 33.8s\tremaining: 1m 22s\n",
      "291:\tlearn: 1681.8817840\ttotal: 34s\tremaining: 1m 22s\n",
      "292:\tlearn: 1681.5797711\ttotal: 34.1s\tremaining: 1m 22s\n",
      "293:\tlearn: 1681.4528231\ttotal: 34.2s\tremaining: 1m 22s\n",
      "294:\tlearn: 1681.4086802\ttotal: 34.3s\tremaining: 1m 21s\n",
      "295:\tlearn: 1680.9302264\ttotal: 34.4s\tremaining: 1m 21s\n",
      "296:\tlearn: 1680.5865029\ttotal: 34.5s\tremaining: 1m 21s\n",
      "297:\tlearn: 1680.4853252\ttotal: 34.6s\tremaining: 1m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298:\tlearn: 1680.1057845\ttotal: 34.7s\tremaining: 1m 21s\n",
      "299:\tlearn: 1679.6086670\ttotal: 34.8s\tremaining: 1m 21s\n",
      "300:\tlearn: 1679.1624779\ttotal: 34.9s\tremaining: 1m 21s\n",
      "301:\tlearn: 1678.4757430\ttotal: 35s\tremaining: 1m 20s\n",
      "302:\tlearn: 1678.1312866\ttotal: 35.2s\tremaining: 1m 20s\n",
      "303:\tlearn: 1677.8582446\ttotal: 35.3s\tremaining: 1m 20s\n",
      "304:\tlearn: 1677.3182160\ttotal: 35.4s\tremaining: 1m 20s\n",
      "305:\tlearn: 1676.8827941\ttotal: 35.5s\tremaining: 1m 20s\n",
      "306:\tlearn: 1676.3842882\ttotal: 35.6s\tremaining: 1m 20s\n",
      "307:\tlearn: 1676.2121545\ttotal: 35.7s\tremaining: 1m 20s\n",
      "308:\tlearn: 1676.0244217\ttotal: 35.7s\tremaining: 1m 19s\n",
      "309:\tlearn: 1675.8883077\ttotal: 35.8s\tremaining: 1m 19s\n",
      "310:\tlearn: 1675.6978115\ttotal: 35.9s\tremaining: 1m 19s\n",
      "311:\tlearn: 1675.4668420\ttotal: 36s\tremaining: 1m 19s\n",
      "312:\tlearn: 1675.0860795\ttotal: 36.1s\tremaining: 1m 19s\n",
      "313:\tlearn: 1674.7392769\ttotal: 36.2s\tremaining: 1m 19s\n",
      "314:\tlearn: 1674.3029517\ttotal: 36.4s\tremaining: 1m 19s\n",
      "315:\tlearn: 1674.0929050\ttotal: 36.5s\tremaining: 1m 18s\n",
      "316:\tlearn: 1673.6524452\ttotal: 36.6s\tremaining: 1m 18s\n",
      "317:\tlearn: 1673.2279284\ttotal: 36.7s\tremaining: 1m 18s\n",
      "318:\tlearn: 1672.9686242\ttotal: 36.8s\tremaining: 1m 18s\n",
      "319:\tlearn: 1672.7450040\ttotal: 36.9s\tremaining: 1m 18s\n",
      "320:\tlearn: 1672.4828496\ttotal: 37s\tremaining: 1m 18s\n",
      "321:\tlearn: 1672.1427618\ttotal: 37.1s\tremaining: 1m 18s\n",
      "322:\tlearn: 1672.0102335\ttotal: 37.3s\tremaining: 1m 18s\n",
      "323:\tlearn: 1671.7219656\ttotal: 37.4s\tremaining: 1m 18s\n",
      "324:\tlearn: 1671.3906506\ttotal: 37.5s\tremaining: 1m 17s\n",
      "325:\tlearn: 1671.0367395\ttotal: 37.6s\tremaining: 1m 17s\n",
      "326:\tlearn: 1670.6063630\ttotal: 37.7s\tremaining: 1m 17s\n",
      "327:\tlearn: 1670.3695192\ttotal: 37.8s\tremaining: 1m 17s\n",
      "328:\tlearn: 1670.2415775\ttotal: 37.9s\tremaining: 1m 17s\n",
      "329:\tlearn: 1669.7568922\ttotal: 38.1s\tremaining: 1m 17s\n",
      "330:\tlearn: 1669.2724715\ttotal: 38.2s\tremaining: 1m 17s\n",
      "331:\tlearn: 1668.9562029\ttotal: 38.3s\tremaining: 1m 17s\n",
      "332:\tlearn: 1668.6467548\ttotal: 38.5s\tremaining: 1m 17s\n",
      "333:\tlearn: 1668.3911950\ttotal: 38.6s\tremaining: 1m 16s\n",
      "334:\tlearn: 1668.1247385\ttotal: 38.7s\tremaining: 1m 16s\n",
      "335:\tlearn: 1667.9879397\ttotal: 38.8s\tremaining: 1m 16s\n",
      "336:\tlearn: 1667.7402287\ttotal: 38.9s\tremaining: 1m 16s\n",
      "337:\tlearn: 1667.4385333\ttotal: 39.1s\tremaining: 1m 16s\n",
      "338:\tlearn: 1667.2646547\ttotal: 39.2s\tremaining: 1m 16s\n",
      "339:\tlearn: 1667.0320747\ttotal: 39.3s\tremaining: 1m 16s\n",
      "340:\tlearn: 1666.5064771\ttotal: 39.4s\tremaining: 1m 16s\n",
      "341:\tlearn: 1666.3856372\ttotal: 39.5s\tremaining: 1m 16s\n",
      "342:\tlearn: 1665.9391071\ttotal: 39.6s\tremaining: 1m 15s\n",
      "343:\tlearn: 1665.5476859\ttotal: 39.8s\tremaining: 1m 15s\n",
      "344:\tlearn: 1665.2001947\ttotal: 39.9s\tremaining: 1m 15s\n",
      "345:\tlearn: 1665.0235042\ttotal: 40s\tremaining: 1m 15s\n",
      "346:\tlearn: 1664.6387887\ttotal: 40.1s\tremaining: 1m 15s\n",
      "347:\tlearn: 1664.2974915\ttotal: 40.3s\tremaining: 1m 15s\n",
      "348:\tlearn: 1663.9466289\ttotal: 40.4s\tremaining: 1m 15s\n",
      "349:\tlearn: 1663.7395713\ttotal: 40.5s\tremaining: 1m 15s\n",
      "350:\tlearn: 1663.5413316\ttotal: 40.6s\tremaining: 1m 15s\n",
      "351:\tlearn: 1663.1244222\ttotal: 40.7s\tremaining: 1m 14s\n",
      "352:\tlearn: 1662.6472473\ttotal: 40.8s\tremaining: 1m 14s\n",
      "353:\tlearn: 1662.5578938\ttotal: 40.9s\tremaining: 1m 14s\n",
      "354:\tlearn: 1662.1466811\ttotal: 41s\tremaining: 1m 14s\n",
      "355:\tlearn: 1661.8290554\ttotal: 41.1s\tremaining: 1m 14s\n",
      "356:\tlearn: 1661.5666405\ttotal: 41.3s\tremaining: 1m 14s\n",
      "357:\tlearn: 1661.1026209\ttotal: 41.4s\tremaining: 1m 14s\n",
      "358:\tlearn: 1660.8684271\ttotal: 41.5s\tremaining: 1m 14s\n",
      "359:\tlearn: 1660.6222177\ttotal: 41.7s\tremaining: 1m 14s\n",
      "360:\tlearn: 1660.3252142\ttotal: 41.8s\tremaining: 1m 13s\n",
      "361:\tlearn: 1660.1910138\ttotal: 41.9s\tremaining: 1m 13s\n",
      "362:\tlearn: 1659.7405297\ttotal: 42s\tremaining: 1m 13s\n",
      "363:\tlearn: 1659.2836072\ttotal: 42.1s\tremaining: 1m 13s\n",
      "364:\tlearn: 1659.1104278\ttotal: 42.3s\tremaining: 1m 13s\n",
      "365:\tlearn: 1658.9633404\ttotal: 42.4s\tremaining: 1m 13s\n",
      "366:\tlearn: 1658.7125524\ttotal: 42.5s\tremaining: 1m 13s\n",
      "367:\tlearn: 1658.4643035\ttotal: 42.6s\tremaining: 1m 13s\n",
      "368:\tlearn: 1658.2337331\ttotal: 42.7s\tremaining: 1m 13s\n",
      "369:\tlearn: 1658.1312495\ttotal: 42.8s\tremaining: 1m 12s\n",
      "370:\tlearn: 1657.9038676\ttotal: 42.9s\tremaining: 1m 12s\n",
      "371:\tlearn: 1657.6939498\ttotal: 43s\tremaining: 1m 12s\n",
      "372:\tlearn: 1657.3813558\ttotal: 43.1s\tremaining: 1m 12s\n",
      "373:\tlearn: 1657.0035339\ttotal: 43.3s\tremaining: 1m 12s\n",
      "374:\tlearn: 1656.7858579\ttotal: 43.4s\tremaining: 1m 12s\n",
      "375:\tlearn: 1656.5713300\ttotal: 43.5s\tremaining: 1m 12s\n",
      "376:\tlearn: 1656.2434419\ttotal: 43.7s\tremaining: 1m 12s\n",
      "377:\tlearn: 1656.0614968\ttotal: 43.8s\tremaining: 1m 12s\n",
      "378:\tlearn: 1655.7878328\ttotal: 43.9s\tremaining: 1m 11s\n",
      "379:\tlearn: 1655.6729285\ttotal: 44s\tremaining: 1m 11s\n",
      "380:\tlearn: 1655.3112936\ttotal: 44.1s\tremaining: 1m 11s\n",
      "381:\tlearn: 1655.0481244\ttotal: 44.2s\tremaining: 1m 11s\n",
      "382:\tlearn: 1654.8606532\ttotal: 44.4s\tremaining: 1m 11s\n",
      "383:\tlearn: 1654.5440734\ttotal: 44.5s\tremaining: 1m 11s\n",
      "384:\tlearn: 1654.3744699\ttotal: 44.7s\tremaining: 1m 11s\n",
      "385:\tlearn: 1653.9978012\ttotal: 44.8s\tremaining: 1m 11s\n",
      "386:\tlearn: 1653.7532111\ttotal: 44.9s\tremaining: 1m 11s\n",
      "387:\tlearn: 1653.4364297\ttotal: 45s\tremaining: 1m 11s\n",
      "388:\tlearn: 1653.1406567\ttotal: 45.2s\tremaining: 1m 10s\n",
      "389:\tlearn: 1652.8409774\ttotal: 45.3s\tremaining: 1m 10s\n",
      "390:\tlearn: 1652.6009367\ttotal: 45.3s\tremaining: 1m 10s\n",
      "391:\tlearn: 1652.3296945\ttotal: 45.4s\tremaining: 1m 10s\n",
      "392:\tlearn: 1652.1552813\ttotal: 45.5s\tremaining: 1m 10s\n",
      "393:\tlearn: 1651.8571624\ttotal: 45.6s\tremaining: 1m 10s\n",
      "394:\tlearn: 1651.7704644\ttotal: 45.7s\tremaining: 1m 10s\n",
      "395:\tlearn: 1651.2580169\ttotal: 45.9s\tremaining: 1m 9s\n",
      "396:\tlearn: 1651.1474941\ttotal: 46s\tremaining: 1m 9s\n",
      "397:\tlearn: 1650.7451027\ttotal: 46.1s\tremaining: 1m 9s\n",
      "398:\tlearn: 1650.5503256\ttotal: 46.2s\tremaining: 1m 9s\n",
      "399:\tlearn: 1650.2619198\ttotal: 46.3s\tremaining: 1m 9s\n",
      "400:\tlearn: 1649.9550760\ttotal: 46.4s\tremaining: 1m 9s\n",
      "401:\tlearn: 1649.7612035\ttotal: 46.5s\tremaining: 1m 9s\n",
      "402:\tlearn: 1649.6318160\ttotal: 46.6s\tremaining: 1m 9s\n",
      "403:\tlearn: 1649.2432262\ttotal: 46.8s\tremaining: 1m 9s\n",
      "404:\tlearn: 1649.0348318\ttotal: 46.9s\tremaining: 1m 8s\n",
      "405:\tlearn: 1648.8399191\ttotal: 47s\tremaining: 1m 8s\n",
      "406:\tlearn: 1648.5163932\ttotal: 47.2s\tremaining: 1m 8s\n",
      "407:\tlearn: 1648.2108376\ttotal: 47.3s\tremaining: 1m 8s\n",
      "408:\tlearn: 1647.8388271\ttotal: 47.4s\tremaining: 1m 8s\n",
      "409:\tlearn: 1647.5497589\ttotal: 47.4s\tremaining: 1m 8s\n",
      "410:\tlearn: 1647.3332508\ttotal: 47.5s\tremaining: 1m 8s\n",
      "411:\tlearn: 1646.9372195\ttotal: 47.7s\tremaining: 1m 8s\n",
      "412:\tlearn: 1646.7824754\ttotal: 47.8s\tremaining: 1m 7s\n",
      "413:\tlearn: 1646.7143640\ttotal: 47.9s\tremaining: 1m 7s\n",
      "414:\tlearn: 1646.4251142\ttotal: 48s\tremaining: 1m 7s\n",
      "415:\tlearn: 1646.2843180\ttotal: 48.1s\tremaining: 1m 7s\n",
      "416:\tlearn: 1646.1006195\ttotal: 48.3s\tremaining: 1m 7s\n",
      "417:\tlearn: 1645.7368283\ttotal: 48.4s\tremaining: 1m 7s\n",
      "418:\tlearn: 1645.3561149\ttotal: 48.5s\tremaining: 1m 7s\n",
      "419:\tlearn: 1645.1213670\ttotal: 48.6s\tremaining: 1m 7s\n",
      "420:\tlearn: 1644.6782576\ttotal: 48.7s\tremaining: 1m 6s\n",
      "421:\tlearn: 1644.5155435\ttotal: 48.8s\tremaining: 1m 6s\n",
      "422:\tlearn: 1644.3152276\ttotal: 48.9s\tremaining: 1m 6s\n",
      "423:\tlearn: 1643.9102824\ttotal: 49.1s\tremaining: 1m 6s\n",
      "424:\tlearn: 1643.5541038\ttotal: 49.2s\tremaining: 1m 6s\n",
      "425:\tlearn: 1643.3594368\ttotal: 49.3s\tremaining: 1m 6s\n",
      "426:\tlearn: 1643.1429044\ttotal: 49.4s\tremaining: 1m 6s\n",
      "427:\tlearn: 1643.0374552\ttotal: 49.5s\tremaining: 1m 6s\n",
      "428:\tlearn: 1642.7870704\ttotal: 49.7s\tremaining: 1m 6s\n",
      "429:\tlearn: 1642.5434664\ttotal: 49.8s\tremaining: 1m 6s\n",
      "430:\tlearn: 1642.1791451\ttotal: 49.9s\tremaining: 1m 5s\n",
      "431:\tlearn: 1642.0722359\ttotal: 50s\tremaining: 1m 5s\n",
      "432:\tlearn: 1641.9100975\ttotal: 50.1s\tremaining: 1m 5s\n",
      "433:\tlearn: 1641.7276883\ttotal: 50.2s\tremaining: 1m 5s\n",
      "434:\tlearn: 1641.5284948\ttotal: 50.4s\tremaining: 1m 5s\n",
      "435:\tlearn: 1641.2170830\ttotal: 50.5s\tremaining: 1m 5s\n",
      "436:\tlearn: 1641.0322177\ttotal: 50.6s\tremaining: 1m 5s\n",
      "437:\tlearn: 1640.8136329\ttotal: 50.7s\tremaining: 1m 5s\n",
      "438:\tlearn: 1640.4971293\ttotal: 50.8s\tremaining: 1m 4s\n",
      "439:\tlearn: 1640.3739795\ttotal: 50.9s\tremaining: 1m 4s\n",
      "440:\tlearn: 1640.0053543\ttotal: 51s\tremaining: 1m 4s\n",
      "441:\tlearn: 1639.8096321\ttotal: 51.1s\tremaining: 1m 4s\n",
      "442:\tlearn: 1639.4540733\ttotal: 51.2s\tremaining: 1m 4s\n",
      "443:\tlearn: 1639.1661483\ttotal: 51.3s\tremaining: 1m 4s\n",
      "444:\tlearn: 1639.0617035\ttotal: 51.4s\tremaining: 1m 4s\n",
      "445:\tlearn: 1638.9344642\ttotal: 51.6s\tremaining: 1m 4s\n",
      "446:\tlearn: 1638.6420742\ttotal: 51.7s\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447:\tlearn: 1638.3814044\ttotal: 51.8s\tremaining: 1m 3s\n",
      "448:\tlearn: 1638.3180058\ttotal: 51.9s\tremaining: 1m 3s\n",
      "449:\tlearn: 1638.0178179\ttotal: 52s\tremaining: 1m 3s\n",
      "450:\tlearn: 1637.6232059\ttotal: 52.1s\tremaining: 1m 3s\n",
      "451:\tlearn: 1637.4235738\ttotal: 52.2s\tremaining: 1m 3s\n",
      "452:\tlearn: 1637.3246491\ttotal: 52.3s\tremaining: 1m 3s\n",
      "453:\tlearn: 1637.1736867\ttotal: 52.4s\tremaining: 1m 3s\n",
      "454:\tlearn: 1636.9745047\ttotal: 52.5s\tremaining: 1m 2s\n",
      "455:\tlearn: 1636.7835553\ttotal: 52.7s\tremaining: 1m 2s\n",
      "456:\tlearn: 1636.5310010\ttotal: 52.8s\tremaining: 1m 2s\n",
      "457:\tlearn: 1636.2553609\ttotal: 52.9s\tremaining: 1m 2s\n",
      "458:\tlearn: 1636.1978783\ttotal: 53s\tremaining: 1m 2s\n",
      "459:\tlearn: 1636.0344700\ttotal: 53.1s\tremaining: 1m 2s\n",
      "460:\tlearn: 1635.7062620\ttotal: 53.2s\tremaining: 1m 2s\n",
      "461:\tlearn: 1635.5428417\ttotal: 53.3s\tremaining: 1m 2s\n",
      "462:\tlearn: 1635.3794161\ttotal: 53.4s\tremaining: 1m 1s\n",
      "463:\tlearn: 1635.0812081\ttotal: 53.6s\tremaining: 1m 1s\n",
      "464:\tlearn: 1635.0419350\ttotal: 53.7s\tremaining: 1m 1s\n",
      "465:\tlearn: 1634.7892916\ttotal: 53.8s\tremaining: 1m 1s\n",
      "466:\tlearn: 1634.5542160\ttotal: 54s\tremaining: 1m 1s\n",
      "467:\tlearn: 1634.1443885\ttotal: 54.1s\tremaining: 1m 1s\n",
      "468:\tlearn: 1634.0901189\ttotal: 54.2s\tremaining: 1m 1s\n",
      "469:\tlearn: 1633.9824260\ttotal: 54.3s\tremaining: 1m 1s\n",
      "470:\tlearn: 1633.7142265\ttotal: 54.4s\tremaining: 1m 1s\n",
      "471:\tlearn: 1633.5235459\ttotal: 54.5s\tremaining: 1m 1s\n",
      "472:\tlearn: 1633.4046390\ttotal: 54.6s\tremaining: 1m\n",
      "473:\tlearn: 1633.0464791\ttotal: 54.8s\tremaining: 1m\n",
      "474:\tlearn: 1632.8345572\ttotal: 54.9s\tremaining: 1m\n",
      "475:\tlearn: 1632.4218542\ttotal: 55s\tremaining: 1m\n",
      "476:\tlearn: 1632.2260242\ttotal: 55.1s\tremaining: 1m\n",
      "477:\tlearn: 1632.1113115\ttotal: 55.3s\tremaining: 1m\n",
      "478:\tlearn: 1631.8932235\ttotal: 55.4s\tremaining: 1m\n",
      "479:\tlearn: 1631.6071875\ttotal: 55.5s\tremaining: 1m\n",
      "480:\tlearn: 1631.4991484\ttotal: 55.6s\tremaining: 60s\n",
      "481:\tlearn: 1631.2597419\ttotal: 55.7s\tremaining: 59.8s\n",
      "482:\tlearn: 1631.0650917\ttotal: 55.8s\tremaining: 59.8s\n",
      "483:\tlearn: 1630.9865369\ttotal: 56s\tremaining: 59.7s\n",
      "484:\tlearn: 1630.7604239\ttotal: 56.1s\tremaining: 59.5s\n",
      "485:\tlearn: 1630.2165668\ttotal: 56.2s\tremaining: 59.4s\n",
      "486:\tlearn: 1629.9576019\ttotal: 56.3s\tremaining: 59.3s\n",
      "487:\tlearn: 1629.7547360\ttotal: 56.4s\tremaining: 59.2s\n",
      "488:\tlearn: 1629.5353902\ttotal: 56.5s\tremaining: 59.1s\n",
      "489:\tlearn: 1629.3057370\ttotal: 56.7s\tremaining: 59s\n",
      "490:\tlearn: 1629.0435157\ttotal: 56.8s\tremaining: 58.9s\n",
      "491:\tlearn: 1628.5618860\ttotal: 56.9s\tremaining: 58.7s\n",
      "492:\tlearn: 1628.3083846\ttotal: 57s\tremaining: 58.6s\n",
      "493:\tlearn: 1628.2980433\ttotal: 57.1s\tremaining: 58.5s\n",
      "494:\tlearn: 1628.1369541\ttotal: 57.3s\tremaining: 58.4s\n",
      "495:\tlearn: 1627.9440772\ttotal: 57.4s\tremaining: 58.3s\n",
      "496:\tlearn: 1627.7539874\ttotal: 57.5s\tremaining: 58.2s\n",
      "497:\tlearn: 1627.7076643\ttotal: 57.6s\tremaining: 58.1s\n",
      "498:\tlearn: 1627.6492897\ttotal: 57.7s\tremaining: 58s\n",
      "499:\tlearn: 1627.4171906\ttotal: 57.8s\tremaining: 57.8s\n",
      "500:\tlearn: 1627.1178010\ttotal: 57.9s\tremaining: 57.7s\n",
      "501:\tlearn: 1626.8220044\ttotal: 58.1s\tremaining: 57.6s\n",
      "502:\tlearn: 1626.7302623\ttotal: 58.2s\tremaining: 57.5s\n",
      "503:\tlearn: 1626.5661817\ttotal: 58.3s\tremaining: 57.3s\n",
      "504:\tlearn: 1626.1278218\ttotal: 58.4s\tremaining: 57.2s\n",
      "505:\tlearn: 1625.9683394\ttotal: 58.5s\tremaining: 57.1s\n",
      "506:\tlearn: 1625.8444874\ttotal: 58.6s\tremaining: 57s\n",
      "507:\tlearn: 1625.5645962\ttotal: 58.8s\tremaining: 56.9s\n",
      "508:\tlearn: 1625.3624133\ttotal: 58.9s\tremaining: 56.8s\n",
      "509:\tlearn: 1625.1583018\ttotal: 59s\tremaining: 56.7s\n",
      "510:\tlearn: 1625.0483682\ttotal: 59.1s\tremaining: 56.6s\n",
      "511:\tlearn: 1624.9144586\ttotal: 59.2s\tremaining: 56.4s\n",
      "512:\tlearn: 1624.8156740\ttotal: 59.3s\tremaining: 56.3s\n",
      "513:\tlearn: 1624.6652461\ttotal: 59.4s\tremaining: 56.2s\n",
      "514:\tlearn: 1624.4861788\ttotal: 59.6s\tremaining: 56.1s\n",
      "515:\tlearn: 1624.1878647\ttotal: 59.7s\tremaining: 56s\n",
      "516:\tlearn: 1623.9133006\ttotal: 59.8s\tremaining: 55.9s\n",
      "517:\tlearn: 1623.7255512\ttotal: 59.9s\tremaining: 55.8s\n",
      "518:\tlearn: 1623.5536675\ttotal: 1m\tremaining: 55.7s\n",
      "519:\tlearn: 1623.4516888\ttotal: 1m\tremaining: 55.6s\n",
      "520:\tlearn: 1623.3379139\ttotal: 1m\tremaining: 55.5s\n",
      "521:\tlearn: 1623.2436189\ttotal: 1m\tremaining: 55.4s\n",
      "522:\tlearn: 1623.1543101\ttotal: 1m\tremaining: 55.2s\n",
      "523:\tlearn: 1622.9473857\ttotal: 1m\tremaining: 55.1s\n",
      "524:\tlearn: 1622.8637561\ttotal: 1m\tremaining: 55s\n",
      "525:\tlearn: 1622.5782128\ttotal: 1m\tremaining: 54.9s\n",
      "526:\tlearn: 1622.5164021\ttotal: 1m 1s\tremaining: 54.8s\n",
      "527:\tlearn: 1622.4174167\ttotal: 1m 1s\tremaining: 54.7s\n",
      "528:\tlearn: 1622.3233099\ttotal: 1m 1s\tremaining: 54.5s\n",
      "529:\tlearn: 1621.9746319\ttotal: 1m 1s\tremaining: 54.4s\n",
      "530:\tlearn: 1621.6214081\ttotal: 1m 1s\tremaining: 54.3s\n",
      "531:\tlearn: 1621.3485215\ttotal: 1m 1s\tremaining: 54.2s\n",
      "532:\tlearn: 1621.3081549\ttotal: 1m 1s\tremaining: 54s\n",
      "533:\tlearn: 1621.1042922\ttotal: 1m 1s\tremaining: 53.9s\n",
      "534:\tlearn: 1620.8961321\ttotal: 1m 1s\tremaining: 53.8s\n",
      "535:\tlearn: 1620.8869577\ttotal: 1m 2s\tremaining: 53.7s\n",
      "536:\tlearn: 1620.6176063\ttotal: 1m 2s\tremaining: 53.6s\n",
      "537:\tlearn: 1620.4611560\ttotal: 1m 2s\tremaining: 53.5s\n",
      "538:\tlearn: 1620.3780487\ttotal: 1m 2s\tremaining: 53.4s\n",
      "539:\tlearn: 1620.3106399\ttotal: 1m 2s\tremaining: 53.3s\n",
      "540:\tlearn: 1620.0943507\ttotal: 1m 2s\tremaining: 53.1s\n",
      "541:\tlearn: 1619.9230326\ttotal: 1m 2s\tremaining: 53s\n",
      "542:\tlearn: 1619.7420779\ttotal: 1m 2s\tremaining: 52.9s\n",
      "543:\tlearn: 1619.6856918\ttotal: 1m 2s\tremaining: 52.8s\n",
      "544:\tlearn: 1619.4297852\ttotal: 1m 3s\tremaining: 52.7s\n",
      "545:\tlearn: 1619.3515927\ttotal: 1m 3s\tremaining: 52.6s\n",
      "546:\tlearn: 1619.1596126\ttotal: 1m 3s\tremaining: 52.4s\n",
      "547:\tlearn: 1619.0174890\ttotal: 1m 3s\tremaining: 52.3s\n",
      "548:\tlearn: 1618.8265623\ttotal: 1m 3s\tremaining: 52.2s\n",
      "549:\tlearn: 1618.7033673\ttotal: 1m 3s\tremaining: 52.1s\n",
      "550:\tlearn: 1618.4689716\ttotal: 1m 3s\tremaining: 52s\n",
      "551:\tlearn: 1618.1936233\ttotal: 1m 3s\tremaining: 51.8s\n",
      "552:\tlearn: 1618.0112432\ttotal: 1m 4s\tremaining: 51.7s\n",
      "553:\tlearn: 1617.7925002\ttotal: 1m 4s\tremaining: 51.6s\n",
      "554:\tlearn: 1617.3451540\ttotal: 1m 4s\tremaining: 51.5s\n",
      "555:\tlearn: 1617.2511490\ttotal: 1m 4s\tremaining: 51.4s\n",
      "556:\tlearn: 1616.9658101\ttotal: 1m 4s\tremaining: 51.3s\n",
      "557:\tlearn: 1616.8633385\ttotal: 1m 4s\tremaining: 51.2s\n",
      "558:\tlearn: 1616.6594718\ttotal: 1m 4s\tremaining: 51.1s\n",
      "559:\tlearn: 1616.5814941\ttotal: 1m 4s\tremaining: 51s\n",
      "560:\tlearn: 1616.3838597\ttotal: 1m 4s\tremaining: 50.9s\n",
      "561:\tlearn: 1616.2046069\ttotal: 1m 5s\tremaining: 50.8s\n",
      "562:\tlearn: 1616.0167798\ttotal: 1m 5s\tremaining: 50.7s\n",
      "563:\tlearn: 1615.8948783\ttotal: 1m 5s\tremaining: 50.5s\n",
      "564:\tlearn: 1615.8544170\ttotal: 1m 5s\tremaining: 50.4s\n",
      "565:\tlearn: 1615.5740127\ttotal: 1m 5s\tremaining: 50.3s\n",
      "566:\tlearn: 1615.3963205\ttotal: 1m 5s\tremaining: 50.2s\n",
      "567:\tlearn: 1615.0783018\ttotal: 1m 5s\tremaining: 50.1s\n",
      "568:\tlearn: 1614.8406315\ttotal: 1m 5s\tremaining: 50s\n",
      "569:\tlearn: 1614.6903562\ttotal: 1m 6s\tremaining: 49.9s\n",
      "570:\tlearn: 1614.4106700\ttotal: 1m 6s\tremaining: 49.7s\n",
      "571:\tlearn: 1614.3514032\ttotal: 1m 6s\tremaining: 49.6s\n",
      "572:\tlearn: 1614.1993561\ttotal: 1m 6s\tremaining: 49.5s\n",
      "573:\tlearn: 1614.0156680\ttotal: 1m 6s\tremaining: 49.4s\n",
      "574:\tlearn: 1613.7201860\ttotal: 1m 6s\tremaining: 49.3s\n",
      "575:\tlearn: 1613.5527692\ttotal: 1m 6s\tremaining: 49.2s\n",
      "576:\tlearn: 1613.4675701\ttotal: 1m 6s\tremaining: 49.1s\n",
      "577:\tlearn: 1613.2873275\ttotal: 1m 6s\tremaining: 48.9s\n",
      "578:\tlearn: 1613.2097110\ttotal: 1m 7s\tremaining: 48.8s\n",
      "579:\tlearn: 1613.1167173\ttotal: 1m 7s\tremaining: 48.7s\n",
      "580:\tlearn: 1613.0332644\ttotal: 1m 7s\tremaining: 48.6s\n",
      "581:\tlearn: 1612.9070705\ttotal: 1m 7s\tremaining: 48.5s\n",
      "582:\tlearn: 1612.6899795\ttotal: 1m 7s\tremaining: 48.4s\n",
      "583:\tlearn: 1612.6562352\ttotal: 1m 7s\tremaining: 48.2s\n",
      "584:\tlearn: 1612.4558048\ttotal: 1m 7s\tremaining: 48.1s\n",
      "585:\tlearn: 1612.4074526\ttotal: 1m 7s\tremaining: 48s\n",
      "586:\tlearn: 1612.2062363\ttotal: 1m 8s\tremaining: 47.9s\n",
      "587:\tlearn: 1612.1785349\ttotal: 1m 8s\tremaining: 47.8s\n",
      "588:\tlearn: 1612.0031981\ttotal: 1m 8s\tremaining: 47.7s\n",
      "589:\tlearn: 1611.9791301\ttotal: 1m 8s\tremaining: 47.6s\n",
      "590:\tlearn: 1611.8302671\ttotal: 1m 8s\tremaining: 47.4s\n",
      "591:\tlearn: 1611.7111214\ttotal: 1m 8s\tremaining: 47.3s\n",
      "592:\tlearn: 1611.4531665\ttotal: 1m 8s\tremaining: 47.2s\n",
      "593:\tlearn: 1611.1489950\ttotal: 1m 8s\tremaining: 47.1s\n",
      "594:\tlearn: 1610.9211590\ttotal: 1m 8s\tremaining: 47s\n",
      "595:\tlearn: 1610.8040896\ttotal: 1m 9s\tremaining: 46.8s\n",
      "596:\tlearn: 1610.6593962\ttotal: 1m 9s\tremaining: 46.7s\n",
      "597:\tlearn: 1610.5169105\ttotal: 1m 9s\tremaining: 46.6s\n",
      "598:\tlearn: 1610.3742200\ttotal: 1m 9s\tremaining: 46.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\tlearn: 1610.2360514\ttotal: 1m 9s\tremaining: 46.4s\n",
      "600:\tlearn: 1610.0608822\ttotal: 1m 9s\tremaining: 46.3s\n",
      "601:\tlearn: 1609.9061932\ttotal: 1m 9s\tremaining: 46.1s\n",
      "602:\tlearn: 1609.8079785\ttotal: 1m 9s\tremaining: 46s\n",
      "603:\tlearn: 1609.6504072\ttotal: 1m 10s\tremaining: 45.9s\n",
      "604:\tlearn: 1609.5115764\ttotal: 1m 10s\tremaining: 45.8s\n",
      "605:\tlearn: 1609.4706802\ttotal: 1m 10s\tremaining: 45.7s\n",
      "606:\tlearn: 1609.3557421\ttotal: 1m 10s\tremaining: 45.6s\n",
      "607:\tlearn: 1609.2292284\ttotal: 1m 10s\tremaining: 45.5s\n",
      "608:\tlearn: 1609.1097706\ttotal: 1m 10s\tremaining: 45.3s\n",
      "609:\tlearn: 1608.9878199\ttotal: 1m 10s\tremaining: 45.2s\n",
      "610:\tlearn: 1608.4535247\ttotal: 1m 10s\tremaining: 45.1s\n",
      "611:\tlearn: 1608.3939507\ttotal: 1m 10s\tremaining: 45s\n",
      "612:\tlearn: 1608.2014276\ttotal: 1m 11s\tremaining: 44.9s\n",
      "613:\tlearn: 1607.5860674\ttotal: 1m 11s\tremaining: 44.8s\n",
      "614:\tlearn: 1607.4530184\ttotal: 1m 11s\tremaining: 44.7s\n",
      "615:\tlearn: 1607.2521250\ttotal: 1m 11s\tremaining: 44.6s\n",
      "616:\tlearn: 1607.1720009\ttotal: 1m 11s\tremaining: 44.5s\n",
      "617:\tlearn: 1606.8460876\ttotal: 1m 11s\tremaining: 44.4s\n",
      "618:\tlearn: 1606.6909325\ttotal: 1m 11s\tremaining: 44.3s\n",
      "619:\tlearn: 1606.6152075\ttotal: 1m 12s\tremaining: 44.2s\n",
      "620:\tlearn: 1606.4561529\ttotal: 1m 12s\tremaining: 44s\n",
      "621:\tlearn: 1606.4354773\ttotal: 1m 12s\tremaining: 43.9s\n",
      "622:\tlearn: 1606.3535481\ttotal: 1m 12s\tremaining: 43.8s\n",
      "623:\tlearn: 1606.0905401\ttotal: 1m 12s\tremaining: 43.7s\n",
      "624:\tlearn: 1606.0493095\ttotal: 1m 12s\tremaining: 43.6s\n",
      "625:\tlearn: 1605.8866931\ttotal: 1m 12s\tremaining: 43.5s\n",
      "626:\tlearn: 1605.7471833\ttotal: 1m 12s\tremaining: 43.4s\n",
      "627:\tlearn: 1605.5638574\ttotal: 1m 13s\tremaining: 43.2s\n",
      "628:\tlearn: 1605.5275351\ttotal: 1m 13s\tremaining: 43.1s\n",
      "629:\tlearn: 1605.3300719\ttotal: 1m 13s\tremaining: 43s\n",
      "630:\tlearn: 1605.2285512\ttotal: 1m 13s\tremaining: 42.9s\n",
      "631:\tlearn: 1605.1108552\ttotal: 1m 13s\tremaining: 42.8s\n",
      "632:\tlearn: 1605.0393400\ttotal: 1m 13s\tremaining: 42.7s\n",
      "633:\tlearn: 1604.9857061\ttotal: 1m 13s\tremaining: 42.6s\n",
      "634:\tlearn: 1604.8629600\ttotal: 1m 13s\tremaining: 42.4s\n",
      "635:\tlearn: 1604.7659149\ttotal: 1m 13s\tremaining: 42.3s\n",
      "636:\tlearn: 1604.5956317\ttotal: 1m 14s\tremaining: 42.2s\n",
      "637:\tlearn: 1604.4143808\ttotal: 1m 14s\tremaining: 42.1s\n",
      "638:\tlearn: 1604.3650451\ttotal: 1m 14s\tremaining: 42s\n",
      "639:\tlearn: 1604.3043814\ttotal: 1m 14s\tremaining: 41.9s\n",
      "640:\tlearn: 1604.1179444\ttotal: 1m 14s\tremaining: 41.7s\n",
      "641:\tlearn: 1603.8679136\ttotal: 1m 14s\tremaining: 41.6s\n",
      "642:\tlearn: 1603.6938614\ttotal: 1m 14s\tremaining: 41.5s\n",
      "643:\tlearn: 1603.5362250\ttotal: 1m 14s\tremaining: 41.4s\n",
      "644:\tlearn: 1603.3901732\ttotal: 1m 15s\tremaining: 41.3s\n",
      "645:\tlearn: 1603.3133488\ttotal: 1m 15s\tremaining: 41.2s\n",
      "646:\tlearn: 1603.2596965\ttotal: 1m 15s\tremaining: 41.1s\n",
      "647:\tlearn: 1603.0764658\ttotal: 1m 15s\tremaining: 40.9s\n",
      "648:\tlearn: 1602.9897859\ttotal: 1m 15s\tremaining: 40.8s\n",
      "649:\tlearn: 1602.8542451\ttotal: 1m 15s\tremaining: 40.7s\n",
      "650:\tlearn: 1602.7900902\ttotal: 1m 15s\tremaining: 40.6s\n",
      "651:\tlearn: 1602.5383435\ttotal: 1m 15s\tremaining: 40.4s\n",
      "652:\tlearn: 1602.2937852\ttotal: 1m 15s\tremaining: 40.3s\n",
      "653:\tlearn: 1602.1704406\ttotal: 1m 16s\tremaining: 40.2s\n",
      "654:\tlearn: 1601.8800673\ttotal: 1m 16s\tremaining: 40.1s\n",
      "655:\tlearn: 1601.7584553\ttotal: 1m 16s\tremaining: 40s\n",
      "656:\tlearn: 1601.5396649\ttotal: 1m 16s\tremaining: 39.9s\n",
      "657:\tlearn: 1601.4142744\ttotal: 1m 16s\tremaining: 39.8s\n",
      "658:\tlearn: 1601.3563340\ttotal: 1m 16s\tremaining: 39.6s\n",
      "659:\tlearn: 1601.2004975\ttotal: 1m 16s\tremaining: 39.5s\n",
      "660:\tlearn: 1601.0482322\ttotal: 1m 16s\tremaining: 39.4s\n",
      "661:\tlearn: 1600.9425957\ttotal: 1m 16s\tremaining: 39.3s\n",
      "662:\tlearn: 1600.8135662\ttotal: 1m 17s\tremaining: 39.1s\n",
      "663:\tlearn: 1600.6076339\ttotal: 1m 17s\tremaining: 39s\n",
      "664:\tlearn: 1600.5888241\ttotal: 1m 17s\tremaining: 38.9s\n",
      "665:\tlearn: 1600.4858829\ttotal: 1m 17s\tremaining: 38.8s\n",
      "666:\tlearn: 1600.3937061\ttotal: 1m 17s\tremaining: 38.7s\n",
      "667:\tlearn: 1600.1885490\ttotal: 1m 17s\tremaining: 38.6s\n",
      "668:\tlearn: 1600.1124514\ttotal: 1m 17s\tremaining: 38.5s\n",
      "669:\tlearn: 1599.9820935\ttotal: 1m 17s\tremaining: 38.3s\n",
      "670:\tlearn: 1599.9059751\ttotal: 1m 17s\tremaining: 38.2s\n",
      "671:\tlearn: 1599.5674367\ttotal: 1m 18s\tremaining: 38.1s\n",
      "672:\tlearn: 1599.5415606\ttotal: 1m 18s\tremaining: 38s\n",
      "673:\tlearn: 1599.3779732\ttotal: 1m 18s\tremaining: 37.9s\n",
      "674:\tlearn: 1599.2913964\ttotal: 1m 18s\tremaining: 37.8s\n",
      "675:\tlearn: 1599.2877927\ttotal: 1m 18s\tremaining: 37.6s\n",
      "676:\tlearn: 1599.1930388\ttotal: 1m 18s\tremaining: 37.5s\n",
      "677:\tlearn: 1599.0287945\ttotal: 1m 18s\tremaining: 37.4s\n",
      "678:\tlearn: 1598.8711911\ttotal: 1m 18s\tremaining: 37.3s\n",
      "679:\tlearn: 1598.6252562\ttotal: 1m 18s\tremaining: 37.2s\n",
      "680:\tlearn: 1598.4900429\ttotal: 1m 19s\tremaining: 37s\n",
      "681:\tlearn: 1598.3640052\ttotal: 1m 19s\tremaining: 36.9s\n",
      "682:\tlearn: 1598.2061818\ttotal: 1m 19s\tremaining: 36.8s\n",
      "683:\tlearn: 1598.1082598\ttotal: 1m 19s\tremaining: 36.7s\n",
      "684:\tlearn: 1597.9970713\ttotal: 1m 19s\tremaining: 36.6s\n",
      "685:\tlearn: 1597.9224087\ttotal: 1m 19s\tremaining: 36.5s\n",
      "686:\tlearn: 1597.7836110\ttotal: 1m 19s\tremaining: 36.4s\n",
      "687:\tlearn: 1597.7004596\ttotal: 1m 19s\tremaining: 36.3s\n",
      "688:\tlearn: 1597.6972770\ttotal: 1m 20s\tremaining: 36.1s\n",
      "689:\tlearn: 1597.4869056\ttotal: 1m 20s\tremaining: 36s\n",
      "690:\tlearn: 1597.4239021\ttotal: 1m 20s\tremaining: 35.9s\n",
      "691:\tlearn: 1597.1833246\ttotal: 1m 20s\tremaining: 35.8s\n",
      "692:\tlearn: 1597.0568839\ttotal: 1m 20s\tremaining: 35.7s\n",
      "693:\tlearn: 1596.9812175\ttotal: 1m 20s\tremaining: 35.6s\n",
      "694:\tlearn: 1596.8143297\ttotal: 1m 20s\tremaining: 35.5s\n",
      "695:\tlearn: 1596.6781922\ttotal: 1m 20s\tremaining: 35.4s\n",
      "696:\tlearn: 1596.4778986\ttotal: 1m 21s\tremaining: 35.2s\n",
      "697:\tlearn: 1596.3160729\ttotal: 1m 21s\tremaining: 35.1s\n",
      "698:\tlearn: 1596.2481589\ttotal: 1m 21s\tremaining: 35s\n",
      "699:\tlearn: 1596.2058840\ttotal: 1m 21s\tremaining: 34.9s\n",
      "700:\tlearn: 1596.0981123\ttotal: 1m 21s\tremaining: 34.8s\n",
      "701:\tlearn: 1595.9741872\ttotal: 1m 21s\tremaining: 34.6s\n",
      "702:\tlearn: 1595.8837357\ttotal: 1m 21s\tremaining: 34.5s\n",
      "703:\tlearn: 1595.6983434\ttotal: 1m 21s\tremaining: 34.4s\n",
      "704:\tlearn: 1595.5664438\ttotal: 1m 21s\tremaining: 34.3s\n",
      "705:\tlearn: 1595.3449020\ttotal: 1m 22s\tremaining: 34.2s\n",
      "706:\tlearn: 1595.2803001\ttotal: 1m 22s\tremaining: 34.1s\n",
      "707:\tlearn: 1595.1827798\ttotal: 1m 22s\tremaining: 33.9s\n",
      "708:\tlearn: 1595.1489402\ttotal: 1m 22s\tremaining: 33.8s\n",
      "709:\tlearn: 1595.0061557\ttotal: 1m 22s\tremaining: 33.7s\n",
      "710:\tlearn: 1594.9286731\ttotal: 1m 22s\tremaining: 33.6s\n",
      "711:\tlearn: 1594.8304970\ttotal: 1m 22s\tremaining: 33.5s\n",
      "712:\tlearn: 1594.6887666\ttotal: 1m 22s\tremaining: 33.4s\n",
      "713:\tlearn: 1594.5918469\ttotal: 1m 23s\tremaining: 33.3s\n",
      "714:\tlearn: 1594.4822559\ttotal: 1m 23s\tremaining: 33.1s\n",
      "715:\tlearn: 1594.2696590\ttotal: 1m 23s\tremaining: 33s\n",
      "716:\tlearn: 1594.0454129\ttotal: 1m 23s\tremaining: 32.9s\n",
      "717:\tlearn: 1593.9138111\ttotal: 1m 23s\tremaining: 32.8s\n",
      "718:\tlearn: 1593.8587922\ttotal: 1m 23s\tremaining: 32.7s\n",
      "719:\tlearn: 1593.6894431\ttotal: 1m 23s\tremaining: 32.5s\n",
      "720:\tlearn: 1593.6449177\ttotal: 1m 23s\tremaining: 32.4s\n",
      "721:\tlearn: 1593.5991076\ttotal: 1m 23s\tremaining: 32.3s\n",
      "722:\tlearn: 1593.4889725\ttotal: 1m 24s\tremaining: 32.2s\n",
      "723:\tlearn: 1593.2803172\ttotal: 1m 24s\tremaining: 32.1s\n",
      "724:\tlearn: 1593.2772410\ttotal: 1m 24s\tremaining: 32s\n",
      "725:\tlearn: 1593.0564423\ttotal: 1m 24s\tremaining: 31.8s\n",
      "726:\tlearn: 1592.8881408\ttotal: 1m 24s\tremaining: 31.7s\n",
      "727:\tlearn: 1592.7794684\ttotal: 1m 24s\tremaining: 31.6s\n",
      "728:\tlearn: 1592.6104816\ttotal: 1m 24s\tremaining: 31.5s\n",
      "729:\tlearn: 1592.5079608\ttotal: 1m 24s\tremaining: 31.4s\n",
      "730:\tlearn: 1592.3925183\ttotal: 1m 24s\tremaining: 31.3s\n",
      "731:\tlearn: 1592.2158597\ttotal: 1m 25s\tremaining: 31.2s\n",
      "732:\tlearn: 1592.0572652\ttotal: 1m 25s\tremaining: 31s\n",
      "733:\tlearn: 1591.8147950\ttotal: 1m 25s\tremaining: 30.9s\n",
      "734:\tlearn: 1591.6114606\ttotal: 1m 25s\tremaining: 30.8s\n",
      "735:\tlearn: 1591.4794530\ttotal: 1m 25s\tremaining: 30.7s\n",
      "736:\tlearn: 1591.3658963\ttotal: 1m 25s\tremaining: 30.6s\n",
      "737:\tlearn: 1591.2827453\ttotal: 1m 25s\tremaining: 30.5s\n",
      "738:\tlearn: 1591.1891849\ttotal: 1m 25s\tremaining: 30.3s\n",
      "739:\tlearn: 1590.9804661\ttotal: 1m 26s\tremaining: 30.2s\n",
      "740:\tlearn: 1590.7300471\ttotal: 1m 26s\tremaining: 30.1s\n",
      "741:\tlearn: 1590.6364926\ttotal: 1m 26s\tremaining: 30s\n",
      "742:\tlearn: 1590.5131063\ttotal: 1m 26s\tremaining: 29.9s\n",
      "743:\tlearn: 1590.3911868\ttotal: 1m 26s\tremaining: 29.8s\n",
      "744:\tlearn: 1590.3442302\ttotal: 1m 26s\tremaining: 29.7s\n",
      "745:\tlearn: 1590.2920654\ttotal: 1m 26s\tremaining: 29.5s\n",
      "746:\tlearn: 1590.1335034\ttotal: 1m 26s\tremaining: 29.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747:\tlearn: 1590.0963810\ttotal: 1m 27s\tremaining: 29.3s\n",
      "748:\tlearn: 1590.0124110\ttotal: 1m 27s\tremaining: 29.2s\n",
      "749:\tlearn: 1589.9273963\ttotal: 1m 27s\tremaining: 29.1s\n",
      "750:\tlearn: 1589.8170824\ttotal: 1m 27s\tremaining: 29s\n",
      "751:\tlearn: 1589.6432870\ttotal: 1m 27s\tremaining: 28.9s\n",
      "752:\tlearn: 1589.5324092\ttotal: 1m 27s\tremaining: 28.8s\n",
      "753:\tlearn: 1589.4213027\ttotal: 1m 27s\tremaining: 28.7s\n",
      "754:\tlearn: 1589.2598193\ttotal: 1m 27s\tremaining: 28.5s\n",
      "755:\tlearn: 1589.0783426\ttotal: 1m 28s\tremaining: 28.4s\n",
      "756:\tlearn: 1588.9631810\ttotal: 1m 28s\tremaining: 28.3s\n",
      "757:\tlearn: 1588.8944753\ttotal: 1m 28s\tremaining: 28.2s\n",
      "758:\tlearn: 1588.7684629\ttotal: 1m 28s\tremaining: 28.1s\n",
      "759:\tlearn: 1588.6523402\ttotal: 1m 28s\tremaining: 28s\n",
      "760:\tlearn: 1588.4886654\ttotal: 1m 28s\tremaining: 27.9s\n",
      "761:\tlearn: 1588.4428083\ttotal: 1m 28s\tremaining: 27.8s\n",
      "762:\tlearn: 1588.3250326\ttotal: 1m 28s\tremaining: 27.6s\n",
      "763:\tlearn: 1588.2142500\ttotal: 1m 29s\tremaining: 27.5s\n",
      "764:\tlearn: 1588.1659973\ttotal: 1m 29s\tremaining: 27.4s\n",
      "765:\tlearn: 1588.1150341\ttotal: 1m 29s\tremaining: 27.3s\n",
      "766:\tlearn: 1587.8844844\ttotal: 1m 29s\tremaining: 27.2s\n",
      "767:\tlearn: 1587.7863139\ttotal: 1m 29s\tremaining: 27s\n",
      "768:\tlearn: 1587.7447764\ttotal: 1m 29s\tremaining: 26.9s\n",
      "769:\tlearn: 1587.7045614\ttotal: 1m 29s\tremaining: 26.8s\n",
      "770:\tlearn: 1587.6427694\ttotal: 1m 29s\tremaining: 26.7s\n",
      "771:\tlearn: 1587.5226295\ttotal: 1m 30s\tremaining: 26.6s\n",
      "772:\tlearn: 1587.3203881\ttotal: 1m 30s\tremaining: 26.5s\n",
      "773:\tlearn: 1587.0846028\ttotal: 1m 30s\tremaining: 26.4s\n",
      "774:\tlearn: 1586.9850301\ttotal: 1m 30s\tremaining: 26.2s\n",
      "775:\tlearn: 1586.8131700\ttotal: 1m 30s\tremaining: 26.1s\n",
      "776:\tlearn: 1586.6142431\ttotal: 1m 30s\tremaining: 26s\n",
      "777:\tlearn: 1586.6107260\ttotal: 1m 30s\tremaining: 25.9s\n",
      "778:\tlearn: 1586.5274405\ttotal: 1m 30s\tremaining: 25.8s\n",
      "779:\tlearn: 1586.4287415\ttotal: 1m 30s\tremaining: 25.6s\n",
      "780:\tlearn: 1586.3069764\ttotal: 1m 31s\tremaining: 25.5s\n",
      "781:\tlearn: 1586.2449276\ttotal: 1m 31s\tremaining: 25.4s\n",
      "782:\tlearn: 1586.0900782\ttotal: 1m 31s\tremaining: 25.3s\n",
      "783:\tlearn: 1585.9922126\ttotal: 1m 31s\tremaining: 25.2s\n",
      "784:\tlearn: 1585.9552421\ttotal: 1m 31s\tremaining: 25s\n",
      "785:\tlearn: 1585.8624981\ttotal: 1m 31s\tremaining: 24.9s\n",
      "786:\tlearn: 1585.7989704\ttotal: 1m 31s\tremaining: 24.8s\n",
      "787:\tlearn: 1585.6802648\ttotal: 1m 31s\tremaining: 24.7s\n",
      "788:\tlearn: 1585.5348841\ttotal: 1m 31s\tremaining: 24.6s\n",
      "789:\tlearn: 1585.4338786\ttotal: 1m 32s\tremaining: 24.5s\n",
      "790:\tlearn: 1585.2809925\ttotal: 1m 32s\tremaining: 24.3s\n",
      "791:\tlearn: 1585.1871670\ttotal: 1m 32s\tremaining: 24.2s\n",
      "792:\tlearn: 1585.0059027\ttotal: 1m 32s\tremaining: 24.1s\n",
      "793:\tlearn: 1584.8816780\ttotal: 1m 32s\tremaining: 24s\n",
      "794:\tlearn: 1584.8528110\ttotal: 1m 32s\tremaining: 23.9s\n",
      "795:\tlearn: 1584.6643461\ttotal: 1m 32s\tremaining: 23.8s\n",
      "796:\tlearn: 1584.6074003\ttotal: 1m 32s\tremaining: 23.7s\n",
      "797:\tlearn: 1584.4562065\ttotal: 1m 33s\tremaining: 23.6s\n",
      "798:\tlearn: 1584.3758590\ttotal: 1m 33s\tremaining: 23.4s\n",
      "799:\tlearn: 1584.1987790\ttotal: 1m 33s\tremaining: 23.3s\n",
      "800:\tlearn: 1584.0483448\ttotal: 1m 33s\tremaining: 23.2s\n",
      "801:\tlearn: 1583.8708790\ttotal: 1m 33s\tremaining: 23.1s\n",
      "802:\tlearn: 1583.7045640\ttotal: 1m 33s\tremaining: 23s\n",
      "803:\tlearn: 1583.6352902\ttotal: 1m 33s\tremaining: 22.9s\n",
      "804:\tlearn: 1583.6132159\ttotal: 1m 33s\tremaining: 22.7s\n",
      "805:\tlearn: 1583.3990224\ttotal: 1m 34s\tremaining: 22.6s\n",
      "806:\tlearn: 1583.2679871\ttotal: 1m 34s\tremaining: 22.5s\n",
      "807:\tlearn: 1583.0984360\ttotal: 1m 34s\tremaining: 22.4s\n",
      "808:\tlearn: 1582.9588685\ttotal: 1m 34s\tremaining: 22.3s\n",
      "809:\tlearn: 1582.7578983\ttotal: 1m 34s\tremaining: 22.2s\n",
      "810:\tlearn: 1582.6863937\ttotal: 1m 34s\tremaining: 22.1s\n",
      "811:\tlearn: 1582.5173190\ttotal: 1m 34s\tremaining: 21.9s\n",
      "812:\tlearn: 1582.4603476\ttotal: 1m 34s\tremaining: 21.8s\n",
      "813:\tlearn: 1582.4268714\ttotal: 1m 35s\tremaining: 21.7s\n",
      "814:\tlearn: 1582.3044180\ttotal: 1m 35s\tremaining: 21.6s\n",
      "815:\tlearn: 1582.2431653\ttotal: 1m 35s\tremaining: 21.5s\n",
      "816:\tlearn: 1582.0613505\ttotal: 1m 35s\tremaining: 21.4s\n",
      "817:\tlearn: 1582.0301343\ttotal: 1m 35s\tremaining: 21.2s\n",
      "818:\tlearn: 1581.9224686\ttotal: 1m 35s\tremaining: 21.1s\n",
      "819:\tlearn: 1581.8737649\ttotal: 1m 35s\tremaining: 21s\n",
      "820:\tlearn: 1581.6329463\ttotal: 1m 35s\tremaining: 20.9s\n",
      "821:\tlearn: 1581.4553178\ttotal: 1m 35s\tremaining: 20.8s\n",
      "822:\tlearn: 1581.3700225\ttotal: 1m 36s\tremaining: 20.7s\n",
      "823:\tlearn: 1581.3116706\ttotal: 1m 36s\tremaining: 20.5s\n",
      "824:\tlearn: 1581.1501831\ttotal: 1m 36s\tremaining: 20.4s\n",
      "825:\tlearn: 1581.0391887\ttotal: 1m 36s\tremaining: 20.3s\n",
      "826:\tlearn: 1580.8523639\ttotal: 1m 36s\tremaining: 20.2s\n",
      "827:\tlearn: 1580.7274969\ttotal: 1m 36s\tremaining: 20s\n",
      "828:\tlearn: 1580.5746723\ttotal: 1m 36s\tremaining: 19.9s\n",
      "829:\tlearn: 1580.2782952\ttotal: 1m 36s\tremaining: 19.8s\n",
      "830:\tlearn: 1580.0187731\ttotal: 1m 36s\tremaining: 19.7s\n",
      "831:\tlearn: 1579.9349324\ttotal: 1m 36s\tremaining: 19.6s\n",
      "832:\tlearn: 1579.8331663\ttotal: 1m 37s\tremaining: 19.5s\n",
      "833:\tlearn: 1579.8185476\ttotal: 1m 37s\tremaining: 19.4s\n",
      "834:\tlearn: 1579.7336481\ttotal: 1m 37s\tremaining: 19.2s\n",
      "835:\tlearn: 1579.6574299\ttotal: 1m 37s\tremaining: 19.1s\n",
      "836:\tlearn: 1579.5377100\ttotal: 1m 37s\tremaining: 19s\n",
      "837:\tlearn: 1579.4466567\ttotal: 1m 37s\tremaining: 18.9s\n",
      "838:\tlearn: 1579.3538110\ttotal: 1m 37s\tremaining: 18.8s\n",
      "839:\tlearn: 1579.2372421\ttotal: 1m 37s\tremaining: 18.6s\n",
      "840:\tlearn: 1579.2033910\ttotal: 1m 37s\tremaining: 18.5s\n",
      "841:\tlearn: 1579.1696621\ttotal: 1m 38s\tremaining: 18.4s\n",
      "842:\tlearn: 1578.9362961\ttotal: 1m 38s\tremaining: 18.3s\n",
      "843:\tlearn: 1578.8006158\ttotal: 1m 38s\tremaining: 18.2s\n",
      "844:\tlearn: 1578.8005977\ttotal: 1m 38s\tremaining: 18.1s\n",
      "845:\tlearn: 1578.7250005\ttotal: 1m 38s\tremaining: 17.9s\n",
      "846:\tlearn: 1578.5805231\ttotal: 1m 38s\tremaining: 17.8s\n",
      "847:\tlearn: 1578.4394630\ttotal: 1m 38s\tremaining: 17.7s\n",
      "848:\tlearn: 1578.3411482\ttotal: 1m 38s\tremaining: 17.6s\n",
      "849:\tlearn: 1578.2110020\ttotal: 1m 39s\tremaining: 17.5s\n",
      "850:\tlearn: 1578.0779555\ttotal: 1m 39s\tremaining: 17.4s\n",
      "851:\tlearn: 1578.0465968\ttotal: 1m 39s\tremaining: 17.2s\n",
      "852:\tlearn: 1577.9532664\ttotal: 1m 39s\tremaining: 17.1s\n",
      "853:\tlearn: 1577.8873353\ttotal: 1m 39s\tremaining: 17s\n",
      "854:\tlearn: 1577.7558593\ttotal: 1m 39s\tremaining: 16.9s\n",
      "855:\tlearn: 1577.6888366\ttotal: 1m 39s\tremaining: 16.8s\n",
      "856:\tlearn: 1577.6635558\ttotal: 1m 39s\tremaining: 16.7s\n",
      "857:\tlearn: 1577.5786342\ttotal: 1m 39s\tremaining: 16.5s\n",
      "858:\tlearn: 1577.4347259\ttotal: 1m 40s\tremaining: 16.4s\n",
      "859:\tlearn: 1577.3380339\ttotal: 1m 40s\tremaining: 16.3s\n",
      "860:\tlearn: 1577.3044381\ttotal: 1m 40s\tremaining: 16.2s\n",
      "861:\tlearn: 1577.2228027\ttotal: 1m 40s\tremaining: 16.1s\n",
      "862:\tlearn: 1577.0320404\ttotal: 1m 40s\tremaining: 16s\n",
      "863:\tlearn: 1576.9024262\ttotal: 1m 40s\tremaining: 15.8s\n",
      "864:\tlearn: 1576.6944386\ttotal: 1m 40s\tremaining: 15.7s\n",
      "865:\tlearn: 1576.6167418\ttotal: 1m 40s\tremaining: 15.6s\n",
      "866:\tlearn: 1576.5646480\ttotal: 1m 41s\tremaining: 15.5s\n",
      "867:\tlearn: 1576.4383532\ttotal: 1m 41s\tremaining: 15.4s\n",
      "868:\tlearn: 1576.3915708\ttotal: 1m 41s\tremaining: 15.3s\n",
      "869:\tlearn: 1576.3134658\ttotal: 1m 41s\tremaining: 15.2s\n",
      "870:\tlearn: 1576.1776892\ttotal: 1m 41s\tremaining: 15s\n",
      "871:\tlearn: 1576.0800669\ttotal: 1m 41s\tremaining: 14.9s\n",
      "872:\tlearn: 1576.0034923\ttotal: 1m 41s\tremaining: 14.8s\n",
      "873:\tlearn: 1575.9222296\ttotal: 1m 41s\tremaining: 14.7s\n",
      "874:\tlearn: 1575.8582410\ttotal: 1m 42s\tremaining: 14.6s\n",
      "875:\tlearn: 1575.7322956\ttotal: 1m 42s\tremaining: 14.5s\n",
      "876:\tlearn: 1575.4434661\ttotal: 1m 42s\tremaining: 14.3s\n",
      "877:\tlearn: 1575.3884575\ttotal: 1m 42s\tremaining: 14.2s\n",
      "878:\tlearn: 1575.3638665\ttotal: 1m 42s\tremaining: 14.1s\n",
      "879:\tlearn: 1575.3239793\ttotal: 1m 42s\tremaining: 14s\n",
      "880:\tlearn: 1575.2745525\ttotal: 1m 42s\tremaining: 13.9s\n",
      "881:\tlearn: 1575.1731547\ttotal: 1m 42s\tremaining: 13.8s\n",
      "882:\tlearn: 1575.1059878\ttotal: 1m 43s\tremaining: 13.7s\n",
      "883:\tlearn: 1575.0529353\ttotal: 1m 43s\tremaining: 13.5s\n",
      "884:\tlearn: 1574.9900271\ttotal: 1m 43s\tremaining: 13.4s\n",
      "885:\tlearn: 1574.9789542\ttotal: 1m 43s\tremaining: 13.3s\n",
      "886:\tlearn: 1574.9370249\ttotal: 1m 43s\tremaining: 13.2s\n",
      "887:\tlearn: 1574.8712806\ttotal: 1m 43s\tremaining: 13.1s\n",
      "888:\tlearn: 1574.7635508\ttotal: 1m 43s\tremaining: 13s\n",
      "889:\tlearn: 1574.5917667\ttotal: 1m 43s\tremaining: 12.8s\n",
      "890:\tlearn: 1574.4480027\ttotal: 1m 44s\tremaining: 12.7s\n",
      "891:\tlearn: 1574.3367107\ttotal: 1m 44s\tremaining: 12.6s\n",
      "892:\tlearn: 1574.2326164\ttotal: 1m 44s\tremaining: 12.5s\n",
      "893:\tlearn: 1574.0892702\ttotal: 1m 44s\tremaining: 12.4s\n",
      "894:\tlearn: 1573.8976942\ttotal: 1m 44s\tremaining: 12.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895:\tlearn: 1573.8883645\ttotal: 1m 44s\tremaining: 12.1s\n",
      "896:\tlearn: 1573.7703798\ttotal: 1m 44s\tremaining: 12s\n",
      "897:\tlearn: 1573.6600979\ttotal: 1m 44s\tremaining: 11.9s\n",
      "898:\tlearn: 1573.6052971\ttotal: 1m 45s\tremaining: 11.8s\n",
      "899:\tlearn: 1573.4666728\ttotal: 1m 45s\tremaining: 11.7s\n",
      "900:\tlearn: 1573.3026022\ttotal: 1m 45s\tremaining: 11.6s\n",
      "901:\tlearn: 1573.2226607\ttotal: 1m 45s\tremaining: 11.4s\n",
      "902:\tlearn: 1573.1045404\ttotal: 1m 45s\tremaining: 11.3s\n",
      "903:\tlearn: 1573.0982174\ttotal: 1m 45s\tremaining: 11.2s\n",
      "904:\tlearn: 1572.9478692\ttotal: 1m 45s\tremaining: 11.1s\n",
      "905:\tlearn: 1572.8670233\ttotal: 1m 45s\tremaining: 11s\n",
      "906:\tlearn: 1572.7487707\ttotal: 1m 45s\tremaining: 10.9s\n",
      "907:\tlearn: 1572.5611497\ttotal: 1m 46s\tremaining: 10.8s\n",
      "908:\tlearn: 1572.4655479\ttotal: 1m 46s\tremaining: 10.6s\n",
      "909:\tlearn: 1572.3344193\ttotal: 1m 46s\tremaining: 10.5s\n",
      "910:\tlearn: 1572.2030353\ttotal: 1m 46s\tremaining: 10.4s\n",
      "911:\tlearn: 1572.1359893\ttotal: 1m 46s\tremaining: 10.3s\n",
      "912:\tlearn: 1571.8700577\ttotal: 1m 46s\tremaining: 10.2s\n",
      "913:\tlearn: 1571.8060638\ttotal: 1m 46s\tremaining: 10.1s\n",
      "914:\tlearn: 1571.6817473\ttotal: 1m 47s\tremaining: 9.94s\n",
      "915:\tlearn: 1571.5429849\ttotal: 1m 47s\tremaining: 9.83s\n",
      "916:\tlearn: 1571.3625490\ttotal: 1m 47s\tremaining: 9.71s\n",
      "917:\tlearn: 1571.3295439\ttotal: 1m 47s\tremaining: 9.6s\n",
      "918:\tlearn: 1571.2019361\ttotal: 1m 47s\tremaining: 9.48s\n",
      "919:\tlearn: 1571.1305515\ttotal: 1m 47s\tremaining: 9.36s\n",
      "920:\tlearn: 1571.0206656\ttotal: 1m 47s\tremaining: 9.25s\n",
      "921:\tlearn: 1570.9660671\ttotal: 1m 47s\tremaining: 9.13s\n",
      "922:\tlearn: 1570.9146551\ttotal: 1m 48s\tremaining: 9.01s\n",
      "923:\tlearn: 1570.6841888\ttotal: 1m 48s\tremaining: 8.9s\n",
      "924:\tlearn: 1570.5682789\ttotal: 1m 48s\tremaining: 8.78s\n",
      "925:\tlearn: 1570.4163717\ttotal: 1m 48s\tremaining: 8.66s\n",
      "926:\tlearn: 1570.3065581\ttotal: 1m 48s\tremaining: 8.55s\n",
      "927:\tlearn: 1570.2267199\ttotal: 1m 48s\tremaining: 8.43s\n",
      "928:\tlearn: 1570.2029194\ttotal: 1m 48s\tremaining: 8.31s\n",
      "929:\tlearn: 1569.9960602\ttotal: 1m 48s\tremaining: 8.2s\n",
      "930:\tlearn: 1569.9412066\ttotal: 1m 49s\tremaining: 8.08s\n",
      "931:\tlearn: 1569.8080029\ttotal: 1m 49s\tremaining: 7.96s\n",
      "932:\tlearn: 1569.7269058\ttotal: 1m 49s\tremaining: 7.85s\n",
      "933:\tlearn: 1569.6296729\ttotal: 1m 49s\tremaining: 7.74s\n",
      "934:\tlearn: 1569.5960500\ttotal: 1m 49s\tremaining: 7.62s\n",
      "935:\tlearn: 1569.5248530\ttotal: 1m 49s\tremaining: 7.5s\n",
      "936:\tlearn: 1569.4932787\ttotal: 1m 49s\tremaining: 7.38s\n",
      "937:\tlearn: 1569.4031936\ttotal: 1m 49s\tremaining: 7.27s\n",
      "938:\tlearn: 1569.3461895\ttotal: 1m 50s\tremaining: 7.15s\n",
      "939:\tlearn: 1569.3093951\ttotal: 1m 50s\tremaining: 7.04s\n",
      "940:\tlearn: 1569.2401484\ttotal: 1m 50s\tremaining: 6.92s\n",
      "941:\tlearn: 1569.0788583\ttotal: 1m 50s\tremaining: 6.8s\n",
      "942:\tlearn: 1569.0101260\ttotal: 1m 50s\tremaining: 6.68s\n",
      "943:\tlearn: 1568.9650332\ttotal: 1m 50s\tremaining: 6.57s\n",
      "944:\tlearn: 1568.8681004\ttotal: 1m 50s\tremaining: 6.45s\n",
      "945:\tlearn: 1568.7390860\ttotal: 1m 50s\tremaining: 6.33s\n",
      "946:\tlearn: 1568.5456195\ttotal: 1m 51s\tremaining: 6.21s\n",
      "947:\tlearn: 1568.4819564\ttotal: 1m 51s\tremaining: 6.1s\n",
      "948:\tlearn: 1568.3624776\ttotal: 1m 51s\tremaining: 5.98s\n",
      "949:\tlearn: 1568.2292345\ttotal: 1m 51s\tremaining: 5.87s\n",
      "950:\tlearn: 1568.1362166\ttotal: 1m 51s\tremaining: 5.75s\n",
      "951:\tlearn: 1567.9643486\ttotal: 1m 51s\tremaining: 5.64s\n",
      "952:\tlearn: 1567.8462643\ttotal: 1m 51s\tremaining: 5.52s\n",
      "953:\tlearn: 1567.7514022\ttotal: 1m 52s\tremaining: 5.4s\n",
      "954:\tlearn: 1567.6532246\ttotal: 1m 52s\tremaining: 5.29s\n",
      "955:\tlearn: 1567.4745593\ttotal: 1m 52s\tremaining: 5.17s\n",
      "956:\tlearn: 1567.4387556\ttotal: 1m 52s\tremaining: 5.05s\n",
      "957:\tlearn: 1567.3504641\ttotal: 1m 52s\tremaining: 4.94s\n",
      "958:\tlearn: 1567.3252433\ttotal: 1m 52s\tremaining: 4.82s\n",
      "959:\tlearn: 1567.2597304\ttotal: 1m 52s\tremaining: 4.7s\n",
      "960:\tlearn: 1567.2178317\ttotal: 1m 53s\tremaining: 4.59s\n",
      "961:\tlearn: 1567.1804022\ttotal: 1m 53s\tremaining: 4.47s\n",
      "962:\tlearn: 1567.0707367\ttotal: 1m 53s\tremaining: 4.35s\n",
      "963:\tlearn: 1566.9652237\ttotal: 1m 53s\tremaining: 4.24s\n",
      "964:\tlearn: 1566.8665679\ttotal: 1m 53s\tremaining: 4.12s\n",
      "965:\tlearn: 1566.7361579\ttotal: 1m 53s\tremaining: 4s\n",
      "966:\tlearn: 1566.6532480\ttotal: 1m 53s\tremaining: 3.88s\n",
      "967:\tlearn: 1566.5728957\ttotal: 1m 54s\tremaining: 3.77s\n",
      "968:\tlearn: 1566.4369782\ttotal: 1m 54s\tremaining: 3.65s\n",
      "969:\tlearn: 1566.3539793\ttotal: 1m 54s\tremaining: 3.54s\n",
      "970:\tlearn: 1566.2085987\ttotal: 1m 54s\tremaining: 3.42s\n",
      "971:\tlearn: 1566.1353426\ttotal: 1m 54s\tremaining: 3.3s\n",
      "972:\tlearn: 1566.0613452\ttotal: 1m 54s\tremaining: 3.19s\n",
      "973:\tlearn: 1565.9433727\ttotal: 1m 54s\tremaining: 3.07s\n",
      "974:\tlearn: 1565.8629556\ttotal: 1m 55s\tremaining: 2.95s\n",
      "975:\tlearn: 1565.8292351\ttotal: 1m 55s\tremaining: 2.83s\n",
      "976:\tlearn: 1565.7649363\ttotal: 1m 55s\tremaining: 2.71s\n",
      "977:\tlearn: 1565.6717723\ttotal: 1m 55s\tremaining: 2.6s\n",
      "978:\tlearn: 1565.5742342\ttotal: 1m 55s\tremaining: 2.48s\n",
      "979:\tlearn: 1565.5172695\ttotal: 1m 55s\tremaining: 2.36s\n",
      "980:\tlearn: 1565.3170196\ttotal: 1m 55s\tremaining: 2.24s\n",
      "981:\tlearn: 1565.2919147\ttotal: 1m 55s\tremaining: 2.13s\n",
      "982:\tlearn: 1565.2363478\ttotal: 1m 56s\tremaining: 2.01s\n",
      "983:\tlearn: 1565.1664302\ttotal: 1m 56s\tremaining: 1.89s\n",
      "984:\tlearn: 1565.0969182\ttotal: 1m 56s\tremaining: 1.77s\n",
      "985:\tlearn: 1564.9986669\ttotal: 1m 56s\tremaining: 1.65s\n",
      "986:\tlearn: 1564.9886908\ttotal: 1m 56s\tremaining: 1.54s\n",
      "987:\tlearn: 1564.8501818\ttotal: 1m 56s\tremaining: 1.42s\n",
      "988:\tlearn: 1564.7565793\ttotal: 1m 56s\tremaining: 1.3s\n",
      "989:\tlearn: 1564.6152333\ttotal: 1m 57s\tremaining: 1.18s\n",
      "990:\tlearn: 1564.4496966\ttotal: 1m 57s\tremaining: 1.06s\n",
      "991:\tlearn: 1564.3911037\ttotal: 1m 57s\tremaining: 947ms\n",
      "992:\tlearn: 1564.3445972\ttotal: 1m 57s\tremaining: 829ms\n",
      "993:\tlearn: 1564.2728969\ttotal: 1m 57s\tremaining: 711ms\n",
      "994:\tlearn: 1564.2512687\ttotal: 1m 57s\tremaining: 592ms\n",
      "995:\tlearn: 1564.1808523\ttotal: 1m 58s\tremaining: 474ms\n",
      "996:\tlearn: 1564.1537279\ttotal: 1m 58s\tremaining: 356ms\n",
      "997:\tlearn: 1564.0699695\ttotal: 1m 58s\tremaining: 237ms\n",
      "998:\tlearn: 1564.0076971\ttotal: 1m 58s\tremaining: 119ms\n",
      "999:\tlearn: 1563.9326497\ttotal: 1m 58s\tremaining: 0us\n",
      "Learning rate set to 0.094301\n",
      "0:\tlearn: 4422.5950730\ttotal: 169ms\tremaining: 2m 48s\n",
      "1:\tlearn: 4157.6339522\ttotal: 366ms\tremaining: 3m 2s\n",
      "2:\tlearn: 3923.0482026\ttotal: 502ms\tremaining: 2m 46s\n",
      "3:\tlearn: 3714.2248379\ttotal: 634ms\tremaining: 2m 37s\n",
      "4:\tlearn: 3527.0575214\ttotal: 797ms\tremaining: 2m 38s\n",
      "5:\tlearn: 3354.2568226\ttotal: 923ms\tremaining: 2m 32s\n",
      "6:\tlearn: 3203.9956035\ttotal: 1.05s\tremaining: 2m 29s\n",
      "7:\tlearn: 3073.3529873\ttotal: 1.18s\tremaining: 2m 26s\n",
      "8:\tlearn: 2956.8739131\ttotal: 1.31s\tremaining: 2m 24s\n",
      "9:\tlearn: 2850.4988631\ttotal: 1.43s\tremaining: 2m 21s\n",
      "10:\tlearn: 2758.8575526\ttotal: 1.56s\tremaining: 2m 20s\n",
      "11:\tlearn: 2673.2918291\ttotal: 1.72s\tremaining: 2m 21s\n",
      "12:\tlearn: 2601.5383456\ttotal: 1.84s\tremaining: 2m 19s\n",
      "13:\tlearn: 2537.9160780\ttotal: 1.96s\tremaining: 2m 17s\n",
      "14:\tlearn: 2481.8133428\ttotal: 2.1s\tremaining: 2m 18s\n",
      "15:\tlearn: 2423.7519969\ttotal: 2.25s\tremaining: 2m 18s\n",
      "16:\tlearn: 2370.6958177\ttotal: 2.39s\tremaining: 2m 18s\n",
      "17:\tlearn: 2324.2349156\ttotal: 2.52s\tremaining: 2m 17s\n",
      "18:\tlearn: 2284.0070691\ttotal: 2.64s\tremaining: 2m 16s\n",
      "19:\tlearn: 2252.4420108\ttotal: 2.76s\tremaining: 2m 15s\n",
      "20:\tlearn: 2220.8649641\ttotal: 2.89s\tremaining: 2m 14s\n",
      "21:\tlearn: 2193.8864487\ttotal: 3.02s\tremaining: 2m 14s\n",
      "22:\tlearn: 2169.2088446\ttotal: 3.12s\tremaining: 2m 12s\n",
      "23:\tlearn: 2147.7882146\ttotal: 3.28s\tremaining: 2m 13s\n",
      "24:\tlearn: 2130.2821658\ttotal: 3.36s\tremaining: 2m 10s\n",
      "25:\tlearn: 2111.0112148\ttotal: 3.46s\tremaining: 2m 9s\n",
      "26:\tlearn: 2095.8807070\ttotal: 3.61s\tremaining: 2m 10s\n",
      "27:\tlearn: 2076.8092548\ttotal: 3.73s\tremaining: 2m 9s\n",
      "28:\tlearn: 2059.9590776\ttotal: 3.84s\tremaining: 2m 8s\n",
      "29:\tlearn: 2045.8279900\ttotal: 3.93s\tremaining: 2m 7s\n",
      "30:\tlearn: 2032.5001375\ttotal: 4.03s\tremaining: 2m 6s\n",
      "31:\tlearn: 2021.8594476\ttotal: 4.17s\tremaining: 2m 6s\n",
      "32:\tlearn: 2012.1659597\ttotal: 4.28s\tremaining: 2m 5s\n",
      "33:\tlearn: 2004.1318023\ttotal: 4.41s\tremaining: 2m 5s\n",
      "34:\tlearn: 1994.5625772\ttotal: 4.52s\tremaining: 2m 4s\n",
      "35:\tlearn: 1988.2004360\ttotal: 4.62s\tremaining: 2m 3s\n",
      "36:\tlearn: 1981.9348997\ttotal: 4.75s\tremaining: 2m 3s\n",
      "37:\tlearn: 1975.2752701\ttotal: 4.85s\tremaining: 2m 2s\n",
      "38:\tlearn: 1969.1058966\ttotal: 4.97s\tremaining: 2m 2s\n",
      "39:\tlearn: 1961.7966463\ttotal: 5.1s\tremaining: 2m 2s\n",
      "40:\tlearn: 1956.0036556\ttotal: 5.21s\tremaining: 2m 1s\n",
      "41:\tlearn: 1951.1730431\ttotal: 5.32s\tremaining: 2m 1s\n",
      "42:\tlearn: 1946.4764702\ttotal: 5.44s\tremaining: 2m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43:\tlearn: 1940.0919001\ttotal: 5.53s\tremaining: 2m\n",
      "44:\tlearn: 1935.6349828\ttotal: 5.63s\tremaining: 1m 59s\n",
      "45:\tlearn: 1930.0389029\ttotal: 5.72s\tremaining: 1m 58s\n",
      "46:\tlearn: 1926.5861586\ttotal: 5.87s\tremaining: 1m 59s\n",
      "47:\tlearn: 1922.5799512\ttotal: 5.99s\tremaining: 1m 58s\n",
      "48:\tlearn: 1919.6509828\ttotal: 6.09s\tremaining: 1m 58s\n",
      "49:\tlearn: 1916.1813252\ttotal: 6.23s\tremaining: 1m 58s\n",
      "50:\tlearn: 1913.2182653\ttotal: 6.37s\tremaining: 1m 58s\n",
      "51:\tlearn: 1910.4083146\ttotal: 6.48s\tremaining: 1m 58s\n",
      "52:\tlearn: 1905.4481953\ttotal: 6.58s\tremaining: 1m 57s\n",
      "53:\tlearn: 1903.2079438\ttotal: 6.72s\tremaining: 1m 57s\n",
      "54:\tlearn: 1900.5543271\ttotal: 6.82s\tremaining: 1m 57s\n",
      "55:\tlearn: 1897.7929769\ttotal: 6.97s\tremaining: 1m 57s\n",
      "56:\tlearn: 1894.5757011\ttotal: 7.07s\tremaining: 1m 57s\n",
      "57:\tlearn: 1891.8924953\ttotal: 7.17s\tremaining: 1m 56s\n",
      "58:\tlearn: 1889.9600403\ttotal: 7.31s\tremaining: 1m 56s\n",
      "59:\tlearn: 1887.8311129\ttotal: 7.42s\tremaining: 1m 56s\n",
      "60:\tlearn: 1885.1358661\ttotal: 7.57s\tremaining: 1m 56s\n",
      "61:\tlearn: 1882.3638125\ttotal: 7.69s\tremaining: 1m 56s\n",
      "62:\tlearn: 1878.9422982\ttotal: 7.84s\tremaining: 1m 56s\n",
      "63:\tlearn: 1876.5936058\ttotal: 7.93s\tremaining: 1m 56s\n",
      "64:\tlearn: 1875.1471994\ttotal: 8.08s\tremaining: 1m 56s\n",
      "65:\tlearn: 1872.2815671\ttotal: 8.18s\tremaining: 1m 55s\n",
      "66:\tlearn: 1870.7450832\ttotal: 8.3s\tremaining: 1m 55s\n",
      "67:\tlearn: 1868.6739058\ttotal: 8.43s\tremaining: 1m 55s\n",
      "68:\tlearn: 1865.7061162\ttotal: 8.54s\tremaining: 1m 55s\n",
      "69:\tlearn: 1863.3825522\ttotal: 8.69s\tremaining: 1m 55s\n",
      "70:\tlearn: 1861.6165760\ttotal: 8.79s\tremaining: 1m 55s\n",
      "71:\tlearn: 1860.2714708\ttotal: 8.91s\tremaining: 1m 54s\n",
      "72:\tlearn: 1857.9485317\ttotal: 8.99s\tremaining: 1m 54s\n",
      "73:\tlearn: 1856.0087678\ttotal: 9.14s\tremaining: 1m 54s\n",
      "74:\tlearn: 1853.4450575\ttotal: 9.28s\tremaining: 1m 54s\n",
      "75:\tlearn: 1851.0579691\ttotal: 9.37s\tremaining: 1m 53s\n",
      "76:\tlearn: 1847.9696000\ttotal: 9.5s\tremaining: 1m 53s\n",
      "77:\tlearn: 1846.4995187\ttotal: 9.6s\tremaining: 1m 53s\n",
      "78:\tlearn: 1844.7475608\ttotal: 9.72s\tremaining: 1m 53s\n",
      "79:\tlearn: 1843.6950764\ttotal: 9.84s\tremaining: 1m 53s\n",
      "80:\tlearn: 1842.3372862\ttotal: 9.98s\tremaining: 1m 53s\n",
      "81:\tlearn: 1840.3440598\ttotal: 10.1s\tremaining: 1m 53s\n",
      "82:\tlearn: 1839.0951549\ttotal: 10.3s\tremaining: 1m 53s\n",
      "83:\tlearn: 1837.3490169\ttotal: 10.4s\tremaining: 1m 53s\n",
      "84:\tlearn: 1834.9756859\ttotal: 10.5s\tremaining: 1m 52s\n",
      "85:\tlearn: 1833.9838217\ttotal: 10.6s\tremaining: 1m 52s\n",
      "86:\tlearn: 1831.8682909\ttotal: 10.7s\tremaining: 1m 52s\n",
      "87:\tlearn: 1829.4876655\ttotal: 10.9s\tremaining: 1m 52s\n",
      "88:\tlearn: 1828.2134554\ttotal: 11s\tremaining: 1m 52s\n",
      "89:\tlearn: 1826.3691249\ttotal: 11.1s\tremaining: 1m 52s\n",
      "90:\tlearn: 1824.6607520\ttotal: 11.2s\tremaining: 1m 51s\n",
      "91:\tlearn: 1822.6308198\ttotal: 11.4s\tremaining: 1m 52s\n",
      "92:\tlearn: 1820.8590120\ttotal: 11.5s\tremaining: 1m 51s\n",
      "93:\tlearn: 1819.1179408\ttotal: 11.6s\tremaining: 1m 51s\n",
      "94:\tlearn: 1817.3304718\ttotal: 11.7s\tremaining: 1m 51s\n",
      "95:\tlearn: 1816.1936110\ttotal: 11.8s\tremaining: 1m 51s\n",
      "96:\tlearn: 1814.4393169\ttotal: 12s\tremaining: 1m 51s\n",
      "97:\tlearn: 1813.0670156\ttotal: 12.1s\tremaining: 1m 51s\n",
      "98:\tlearn: 1812.1177922\ttotal: 12.2s\tremaining: 1m 50s\n",
      "99:\tlearn: 1810.1040069\ttotal: 12.3s\tremaining: 1m 50s\n",
      "100:\tlearn: 1808.1889487\ttotal: 12.4s\tremaining: 1m 50s\n",
      "101:\tlearn: 1807.3592206\ttotal: 12.5s\tremaining: 1m 50s\n",
      "102:\tlearn: 1806.1412632\ttotal: 12.6s\tremaining: 1m 50s\n",
      "103:\tlearn: 1805.6273867\ttotal: 12.8s\tremaining: 1m 49s\n",
      "104:\tlearn: 1803.5435475\ttotal: 12.9s\tremaining: 1m 49s\n",
      "105:\tlearn: 1802.9464846\ttotal: 13s\tremaining: 1m 49s\n",
      "106:\tlearn: 1801.4979541\ttotal: 13.1s\tremaining: 1m 49s\n",
      "107:\tlearn: 1799.8787463\ttotal: 13.2s\tremaining: 1m 49s\n",
      "108:\tlearn: 1799.1000345\ttotal: 13.4s\tremaining: 1m 49s\n",
      "109:\tlearn: 1798.0198820\ttotal: 13.5s\tremaining: 1m 49s\n",
      "110:\tlearn: 1796.9773743\ttotal: 13.6s\tremaining: 1m 49s\n",
      "111:\tlearn: 1795.6786110\ttotal: 13.7s\tremaining: 1m 48s\n",
      "112:\tlearn: 1794.0164228\ttotal: 13.8s\tremaining: 1m 48s\n",
      "113:\tlearn: 1792.4841989\ttotal: 14s\tremaining: 1m 48s\n",
      "114:\tlearn: 1791.5224775\ttotal: 14.1s\tremaining: 1m 48s\n",
      "115:\tlearn: 1790.1808710\ttotal: 14.3s\tremaining: 1m 48s\n",
      "116:\tlearn: 1787.8764628\ttotal: 14.4s\tremaining: 1m 48s\n",
      "117:\tlearn: 1786.7979905\ttotal: 14.5s\tremaining: 1m 48s\n",
      "118:\tlearn: 1786.0313785\ttotal: 14.6s\tremaining: 1m 48s\n",
      "119:\tlearn: 1784.4976522\ttotal: 14.8s\tremaining: 1m 48s\n",
      "120:\tlearn: 1783.4149733\ttotal: 14.9s\tremaining: 1m 48s\n",
      "121:\tlearn: 1782.3194315\ttotal: 15s\tremaining: 1m 47s\n",
      "122:\tlearn: 1781.4968665\ttotal: 15.1s\tremaining: 1m 47s\n",
      "123:\tlearn: 1780.4160090\ttotal: 15.3s\tremaining: 1m 47s\n",
      "124:\tlearn: 1779.4510330\ttotal: 15.4s\tremaining: 1m 47s\n",
      "125:\tlearn: 1778.3377902\ttotal: 15.6s\tremaining: 1m 47s\n",
      "126:\tlearn: 1777.6322107\ttotal: 15.7s\tremaining: 1m 47s\n",
      "127:\tlearn: 1776.4206697\ttotal: 15.8s\tremaining: 1m 47s\n",
      "128:\tlearn: 1775.2976014\ttotal: 15.9s\tremaining: 1m 47s\n",
      "129:\tlearn: 1773.9132582\ttotal: 16s\tremaining: 1m 47s\n",
      "130:\tlearn: 1773.1235476\ttotal: 16.2s\tremaining: 1m 47s\n",
      "131:\tlearn: 1772.3300087\ttotal: 16.3s\tremaining: 1m 47s\n",
      "132:\tlearn: 1771.2613829\ttotal: 16.4s\tremaining: 1m 47s\n",
      "133:\tlearn: 1770.4052442\ttotal: 16.6s\tremaining: 1m 47s\n",
      "134:\tlearn: 1769.4416131\ttotal: 16.7s\tremaining: 1m 47s\n",
      "135:\tlearn: 1768.0529302\ttotal: 16.8s\tremaining: 1m 46s\n",
      "136:\tlearn: 1767.4140500\ttotal: 16.9s\tremaining: 1m 46s\n",
      "137:\tlearn: 1765.5694713\ttotal: 17s\tremaining: 1m 46s\n",
      "138:\tlearn: 1763.8338556\ttotal: 17.2s\tremaining: 1m 46s\n",
      "139:\tlearn: 1762.5886724\ttotal: 17.3s\tremaining: 1m 46s\n",
      "140:\tlearn: 1761.8797925\ttotal: 17.4s\tremaining: 1m 45s\n",
      "141:\tlearn: 1761.0928339\ttotal: 17.5s\tremaining: 1m 45s\n",
      "142:\tlearn: 1760.1906129\ttotal: 17.6s\tremaining: 1m 45s\n",
      "143:\tlearn: 1759.6257262\ttotal: 17.8s\tremaining: 1m 45s\n",
      "144:\tlearn: 1758.8702233\ttotal: 17.9s\tremaining: 1m 45s\n",
      "145:\tlearn: 1758.3352958\ttotal: 18s\tremaining: 1m 45s\n",
      "146:\tlearn: 1757.2175217\ttotal: 18.1s\tremaining: 1m 45s\n",
      "147:\tlearn: 1756.7838319\ttotal: 18.2s\tremaining: 1m 44s\n",
      "148:\tlearn: 1755.3629442\ttotal: 18.3s\tremaining: 1m 44s\n",
      "149:\tlearn: 1754.8494340\ttotal: 18.5s\tremaining: 1m 44s\n",
      "150:\tlearn: 1754.3884341\ttotal: 18.6s\tremaining: 1m 44s\n",
      "151:\tlearn: 1753.5138922\ttotal: 18.7s\tremaining: 1m 44s\n",
      "152:\tlearn: 1752.1372705\ttotal: 18.8s\tremaining: 1m 44s\n",
      "153:\tlearn: 1751.2384343\ttotal: 18.9s\tremaining: 1m 43s\n",
      "154:\tlearn: 1750.5281611\ttotal: 19s\tremaining: 1m 43s\n",
      "155:\tlearn: 1749.5775100\ttotal: 19.2s\tremaining: 1m 43s\n",
      "156:\tlearn: 1748.7712220\ttotal: 19.2s\tremaining: 1m 43s\n",
      "157:\tlearn: 1748.3222567\ttotal: 19.4s\tremaining: 1m 43s\n",
      "158:\tlearn: 1747.5187875\ttotal: 19.5s\tremaining: 1m 42s\n",
      "159:\tlearn: 1747.1977847\ttotal: 19.6s\tremaining: 1m 43s\n",
      "160:\tlearn: 1746.7485546\ttotal: 19.7s\tremaining: 1m 42s\n",
      "161:\tlearn: 1745.8926023\ttotal: 19.9s\tremaining: 1m 42s\n",
      "162:\tlearn: 1744.9622057\ttotal: 20s\tremaining: 1m 42s\n",
      "163:\tlearn: 1743.7806857\ttotal: 20.1s\tremaining: 1m 42s\n",
      "164:\tlearn: 1743.2102325\ttotal: 20.3s\tremaining: 1m 42s\n",
      "165:\tlearn: 1742.1667750\ttotal: 20.4s\tremaining: 1m 42s\n",
      "166:\tlearn: 1741.2706484\ttotal: 20.5s\tremaining: 1m 42s\n",
      "167:\tlearn: 1740.6859372\ttotal: 20.6s\tremaining: 1m 42s\n",
      "168:\tlearn: 1739.9694501\ttotal: 20.7s\tremaining: 1m 41s\n",
      "169:\tlearn: 1739.2971482\ttotal: 20.8s\tremaining: 1m 41s\n",
      "170:\tlearn: 1739.0412857\ttotal: 20.9s\tremaining: 1m 41s\n",
      "171:\tlearn: 1738.6653391\ttotal: 21.1s\tremaining: 1m 41s\n",
      "172:\tlearn: 1737.7020277\ttotal: 21.2s\tremaining: 1m 41s\n",
      "173:\tlearn: 1736.9619417\ttotal: 21.3s\tremaining: 1m 41s\n",
      "174:\tlearn: 1736.6806622\ttotal: 21.4s\tremaining: 1m 40s\n",
      "175:\tlearn: 1735.8223056\ttotal: 21.5s\tremaining: 1m 40s\n",
      "176:\tlearn: 1735.1279689\ttotal: 21.6s\tremaining: 1m 40s\n",
      "177:\tlearn: 1734.2052642\ttotal: 21.8s\tremaining: 1m 40s\n",
      "178:\tlearn: 1733.7177509\ttotal: 21.9s\tremaining: 1m 40s\n",
      "179:\tlearn: 1733.0389698\ttotal: 22s\tremaining: 1m 40s\n",
      "180:\tlearn: 1732.8662399\ttotal: 22.1s\tremaining: 1m 40s\n",
      "181:\tlearn: 1732.3906534\ttotal: 22.2s\tremaining: 1m 39s\n",
      "182:\tlearn: 1731.6620302\ttotal: 22.4s\tremaining: 1m 39s\n",
      "183:\tlearn: 1730.8940883\ttotal: 22.5s\tremaining: 1m 39s\n",
      "184:\tlearn: 1730.6017034\ttotal: 22.6s\tremaining: 1m 39s\n",
      "185:\tlearn: 1729.9444576\ttotal: 22.8s\tremaining: 1m 39s\n",
      "186:\tlearn: 1729.4160804\ttotal: 22.9s\tremaining: 1m 39s\n",
      "187:\tlearn: 1728.4128624\ttotal: 23s\tremaining: 1m 39s\n",
      "188:\tlearn: 1727.7768548\ttotal: 23.1s\tremaining: 1m 39s\n",
      "189:\tlearn: 1727.0965112\ttotal: 23.2s\tremaining: 1m 39s\n",
      "190:\tlearn: 1726.2462829\ttotal: 23.4s\tremaining: 1m 39s\n",
      "191:\tlearn: 1725.7323716\ttotal: 23.5s\tremaining: 1m 38s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192:\tlearn: 1725.3397732\ttotal: 23.6s\tremaining: 1m 38s\n",
      "193:\tlearn: 1724.9527351\ttotal: 23.8s\tremaining: 1m 38s\n",
      "194:\tlearn: 1724.4718082\ttotal: 23.9s\tremaining: 1m 38s\n",
      "195:\tlearn: 1723.8531643\ttotal: 24s\tremaining: 1m 38s\n",
      "196:\tlearn: 1723.0257419\ttotal: 24.1s\tremaining: 1m 38s\n",
      "197:\tlearn: 1722.2855722\ttotal: 24.3s\tremaining: 1m 38s\n",
      "198:\tlearn: 1721.6137029\ttotal: 24.4s\tremaining: 1m 38s\n",
      "199:\tlearn: 1721.1778448\ttotal: 24.5s\tremaining: 1m 38s\n",
      "200:\tlearn: 1720.7676208\ttotal: 24.7s\tremaining: 1m 38s\n",
      "201:\tlearn: 1720.0215281\ttotal: 24.8s\tremaining: 1m 37s\n",
      "202:\tlearn: 1719.7351752\ttotal: 24.9s\tremaining: 1m 37s\n",
      "203:\tlearn: 1719.4110394\ttotal: 25s\tremaining: 1m 37s\n",
      "204:\tlearn: 1718.5484108\ttotal: 25.2s\tremaining: 1m 37s\n",
      "205:\tlearn: 1718.0817839\ttotal: 25.3s\tremaining: 1m 37s\n",
      "206:\tlearn: 1717.2867608\ttotal: 25.4s\tremaining: 1m 37s\n",
      "207:\tlearn: 1716.5107250\ttotal: 25.5s\tremaining: 1m 37s\n",
      "208:\tlearn: 1715.3734475\ttotal: 25.7s\tremaining: 1m 37s\n",
      "209:\tlearn: 1714.5556279\ttotal: 25.8s\tremaining: 1m 37s\n",
      "210:\tlearn: 1713.7796748\ttotal: 25.9s\tremaining: 1m 36s\n",
      "211:\tlearn: 1713.2090198\ttotal: 26.1s\tremaining: 1m 36s\n",
      "212:\tlearn: 1712.7421413\ttotal: 26.2s\tremaining: 1m 36s\n",
      "213:\tlearn: 1712.0117127\ttotal: 26.3s\tremaining: 1m 36s\n",
      "214:\tlearn: 1711.4469286\ttotal: 26.4s\tremaining: 1m 36s\n",
      "215:\tlearn: 1710.9805675\ttotal: 26.6s\tremaining: 1m 36s\n",
      "216:\tlearn: 1710.5663781\ttotal: 26.7s\tremaining: 1m 36s\n",
      "217:\tlearn: 1710.1291051\ttotal: 26.8s\tremaining: 1m 36s\n",
      "218:\tlearn: 1709.2218554\ttotal: 27s\tremaining: 1m 36s\n",
      "219:\tlearn: 1708.6419757\ttotal: 27s\tremaining: 1m 35s\n",
      "220:\tlearn: 1708.2338056\ttotal: 27.1s\tremaining: 1m 35s\n",
      "221:\tlearn: 1708.0336367\ttotal: 27.3s\tremaining: 1m 35s\n",
      "222:\tlearn: 1706.9497837\ttotal: 27.4s\tremaining: 1m 35s\n",
      "223:\tlearn: 1706.6075527\ttotal: 27.5s\tremaining: 1m 35s\n",
      "224:\tlearn: 1705.9485963\ttotal: 27.6s\tremaining: 1m 35s\n",
      "225:\tlearn: 1705.5715682\ttotal: 27.8s\tremaining: 1m 35s\n",
      "226:\tlearn: 1704.9296783\ttotal: 27.9s\tremaining: 1m 34s\n",
      "227:\tlearn: 1703.9804922\ttotal: 28s\tremaining: 1m 34s\n",
      "228:\tlearn: 1703.3380935\ttotal: 28.1s\tremaining: 1m 34s\n",
      "229:\tlearn: 1702.7364363\ttotal: 28.2s\tremaining: 1m 34s\n",
      "230:\tlearn: 1702.6264860\ttotal: 28.3s\tremaining: 1m 34s\n",
      "231:\tlearn: 1702.0749671\ttotal: 28.4s\tremaining: 1m 34s\n",
      "232:\tlearn: 1701.4607972\ttotal: 28.6s\tremaining: 1m 34s\n",
      "233:\tlearn: 1701.1408848\ttotal: 28.7s\tremaining: 1m 33s\n",
      "234:\tlearn: 1700.8834683\ttotal: 28.8s\tremaining: 1m 33s\n",
      "235:\tlearn: 1700.5624272\ttotal: 28.9s\tremaining: 1m 33s\n",
      "236:\tlearn: 1700.2524370\ttotal: 29s\tremaining: 1m 33s\n",
      "237:\tlearn: 1699.7715145\ttotal: 29.1s\tremaining: 1m 33s\n",
      "238:\tlearn: 1698.9465269\ttotal: 29.2s\tremaining: 1m 33s\n",
      "239:\tlearn: 1698.4904863\ttotal: 29.3s\tremaining: 1m 32s\n",
      "240:\tlearn: 1698.2550555\ttotal: 29.5s\tremaining: 1m 32s\n",
      "241:\tlearn: 1697.9954641\ttotal: 29.6s\tremaining: 1m 32s\n",
      "242:\tlearn: 1697.3777596\ttotal: 29.7s\tremaining: 1m 32s\n",
      "243:\tlearn: 1696.8127119\ttotal: 29.8s\tremaining: 1m 32s\n",
      "244:\tlearn: 1696.1660067\ttotal: 29.9s\tremaining: 1m 32s\n",
      "245:\tlearn: 1695.6038279\ttotal: 30s\tremaining: 1m 32s\n",
      "246:\tlearn: 1695.5206293\ttotal: 30.2s\tremaining: 1m 31s\n",
      "247:\tlearn: 1695.0745648\ttotal: 30.3s\tremaining: 1m 31s\n",
      "248:\tlearn: 1694.5083952\ttotal: 30.4s\tremaining: 1m 31s\n",
      "249:\tlearn: 1694.1738446\ttotal: 30.6s\tremaining: 1m 31s\n",
      "250:\tlearn: 1693.8573145\ttotal: 30.7s\tremaining: 1m 31s\n",
      "251:\tlearn: 1693.5699694\ttotal: 30.8s\tremaining: 1m 31s\n",
      "252:\tlearn: 1693.1700464\ttotal: 30.9s\tremaining: 1m 31s\n",
      "253:\tlearn: 1692.7992994\ttotal: 31s\tremaining: 1m 31s\n",
      "254:\tlearn: 1692.5875439\ttotal: 31.1s\tremaining: 1m 30s\n",
      "255:\tlearn: 1692.2526448\ttotal: 31.2s\tremaining: 1m 30s\n",
      "256:\tlearn: 1691.7404397\ttotal: 31.4s\tremaining: 1m 30s\n",
      "257:\tlearn: 1691.4493657\ttotal: 31.5s\tremaining: 1m 30s\n",
      "258:\tlearn: 1691.1513668\ttotal: 31.6s\tremaining: 1m 30s\n",
      "259:\tlearn: 1690.7866192\ttotal: 31.7s\tremaining: 1m 30s\n",
      "260:\tlearn: 1690.4944121\ttotal: 31.8s\tremaining: 1m 30s\n",
      "261:\tlearn: 1689.8217820\ttotal: 31.9s\tremaining: 1m 29s\n",
      "262:\tlearn: 1689.4803133\ttotal: 32.1s\tremaining: 1m 29s\n",
      "263:\tlearn: 1689.1226640\ttotal: 32.2s\tremaining: 1m 29s\n",
      "264:\tlearn: 1688.9946921\ttotal: 32.3s\tremaining: 1m 29s\n",
      "265:\tlearn: 1688.7777035\ttotal: 32.4s\tremaining: 1m 29s\n",
      "266:\tlearn: 1688.5330263\ttotal: 32.5s\tremaining: 1m 29s\n",
      "267:\tlearn: 1688.4429088\ttotal: 32.6s\tremaining: 1m 29s\n",
      "268:\tlearn: 1688.2489279\ttotal: 32.8s\tremaining: 1m 29s\n",
      "269:\tlearn: 1687.9129024\ttotal: 32.8s\tremaining: 1m 28s\n",
      "270:\tlearn: 1687.3747771\ttotal: 33s\tremaining: 1m 28s\n",
      "271:\tlearn: 1686.9449271\ttotal: 33.1s\tremaining: 1m 28s\n",
      "272:\tlearn: 1686.5075713\ttotal: 33.2s\tremaining: 1m 28s\n",
      "273:\tlearn: 1685.9792805\ttotal: 33.4s\tremaining: 1m 28s\n",
      "274:\tlearn: 1685.4131472\ttotal: 33.5s\tremaining: 1m 28s\n",
      "275:\tlearn: 1685.1056217\ttotal: 33.6s\tremaining: 1m 28s\n",
      "276:\tlearn: 1684.6930442\ttotal: 33.8s\tremaining: 1m 28s\n",
      "277:\tlearn: 1684.3523846\ttotal: 33.9s\tremaining: 1m 28s\n",
      "278:\tlearn: 1684.0637089\ttotal: 34s\tremaining: 1m 27s\n",
      "279:\tlearn: 1683.6973615\ttotal: 34.1s\tremaining: 1m 27s\n",
      "280:\tlearn: 1683.2445067\ttotal: 34.3s\tremaining: 1m 27s\n",
      "281:\tlearn: 1682.9194688\ttotal: 34.4s\tremaining: 1m 27s\n",
      "282:\tlearn: 1682.6145908\ttotal: 34.5s\tremaining: 1m 27s\n",
      "283:\tlearn: 1682.4271741\ttotal: 34.6s\tremaining: 1m 27s\n",
      "284:\tlearn: 1682.1559198\ttotal: 34.8s\tremaining: 1m 27s\n",
      "285:\tlearn: 1681.8084950\ttotal: 34.9s\tremaining: 1m 27s\n",
      "286:\tlearn: 1681.4004440\ttotal: 35s\tremaining: 1m 26s\n",
      "287:\tlearn: 1681.0732125\ttotal: 35.2s\tremaining: 1m 26s\n",
      "288:\tlearn: 1680.5159412\ttotal: 35.2s\tremaining: 1m 26s\n",
      "289:\tlearn: 1680.1179810\ttotal: 35.4s\tremaining: 1m 26s\n",
      "290:\tlearn: 1680.0164528\ttotal: 35.5s\tremaining: 1m 26s\n",
      "291:\tlearn: 1679.7030290\ttotal: 35.6s\tremaining: 1m 26s\n",
      "292:\tlearn: 1679.6267114\ttotal: 35.8s\tremaining: 1m 26s\n",
      "293:\tlearn: 1679.2909532\ttotal: 35.9s\tremaining: 1m 26s\n",
      "294:\tlearn: 1678.7476758\ttotal: 36s\tremaining: 1m 25s\n",
      "295:\tlearn: 1678.2106921\ttotal: 36.1s\tremaining: 1m 25s\n",
      "296:\tlearn: 1678.0967716\ttotal: 36.3s\tremaining: 1m 25s\n",
      "297:\tlearn: 1677.7229870\ttotal: 36.4s\tremaining: 1m 25s\n",
      "298:\tlearn: 1677.2995473\ttotal: 36.5s\tremaining: 1m 25s\n",
      "299:\tlearn: 1676.8977429\ttotal: 36.6s\tremaining: 1m 25s\n",
      "300:\tlearn: 1676.4895539\ttotal: 36.7s\tremaining: 1m 25s\n",
      "301:\tlearn: 1676.2515888\ttotal: 36.8s\tremaining: 1m 25s\n",
      "302:\tlearn: 1675.9012951\ttotal: 37s\tremaining: 1m 25s\n",
      "303:\tlearn: 1675.6606011\ttotal: 37.1s\tremaining: 1m 24s\n",
      "304:\tlearn: 1675.3270859\ttotal: 37.2s\tremaining: 1m 24s\n",
      "305:\tlearn: 1675.1340749\ttotal: 37.3s\tremaining: 1m 24s\n",
      "306:\tlearn: 1674.7276346\ttotal: 37.4s\tremaining: 1m 24s\n",
      "307:\tlearn: 1674.4396375\ttotal: 37.5s\tremaining: 1m 24s\n",
      "308:\tlearn: 1674.1170942\ttotal: 37.7s\tremaining: 1m 24s\n",
      "309:\tlearn: 1673.8632970\ttotal: 37.8s\tremaining: 1m 24s\n",
      "310:\tlearn: 1673.6644721\ttotal: 38s\tremaining: 1m 24s\n",
      "311:\tlearn: 1673.5807894\ttotal: 38.1s\tremaining: 1m 24s\n",
      "312:\tlearn: 1673.0404896\ttotal: 38.2s\tremaining: 1m 23s\n",
      "313:\tlearn: 1672.9123261\ttotal: 38.3s\tremaining: 1m 23s\n",
      "314:\tlearn: 1672.7379396\ttotal: 38.5s\tremaining: 1m 23s\n",
      "315:\tlearn: 1672.5805629\ttotal: 38.6s\tremaining: 1m 23s\n",
      "316:\tlearn: 1672.3817871\ttotal: 38.7s\tremaining: 1m 23s\n",
      "317:\tlearn: 1672.2128563\ttotal: 38.8s\tremaining: 1m 23s\n",
      "318:\tlearn: 1671.8681502\ttotal: 38.9s\tremaining: 1m 23s\n",
      "319:\tlearn: 1671.2924888\ttotal: 39s\tremaining: 1m 22s\n",
      "320:\tlearn: 1671.0245813\ttotal: 39.1s\tremaining: 1m 22s\n",
      "321:\tlearn: 1670.6686324\ttotal: 39.2s\tremaining: 1m 22s\n",
      "322:\tlearn: 1670.1926649\ttotal: 39.3s\tremaining: 1m 22s\n",
      "323:\tlearn: 1669.7617916\ttotal: 39.5s\tremaining: 1m 22s\n",
      "324:\tlearn: 1669.3273833\ttotal: 39.6s\tremaining: 1m 22s\n",
      "325:\tlearn: 1669.0185028\ttotal: 39.7s\tremaining: 1m 22s\n",
      "326:\tlearn: 1668.4654415\ttotal: 39.8s\tremaining: 1m 21s\n",
      "327:\tlearn: 1668.2365007\ttotal: 39.9s\tremaining: 1m 21s\n",
      "328:\tlearn: 1668.0361056\ttotal: 40.1s\tremaining: 1m 21s\n",
      "329:\tlearn: 1667.7660850\ttotal: 40.2s\tremaining: 1m 21s\n",
      "330:\tlearn: 1667.5004028\ttotal: 40.3s\tremaining: 1m 21s\n",
      "331:\tlearn: 1667.2701323\ttotal: 40.5s\tremaining: 1m 21s\n",
      "332:\tlearn: 1667.0477114\ttotal: 40.6s\tremaining: 1m 21s\n",
      "333:\tlearn: 1666.8981646\ttotal: 40.7s\tremaining: 1m 21s\n",
      "334:\tlearn: 1666.5995002\ttotal: 40.8s\tremaining: 1m 20s\n",
      "335:\tlearn: 1666.2530623\ttotal: 40.9s\tremaining: 1m 20s\n",
      "336:\tlearn: 1666.0497111\ttotal: 41s\tremaining: 1m 20s\n",
      "337:\tlearn: 1665.6110452\ttotal: 41.1s\tremaining: 1m 20s\n",
      "338:\tlearn: 1665.2025819\ttotal: 41.2s\tremaining: 1m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339:\tlearn: 1664.9596110\ttotal: 41.3s\tremaining: 1m 20s\n",
      "340:\tlearn: 1664.7729497\ttotal: 41.5s\tremaining: 1m 20s\n",
      "341:\tlearn: 1664.5757229\ttotal: 41.6s\tremaining: 1m 20s\n",
      "342:\tlearn: 1664.3992422\ttotal: 41.7s\tremaining: 1m 19s\n",
      "343:\tlearn: 1664.3403122\ttotal: 41.8s\tremaining: 1m 19s\n",
      "344:\tlearn: 1664.1187199\ttotal: 42s\tremaining: 1m 19s\n",
      "345:\tlearn: 1663.6319206\ttotal: 42.1s\tremaining: 1m 19s\n",
      "346:\tlearn: 1663.3967587\ttotal: 42.2s\tremaining: 1m 19s\n",
      "347:\tlearn: 1663.1565446\ttotal: 42.4s\tremaining: 1m 19s\n",
      "348:\tlearn: 1662.6439266\ttotal: 42.4s\tremaining: 1m 19s\n",
      "349:\tlearn: 1662.4097843\ttotal: 42.6s\tremaining: 1m 19s\n",
      "350:\tlearn: 1661.9122956\ttotal: 42.7s\tremaining: 1m 18s\n",
      "351:\tlearn: 1661.7508195\ttotal: 42.8s\tremaining: 1m 18s\n",
      "352:\tlearn: 1661.5591154\ttotal: 42.9s\tremaining: 1m 18s\n",
      "353:\tlearn: 1661.1033853\ttotal: 43s\tremaining: 1m 18s\n",
      "354:\tlearn: 1660.9308003\ttotal: 43.2s\tremaining: 1m 18s\n",
      "355:\tlearn: 1660.6369576\ttotal: 43.3s\tremaining: 1m 18s\n",
      "356:\tlearn: 1660.4695827\ttotal: 43.5s\tremaining: 1m 18s\n",
      "357:\tlearn: 1660.2309491\ttotal: 43.6s\tremaining: 1m 18s\n",
      "358:\tlearn: 1660.0396534\ttotal: 43.8s\tremaining: 1m 18s\n",
      "359:\tlearn: 1659.9044263\ttotal: 43.9s\tremaining: 1m 18s\n",
      "360:\tlearn: 1659.7175143\ttotal: 44s\tremaining: 1m 17s\n",
      "361:\tlearn: 1659.4128337\ttotal: 44.1s\tremaining: 1m 17s\n",
      "362:\tlearn: 1659.3367918\ttotal: 44.2s\tremaining: 1m 17s\n",
      "363:\tlearn: 1659.0220372\ttotal: 44.4s\tremaining: 1m 17s\n",
      "364:\tlearn: 1658.6754263\ttotal: 44.5s\tremaining: 1m 17s\n",
      "365:\tlearn: 1658.5136478\ttotal: 44.6s\tremaining: 1m 17s\n",
      "366:\tlearn: 1658.1396454\ttotal: 44.7s\tremaining: 1m 17s\n",
      "367:\tlearn: 1657.8522816\ttotal: 44.9s\tremaining: 1m 17s\n",
      "368:\tlearn: 1657.5460419\ttotal: 45s\tremaining: 1m 16s\n",
      "369:\tlearn: 1657.1677370\ttotal: 45.1s\tremaining: 1m 16s\n",
      "370:\tlearn: 1657.0395520\ttotal: 45.3s\tremaining: 1m 16s\n",
      "371:\tlearn: 1656.8314024\ttotal: 45.4s\tremaining: 1m 16s\n",
      "372:\tlearn: 1656.6851689\ttotal: 45.5s\tremaining: 1m 16s\n",
      "373:\tlearn: 1656.3426684\ttotal: 45.6s\tremaining: 1m 16s\n",
      "374:\tlearn: 1656.0763733\ttotal: 45.7s\tremaining: 1m 16s\n",
      "375:\tlearn: 1655.9030355\ttotal: 45.8s\tremaining: 1m 15s\n",
      "376:\tlearn: 1655.6120700\ttotal: 45.9s\tremaining: 1m 15s\n",
      "377:\tlearn: 1655.2497448\ttotal: 46s\tremaining: 1m 15s\n",
      "378:\tlearn: 1655.0267416\ttotal: 46.1s\tremaining: 1m 15s\n",
      "379:\tlearn: 1654.7294902\ttotal: 46.3s\tremaining: 1m 15s\n",
      "380:\tlearn: 1654.5042264\ttotal: 46.4s\tremaining: 1m 15s\n",
      "381:\tlearn: 1654.3168449\ttotal: 46.5s\tremaining: 1m 15s\n",
      "382:\tlearn: 1653.9668878\ttotal: 46.6s\tremaining: 1m 15s\n",
      "383:\tlearn: 1653.8284975\ttotal: 46.7s\tremaining: 1m 14s\n",
      "384:\tlearn: 1653.5200251\ttotal: 46.9s\tremaining: 1m 14s\n",
      "385:\tlearn: 1653.1984859\ttotal: 47s\tremaining: 1m 14s\n",
      "386:\tlearn: 1652.6379874\ttotal: 47.1s\tremaining: 1m 14s\n",
      "387:\tlearn: 1652.3627791\ttotal: 47.2s\tremaining: 1m 14s\n",
      "388:\tlearn: 1652.0878668\ttotal: 47.3s\tremaining: 1m 14s\n",
      "389:\tlearn: 1651.7741703\ttotal: 47.4s\tremaining: 1m 14s\n",
      "390:\tlearn: 1651.3975274\ttotal: 47.6s\tremaining: 1m 14s\n",
      "391:\tlearn: 1651.2283967\ttotal: 47.7s\tremaining: 1m 13s\n",
      "392:\tlearn: 1651.0351375\ttotal: 47.8s\tremaining: 1m 13s\n",
      "393:\tlearn: 1650.9318511\ttotal: 47.9s\tremaining: 1m 13s\n",
      "394:\tlearn: 1650.4009542\ttotal: 48s\tremaining: 1m 13s\n",
      "395:\tlearn: 1649.9306894\ttotal: 48.2s\tremaining: 1m 13s\n",
      "396:\tlearn: 1649.6114255\ttotal: 48.3s\tremaining: 1m 13s\n",
      "397:\tlearn: 1649.3626783\ttotal: 48.4s\tremaining: 1m 13s\n",
      "398:\tlearn: 1649.2257734\ttotal: 48.5s\tremaining: 1m 13s\n",
      "399:\tlearn: 1648.7881864\ttotal: 48.6s\tremaining: 1m 12s\n",
      "400:\tlearn: 1648.6635568\ttotal: 48.8s\tremaining: 1m 12s\n",
      "401:\tlearn: 1648.4229512\ttotal: 48.9s\tremaining: 1m 12s\n",
      "402:\tlearn: 1648.1000326\ttotal: 49s\tremaining: 1m 12s\n",
      "403:\tlearn: 1647.6874282\ttotal: 49.1s\tremaining: 1m 12s\n",
      "404:\tlearn: 1647.4919919\ttotal: 49.2s\tremaining: 1m 12s\n",
      "405:\tlearn: 1647.3274495\ttotal: 49.4s\tremaining: 1m 12s\n",
      "406:\tlearn: 1647.1208151\ttotal: 49.5s\tremaining: 1m 12s\n",
      "407:\tlearn: 1646.7632026\ttotal: 49.7s\tremaining: 1m 12s\n",
      "408:\tlearn: 1646.6258470\ttotal: 49.9s\tremaining: 1m 12s\n",
      "409:\tlearn: 1646.3769583\ttotal: 50s\tremaining: 1m 11s\n",
      "410:\tlearn: 1646.2322435\ttotal: 50.1s\tremaining: 1m 11s\n",
      "411:\tlearn: 1646.1494048\ttotal: 50.2s\tremaining: 1m 11s\n",
      "412:\tlearn: 1645.8587511\ttotal: 50.3s\tremaining: 1m 11s\n",
      "413:\tlearn: 1645.4707547\ttotal: 50.4s\tremaining: 1m 11s\n",
      "414:\tlearn: 1645.2164573\ttotal: 50.5s\tremaining: 1m 11s\n",
      "415:\tlearn: 1644.8130320\ttotal: 50.6s\tremaining: 1m 11s\n",
      "416:\tlearn: 1643.9817975\ttotal: 50.8s\tremaining: 1m 11s\n",
      "417:\tlearn: 1643.5860853\ttotal: 50.9s\tremaining: 1m 10s\n",
      "418:\tlearn: 1643.3003140\ttotal: 51s\tremaining: 1m 10s\n",
      "419:\tlearn: 1642.8796402\ttotal: 51.2s\tremaining: 1m 10s\n",
      "420:\tlearn: 1642.5138406\ttotal: 51.3s\tremaining: 1m 10s\n",
      "421:\tlearn: 1642.3156685\ttotal: 51.4s\tremaining: 1m 10s\n",
      "422:\tlearn: 1642.0941203\ttotal: 51.5s\tremaining: 1m 10s\n",
      "423:\tlearn: 1641.8454798\ttotal: 51.7s\tremaining: 1m 10s\n",
      "424:\tlearn: 1641.6828897\ttotal: 51.8s\tremaining: 1m 10s\n",
      "425:\tlearn: 1641.4630340\ttotal: 51.9s\tremaining: 1m 9s\n",
      "426:\tlearn: 1641.2193000\ttotal: 52s\tremaining: 1m 9s\n",
      "427:\tlearn: 1641.1084440\ttotal: 52.2s\tremaining: 1m 9s\n",
      "428:\tlearn: 1640.8577814\ttotal: 52.3s\tremaining: 1m 9s\n",
      "429:\tlearn: 1640.1043758\ttotal: 52.4s\tremaining: 1m 9s\n",
      "430:\tlearn: 1639.8936659\ttotal: 52.5s\tremaining: 1m 9s\n",
      "431:\tlearn: 1639.7244585\ttotal: 52.7s\tremaining: 1m 9s\n",
      "432:\tlearn: 1639.5973944\ttotal: 52.8s\tremaining: 1m 9s\n",
      "433:\tlearn: 1639.4448274\ttotal: 52.9s\tremaining: 1m 9s\n",
      "434:\tlearn: 1639.3596762\ttotal: 53s\tremaining: 1m 8s\n",
      "435:\tlearn: 1639.1043292\ttotal: 53.1s\tremaining: 1m 8s\n",
      "436:\tlearn: 1638.8354523\ttotal: 53.3s\tremaining: 1m 8s\n",
      "437:\tlearn: 1638.5752489\ttotal: 53.4s\tremaining: 1m 8s\n",
      "438:\tlearn: 1638.2213794\ttotal: 53.5s\tremaining: 1m 8s\n",
      "439:\tlearn: 1638.1348876\ttotal: 53.6s\tremaining: 1m 8s\n",
      "440:\tlearn: 1637.6946149\ttotal: 53.7s\tremaining: 1m 8s\n",
      "441:\tlearn: 1637.4778694\ttotal: 53.8s\tremaining: 1m 7s\n",
      "442:\tlearn: 1637.2646249\ttotal: 53.9s\tremaining: 1m 7s\n",
      "443:\tlearn: 1637.0460659\ttotal: 54s\tremaining: 1m 7s\n",
      "444:\tlearn: 1636.8761661\ttotal: 54.1s\tremaining: 1m 7s\n",
      "445:\tlearn: 1636.6645018\ttotal: 54.3s\tremaining: 1m 7s\n",
      "446:\tlearn: 1636.4579149\ttotal: 54.4s\tremaining: 1m 7s\n",
      "447:\tlearn: 1636.3744955\ttotal: 54.5s\tremaining: 1m 7s\n",
      "448:\tlearn: 1636.1607353\ttotal: 54.7s\tremaining: 1m 7s\n",
      "449:\tlearn: 1636.0650541\ttotal: 54.8s\tremaining: 1m 6s\n",
      "450:\tlearn: 1635.9504673\ttotal: 54.9s\tremaining: 1m 6s\n",
      "451:\tlearn: 1635.8421136\ttotal: 54.9s\tremaining: 1m 6s\n",
      "452:\tlearn: 1635.5776410\ttotal: 55.1s\tremaining: 1m 6s\n",
      "453:\tlearn: 1635.4095312\ttotal: 55.1s\tremaining: 1m 6s\n",
      "454:\tlearn: 1635.1173907\ttotal: 55.3s\tremaining: 1m 6s\n",
      "455:\tlearn: 1635.0666562\ttotal: 55.4s\tremaining: 1m 6s\n",
      "456:\tlearn: 1634.8278811\ttotal: 55.5s\tremaining: 1m 6s\n",
      "457:\tlearn: 1634.7931409\ttotal: 55.6s\tremaining: 1m 5s\n",
      "458:\tlearn: 1634.5142041\ttotal: 55.7s\tremaining: 1m 5s\n",
      "459:\tlearn: 1634.2192663\ttotal: 55.8s\tremaining: 1m 5s\n",
      "460:\tlearn: 1634.0268855\ttotal: 55.9s\tremaining: 1m 5s\n",
      "461:\tlearn: 1633.9172088\ttotal: 56s\tremaining: 1m 5s\n",
      "462:\tlearn: 1633.7354279\ttotal: 56.1s\tremaining: 1m 5s\n",
      "463:\tlearn: 1633.5627846\ttotal: 56.2s\tremaining: 1m 4s\n",
      "464:\tlearn: 1633.1340426\ttotal: 56.3s\tremaining: 1m 4s\n",
      "465:\tlearn: 1632.9990488\ttotal: 56.4s\tremaining: 1m 4s\n",
      "466:\tlearn: 1632.6924391\ttotal: 56.6s\tremaining: 1m 4s\n",
      "467:\tlearn: 1632.4439502\ttotal: 56.7s\tremaining: 1m 4s\n",
      "468:\tlearn: 1632.2983819\ttotal: 56.8s\tremaining: 1m 4s\n",
      "469:\tlearn: 1632.0143620\ttotal: 56.9s\tremaining: 1m 4s\n",
      "470:\tlearn: 1631.7729346\ttotal: 57s\tremaining: 1m 3s\n",
      "471:\tlearn: 1631.6504350\ttotal: 57.1s\tremaining: 1m 3s\n",
      "472:\tlearn: 1631.4960873\ttotal: 57.2s\tremaining: 1m 3s\n",
      "473:\tlearn: 1631.3160688\ttotal: 57.3s\tremaining: 1m 3s\n",
      "474:\tlearn: 1630.9356038\ttotal: 57.5s\tremaining: 1m 3s\n",
      "475:\tlearn: 1630.7074265\ttotal: 57.6s\tremaining: 1m 3s\n",
      "476:\tlearn: 1630.4241083\ttotal: 57.7s\tremaining: 1m 3s\n",
      "477:\tlearn: 1630.2857779\ttotal: 57.8s\tremaining: 1m 3s\n",
      "478:\tlearn: 1630.1460545\ttotal: 57.9s\tremaining: 1m 2s\n",
      "479:\tlearn: 1629.8787478\ttotal: 58s\tremaining: 1m 2s\n",
      "480:\tlearn: 1629.7042385\ttotal: 58.2s\tremaining: 1m 2s\n",
      "481:\tlearn: 1629.5100330\ttotal: 58.3s\tremaining: 1m 2s\n",
      "482:\tlearn: 1629.4065849\ttotal: 58.4s\tremaining: 1m 2s\n",
      "483:\tlearn: 1629.1347795\ttotal: 58.5s\tremaining: 1m 2s\n",
      "484:\tlearn: 1628.9403606\ttotal: 58.6s\tremaining: 1m 2s\n",
      "485:\tlearn: 1628.7301007\ttotal: 58.7s\tremaining: 1m 2s\n",
      "486:\tlearn: 1628.5152788\ttotal: 58.8s\tremaining: 1m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487:\tlearn: 1628.3769311\ttotal: 59s\tremaining: 1m 1s\n",
      "488:\tlearn: 1628.1704329\ttotal: 59.1s\tremaining: 1m 1s\n",
      "489:\tlearn: 1627.9901058\ttotal: 59.2s\tremaining: 1m 1s\n",
      "490:\tlearn: 1627.7218492\ttotal: 59.4s\tremaining: 1m 1s\n",
      "491:\tlearn: 1627.3575246\ttotal: 59.5s\tremaining: 1m 1s\n",
      "492:\tlearn: 1627.2497752\ttotal: 59.6s\tremaining: 1m 1s\n",
      "493:\tlearn: 1627.1430354\ttotal: 59.7s\tremaining: 1m 1s\n",
      "494:\tlearn: 1626.9823277\ttotal: 59.9s\tremaining: 1m 1s\n",
      "495:\tlearn: 1626.7050828\ttotal: 60s\tremaining: 1m\n",
      "496:\tlearn: 1626.5933556\ttotal: 1m\tremaining: 1m\n",
      "497:\tlearn: 1626.2392201\ttotal: 1m\tremaining: 1m\n",
      "498:\tlearn: 1625.9627809\ttotal: 1m\tremaining: 1m\n",
      "499:\tlearn: 1625.8131154\ttotal: 1m\tremaining: 1m\n",
      "500:\tlearn: 1625.3459468\ttotal: 1m\tremaining: 1m\n",
      "501:\tlearn: 1625.2953351\ttotal: 1m\tremaining: 1m\n",
      "502:\tlearn: 1625.1535738\ttotal: 1m\tremaining: 1m\n",
      "503:\tlearn: 1625.0771240\ttotal: 1m\tremaining: 1m\n",
      "504:\tlearn: 1624.9320551\ttotal: 1m 1s\tremaining: 59.9s\n",
      "505:\tlearn: 1624.6847710\ttotal: 1m 1s\tremaining: 59.8s\n",
      "506:\tlearn: 1624.3955074\ttotal: 1m 1s\tremaining: 59.6s\n",
      "507:\tlearn: 1624.3533150\ttotal: 1m 1s\tremaining: 59.5s\n",
      "508:\tlearn: 1624.1592877\ttotal: 1m 1s\tremaining: 59.4s\n",
      "509:\tlearn: 1623.8776188\ttotal: 1m 1s\tremaining: 59.2s\n",
      "510:\tlearn: 1623.8516828\ttotal: 1m 1s\tremaining: 59.1s\n",
      "511:\tlearn: 1623.4996098\ttotal: 1m 1s\tremaining: 59s\n",
      "512:\tlearn: 1623.3771100\ttotal: 1m 2s\tremaining: 58.9s\n",
      "513:\tlearn: 1623.1210225\ttotal: 1m 2s\tremaining: 58.7s\n",
      "514:\tlearn: 1622.8083282\ttotal: 1m 2s\tremaining: 58.6s\n",
      "515:\tlearn: 1622.5624015\ttotal: 1m 2s\tremaining: 58.5s\n",
      "516:\tlearn: 1622.4660404\ttotal: 1m 2s\tremaining: 58.4s\n",
      "517:\tlearn: 1622.2845455\ttotal: 1m 2s\tremaining: 58.3s\n",
      "518:\tlearn: 1621.9723206\ttotal: 1m 2s\tremaining: 58.1s\n",
      "519:\tlearn: 1621.8520679\ttotal: 1m 2s\tremaining: 58s\n",
      "520:\tlearn: 1621.6564655\ttotal: 1m 2s\tremaining: 57.8s\n",
      "521:\tlearn: 1621.4147045\ttotal: 1m 3s\tremaining: 57.7s\n",
      "522:\tlearn: 1621.2609523\ttotal: 1m 3s\tremaining: 57.6s\n",
      "523:\tlearn: 1620.9915011\ttotal: 1m 3s\tremaining: 57.5s\n",
      "524:\tlearn: 1620.7903033\ttotal: 1m 3s\tremaining: 57.4s\n",
      "525:\tlearn: 1620.6327963\ttotal: 1m 3s\tremaining: 57.3s\n",
      "526:\tlearn: 1620.4296280\ttotal: 1m 3s\tremaining: 57.1s\n",
      "527:\tlearn: 1619.9513439\ttotal: 1m 3s\tremaining: 57s\n",
      "528:\tlearn: 1619.9008171\ttotal: 1m 3s\tremaining: 56.9s\n",
      "529:\tlearn: 1619.7633800\ttotal: 1m 4s\tremaining: 56.8s\n",
      "530:\tlearn: 1619.6578460\ttotal: 1m 4s\tremaining: 56.7s\n",
      "531:\tlearn: 1619.4064576\ttotal: 1m 4s\tremaining: 56.5s\n",
      "532:\tlearn: 1619.0198707\ttotal: 1m 4s\tremaining: 56.4s\n",
      "533:\tlearn: 1618.7351903\ttotal: 1m 4s\tremaining: 56.3s\n",
      "534:\tlearn: 1618.4536980\ttotal: 1m 4s\tremaining: 56.2s\n",
      "535:\tlearn: 1618.3413860\ttotal: 1m 4s\tremaining: 56s\n",
      "536:\tlearn: 1618.1600988\ttotal: 1m 4s\tremaining: 55.9s\n",
      "537:\tlearn: 1618.0268280\ttotal: 1m 4s\tremaining: 55.8s\n",
      "538:\tlearn: 1617.7775418\ttotal: 1m 5s\tremaining: 55.7s\n",
      "539:\tlearn: 1617.6666572\ttotal: 1m 5s\tremaining: 55.5s\n",
      "540:\tlearn: 1617.5155152\ttotal: 1m 5s\tremaining: 55.4s\n",
      "541:\tlearn: 1617.2791164\ttotal: 1m 5s\tremaining: 55.3s\n",
      "542:\tlearn: 1617.1327073\ttotal: 1m 5s\tremaining: 55.1s\n",
      "543:\tlearn: 1617.0138206\ttotal: 1m 5s\tremaining: 55.1s\n",
      "544:\tlearn: 1616.8088686\ttotal: 1m 5s\tremaining: 54.9s\n",
      "545:\tlearn: 1616.7617593\ttotal: 1m 5s\tremaining: 54.8s\n",
      "546:\tlearn: 1616.6255145\ttotal: 1m 6s\tremaining: 54.7s\n",
      "547:\tlearn: 1616.4451125\ttotal: 1m 6s\tremaining: 54.6s\n",
      "548:\tlearn: 1616.3835592\ttotal: 1m 6s\tremaining: 54.4s\n",
      "549:\tlearn: 1616.3036045\ttotal: 1m 6s\tremaining: 54.3s\n",
      "550:\tlearn: 1616.0649570\ttotal: 1m 6s\tremaining: 54.2s\n",
      "551:\tlearn: 1616.0025489\ttotal: 1m 6s\tremaining: 54.1s\n",
      "552:\tlearn: 1615.8949257\ttotal: 1m 6s\tremaining: 54s\n",
      "553:\tlearn: 1615.6171676\ttotal: 1m 6s\tremaining: 53.9s\n",
      "554:\tlearn: 1615.5157692\ttotal: 1m 7s\tremaining: 53.8s\n",
      "555:\tlearn: 1615.2836071\ttotal: 1m 7s\tremaining: 53.7s\n",
      "556:\tlearn: 1615.1699580\ttotal: 1m 7s\tremaining: 53.5s\n",
      "557:\tlearn: 1615.0813963\ttotal: 1m 7s\tremaining: 53.4s\n",
      "558:\tlearn: 1615.0508344\ttotal: 1m 7s\tremaining: 53.3s\n",
      "559:\tlearn: 1614.8411922\ttotal: 1m 7s\tremaining: 53.1s\n",
      "560:\tlearn: 1614.6686703\ttotal: 1m 7s\tremaining: 53s\n",
      "561:\tlearn: 1614.4478440\ttotal: 1m 7s\tremaining: 52.9s\n",
      "562:\tlearn: 1614.1913027\ttotal: 1m 7s\tremaining: 52.8s\n",
      "563:\tlearn: 1613.9258515\ttotal: 1m 8s\tremaining: 52.7s\n",
      "564:\tlearn: 1613.7938474\ttotal: 1m 8s\tremaining: 52.5s\n",
      "565:\tlearn: 1613.7076184\ttotal: 1m 8s\tremaining: 52.4s\n",
      "566:\tlearn: 1613.6688161\ttotal: 1m 8s\tremaining: 52.3s\n",
      "567:\tlearn: 1613.5401569\ttotal: 1m 8s\tremaining: 52.2s\n",
      "568:\tlearn: 1613.3587838\ttotal: 1m 8s\tremaining: 52.1s\n",
      "569:\tlearn: 1613.2172620\ttotal: 1m 8s\tremaining: 52s\n",
      "570:\tlearn: 1613.0957336\ttotal: 1m 8s\tremaining: 51.8s\n",
      "571:\tlearn: 1612.9097243\ttotal: 1m 9s\tremaining: 51.7s\n",
      "572:\tlearn: 1612.7118430\ttotal: 1m 9s\tremaining: 51.6s\n",
      "573:\tlearn: 1612.4989129\ttotal: 1m 9s\tremaining: 51.5s\n",
      "574:\tlearn: 1612.3873497\ttotal: 1m 9s\tremaining: 51.4s\n",
      "575:\tlearn: 1612.3044964\ttotal: 1m 9s\tremaining: 51.2s\n",
      "576:\tlearn: 1612.1359905\ttotal: 1m 9s\tremaining: 51.1s\n",
      "577:\tlearn: 1612.0349324\ttotal: 1m 9s\tremaining: 51s\n",
      "578:\tlearn: 1611.8864404\ttotal: 1m 9s\tremaining: 50.9s\n",
      "579:\tlearn: 1611.7467586\ttotal: 1m 10s\tremaining: 50.7s\n",
      "580:\tlearn: 1611.4697698\ttotal: 1m 10s\tremaining: 50.6s\n",
      "581:\tlearn: 1611.1914516\ttotal: 1m 10s\tremaining: 50.5s\n",
      "582:\tlearn: 1611.1196431\ttotal: 1m 10s\tremaining: 50.4s\n",
      "583:\tlearn: 1610.8354462\ttotal: 1m 10s\tremaining: 50.3s\n",
      "584:\tlearn: 1610.6549529\ttotal: 1m 10s\tremaining: 50.1s\n",
      "585:\tlearn: 1610.5354048\ttotal: 1m 10s\tremaining: 50s\n",
      "586:\tlearn: 1610.4362332\ttotal: 1m 10s\tremaining: 49.9s\n",
      "587:\tlearn: 1610.3022467\ttotal: 1m 10s\tremaining: 49.7s\n",
      "588:\tlearn: 1610.1561181\ttotal: 1m 11s\tremaining: 49.6s\n",
      "589:\tlearn: 1609.9334334\ttotal: 1m 11s\tremaining: 49.5s\n",
      "590:\tlearn: 1609.7310589\ttotal: 1m 11s\tremaining: 49.4s\n",
      "591:\tlearn: 1609.6606372\ttotal: 1m 11s\tremaining: 49.2s\n",
      "592:\tlearn: 1609.4555370\ttotal: 1m 11s\tremaining: 49.1s\n",
      "593:\tlearn: 1609.3245058\ttotal: 1m 11s\tremaining: 49s\n",
      "594:\tlearn: 1609.1144302\ttotal: 1m 11s\tremaining: 48.9s\n",
      "595:\tlearn: 1608.9339013\ttotal: 1m 11s\tremaining: 48.8s\n",
      "596:\tlearn: 1608.7862849\ttotal: 1m 12s\tremaining: 48.7s\n",
      "597:\tlearn: 1608.5462443\ttotal: 1m 12s\tremaining: 48.6s\n",
      "598:\tlearn: 1608.1262993\ttotal: 1m 12s\tremaining: 48.5s\n",
      "599:\tlearn: 1608.0123440\ttotal: 1m 12s\tremaining: 48.4s\n",
      "600:\tlearn: 1607.7887568\ttotal: 1m 12s\tremaining: 48.3s\n",
      "601:\tlearn: 1607.3803930\ttotal: 1m 12s\tremaining: 48.1s\n",
      "602:\tlearn: 1607.1196126\ttotal: 1m 12s\tremaining: 48s\n",
      "603:\tlearn: 1607.0704731\ttotal: 1m 13s\tremaining: 47.9s\n",
      "604:\tlearn: 1606.6906734\ttotal: 1m 13s\tremaining: 47.8s\n",
      "605:\tlearn: 1606.6413253\ttotal: 1m 13s\tremaining: 47.6s\n",
      "606:\tlearn: 1606.4632630\ttotal: 1m 13s\tremaining: 47.5s\n",
      "607:\tlearn: 1606.2908677\ttotal: 1m 13s\tremaining: 47.4s\n",
      "608:\tlearn: 1606.1298189\ttotal: 1m 13s\tremaining: 47.3s\n",
      "609:\tlearn: 1606.0186144\ttotal: 1m 13s\tremaining: 47.2s\n",
      "610:\tlearn: 1605.7388295\ttotal: 1m 13s\tremaining: 47s\n",
      "611:\tlearn: 1605.6372232\ttotal: 1m 13s\tremaining: 46.9s\n",
      "612:\tlearn: 1605.5636516\ttotal: 1m 14s\tremaining: 46.8s\n",
      "613:\tlearn: 1605.4255420\ttotal: 1m 14s\tremaining: 46.7s\n",
      "614:\tlearn: 1605.3799441\ttotal: 1m 14s\tremaining: 46.5s\n",
      "615:\tlearn: 1605.2206507\ttotal: 1m 14s\tremaining: 46.4s\n",
      "616:\tlearn: 1605.0004814\ttotal: 1m 14s\tremaining: 46.3s\n",
      "617:\tlearn: 1604.8018945\ttotal: 1m 14s\tremaining: 46.2s\n",
      "618:\tlearn: 1604.7248691\ttotal: 1m 14s\tremaining: 46s\n",
      "619:\tlearn: 1604.5630008\ttotal: 1m 14s\tremaining: 45.9s\n",
      "620:\tlearn: 1604.4573058\ttotal: 1m 15s\tremaining: 45.8s\n",
      "621:\tlearn: 1604.2073893\ttotal: 1m 15s\tremaining: 45.7s\n",
      "622:\tlearn: 1604.0268413\ttotal: 1m 15s\tremaining: 45.6s\n",
      "623:\tlearn: 1603.8927400\ttotal: 1m 15s\tremaining: 45.5s\n",
      "624:\tlearn: 1603.6971756\ttotal: 1m 15s\tremaining: 45.4s\n",
      "625:\tlearn: 1603.5826021\ttotal: 1m 15s\tremaining: 45.3s\n",
      "626:\tlearn: 1603.2193647\ttotal: 1m 15s\tremaining: 45.1s\n",
      "627:\tlearn: 1602.9886459\ttotal: 1m 15s\tremaining: 45s\n",
      "628:\tlearn: 1602.9789143\ttotal: 1m 16s\tremaining: 44.9s\n",
      "629:\tlearn: 1602.7912997\ttotal: 1m 16s\tremaining: 44.7s\n",
      "630:\tlearn: 1602.6920838\ttotal: 1m 16s\tremaining: 44.6s\n",
      "631:\tlearn: 1602.5978919\ttotal: 1m 16s\tremaining: 44.5s\n",
      "632:\tlearn: 1602.3966552\ttotal: 1m 16s\tremaining: 44.4s\n",
      "633:\tlearn: 1602.1614942\ttotal: 1m 16s\tremaining: 44.3s\n",
      "634:\tlearn: 1602.0726129\ttotal: 1m 16s\tremaining: 44.1s\n",
      "635:\tlearn: 1601.8685488\ttotal: 1m 16s\tremaining: 44s\n",
      "636:\tlearn: 1601.7181766\ttotal: 1m 16s\tremaining: 43.9s\n",
      "637:\tlearn: 1601.4867311\ttotal: 1m 17s\tremaining: 43.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638:\tlearn: 1601.2513749\ttotal: 1m 17s\tremaining: 43.6s\n",
      "639:\tlearn: 1601.1866554\ttotal: 1m 17s\tremaining: 43.5s\n",
      "640:\tlearn: 1601.0736723\ttotal: 1m 17s\tremaining: 43.4s\n",
      "641:\tlearn: 1600.8934798\ttotal: 1m 17s\tremaining: 43.3s\n",
      "642:\tlearn: 1600.8898616\ttotal: 1m 17s\tremaining: 43.1s\n",
      "643:\tlearn: 1600.8359301\ttotal: 1m 17s\tremaining: 43s\n",
      "644:\tlearn: 1600.6903192\ttotal: 1m 17s\tremaining: 42.9s\n",
      "645:\tlearn: 1600.5867434\ttotal: 1m 18s\tremaining: 42.7s\n",
      "646:\tlearn: 1600.3804190\ttotal: 1m 18s\tremaining: 42.6s\n",
      "647:\tlearn: 1600.1396155\ttotal: 1m 18s\tremaining: 42.5s\n",
      "648:\tlearn: 1600.0393538\ttotal: 1m 18s\tremaining: 42.4s\n",
      "649:\tlearn: 1599.9089335\ttotal: 1m 18s\tremaining: 42.3s\n",
      "650:\tlearn: 1599.8004567\ttotal: 1m 18s\tremaining: 42.2s\n",
      "651:\tlearn: 1599.5795390\ttotal: 1m 18s\tremaining: 42s\n",
      "652:\tlearn: 1599.5272700\ttotal: 1m 18s\tremaining: 41.9s\n",
      "653:\tlearn: 1599.3709897\ttotal: 1m 19s\tremaining: 41.8s\n",
      "654:\tlearn: 1599.3298596\ttotal: 1m 19s\tremaining: 41.7s\n",
      "655:\tlearn: 1599.2531003\ttotal: 1m 19s\tremaining: 41.6s\n",
      "656:\tlearn: 1599.1377910\ttotal: 1m 19s\tremaining: 41.5s\n",
      "657:\tlearn: 1599.0836804\ttotal: 1m 19s\tremaining: 41.3s\n",
      "658:\tlearn: 1598.9751156\ttotal: 1m 19s\tremaining: 41.2s\n",
      "659:\tlearn: 1598.8448422\ttotal: 1m 19s\tremaining: 41.1s\n",
      "660:\tlearn: 1598.6744102\ttotal: 1m 19s\tremaining: 41s\n",
      "661:\tlearn: 1598.5693649\ttotal: 1m 20s\tremaining: 40.9s\n",
      "662:\tlearn: 1598.4192976\ttotal: 1m 20s\tremaining: 40.7s\n",
      "663:\tlearn: 1598.3710814\ttotal: 1m 20s\tremaining: 40.6s\n",
      "664:\tlearn: 1598.2327720\ttotal: 1m 20s\tremaining: 40.5s\n",
      "665:\tlearn: 1598.1842984\ttotal: 1m 20s\tremaining: 40.4s\n",
      "666:\tlearn: 1598.0444821\ttotal: 1m 20s\tremaining: 40.2s\n",
      "667:\tlearn: 1597.8258202\ttotal: 1m 20s\tremaining: 40.1s\n",
      "668:\tlearn: 1597.6441504\ttotal: 1m 20s\tremaining: 40s\n",
      "669:\tlearn: 1597.4903506\ttotal: 1m 20s\tremaining: 39.9s\n",
      "670:\tlearn: 1597.4065260\ttotal: 1m 21s\tremaining: 39.7s\n",
      "671:\tlearn: 1597.1694592\ttotal: 1m 21s\tremaining: 39.6s\n",
      "672:\tlearn: 1597.0995915\ttotal: 1m 21s\tremaining: 39.5s\n",
      "673:\tlearn: 1596.9514915\ttotal: 1m 21s\tremaining: 39.4s\n",
      "674:\tlearn: 1596.9431667\ttotal: 1m 21s\tremaining: 39.3s\n",
      "675:\tlearn: 1596.7930827\ttotal: 1m 21s\tremaining: 39.1s\n",
      "676:\tlearn: 1596.6509398\ttotal: 1m 21s\tremaining: 39s\n",
      "677:\tlearn: 1596.4763340\ttotal: 1m 21s\tremaining: 38.9s\n",
      "678:\tlearn: 1596.2937404\ttotal: 1m 22s\tremaining: 38.8s\n",
      "679:\tlearn: 1596.0698746\ttotal: 1m 22s\tremaining: 38.7s\n",
      "680:\tlearn: 1595.8202072\ttotal: 1m 22s\tremaining: 38.5s\n",
      "681:\tlearn: 1595.6846930\ttotal: 1m 22s\tremaining: 38.4s\n",
      "682:\tlearn: 1595.6362461\ttotal: 1m 22s\tremaining: 38.3s\n",
      "683:\tlearn: 1595.4822313\ttotal: 1m 22s\tremaining: 38.2s\n",
      "684:\tlearn: 1595.4199159\ttotal: 1m 22s\tremaining: 38s\n",
      "685:\tlearn: 1595.3499618\ttotal: 1m 22s\tremaining: 37.9s\n",
      "686:\tlearn: 1595.2757858\ttotal: 1m 22s\tremaining: 37.8s\n",
      "687:\tlearn: 1595.1034842\ttotal: 1m 23s\tremaining: 37.7s\n",
      "688:\tlearn: 1595.0760511\ttotal: 1m 23s\tremaining: 37.5s\n",
      "689:\tlearn: 1594.9415962\ttotal: 1m 23s\tremaining: 37.4s\n",
      "690:\tlearn: 1594.8009086\ttotal: 1m 23s\tremaining: 37.3s\n",
      "691:\tlearn: 1594.7320587\ttotal: 1m 23s\tremaining: 37.2s\n",
      "692:\tlearn: 1594.5945254\ttotal: 1m 23s\tremaining: 37.1s\n",
      "693:\tlearn: 1594.4840574\ttotal: 1m 23s\tremaining: 36.9s\n",
      "694:\tlearn: 1594.4566175\ttotal: 1m 23s\tremaining: 36.8s\n",
      "695:\tlearn: 1594.3689300\ttotal: 1m 24s\tremaining: 36.7s\n",
      "696:\tlearn: 1594.3026776\ttotal: 1m 24s\tremaining: 36.6s\n",
      "697:\tlearn: 1594.2226612\ttotal: 1m 24s\tremaining: 36.5s\n",
      "698:\tlearn: 1594.1120357\ttotal: 1m 24s\tremaining: 36.4s\n",
      "699:\tlearn: 1593.9113614\ttotal: 1m 24s\tremaining: 36.2s\n",
      "700:\tlearn: 1593.7985627\ttotal: 1m 24s\tremaining: 36.1s\n",
      "701:\tlearn: 1593.6794427\ttotal: 1m 24s\tremaining: 36s\n",
      "702:\tlearn: 1593.4693904\ttotal: 1m 24s\tremaining: 35.9s\n",
      "703:\tlearn: 1593.3191396\ttotal: 1m 25s\tremaining: 35.8s\n",
      "704:\tlearn: 1593.1342469\ttotal: 1m 25s\tremaining: 35.6s\n",
      "705:\tlearn: 1592.9451196\ttotal: 1m 25s\tremaining: 35.5s\n",
      "706:\tlearn: 1592.7690108\ttotal: 1m 25s\tremaining: 35.4s\n",
      "707:\tlearn: 1592.6764936\ttotal: 1m 25s\tremaining: 35.3s\n",
      "708:\tlearn: 1592.5356662\ttotal: 1m 25s\tremaining: 35.2s\n",
      "709:\tlearn: 1592.3686043\ttotal: 1m 25s\tremaining: 35.1s\n",
      "710:\tlearn: 1592.2326101\ttotal: 1m 25s\tremaining: 34.9s\n",
      "711:\tlearn: 1591.9735305\ttotal: 1m 26s\tremaining: 34.8s\n",
      "712:\tlearn: 1591.9220344\ttotal: 1m 26s\tremaining: 34.7s\n",
      "713:\tlearn: 1591.7879532\ttotal: 1m 26s\tremaining: 34.6s\n",
      "714:\tlearn: 1591.5727958\ttotal: 1m 26s\tremaining: 34.5s\n",
      "715:\tlearn: 1591.4149315\ttotal: 1m 26s\tremaining: 34.3s\n",
      "716:\tlearn: 1591.3201724\ttotal: 1m 26s\tremaining: 34.2s\n",
      "717:\tlearn: 1591.1801839\ttotal: 1m 26s\tremaining: 34.1s\n",
      "718:\tlearn: 1591.0649712\ttotal: 1m 26s\tremaining: 34s\n",
      "719:\tlearn: 1590.9705874\ttotal: 1m 26s\tremaining: 33.8s\n",
      "720:\tlearn: 1590.8826423\ttotal: 1m 27s\tremaining: 33.7s\n",
      "721:\tlearn: 1590.7752561\ttotal: 1m 27s\tremaining: 33.6s\n",
      "722:\tlearn: 1590.6465326\ttotal: 1m 27s\tremaining: 33.5s\n",
      "723:\tlearn: 1590.5995467\ttotal: 1m 27s\tremaining: 33.4s\n",
      "724:\tlearn: 1590.5382927\ttotal: 1m 27s\tremaining: 33.2s\n",
      "725:\tlearn: 1590.4547556\ttotal: 1m 27s\tremaining: 33.1s\n",
      "726:\tlearn: 1590.3388571\ttotal: 1m 27s\tremaining: 33s\n",
      "727:\tlearn: 1590.3092552\ttotal: 1m 28s\tremaining: 32.9s\n",
      "728:\tlearn: 1590.1657158\ttotal: 1m 28s\tremaining: 32.8s\n",
      "729:\tlearn: 1590.0569568\ttotal: 1m 28s\tremaining: 32.6s\n",
      "730:\tlearn: 1589.9225382\ttotal: 1m 28s\tremaining: 32.5s\n",
      "731:\tlearn: 1589.6864395\ttotal: 1m 28s\tremaining: 32.4s\n",
      "732:\tlearn: 1589.4999229\ttotal: 1m 28s\tremaining: 32.3s\n",
      "733:\tlearn: 1589.0497319\ttotal: 1m 28s\tremaining: 32.1s\n",
      "734:\tlearn: 1588.9313967\ttotal: 1m 28s\tremaining: 32s\n",
      "735:\tlearn: 1588.8114975\ttotal: 1m 28s\tremaining: 31.9s\n",
      "736:\tlearn: 1588.7168041\ttotal: 1m 29s\tremaining: 31.8s\n",
      "737:\tlearn: 1588.6710872\ttotal: 1m 29s\tremaining: 31.6s\n",
      "738:\tlearn: 1588.6183988\ttotal: 1m 29s\tremaining: 31.5s\n",
      "739:\tlearn: 1588.4080297\ttotal: 1m 29s\tremaining: 31.4s\n",
      "740:\tlearn: 1588.3014824\ttotal: 1m 29s\tremaining: 31.3s\n",
      "741:\tlearn: 1588.1074463\ttotal: 1m 29s\tremaining: 31.2s\n",
      "742:\tlearn: 1587.8729993\ttotal: 1m 29s\tremaining: 31.1s\n",
      "743:\tlearn: 1587.7427888\ttotal: 1m 29s\tremaining: 30.9s\n",
      "744:\tlearn: 1587.6315023\ttotal: 1m 30s\tremaining: 30.8s\n",
      "745:\tlearn: 1587.3702805\ttotal: 1m 30s\tremaining: 30.7s\n",
      "746:\tlearn: 1587.2670359\ttotal: 1m 30s\tremaining: 30.6s\n",
      "747:\tlearn: 1587.0971713\ttotal: 1m 30s\tremaining: 30.4s\n",
      "748:\tlearn: 1586.9794382\ttotal: 1m 30s\tremaining: 30.3s\n",
      "749:\tlearn: 1586.7638763\ttotal: 1m 30s\tremaining: 30.2s\n",
      "750:\tlearn: 1586.6408637\ttotal: 1m 30s\tremaining: 30.1s\n",
      "751:\tlearn: 1586.5184179\ttotal: 1m 30s\tremaining: 30s\n",
      "752:\tlearn: 1586.3560452\ttotal: 1m 30s\tremaining: 29.8s\n",
      "753:\tlearn: 1586.2783332\ttotal: 1m 31s\tremaining: 29.7s\n",
      "754:\tlearn: 1586.1074244\ttotal: 1m 31s\tremaining: 29.6s\n",
      "755:\tlearn: 1586.0111263\ttotal: 1m 31s\tremaining: 29.5s\n",
      "756:\tlearn: 1585.8898663\ttotal: 1m 31s\tremaining: 29.3s\n",
      "757:\tlearn: 1585.8501271\ttotal: 1m 31s\tremaining: 29.2s\n",
      "758:\tlearn: 1585.6900247\ttotal: 1m 31s\tremaining: 29.1s\n",
      "759:\tlearn: 1585.3826229\ttotal: 1m 31s\tremaining: 29s\n",
      "760:\tlearn: 1585.2793670\ttotal: 1m 31s\tremaining: 28.9s\n",
      "761:\tlearn: 1585.1851861\ttotal: 1m 32s\tremaining: 28.8s\n",
      "762:\tlearn: 1585.1300469\ttotal: 1m 32s\tremaining: 28.6s\n",
      "763:\tlearn: 1584.9625534\ttotal: 1m 32s\tremaining: 28.5s\n",
      "764:\tlearn: 1584.8468730\ttotal: 1m 32s\tremaining: 28.4s\n",
      "765:\tlearn: 1584.6910732\ttotal: 1m 32s\tremaining: 28.3s\n",
      "766:\tlearn: 1584.5617018\ttotal: 1m 32s\tremaining: 28.2s\n",
      "767:\tlearn: 1584.4858715\ttotal: 1m 32s\tremaining: 28.1s\n",
      "768:\tlearn: 1584.3744629\ttotal: 1m 33s\tremaining: 27.9s\n",
      "769:\tlearn: 1584.2356054\ttotal: 1m 33s\tremaining: 27.8s\n",
      "770:\tlearn: 1584.1238412\ttotal: 1m 33s\tremaining: 27.7s\n",
      "771:\tlearn: 1584.0511522\ttotal: 1m 33s\tremaining: 27.6s\n",
      "772:\tlearn: 1583.9559310\ttotal: 1m 33s\tremaining: 27.5s\n",
      "773:\tlearn: 1583.9123756\ttotal: 1m 33s\tremaining: 27.3s\n",
      "774:\tlearn: 1583.8129594\ttotal: 1m 33s\tremaining: 27.2s\n",
      "775:\tlearn: 1583.6945410\ttotal: 1m 33s\tremaining: 27.1s\n",
      "776:\tlearn: 1583.5344243\ttotal: 1m 34s\tremaining: 27s\n",
      "777:\tlearn: 1583.4380765\ttotal: 1m 34s\tremaining: 26.9s\n",
      "778:\tlearn: 1583.3601056\ttotal: 1m 34s\tremaining: 26.8s\n",
      "779:\tlearn: 1583.1248516\ttotal: 1m 34s\tremaining: 26.6s\n",
      "780:\tlearn: 1582.9668802\ttotal: 1m 34s\tremaining: 26.5s\n",
      "781:\tlearn: 1582.9060017\ttotal: 1m 34s\tremaining: 26.4s\n",
      "782:\tlearn: 1582.7976338\ttotal: 1m 34s\tremaining: 26.3s\n",
      "783:\tlearn: 1582.7472876\ttotal: 1m 34s\tremaining: 26.1s\n",
      "784:\tlearn: 1582.6704573\ttotal: 1m 34s\tremaining: 26s\n",
      "785:\tlearn: 1582.5860570\ttotal: 1m 35s\tremaining: 25.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786:\tlearn: 1582.4870027\ttotal: 1m 35s\tremaining: 25.8s\n",
      "787:\tlearn: 1582.3428073\ttotal: 1m 35s\tremaining: 25.6s\n",
      "788:\tlearn: 1582.2676546\ttotal: 1m 35s\tremaining: 25.5s\n",
      "789:\tlearn: 1582.1847122\ttotal: 1m 35s\tremaining: 25.4s\n",
      "790:\tlearn: 1581.9611558\ttotal: 1m 35s\tremaining: 25.3s\n",
      "791:\tlearn: 1581.8658004\ttotal: 1m 35s\tremaining: 25.1s\n",
      "792:\tlearn: 1581.7036034\ttotal: 1m 35s\tremaining: 25s\n",
      "793:\tlearn: 1581.5511158\ttotal: 1m 36s\tremaining: 24.9s\n",
      "794:\tlearn: 1581.4942436\ttotal: 1m 36s\tremaining: 24.8s\n",
      "795:\tlearn: 1581.4019826\ttotal: 1m 36s\tremaining: 24.7s\n",
      "796:\tlearn: 1581.3156411\ttotal: 1m 36s\tremaining: 24.6s\n",
      "797:\tlearn: 1581.2134905\ttotal: 1m 36s\tremaining: 24.4s\n",
      "798:\tlearn: 1581.0421093\ttotal: 1m 36s\tremaining: 24.3s\n",
      "799:\tlearn: 1580.9640818\ttotal: 1m 36s\tremaining: 24.2s\n",
      "800:\tlearn: 1580.8906447\ttotal: 1m 36s\tremaining: 24.1s\n",
      "801:\tlearn: 1580.7987322\ttotal: 1m 37s\tremaining: 24s\n",
      "802:\tlearn: 1580.7170379\ttotal: 1m 37s\tremaining: 23.8s\n",
      "803:\tlearn: 1580.5695634\ttotal: 1m 37s\tremaining: 23.7s\n",
      "804:\tlearn: 1580.4299428\ttotal: 1m 37s\tremaining: 23.6s\n",
      "805:\tlearn: 1580.3426992\ttotal: 1m 37s\tremaining: 23.5s\n",
      "806:\tlearn: 1579.9757671\ttotal: 1m 37s\tremaining: 23.4s\n",
      "807:\tlearn: 1579.8561422\ttotal: 1m 37s\tremaining: 23.2s\n",
      "808:\tlearn: 1579.7051396\ttotal: 1m 37s\tremaining: 23.1s\n",
      "809:\tlearn: 1579.4989600\ttotal: 1m 38s\tremaining: 23s\n",
      "810:\tlearn: 1579.3460913\ttotal: 1m 38s\tremaining: 22.9s\n",
      "811:\tlearn: 1579.2670281\ttotal: 1m 38s\tremaining: 22.8s\n",
      "812:\tlearn: 1579.0920728\ttotal: 1m 38s\tremaining: 22.6s\n",
      "813:\tlearn: 1578.9924449\ttotal: 1m 38s\tremaining: 22.5s\n",
      "814:\tlearn: 1578.8844341\ttotal: 1m 38s\tremaining: 22.4s\n",
      "815:\tlearn: 1578.7645534\ttotal: 1m 38s\tremaining: 22.3s\n",
      "816:\tlearn: 1578.5927616\ttotal: 1m 38s\tremaining: 22.2s\n",
      "817:\tlearn: 1578.4279566\ttotal: 1m 39s\tremaining: 22s\n",
      "818:\tlearn: 1578.3455638\ttotal: 1m 39s\tremaining: 21.9s\n",
      "819:\tlearn: 1578.2502530\ttotal: 1m 39s\tremaining: 21.8s\n",
      "820:\tlearn: 1578.0617666\ttotal: 1m 39s\tremaining: 21.7s\n",
      "821:\tlearn: 1577.9858090\ttotal: 1m 39s\tremaining: 21.6s\n",
      "822:\tlearn: 1577.7127219\ttotal: 1m 39s\tremaining: 21.4s\n",
      "823:\tlearn: 1577.6071275\ttotal: 1m 39s\tremaining: 21.3s\n",
      "824:\tlearn: 1577.5394933\ttotal: 1m 39s\tremaining: 21.2s\n",
      "825:\tlearn: 1577.3989294\ttotal: 1m 39s\tremaining: 21.1s\n",
      "826:\tlearn: 1577.2507184\ttotal: 1m 40s\tremaining: 20.9s\n",
      "827:\tlearn: 1577.1869287\ttotal: 1m 40s\tremaining: 20.8s\n",
      "828:\tlearn: 1576.9488608\ttotal: 1m 40s\tremaining: 20.7s\n",
      "829:\tlearn: 1576.7179296\ttotal: 1m 40s\tremaining: 20.6s\n",
      "830:\tlearn: 1576.4027831\ttotal: 1m 40s\tremaining: 20.4s\n",
      "831:\tlearn: 1576.3283595\ttotal: 1m 40s\tremaining: 20.3s\n",
      "832:\tlearn: 1576.2647511\ttotal: 1m 40s\tremaining: 20.2s\n",
      "833:\tlearn: 1576.0768164\ttotal: 1m 40s\tremaining: 20.1s\n",
      "834:\tlearn: 1575.9382229\ttotal: 1m 41s\tremaining: 20s\n",
      "835:\tlearn: 1575.7506158\ttotal: 1m 41s\tremaining: 19.9s\n",
      "836:\tlearn: 1575.6846975\ttotal: 1m 41s\tremaining: 19.7s\n",
      "837:\tlearn: 1575.6115186\ttotal: 1m 41s\tremaining: 19.6s\n",
      "838:\tlearn: 1575.4841201\ttotal: 1m 41s\tremaining: 19.5s\n",
      "839:\tlearn: 1575.3779383\ttotal: 1m 41s\tremaining: 19.4s\n",
      "840:\tlearn: 1575.2403390\ttotal: 1m 41s\tremaining: 19.3s\n",
      "841:\tlearn: 1575.1215277\ttotal: 1m 41s\tremaining: 19.1s\n",
      "842:\tlearn: 1575.0790853\ttotal: 1m 42s\tremaining: 19s\n",
      "843:\tlearn: 1574.8100979\ttotal: 1m 42s\tremaining: 18.9s\n",
      "844:\tlearn: 1574.6128532\ttotal: 1m 42s\tremaining: 18.8s\n",
      "845:\tlearn: 1574.4636857\ttotal: 1m 42s\tremaining: 18.7s\n",
      "846:\tlearn: 1574.3206194\ttotal: 1m 42s\tremaining: 18.6s\n",
      "847:\tlearn: 1574.2907790\ttotal: 1m 42s\tremaining: 18.4s\n",
      "848:\tlearn: 1574.0380687\ttotal: 1m 43s\tremaining: 18.3s\n",
      "849:\tlearn: 1573.9224443\ttotal: 1m 43s\tremaining: 18.2s\n",
      "850:\tlearn: 1573.8151026\ttotal: 1m 43s\tremaining: 18.1s\n",
      "851:\tlearn: 1573.7429360\ttotal: 1m 43s\tremaining: 18s\n",
      "852:\tlearn: 1573.7076903\ttotal: 1m 43s\tremaining: 17.8s\n",
      "853:\tlearn: 1573.6323415\ttotal: 1m 43s\tremaining: 17.7s\n",
      "854:\tlearn: 1573.5163654\ttotal: 1m 43s\tremaining: 17.6s\n",
      "855:\tlearn: 1573.4232366\ttotal: 1m 43s\tremaining: 17.5s\n",
      "856:\tlearn: 1573.3371851\ttotal: 1m 44s\tremaining: 17.4s\n",
      "857:\tlearn: 1573.2273106\ttotal: 1m 44s\tremaining: 17.2s\n",
      "858:\tlearn: 1573.1399579\ttotal: 1m 44s\tremaining: 17.1s\n",
      "859:\tlearn: 1573.0381240\ttotal: 1m 44s\tremaining: 17s\n",
      "860:\tlearn: 1572.9866967\ttotal: 1m 44s\tremaining: 16.9s\n",
      "861:\tlearn: 1572.8349798\ttotal: 1m 44s\tremaining: 16.8s\n",
      "862:\tlearn: 1572.7449713\ttotal: 1m 44s\tremaining: 16.6s\n",
      "863:\tlearn: 1572.6907769\ttotal: 1m 45s\tremaining: 16.5s\n",
      "864:\tlearn: 1572.5982487\ttotal: 1m 45s\tremaining: 16.4s\n",
      "865:\tlearn: 1572.4339022\ttotal: 1m 45s\tremaining: 16.3s\n",
      "866:\tlearn: 1572.3153771\ttotal: 1m 45s\tremaining: 16.2s\n",
      "867:\tlearn: 1572.1387468\ttotal: 1m 45s\tremaining: 16.1s\n",
      "868:\tlearn: 1571.9485941\ttotal: 1m 45s\tremaining: 15.9s\n",
      "869:\tlearn: 1571.7659026\ttotal: 1m 45s\tremaining: 15.8s\n",
      "870:\tlearn: 1571.6529834\ttotal: 1m 45s\tremaining: 15.7s\n",
      "871:\tlearn: 1571.4169712\ttotal: 1m 46s\tremaining: 15.6s\n",
      "872:\tlearn: 1571.2786642\ttotal: 1m 46s\tremaining: 15.4s\n",
      "873:\tlearn: 1571.0761335\ttotal: 1m 46s\tremaining: 15.3s\n",
      "874:\tlearn: 1571.0656449\ttotal: 1m 46s\tremaining: 15.2s\n",
      "875:\tlearn: 1570.9502639\ttotal: 1m 46s\tremaining: 15.1s\n",
      "876:\tlearn: 1570.8769474\ttotal: 1m 46s\tremaining: 15s\n",
      "877:\tlearn: 1570.7671306\ttotal: 1m 46s\tremaining: 14.8s\n",
      "878:\tlearn: 1570.7184583\ttotal: 1m 46s\tremaining: 14.7s\n",
      "879:\tlearn: 1570.6737666\ttotal: 1m 47s\tremaining: 14.6s\n",
      "880:\tlearn: 1570.6205332\ttotal: 1m 47s\tremaining: 14.5s\n",
      "881:\tlearn: 1570.4645802\ttotal: 1m 47s\tremaining: 14.4s\n",
      "882:\tlearn: 1570.3257197\ttotal: 1m 47s\tremaining: 14.2s\n",
      "883:\tlearn: 1570.2133148\ttotal: 1m 47s\tremaining: 14.1s\n",
      "884:\tlearn: 1570.1872856\ttotal: 1m 47s\tremaining: 14s\n",
      "885:\tlearn: 1570.0681114\ttotal: 1m 47s\tremaining: 13.9s\n",
      "886:\tlearn: 1570.0128975\ttotal: 1m 48s\tremaining: 13.8s\n",
      "887:\tlearn: 1569.9517932\ttotal: 1m 48s\tremaining: 13.6s\n",
      "888:\tlearn: 1569.8157564\ttotal: 1m 48s\tremaining: 13.5s\n",
      "889:\tlearn: 1569.7263838\ttotal: 1m 48s\tremaining: 13.4s\n",
      "890:\tlearn: 1569.6165016\ttotal: 1m 48s\tremaining: 13.3s\n",
      "891:\tlearn: 1569.5206785\ttotal: 1m 48s\tremaining: 13.2s\n",
      "892:\tlearn: 1569.4319359\ttotal: 1m 48s\tremaining: 13s\n",
      "893:\tlearn: 1569.3261593\ttotal: 1m 48s\tremaining: 12.9s\n",
      "894:\tlearn: 1569.2505543\ttotal: 1m 49s\tremaining: 12.8s\n",
      "895:\tlearn: 1569.1983125\ttotal: 1m 49s\tremaining: 12.7s\n",
      "896:\tlearn: 1569.0567542\ttotal: 1m 49s\tremaining: 12.6s\n",
      "897:\tlearn: 1568.9152041\ttotal: 1m 49s\tremaining: 12.4s\n",
      "898:\tlearn: 1568.8401740\ttotal: 1m 49s\tremaining: 12.3s\n",
      "899:\tlearn: 1568.6740756\ttotal: 1m 49s\tremaining: 12.2s\n",
      "900:\tlearn: 1568.6299676\ttotal: 1m 49s\tremaining: 12.1s\n",
      "901:\tlearn: 1568.5881599\ttotal: 1m 49s\tremaining: 11.9s\n",
      "902:\tlearn: 1568.4280383\ttotal: 1m 50s\tremaining: 11.8s\n",
      "903:\tlearn: 1568.2502557\ttotal: 1m 50s\tremaining: 11.7s\n",
      "904:\tlearn: 1568.1527587\ttotal: 1m 50s\tremaining: 11.6s\n",
      "905:\tlearn: 1568.1189468\ttotal: 1m 50s\tremaining: 11.5s\n",
      "906:\tlearn: 1567.9495320\ttotal: 1m 50s\tremaining: 11.3s\n",
      "907:\tlearn: 1567.9180749\ttotal: 1m 50s\tremaining: 11.2s\n",
      "908:\tlearn: 1567.7287760\ttotal: 1m 50s\tremaining: 11.1s\n",
      "909:\tlearn: 1567.5348390\ttotal: 1m 50s\tremaining: 11s\n",
      "910:\tlearn: 1567.3957012\ttotal: 1m 51s\tremaining: 10.8s\n",
      "911:\tlearn: 1567.3255534\ttotal: 1m 51s\tremaining: 10.7s\n",
      "912:\tlearn: 1567.2472061\ttotal: 1m 51s\tremaining: 10.6s\n",
      "913:\tlearn: 1567.1818659\ttotal: 1m 51s\tremaining: 10.5s\n",
      "914:\tlearn: 1567.0748525\ttotal: 1m 51s\tremaining: 10.4s\n",
      "915:\tlearn: 1567.0397886\ttotal: 1m 51s\tremaining: 10.2s\n",
      "916:\tlearn: 1566.9406788\ttotal: 1m 51s\tremaining: 10.1s\n",
      "917:\tlearn: 1566.8620880\ttotal: 1m 51s\tremaining: 9.98s\n",
      "918:\tlearn: 1566.7924751\ttotal: 1m 51s\tremaining: 9.86s\n",
      "919:\tlearn: 1566.7171799\ttotal: 1m 52s\tremaining: 9.74s\n",
      "920:\tlearn: 1566.6904535\ttotal: 1m 52s\tremaining: 9.62s\n",
      "921:\tlearn: 1566.5721758\ttotal: 1m 52s\tremaining: 9.5s\n",
      "922:\tlearn: 1566.4936826\ttotal: 1m 52s\tremaining: 9.37s\n",
      "923:\tlearn: 1566.4197409\ttotal: 1m 52s\tremaining: 9.25s\n",
      "924:\tlearn: 1566.2806361\ttotal: 1m 52s\tremaining: 9.13s\n",
      "925:\tlearn: 1566.1636858\ttotal: 1m 52s\tremaining: 9.01s\n",
      "926:\tlearn: 1566.0282151\ttotal: 1m 52s\tremaining: 8.89s\n",
      "927:\tlearn: 1565.8224844\ttotal: 1m 53s\tremaining: 8.77s\n",
      "928:\tlearn: 1565.6974421\ttotal: 1m 53s\tremaining: 8.64s\n",
      "929:\tlearn: 1565.6081395\ttotal: 1m 53s\tremaining: 8.52s\n",
      "930:\tlearn: 1565.4871321\ttotal: 1m 53s\tremaining: 8.4s\n",
      "931:\tlearn: 1565.4035429\ttotal: 1m 53s\tremaining: 8.28s\n",
      "932:\tlearn: 1565.3297604\ttotal: 1m 53s\tremaining: 8.15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933:\tlearn: 1565.2532491\ttotal: 1m 53s\tremaining: 8.04s\n",
      "934:\tlearn: 1565.0155618\ttotal: 1m 53s\tremaining: 7.91s\n",
      "935:\tlearn: 1565.0008354\ttotal: 1m 53s\tremaining: 7.79s\n",
      "936:\tlearn: 1564.9698960\ttotal: 1m 54s\tremaining: 7.67s\n",
      "937:\tlearn: 1564.8662967\ttotal: 1m 54s\tremaining: 7.55s\n",
      "938:\tlearn: 1564.7267458\ttotal: 1m 54s\tremaining: 7.43s\n",
      "939:\tlearn: 1564.5474627\ttotal: 1m 54s\tremaining: 7.31s\n",
      "940:\tlearn: 1564.4124414\ttotal: 1m 54s\tremaining: 7.18s\n",
      "941:\tlearn: 1564.3678918\ttotal: 1m 54s\tremaining: 7.06s\n",
      "942:\tlearn: 1564.2821262\ttotal: 1m 54s\tremaining: 6.94s\n",
      "943:\tlearn: 1564.2190835\ttotal: 1m 54s\tremaining: 6.82s\n",
      "944:\tlearn: 1564.1742555\ttotal: 1m 55s\tremaining: 6.7s\n",
      "945:\tlearn: 1564.0255978\ttotal: 1m 55s\tremaining: 6.58s\n",
      "946:\tlearn: 1563.9973757\ttotal: 1m 55s\tremaining: 6.45s\n",
      "947:\tlearn: 1563.9656927\ttotal: 1m 55s\tremaining: 6.33s\n",
      "948:\tlearn: 1563.9195243\ttotal: 1m 55s\tremaining: 6.21s\n",
      "949:\tlearn: 1563.8398378\ttotal: 1m 55s\tremaining: 6.09s\n",
      "950:\tlearn: 1563.7050314\ttotal: 1m 55s\tremaining: 5.97s\n",
      "951:\tlearn: 1563.6691907\ttotal: 1m 55s\tremaining: 5.84s\n",
      "952:\tlearn: 1563.4973348\ttotal: 1m 56s\tremaining: 5.72s\n",
      "953:\tlearn: 1563.4405632\ttotal: 1m 56s\tremaining: 5.6s\n",
      "954:\tlearn: 1563.3616208\ttotal: 1m 56s\tremaining: 5.47s\n",
      "955:\tlearn: 1563.2445104\ttotal: 1m 56s\tremaining: 5.35s\n",
      "956:\tlearn: 1563.2095964\ttotal: 1m 56s\tremaining: 5.23s\n",
      "957:\tlearn: 1563.1859545\ttotal: 1m 56s\tremaining: 5.11s\n",
      "958:\tlearn: 1563.1546751\ttotal: 1m 56s\tremaining: 4.99s\n",
      "959:\tlearn: 1562.9911503\ttotal: 1m 56s\tremaining: 4.87s\n",
      "960:\tlearn: 1562.9090370\ttotal: 1m 56s\tremaining: 4.74s\n",
      "961:\tlearn: 1562.8230129\ttotal: 1m 57s\tremaining: 4.62s\n",
      "962:\tlearn: 1562.7743894\ttotal: 1m 57s\tremaining: 4.5s\n",
      "963:\tlearn: 1562.6780104\ttotal: 1m 57s\tremaining: 4.38s\n",
      "964:\tlearn: 1562.6585442\ttotal: 1m 57s\tremaining: 4.26s\n",
      "965:\tlearn: 1562.5943716\ttotal: 1m 57s\tremaining: 4.14s\n",
      "966:\tlearn: 1562.4947434\ttotal: 1m 57s\tremaining: 4.01s\n",
      "967:\tlearn: 1562.4565893\ttotal: 1m 57s\tremaining: 3.89s\n",
      "968:\tlearn: 1562.4008218\ttotal: 1m 57s\tremaining: 3.77s\n",
      "969:\tlearn: 1562.3157585\ttotal: 1m 58s\tremaining: 3.65s\n",
      "970:\tlearn: 1562.2495942\ttotal: 1m 58s\tremaining: 3.53s\n",
      "971:\tlearn: 1562.1800199\ttotal: 1m 58s\tremaining: 3.4s\n",
      "972:\tlearn: 1562.1186322\ttotal: 1m 58s\tremaining: 3.28s\n",
      "973:\tlearn: 1562.1009819\ttotal: 1m 58s\tremaining: 3.16s\n",
      "974:\tlearn: 1562.0045118\ttotal: 1m 58s\tremaining: 3.04s\n",
      "975:\tlearn: 1561.9039871\ttotal: 1m 58s\tremaining: 2.92s\n",
      "976:\tlearn: 1561.7969236\ttotal: 1m 58s\tremaining: 2.8s\n",
      "977:\tlearn: 1561.7718624\ttotal: 1m 58s\tremaining: 2.67s\n",
      "978:\tlearn: 1561.7229170\ttotal: 1m 59s\tremaining: 2.55s\n",
      "979:\tlearn: 1561.6674531\ttotal: 1m 59s\tremaining: 2.43s\n",
      "980:\tlearn: 1561.6085966\ttotal: 1m 59s\tremaining: 2.31s\n",
      "981:\tlearn: 1561.5909462\ttotal: 1m 59s\tremaining: 2.19s\n",
      "982:\tlearn: 1561.5157704\ttotal: 1m 59s\tremaining: 2.07s\n",
      "983:\tlearn: 1561.4050691\ttotal: 1m 59s\tremaining: 1.95s\n",
      "984:\tlearn: 1561.3090144\ttotal: 1m 59s\tremaining: 1.82s\n",
      "985:\tlearn: 1561.2266250\ttotal: 1m 59s\tremaining: 1.7s\n",
      "986:\tlearn: 1561.1994661\ttotal: 2m\tremaining: 1.58s\n",
      "987:\tlearn: 1561.1068064\ttotal: 2m\tremaining: 1.46s\n",
      "988:\tlearn: 1561.0301200\ttotal: 2m\tremaining: 1.34s\n",
      "989:\tlearn: 1560.9336301\ttotal: 2m\tremaining: 1.22s\n",
      "990:\tlearn: 1560.9066669\ttotal: 2m\tremaining: 1.09s\n",
      "991:\tlearn: 1560.8486540\ttotal: 2m\tremaining: 974ms\n",
      "992:\tlearn: 1560.6029216\ttotal: 2m\tremaining: 852ms\n",
      "993:\tlearn: 1560.5708317\ttotal: 2m 1s\tremaining: 731ms\n",
      "994:\tlearn: 1560.5194159\ttotal: 2m 1s\tremaining: 609ms\n",
      "995:\tlearn: 1560.4291728\ttotal: 2m 1s\tremaining: 488ms\n",
      "996:\tlearn: 1560.3842162\ttotal: 2m 1s\tremaining: 366ms\n",
      "997:\tlearn: 1560.2365129\ttotal: 2m 1s\tremaining: 244ms\n",
      "998:\tlearn: 1560.1440917\ttotal: 2m 1s\tremaining: 122ms\n",
      "999:\tlearn: 1560.1281448\ttotal: 2m 1s\tremaining: 0us\n",
      "Learning rate set to 0.094301\n",
      "0:\tlearn: 4418.4772824\ttotal: 188ms\tremaining: 3m 7s\n",
      "1:\tlearn: 4156.4854468\ttotal: 379ms\tremaining: 3m 9s\n",
      "2:\tlearn: 3918.7397704\ttotal: 557ms\tremaining: 3m 5s\n",
      "3:\tlearn: 3709.8691142\ttotal: 708ms\tremaining: 2m 56s\n",
      "4:\tlearn: 3521.4508170\ttotal: 859ms\tremaining: 2m 50s\n",
      "5:\tlearn: 3354.8468411\ttotal: 1s\tremaining: 2m 45s\n",
      "6:\tlearn: 3205.4170538\ttotal: 1.18s\tremaining: 2m 46s\n",
      "7:\tlearn: 3074.3375088\ttotal: 1.33s\tremaining: 2m 45s\n",
      "8:\tlearn: 2954.4448324\ttotal: 1.47s\tremaining: 2m 41s\n",
      "9:\tlearn: 2850.5909250\ttotal: 1.62s\tremaining: 2m 40s\n",
      "10:\tlearn: 2755.1105620\ttotal: 1.75s\tremaining: 2m 37s\n",
      "11:\tlearn: 2672.3393043\ttotal: 1.86s\tremaining: 2m 32s\n",
      "12:\tlearn: 2599.5738033\ttotal: 2.03s\tremaining: 2m 33s\n",
      "13:\tlearn: 2525.7301365\ttotal: 2.17s\tremaining: 2m 32s\n",
      "14:\tlearn: 2460.8120030\ttotal: 2.29s\tremaining: 2m 30s\n",
      "15:\tlearn: 2410.2349276\ttotal: 2.44s\tremaining: 2m 30s\n",
      "16:\tlearn: 2360.5222295\ttotal: 2.6s\tremaining: 2m 30s\n",
      "17:\tlearn: 2321.2891615\ttotal: 2.77s\tremaining: 2m 31s\n",
      "18:\tlearn: 2282.2932775\ttotal: 2.88s\tremaining: 2m 28s\n",
      "19:\tlearn: 2247.7890843\ttotal: 3.03s\tremaining: 2m 28s\n",
      "20:\tlearn: 2214.9027006\ttotal: 3.13s\tremaining: 2m 26s\n",
      "21:\tlearn: 2189.1801216\ttotal: 3.27s\tremaining: 2m 25s\n",
      "22:\tlearn: 2162.6157610\ttotal: 3.44s\tremaining: 2m 26s\n",
      "23:\tlearn: 2140.9124242\ttotal: 3.59s\tremaining: 2m 25s\n",
      "24:\tlearn: 2122.8474922\ttotal: 3.75s\tremaining: 2m 26s\n",
      "25:\tlearn: 2104.4806284\ttotal: 3.87s\tremaining: 2m 24s\n",
      "26:\tlearn: 2086.8780292\ttotal: 4s\tremaining: 2m 24s\n",
      "27:\tlearn: 2070.5621077\ttotal: 4.12s\tremaining: 2m 23s\n",
      "28:\tlearn: 2055.2012123\ttotal: 4.2s\tremaining: 2m 20s\n",
      "29:\tlearn: 2043.3595698\ttotal: 4.3s\tremaining: 2m 19s\n",
      "30:\tlearn: 2032.4337020\ttotal: 4.43s\tremaining: 2m 18s\n",
      "31:\tlearn: 2020.4753275\ttotal: 4.55s\tremaining: 2m 17s\n",
      "32:\tlearn: 2011.1942437\ttotal: 4.67s\tremaining: 2m 16s\n",
      "33:\tlearn: 2003.4115434\ttotal: 4.79s\tremaining: 2m 16s\n",
      "34:\tlearn: 1994.6689126\ttotal: 4.9s\tremaining: 2m 15s\n",
      "35:\tlearn: 1986.3490827\ttotal: 5.02s\tremaining: 2m 14s\n",
      "36:\tlearn: 1977.6578359\ttotal: 5.14s\tremaining: 2m 13s\n",
      "37:\tlearn: 1967.7108027\ttotal: 5.24s\tremaining: 2m 12s\n",
      "38:\tlearn: 1961.0364894\ttotal: 5.33s\tremaining: 2m 11s\n",
      "39:\tlearn: 1953.9042566\ttotal: 5.45s\tremaining: 2m 10s\n",
      "40:\tlearn: 1947.6372380\ttotal: 5.53s\tremaining: 2m 9s\n",
      "41:\tlearn: 1942.4715751\ttotal: 5.67s\tremaining: 2m 9s\n",
      "42:\tlearn: 1937.8238311\ttotal: 5.78s\tremaining: 2m 8s\n",
      "43:\tlearn: 1933.5106503\ttotal: 5.92s\tremaining: 2m 8s\n",
      "44:\tlearn: 1928.3243000\ttotal: 6.05s\tremaining: 2m 8s\n",
      "45:\tlearn: 1925.1242433\ttotal: 6.18s\tremaining: 2m 8s\n",
      "46:\tlearn: 1921.4811470\ttotal: 6.32s\tremaining: 2m 8s\n",
      "47:\tlearn: 1918.3265528\ttotal: 6.45s\tremaining: 2m 7s\n",
      "48:\tlearn: 1914.8850419\ttotal: 6.57s\tremaining: 2m 7s\n",
      "49:\tlearn: 1910.5323537\ttotal: 6.7s\tremaining: 2m 7s\n",
      "50:\tlearn: 1907.1344995\ttotal: 6.8s\tremaining: 2m 6s\n",
      "51:\tlearn: 1904.8737068\ttotal: 6.92s\tremaining: 2m 6s\n",
      "52:\tlearn: 1900.4720988\ttotal: 7.03s\tremaining: 2m 5s\n",
      "53:\tlearn: 1896.5147177\ttotal: 7.16s\tremaining: 2m 5s\n",
      "54:\tlearn: 1894.3471389\ttotal: 7.3s\tremaining: 2m 5s\n",
      "55:\tlearn: 1891.0105489\ttotal: 7.41s\tremaining: 2m 4s\n",
      "56:\tlearn: 1888.6467568\ttotal: 7.48s\tremaining: 2m 3s\n",
      "57:\tlearn: 1886.3311008\ttotal: 7.59s\tremaining: 2m 3s\n",
      "58:\tlearn: 1884.3343948\ttotal: 7.71s\tremaining: 2m 3s\n",
      "59:\tlearn: 1881.5469896\ttotal: 7.85s\tremaining: 2m 2s\n",
      "60:\tlearn: 1877.3128487\ttotal: 7.99s\tremaining: 2m 2s\n",
      "61:\tlearn: 1875.7902646\ttotal: 8.13s\tremaining: 2m 3s\n",
      "62:\tlearn: 1873.1262541\ttotal: 8.22s\tremaining: 2m 2s\n",
      "63:\tlearn: 1870.9036386\ttotal: 8.34s\tremaining: 2m 1s\n",
      "64:\tlearn: 1868.6578963\ttotal: 8.48s\tremaining: 2m 2s\n",
      "65:\tlearn: 1866.2659794\ttotal: 8.61s\tremaining: 2m 1s\n",
      "66:\tlearn: 1863.6727273\ttotal: 8.73s\tremaining: 2m 1s\n",
      "67:\tlearn: 1861.5907199\ttotal: 8.84s\tremaining: 2m 1s\n",
      "68:\tlearn: 1859.0472853\ttotal: 8.93s\tremaining: 2m\n",
      "69:\tlearn: 1857.1963333\ttotal: 9.05s\tremaining: 2m\n",
      "70:\tlearn: 1854.3979514\ttotal: 9.16s\tremaining: 1m 59s\n",
      "71:\tlearn: 1852.2833697\ttotal: 9.31s\tremaining: 1m 59s\n",
      "72:\tlearn: 1851.0152152\ttotal: 9.42s\tremaining: 1m 59s\n",
      "73:\tlearn: 1848.6951741\ttotal: 9.54s\tremaining: 1m 59s\n",
      "74:\tlearn: 1847.4009120\ttotal: 9.65s\tremaining: 1m 59s\n",
      "75:\tlearn: 1845.8007254\ttotal: 9.79s\tremaining: 1m 59s\n",
      "76:\tlearn: 1844.0027540\ttotal: 9.92s\tremaining: 1m 58s\n",
      "77:\tlearn: 1841.3903866\ttotal: 10s\tremaining: 1m 58s\n",
      "78:\tlearn: 1839.0535706\ttotal: 10.1s\tremaining: 1m 58s\n",
      "79:\tlearn: 1836.7777702\ttotal: 10.3s\tremaining: 1m 58s\n",
      "80:\tlearn: 1835.6557521\ttotal: 10.4s\tremaining: 1m 57s\n",
      "81:\tlearn: 1834.0752215\ttotal: 10.5s\tremaining: 1m 57s\n",
      "82:\tlearn: 1832.4668273\ttotal: 10.6s\tremaining: 1m 56s\n",
      "83:\tlearn: 1831.3537466\ttotal: 10.7s\tremaining: 1m 56s\n",
      "84:\tlearn: 1829.5436875\ttotal: 10.8s\tremaining: 1m 55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85:\tlearn: 1827.6410479\ttotal: 10.9s\tremaining: 1m 55s\n",
      "86:\tlearn: 1826.1965738\ttotal: 11.1s\tremaining: 1m 56s\n",
      "87:\tlearn: 1823.9799627\ttotal: 11.2s\tremaining: 1m 55s\n",
      "88:\tlearn: 1822.7875334\ttotal: 11.3s\tremaining: 1m 55s\n",
      "89:\tlearn: 1820.3625624\ttotal: 11.4s\tremaining: 1m 55s\n",
      "90:\tlearn: 1819.0572158\ttotal: 11.5s\tremaining: 1m 54s\n",
      "91:\tlearn: 1817.9322756\ttotal: 11.7s\tremaining: 1m 54s\n",
      "92:\tlearn: 1816.3029848\ttotal: 11.7s\tremaining: 1m 54s\n",
      "93:\tlearn: 1814.5405713\ttotal: 11.9s\tremaining: 1m 54s\n",
      "94:\tlearn: 1812.5986006\ttotal: 12s\tremaining: 1m 54s\n",
      "95:\tlearn: 1810.8078461\ttotal: 12.1s\tremaining: 1m 54s\n",
      "96:\tlearn: 1809.4915793\ttotal: 12.3s\tremaining: 1m 54s\n",
      "97:\tlearn: 1808.1579043\ttotal: 12.4s\tremaining: 1m 54s\n",
      "98:\tlearn: 1807.3208787\ttotal: 12.5s\tremaining: 1m 53s\n",
      "99:\tlearn: 1805.3896268\ttotal: 12.6s\tremaining: 1m 53s\n",
      "100:\tlearn: 1804.6752285\ttotal: 12.8s\tremaining: 1m 53s\n",
      "101:\tlearn: 1802.9352550\ttotal: 12.9s\tremaining: 1m 53s\n",
      "102:\tlearn: 1801.0276316\ttotal: 13s\tremaining: 1m 53s\n",
      "103:\tlearn: 1799.6103535\ttotal: 13.1s\tremaining: 1m 53s\n",
      "104:\tlearn: 1798.6073133\ttotal: 13.3s\tremaining: 1m 52s\n",
      "105:\tlearn: 1797.8692664\ttotal: 13.4s\tremaining: 1m 52s\n",
      "106:\tlearn: 1796.4269179\ttotal: 13.5s\tremaining: 1m 52s\n",
      "107:\tlearn: 1794.8408016\ttotal: 13.6s\tremaining: 1m 52s\n",
      "108:\tlearn: 1793.2957333\ttotal: 13.7s\tremaining: 1m 52s\n",
      "109:\tlearn: 1792.3314996\ttotal: 13.8s\tremaining: 1m 52s\n",
      "110:\tlearn: 1791.0075415\ttotal: 14s\tremaining: 1m 52s\n",
      "111:\tlearn: 1789.8610317\ttotal: 14.1s\tremaining: 1m 52s\n",
      "112:\tlearn: 1788.3467366\ttotal: 14.3s\tremaining: 1m 52s\n",
      "113:\tlearn: 1787.1449138\ttotal: 14.4s\tremaining: 1m 51s\n",
      "114:\tlearn: 1786.1884828\ttotal: 14.5s\tremaining: 1m 51s\n",
      "115:\tlearn: 1785.3978595\ttotal: 14.6s\tremaining: 1m 51s\n",
      "116:\tlearn: 1784.4273509\ttotal: 14.7s\tremaining: 1m 51s\n",
      "117:\tlearn: 1783.7052121\ttotal: 14.9s\tremaining: 1m 51s\n",
      "118:\tlearn: 1782.1158687\ttotal: 15s\tremaining: 1m 50s\n",
      "119:\tlearn: 1781.4505981\ttotal: 15.1s\tremaining: 1m 50s\n",
      "120:\tlearn: 1780.4227622\ttotal: 15.2s\tremaining: 1m 50s\n",
      "121:\tlearn: 1778.7411548\ttotal: 15.4s\tremaining: 1m 50s\n",
      "122:\tlearn: 1776.9436587\ttotal: 15.5s\tremaining: 1m 50s\n",
      "123:\tlearn: 1775.7641950\ttotal: 15.6s\tremaining: 1m 50s\n",
      "124:\tlearn: 1774.4205585\ttotal: 15.7s\tremaining: 1m 49s\n",
      "125:\tlearn: 1773.0117384\ttotal: 15.8s\tremaining: 1m 49s\n",
      "126:\tlearn: 1771.8211141\ttotal: 16s\tremaining: 1m 49s\n",
      "127:\tlearn: 1770.5119227\ttotal: 16.1s\tremaining: 1m 49s\n",
      "128:\tlearn: 1770.0889746\ttotal: 16.2s\tremaining: 1m 49s\n",
      "129:\tlearn: 1768.9707098\ttotal: 16.3s\tremaining: 1m 49s\n",
      "130:\tlearn: 1768.3375681\ttotal: 16.5s\tremaining: 1m 49s\n",
      "131:\tlearn: 1767.3941759\ttotal: 16.6s\tremaining: 1m 49s\n",
      "132:\tlearn: 1766.0109900\ttotal: 16.7s\tremaining: 1m 49s\n",
      "133:\tlearn: 1765.2387845\ttotal: 16.9s\tremaining: 1m 49s\n",
      "134:\tlearn: 1763.8283817\ttotal: 17s\tremaining: 1m 48s\n",
      "135:\tlearn: 1762.8996868\ttotal: 17.1s\tremaining: 1m 48s\n",
      "136:\tlearn: 1762.0070623\ttotal: 17.2s\tremaining: 1m 48s\n",
      "137:\tlearn: 1761.1280371\ttotal: 17.3s\tremaining: 1m 48s\n",
      "138:\tlearn: 1760.2549099\ttotal: 17.5s\tremaining: 1m 48s\n",
      "139:\tlearn: 1759.9419989\ttotal: 17.6s\tremaining: 1m 48s\n",
      "140:\tlearn: 1758.7458750\ttotal: 17.7s\tremaining: 1m 47s\n",
      "141:\tlearn: 1758.1112766\ttotal: 17.8s\tremaining: 1m 47s\n",
      "142:\tlearn: 1757.7609033\ttotal: 17.9s\tremaining: 1m 47s\n",
      "143:\tlearn: 1757.1942946\ttotal: 18s\tremaining: 1m 47s\n",
      "144:\tlearn: 1756.7258202\ttotal: 18.2s\tremaining: 1m 47s\n",
      "145:\tlearn: 1755.6207042\ttotal: 18.3s\tremaining: 1m 46s\n",
      "146:\tlearn: 1754.6614701\ttotal: 18.4s\tremaining: 1m 46s\n",
      "147:\tlearn: 1754.3702915\ttotal: 18.5s\tremaining: 1m 46s\n",
      "148:\tlearn: 1753.8527498\ttotal: 18.6s\tremaining: 1m 46s\n",
      "149:\tlearn: 1752.7497799\ttotal: 18.8s\tremaining: 1m 46s\n",
      "150:\tlearn: 1751.6646871\ttotal: 18.9s\tremaining: 1m 46s\n",
      "151:\tlearn: 1751.3329613\ttotal: 19s\tremaining: 1m 46s\n",
      "152:\tlearn: 1750.2475424\ttotal: 19.2s\tremaining: 1m 46s\n",
      "153:\tlearn: 1749.3841522\ttotal: 19.3s\tremaining: 1m 45s\n",
      "154:\tlearn: 1749.0859925\ttotal: 19.4s\tremaining: 1m 45s\n",
      "155:\tlearn: 1748.6169856\ttotal: 19.5s\tremaining: 1m 45s\n",
      "156:\tlearn: 1748.3296945\ttotal: 19.7s\tremaining: 1m 45s\n",
      "157:\tlearn: 1747.3926699\ttotal: 19.8s\tremaining: 1m 45s\n",
      "158:\tlearn: 1746.8150567\ttotal: 19.9s\tremaining: 1m 45s\n",
      "159:\tlearn: 1745.5699188\ttotal: 20.1s\tremaining: 1m 45s\n",
      "160:\tlearn: 1744.8554938\ttotal: 20.2s\tremaining: 1m 45s\n",
      "161:\tlearn: 1744.6335266\ttotal: 20.3s\tremaining: 1m 44s\n",
      "162:\tlearn: 1744.0942686\ttotal: 20.4s\tremaining: 1m 44s\n",
      "163:\tlearn: 1743.4800693\ttotal: 20.5s\tremaining: 1m 44s\n",
      "164:\tlearn: 1742.9063011\ttotal: 20.6s\tremaining: 1m 44s\n",
      "165:\tlearn: 1742.1706963\ttotal: 20.7s\tremaining: 1m 44s\n",
      "166:\tlearn: 1741.6027213\ttotal: 20.9s\tremaining: 1m 44s\n",
      "167:\tlearn: 1741.3059614\ttotal: 21s\tremaining: 1m 44s\n",
      "168:\tlearn: 1741.0048175\ttotal: 21.1s\tremaining: 1m 43s\n",
      "169:\tlearn: 1740.1289547\ttotal: 21.2s\tremaining: 1m 43s\n",
      "170:\tlearn: 1739.1838096\ttotal: 21.4s\tremaining: 1m 43s\n",
      "171:\tlearn: 1738.7684003\ttotal: 21.5s\tremaining: 1m 43s\n",
      "172:\tlearn: 1738.1005104\ttotal: 21.6s\tremaining: 1m 43s\n",
      "173:\tlearn: 1737.5543467\ttotal: 21.7s\tremaining: 1m 43s\n",
      "174:\tlearn: 1737.2190900\ttotal: 21.9s\tremaining: 1m 43s\n",
      "175:\tlearn: 1736.4901115\ttotal: 22s\tremaining: 1m 43s\n",
      "176:\tlearn: 1736.0905911\ttotal: 22.2s\tremaining: 1m 43s\n",
      "177:\tlearn: 1735.5324995\ttotal: 22.3s\tremaining: 1m 42s\n",
      "178:\tlearn: 1734.7035187\ttotal: 22.4s\tremaining: 1m 42s\n",
      "179:\tlearn: 1733.9351414\ttotal: 22.4s\tremaining: 1m 42s\n",
      "180:\tlearn: 1733.3878259\ttotal: 22.6s\tremaining: 1m 42s\n",
      "181:\tlearn: 1732.6185078\ttotal: 22.7s\tremaining: 1m 42s\n",
      "182:\tlearn: 1731.8190787\ttotal: 22.8s\tremaining: 1m 41s\n",
      "183:\tlearn: 1731.5977948\ttotal: 23s\tremaining: 1m 41s\n",
      "184:\tlearn: 1730.8282445\ttotal: 23.1s\tremaining: 1m 41s\n",
      "185:\tlearn: 1730.2405658\ttotal: 23.2s\tremaining: 1m 41s\n",
      "186:\tlearn: 1729.7628064\ttotal: 23.4s\tremaining: 1m 41s\n",
      "187:\tlearn: 1728.6973280\ttotal: 23.5s\tremaining: 1m 41s\n",
      "188:\tlearn: 1728.1857261\ttotal: 23.6s\tremaining: 1m 41s\n",
      "189:\tlearn: 1727.6753345\ttotal: 23.7s\tremaining: 1m 41s\n",
      "190:\tlearn: 1727.1096828\ttotal: 23.8s\tremaining: 1m 40s\n",
      "191:\tlearn: 1726.4437296\ttotal: 24s\tremaining: 1m 40s\n",
      "192:\tlearn: 1725.5794312\ttotal: 24.1s\tremaining: 1m 40s\n",
      "193:\tlearn: 1724.6351955\ttotal: 24.2s\tremaining: 1m 40s\n",
      "194:\tlearn: 1723.6951603\ttotal: 24.3s\tremaining: 1m 40s\n",
      "195:\tlearn: 1723.0123319\ttotal: 24.4s\tremaining: 1m 40s\n",
      "196:\tlearn: 1722.1943398\ttotal: 24.6s\tremaining: 1m 40s\n",
      "197:\tlearn: 1721.6201187\ttotal: 24.7s\tremaining: 1m 40s\n",
      "198:\tlearn: 1720.9873641\ttotal: 24.8s\tremaining: 1m 39s\n",
      "199:\tlearn: 1720.0950751\ttotal: 24.9s\tremaining: 1m 39s\n",
      "200:\tlearn: 1719.7835921\ttotal: 25s\tremaining: 1m 39s\n",
      "201:\tlearn: 1719.1613503\ttotal: 25.1s\tremaining: 1m 39s\n",
      "202:\tlearn: 1718.2159911\ttotal: 25.2s\tremaining: 1m 39s\n",
      "203:\tlearn: 1717.4902313\ttotal: 25.3s\tremaining: 1m 38s\n",
      "204:\tlearn: 1717.2669522\ttotal: 25.5s\tremaining: 1m 38s\n",
      "205:\tlearn: 1716.6336395\ttotal: 25.6s\tremaining: 1m 38s\n",
      "206:\tlearn: 1716.2302802\ttotal: 25.7s\tremaining: 1m 38s\n",
      "207:\tlearn: 1715.7396732\ttotal: 25.8s\tremaining: 1m 38s\n",
      "208:\tlearn: 1715.1329558\ttotal: 25.9s\tremaining: 1m 38s\n",
      "209:\tlearn: 1714.5049228\ttotal: 26s\tremaining: 1m 37s\n",
      "210:\tlearn: 1714.1484351\ttotal: 26.1s\tremaining: 1m 37s\n",
      "211:\tlearn: 1713.3578511\ttotal: 26.2s\tremaining: 1m 37s\n",
      "212:\tlearn: 1713.1202341\ttotal: 26.3s\tremaining: 1m 37s\n",
      "213:\tlearn: 1713.0456176\ttotal: 26.4s\tremaining: 1m 37s\n",
      "214:\tlearn: 1712.3988437\ttotal: 26.6s\tremaining: 1m 36s\n",
      "215:\tlearn: 1712.0400483\ttotal: 26.7s\tremaining: 1m 36s\n",
      "216:\tlearn: 1711.4342260\ttotal: 26.8s\tremaining: 1m 36s\n",
      "217:\tlearn: 1710.9928366\ttotal: 26.9s\tremaining: 1m 36s\n",
      "218:\tlearn: 1710.6291355\ttotal: 27.1s\tremaining: 1m 36s\n",
      "219:\tlearn: 1710.1855586\ttotal: 27.2s\tremaining: 1m 36s\n",
      "220:\tlearn: 1709.7621738\ttotal: 27.3s\tremaining: 1m 36s\n",
      "221:\tlearn: 1709.3454326\ttotal: 27.5s\tremaining: 1m 36s\n",
      "222:\tlearn: 1708.5932038\ttotal: 27.6s\tremaining: 1m 36s\n",
      "223:\tlearn: 1708.3121413\ttotal: 27.7s\tremaining: 1m 35s\n",
      "224:\tlearn: 1707.6188376\ttotal: 27.8s\tremaining: 1m 35s\n",
      "225:\tlearn: 1707.0937477\ttotal: 27.9s\tremaining: 1m 35s\n",
      "226:\tlearn: 1706.7263984\ttotal: 28s\tremaining: 1m 35s\n",
      "227:\tlearn: 1706.3451487\ttotal: 28.1s\tremaining: 1m 35s\n",
      "228:\tlearn: 1705.9839409\ttotal: 28.2s\tremaining: 1m 35s\n",
      "229:\tlearn: 1705.5186488\ttotal: 28.4s\tremaining: 1m 34s\n",
      "230:\tlearn: 1704.7220157\ttotal: 28.5s\tremaining: 1m 34s\n",
      "231:\tlearn: 1704.2187787\ttotal: 28.6s\tremaining: 1m 34s\n",
      "232:\tlearn: 1703.5937329\ttotal: 28.7s\tremaining: 1m 34s\n",
      "233:\tlearn: 1703.0464982\ttotal: 28.8s\tremaining: 1m 34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234:\tlearn: 1702.3567887\ttotal: 28.9s\tremaining: 1m 34s\n",
      "235:\tlearn: 1701.9407531\ttotal: 29s\tremaining: 1m 33s\n",
      "236:\tlearn: 1701.3121917\ttotal: 29.1s\tremaining: 1m 33s\n",
      "237:\tlearn: 1701.1018870\ttotal: 29.3s\tremaining: 1m 33s\n",
      "238:\tlearn: 1700.3496305\ttotal: 29.4s\tremaining: 1m 33s\n",
      "239:\tlearn: 1699.7986993\ttotal: 29.5s\tremaining: 1m 33s\n",
      "240:\tlearn: 1699.0551800\ttotal: 29.6s\tremaining: 1m 33s\n",
      "241:\tlearn: 1698.4409832\ttotal: 29.7s\tremaining: 1m 33s\n",
      "242:\tlearn: 1698.0318731\ttotal: 29.9s\tremaining: 1m 33s\n",
      "243:\tlearn: 1697.4442769\ttotal: 30s\tremaining: 1m 32s\n",
      "244:\tlearn: 1697.0449647\ttotal: 30.1s\tremaining: 1m 32s\n",
      "245:\tlearn: 1696.7251831\ttotal: 30.2s\tremaining: 1m 32s\n",
      "246:\tlearn: 1696.2449476\ttotal: 30.3s\tremaining: 1m 32s\n",
      "247:\tlearn: 1695.5153699\ttotal: 30.5s\tremaining: 1m 32s\n",
      "248:\tlearn: 1695.2287723\ttotal: 30.6s\tremaining: 1m 32s\n",
      "249:\tlearn: 1694.6975717\ttotal: 30.7s\tremaining: 1m 32s\n",
      "250:\tlearn: 1694.3837503\ttotal: 30.8s\tremaining: 1m 31s\n",
      "251:\tlearn: 1694.2554193\ttotal: 30.9s\tremaining: 1m 31s\n",
      "252:\tlearn: 1693.4634364\ttotal: 31.1s\tremaining: 1m 31s\n",
      "253:\tlearn: 1692.7409465\ttotal: 31.2s\tremaining: 1m 31s\n",
      "254:\tlearn: 1692.0515515\ttotal: 31.3s\tremaining: 1m 31s\n",
      "255:\tlearn: 1691.6539564\ttotal: 31.4s\tremaining: 1m 31s\n",
      "256:\tlearn: 1691.1411501\ttotal: 31.5s\tremaining: 1m 31s\n",
      "257:\tlearn: 1690.7565936\ttotal: 31.7s\tremaining: 1m 31s\n",
      "258:\tlearn: 1690.3737055\ttotal: 31.8s\tremaining: 1m 30s\n",
      "259:\tlearn: 1690.2384166\ttotal: 31.9s\tremaining: 1m 30s\n",
      "260:\tlearn: 1689.8289465\ttotal: 32s\tremaining: 1m 30s\n",
      "261:\tlearn: 1689.5412936\ttotal: 32.1s\tremaining: 1m 30s\n",
      "262:\tlearn: 1688.6187924\ttotal: 32.2s\tremaining: 1m 30s\n",
      "263:\tlearn: 1688.4220703\ttotal: 32.3s\tremaining: 1m 30s\n",
      "264:\tlearn: 1687.8936229\ttotal: 32.5s\tremaining: 1m 30s\n",
      "265:\tlearn: 1687.2047212\ttotal: 32.5s\tremaining: 1m 29s\n",
      "266:\tlearn: 1686.8251460\ttotal: 32.7s\tremaining: 1m 29s\n",
      "267:\tlearn: 1686.3062927\ttotal: 32.8s\tremaining: 1m 29s\n",
      "268:\tlearn: 1685.7520213\ttotal: 33s\tremaining: 1m 29s\n",
      "269:\tlearn: 1685.4383314\ttotal: 33.1s\tremaining: 1m 29s\n",
      "270:\tlearn: 1685.2820418\ttotal: 33.2s\tremaining: 1m 29s\n",
      "271:\tlearn: 1684.9049550\ttotal: 33.3s\tremaining: 1m 29s\n",
      "272:\tlearn: 1684.4894319\ttotal: 33.4s\tremaining: 1m 28s\n",
      "273:\tlearn: 1684.1811305\ttotal: 33.5s\tremaining: 1m 28s\n",
      "274:\tlearn: 1684.0109916\ttotal: 33.7s\tremaining: 1m 28s\n",
      "275:\tlearn: 1683.9138868\ttotal: 33.8s\tremaining: 1m 28s\n",
      "276:\tlearn: 1683.5899967\ttotal: 34s\tremaining: 1m 28s\n",
      "277:\tlearn: 1683.1986528\ttotal: 34.1s\tremaining: 1m 28s\n",
      "278:\tlearn: 1682.8502035\ttotal: 34.2s\tremaining: 1m 28s\n",
      "279:\tlearn: 1682.2304493\ttotal: 34.3s\tremaining: 1m 28s\n",
      "280:\tlearn: 1681.7735759\ttotal: 34.4s\tremaining: 1m 28s\n",
      "281:\tlearn: 1681.5672645\ttotal: 34.5s\tremaining: 1m 27s\n",
      "282:\tlearn: 1681.1759768\ttotal: 34.6s\tremaining: 1m 27s\n",
      "283:\tlearn: 1680.5263199\ttotal: 34.8s\tremaining: 1m 27s\n",
      "284:\tlearn: 1680.3344831\ttotal: 34.9s\tremaining: 1m 27s\n",
      "285:\tlearn: 1680.0761366\ttotal: 35s\tremaining: 1m 27s\n",
      "286:\tlearn: 1679.7762711\ttotal: 35.1s\tremaining: 1m 27s\n",
      "287:\tlearn: 1679.5570993\ttotal: 35.3s\tremaining: 1m 27s\n",
      "288:\tlearn: 1679.2352621\ttotal: 35.3s\tremaining: 1m 26s\n",
      "289:\tlearn: 1678.6646725\ttotal: 35.4s\tremaining: 1m 26s\n",
      "290:\tlearn: 1678.2739673\ttotal: 35.5s\tremaining: 1m 26s\n",
      "291:\tlearn: 1678.0535478\ttotal: 35.6s\tremaining: 1m 26s\n",
      "292:\tlearn: 1677.7656708\ttotal: 35.7s\tremaining: 1m 26s\n",
      "293:\tlearn: 1677.3876917\ttotal: 35.9s\tremaining: 1m 26s\n",
      "294:\tlearn: 1676.9606213\ttotal: 36s\tremaining: 1m 26s\n",
      "295:\tlearn: 1676.5109760\ttotal: 36.1s\tremaining: 1m 25s\n",
      "296:\tlearn: 1676.1642425\ttotal: 36.2s\tremaining: 1m 25s\n",
      "297:\tlearn: 1675.6018707\ttotal: 36.3s\tremaining: 1m 25s\n",
      "298:\tlearn: 1675.1266462\ttotal: 36.4s\tremaining: 1m 25s\n",
      "299:\tlearn: 1674.7536998\ttotal: 36.5s\tremaining: 1m 25s\n",
      "300:\tlearn: 1674.5410879\ttotal: 36.6s\tremaining: 1m 25s\n",
      "301:\tlearn: 1674.0086652\ttotal: 36.8s\tremaining: 1m 24s\n",
      "302:\tlearn: 1673.6005765\ttotal: 36.9s\tremaining: 1m 24s\n",
      "303:\tlearn: 1673.1592708\ttotal: 37s\tremaining: 1m 24s\n",
      "304:\tlearn: 1673.0402741\ttotal: 37.1s\tremaining: 1m 24s\n",
      "305:\tlearn: 1672.8273464\ttotal: 37.2s\tremaining: 1m 24s\n",
      "306:\tlearn: 1672.7025105\ttotal: 37.3s\tremaining: 1m 24s\n",
      "307:\tlearn: 1672.5241214\ttotal: 37.4s\tremaining: 1m 24s\n",
      "308:\tlearn: 1672.3929755\ttotal: 37.5s\tremaining: 1m 23s\n",
      "309:\tlearn: 1672.0482966\ttotal: 37.6s\tremaining: 1m 23s\n",
      "310:\tlearn: 1671.9658358\ttotal: 37.7s\tremaining: 1m 23s\n",
      "311:\tlearn: 1671.7296925\ttotal: 37.8s\tremaining: 1m 23s\n",
      "312:\tlearn: 1671.4283656\ttotal: 38s\tremaining: 1m 23s\n",
      "313:\tlearn: 1671.1083324\ttotal: 38.1s\tremaining: 1m 23s\n",
      "314:\tlearn: 1670.8443370\ttotal: 38.2s\tremaining: 1m 23s\n",
      "315:\tlearn: 1670.7056093\ttotal: 38.4s\tremaining: 1m 23s\n",
      "316:\tlearn: 1670.6265253\ttotal: 38.5s\tremaining: 1m 22s\n",
      "317:\tlearn: 1670.1948018\ttotal: 38.6s\tremaining: 1m 22s\n",
      "318:\tlearn: 1669.9410241\ttotal: 38.7s\tremaining: 1m 22s\n",
      "319:\tlearn: 1669.6290907\ttotal: 38.8s\tremaining: 1m 22s\n",
      "320:\tlearn: 1669.2324233\ttotal: 38.9s\tremaining: 1m 22s\n",
      "321:\tlearn: 1669.0276680\ttotal: 39s\tremaining: 1m 22s\n",
      "322:\tlearn: 1668.2914290\ttotal: 39.1s\tremaining: 1m 21s\n",
      "323:\tlearn: 1668.1862411\ttotal: 39.2s\tremaining: 1m 21s\n",
      "324:\tlearn: 1667.9379977\ttotal: 39.3s\tremaining: 1m 21s\n",
      "325:\tlearn: 1667.6132978\ttotal: 39.4s\tremaining: 1m 21s\n",
      "326:\tlearn: 1667.0889986\ttotal: 39.5s\tremaining: 1m 21s\n",
      "327:\tlearn: 1666.9891554\ttotal: 39.6s\tremaining: 1m 21s\n",
      "328:\tlearn: 1666.7898154\ttotal: 39.7s\tremaining: 1m 21s\n",
      "329:\tlearn: 1666.2955324\ttotal: 39.9s\tremaining: 1m 20s\n",
      "330:\tlearn: 1666.2019626\ttotal: 40s\tremaining: 1m 20s\n",
      "331:\tlearn: 1665.9496098\ttotal: 40.1s\tremaining: 1m 20s\n",
      "332:\tlearn: 1665.5550251\ttotal: 40.2s\tremaining: 1m 20s\n",
      "333:\tlearn: 1665.3103055\ttotal: 40.4s\tremaining: 1m 20s\n",
      "334:\tlearn: 1664.6984472\ttotal: 40.5s\tremaining: 1m 20s\n",
      "335:\tlearn: 1664.2832503\ttotal: 40.6s\tremaining: 1m 20s\n",
      "336:\tlearn: 1663.9116662\ttotal: 40.7s\tremaining: 1m 20s\n",
      "337:\tlearn: 1663.6140945\ttotal: 40.8s\tremaining: 1m 20s\n",
      "338:\tlearn: 1663.2203846\ttotal: 41s\tremaining: 1m 19s\n",
      "339:\tlearn: 1662.8763662\ttotal: 41.1s\tremaining: 1m 19s\n",
      "340:\tlearn: 1662.4668183\ttotal: 41.2s\tremaining: 1m 19s\n",
      "341:\tlearn: 1662.3147154\ttotal: 41.3s\tremaining: 1m 19s\n",
      "342:\tlearn: 1662.2446384\ttotal: 41.4s\tremaining: 1m 19s\n",
      "343:\tlearn: 1661.9908660\ttotal: 41.6s\tremaining: 1m 19s\n",
      "344:\tlearn: 1661.5856212\ttotal: 41.7s\tremaining: 1m 19s\n",
      "345:\tlearn: 1661.3604226\ttotal: 41.8s\tremaining: 1m 18s\n",
      "346:\tlearn: 1661.1237722\ttotal: 41.9s\tremaining: 1m 18s\n",
      "347:\tlearn: 1660.8612888\ttotal: 42s\tremaining: 1m 18s\n",
      "348:\tlearn: 1660.6105218\ttotal: 42.1s\tremaining: 1m 18s\n",
      "349:\tlearn: 1660.3603632\ttotal: 42.3s\tremaining: 1m 18s\n",
      "350:\tlearn: 1660.0431951\ttotal: 42.4s\tremaining: 1m 18s\n",
      "351:\tlearn: 1659.6030034\ttotal: 42.5s\tremaining: 1m 18s\n",
      "352:\tlearn: 1659.2903167\ttotal: 42.6s\tremaining: 1m 18s\n",
      "353:\tlearn: 1659.1004354\ttotal: 42.7s\tremaining: 1m 17s\n",
      "354:\tlearn: 1658.7951467\ttotal: 42.9s\tremaining: 1m 17s\n",
      "355:\tlearn: 1658.4544865\ttotal: 43s\tremaining: 1m 17s\n",
      "356:\tlearn: 1658.1699006\ttotal: 43.1s\tremaining: 1m 17s\n",
      "357:\tlearn: 1657.7201906\ttotal: 43.2s\tremaining: 1m 17s\n",
      "358:\tlearn: 1657.3149568\ttotal: 43.3s\tremaining: 1m 17s\n",
      "359:\tlearn: 1656.9762230\ttotal: 43.4s\tremaining: 1m 17s\n",
      "360:\tlearn: 1656.7021877\ttotal: 43.6s\tremaining: 1m 17s\n",
      "361:\tlearn: 1656.2211642\ttotal: 43.7s\tremaining: 1m 17s\n",
      "362:\tlearn: 1655.9081370\ttotal: 43.8s\tremaining: 1m 16s\n",
      "363:\tlearn: 1655.6189632\ttotal: 43.9s\tremaining: 1m 16s\n",
      "364:\tlearn: 1655.4901902\ttotal: 44.1s\tremaining: 1m 16s\n",
      "365:\tlearn: 1655.1807919\ttotal: 44.2s\tremaining: 1m 16s\n",
      "366:\tlearn: 1654.9015872\ttotal: 44.3s\tremaining: 1m 16s\n",
      "367:\tlearn: 1654.8520347\ttotal: 44.4s\tremaining: 1m 16s\n",
      "368:\tlearn: 1654.7383738\ttotal: 44.5s\tremaining: 1m 16s\n",
      "369:\tlearn: 1654.2568434\ttotal: 44.6s\tremaining: 1m 15s\n",
      "370:\tlearn: 1653.6893304\ttotal: 44.7s\tremaining: 1m 15s\n",
      "371:\tlearn: 1653.3564551\ttotal: 44.8s\tremaining: 1m 15s\n",
      "372:\tlearn: 1653.0107647\ttotal: 45s\tremaining: 1m 15s\n",
      "373:\tlearn: 1652.8816320\ttotal: 45s\tremaining: 1m 15s\n",
      "374:\tlearn: 1652.6434591\ttotal: 45.2s\tremaining: 1m 15s\n",
      "375:\tlearn: 1652.4760369\ttotal: 45.3s\tremaining: 1m 15s\n",
      "376:\tlearn: 1652.1842986\ttotal: 45.4s\tremaining: 1m 14s\n",
      "377:\tlearn: 1651.9207174\ttotal: 45.5s\tremaining: 1m 14s\n",
      "378:\tlearn: 1651.6395445\ttotal: 45.6s\tremaining: 1m 14s\n",
      "379:\tlearn: 1651.4610905\ttotal: 45.8s\tremaining: 1m 14s\n",
      "380:\tlearn: 1651.1370336\ttotal: 45.9s\tremaining: 1m 14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381:\tlearn: 1650.9839243\ttotal: 46s\tremaining: 1m 14s\n",
      "382:\tlearn: 1650.8047018\ttotal: 46.1s\tremaining: 1m 14s\n",
      "383:\tlearn: 1650.4852436\ttotal: 46.3s\tremaining: 1m 14s\n",
      "384:\tlearn: 1650.3122444\ttotal: 46.4s\tremaining: 1m 14s\n",
      "385:\tlearn: 1649.9925112\ttotal: 46.5s\tremaining: 1m 14s\n",
      "386:\tlearn: 1649.6563924\ttotal: 46.7s\tremaining: 1m 13s\n",
      "387:\tlearn: 1649.2546472\ttotal: 46.8s\tremaining: 1m 13s\n",
      "388:\tlearn: 1648.9468282\ttotal: 46.9s\tremaining: 1m 13s\n",
      "389:\tlearn: 1648.8136429\ttotal: 47s\tremaining: 1m 13s\n",
      "390:\tlearn: 1648.3027549\ttotal: 47.1s\tremaining: 1m 13s\n",
      "391:\tlearn: 1648.0129333\ttotal: 47.2s\tremaining: 1m 13s\n",
      "392:\tlearn: 1647.7678458\ttotal: 47.3s\tremaining: 1m 13s\n",
      "393:\tlearn: 1647.6404356\ttotal: 47.4s\tremaining: 1m 12s\n",
      "394:\tlearn: 1647.3658207\ttotal: 47.6s\tremaining: 1m 12s\n",
      "395:\tlearn: 1647.1412407\ttotal: 47.7s\tremaining: 1m 12s\n",
      "396:\tlearn: 1646.7684000\ttotal: 47.8s\tremaining: 1m 12s\n",
      "397:\tlearn: 1646.5720075\ttotal: 47.9s\tremaining: 1m 12s\n",
      "398:\tlearn: 1646.2912290\ttotal: 48s\tremaining: 1m 12s\n",
      "399:\tlearn: 1645.9680479\ttotal: 48.1s\tremaining: 1m 12s\n",
      "400:\tlearn: 1645.7816034\ttotal: 48.3s\tremaining: 1m 12s\n",
      "401:\tlearn: 1645.3536001\ttotal: 48.4s\tremaining: 1m 11s\n",
      "402:\tlearn: 1645.0773633\ttotal: 48.5s\tremaining: 1m 11s\n",
      "403:\tlearn: 1644.6520809\ttotal: 48.6s\tremaining: 1m 11s\n",
      "404:\tlearn: 1643.6498364\ttotal: 48.8s\tremaining: 1m 11s\n",
      "405:\tlearn: 1643.4592704\ttotal: 48.9s\tremaining: 1m 11s\n",
      "406:\tlearn: 1643.1073087\ttotal: 49s\tremaining: 1m 11s\n",
      "407:\tlearn: 1642.9588764\ttotal: 49.2s\tremaining: 1m 11s\n",
      "408:\tlearn: 1642.7771862\ttotal: 49.3s\tremaining: 1m 11s\n",
      "409:\tlearn: 1642.5399235\ttotal: 49.4s\tremaining: 1m 11s\n",
      "410:\tlearn: 1642.2843820\ttotal: 49.5s\tremaining: 1m 10s\n",
      "411:\tlearn: 1642.0060300\ttotal: 49.6s\tremaining: 1m 10s\n",
      "412:\tlearn: 1641.8726415\ttotal: 49.7s\tremaining: 1m 10s\n",
      "413:\tlearn: 1641.6128294\ttotal: 49.8s\tremaining: 1m 10s\n",
      "414:\tlearn: 1641.5260851\ttotal: 50s\tremaining: 1m 10s\n",
      "415:\tlearn: 1641.3453579\ttotal: 50.1s\tremaining: 1m 10s\n",
      "416:\tlearn: 1641.1719852\ttotal: 50.2s\tremaining: 1m 10s\n",
      "417:\tlearn: 1641.0058335\ttotal: 50.3s\tremaining: 1m 10s\n",
      "418:\tlearn: 1640.8151573\ttotal: 50.5s\tremaining: 1m 9s\n",
      "419:\tlearn: 1640.5491839\ttotal: 50.6s\tremaining: 1m 9s\n",
      "420:\tlearn: 1640.2734131\ttotal: 50.7s\tremaining: 1m 9s\n",
      "421:\tlearn: 1640.0558378\ttotal: 50.8s\tremaining: 1m 9s\n",
      "422:\tlearn: 1639.5994690\ttotal: 50.9s\tremaining: 1m 9s\n",
      "423:\tlearn: 1639.3291459\ttotal: 51.1s\tremaining: 1m 9s\n",
      "424:\tlearn: 1639.0231319\ttotal: 51.2s\tremaining: 1m 9s\n",
      "425:\tlearn: 1638.8978070\ttotal: 51.3s\tremaining: 1m 9s\n",
      "426:\tlearn: 1638.7989088\ttotal: 51.4s\tremaining: 1m 8s\n",
      "427:\tlearn: 1638.5067964\ttotal: 51.5s\tremaining: 1m 8s\n",
      "428:\tlearn: 1638.2160067\ttotal: 51.6s\tremaining: 1m 8s\n",
      "429:\tlearn: 1638.0935843\ttotal: 51.8s\tremaining: 1m 8s\n",
      "430:\tlearn: 1637.8060550\ttotal: 51.9s\tremaining: 1m 8s\n",
      "431:\tlearn: 1637.4650039\ttotal: 52s\tremaining: 1m 8s\n",
      "432:\tlearn: 1637.3559422\ttotal: 52.1s\tremaining: 1m 8s\n",
      "433:\tlearn: 1637.0677092\ttotal: 52.3s\tremaining: 1m 8s\n",
      "434:\tlearn: 1636.8100007\ttotal: 52.4s\tremaining: 1m 8s\n",
      "435:\tlearn: 1636.6056108\ttotal: 52.5s\tremaining: 1m 7s\n",
      "436:\tlearn: 1636.2679315\ttotal: 52.6s\tremaining: 1m 7s\n",
      "437:\tlearn: 1635.9333281\ttotal: 52.8s\tremaining: 1m 7s\n",
      "438:\tlearn: 1635.8531670\ttotal: 52.9s\tremaining: 1m 7s\n",
      "439:\tlearn: 1635.5629266\ttotal: 53s\tremaining: 1m 7s\n",
      "440:\tlearn: 1635.1985682\ttotal: 53.1s\tremaining: 1m 7s\n",
      "441:\tlearn: 1634.9215960\ttotal: 53.2s\tremaining: 1m 7s\n",
      "442:\tlearn: 1634.5932080\ttotal: 53.4s\tremaining: 1m 7s\n",
      "443:\tlearn: 1634.4448494\ttotal: 53.5s\tremaining: 1m 6s\n",
      "444:\tlearn: 1634.2199229\ttotal: 53.6s\tremaining: 1m 6s\n",
      "445:\tlearn: 1633.8840585\ttotal: 53.7s\tremaining: 1m 6s\n",
      "446:\tlearn: 1633.6656782\ttotal: 53.9s\tremaining: 1m 6s\n",
      "447:\tlearn: 1633.6326434\ttotal: 54s\tremaining: 1m 6s\n",
      "448:\tlearn: 1633.3438649\ttotal: 54.1s\tremaining: 1m 6s\n",
      "449:\tlearn: 1633.2018054\ttotal: 54.2s\tremaining: 1m 6s\n",
      "450:\tlearn: 1633.0647258\ttotal: 54.3s\tremaining: 1m 6s\n",
      "451:\tlearn: 1632.7785539\ttotal: 54.5s\tremaining: 1m 6s\n",
      "452:\tlearn: 1632.7014261\ttotal: 54.6s\tremaining: 1m 5s\n",
      "453:\tlearn: 1632.5055735\ttotal: 54.8s\tremaining: 1m 5s\n",
      "454:\tlearn: 1632.1944057\ttotal: 54.9s\tremaining: 1m 5s\n",
      "455:\tlearn: 1631.9085894\ttotal: 55.1s\tremaining: 1m 5s\n",
      "456:\tlearn: 1631.6307135\ttotal: 55.3s\tremaining: 1m 5s\n",
      "457:\tlearn: 1631.2684244\ttotal: 55.4s\tremaining: 1m 5s\n",
      "458:\tlearn: 1631.0614302\ttotal: 55.5s\tremaining: 1m 5s\n",
      "459:\tlearn: 1631.0267603\ttotal: 55.6s\tremaining: 1m 5s\n",
      "460:\tlearn: 1630.9033949\ttotal: 55.7s\tremaining: 1m 5s\n",
      "461:\tlearn: 1630.7150871\ttotal: 55.9s\tremaining: 1m 5s\n",
      "462:\tlearn: 1630.4571657\ttotal: 56s\tremaining: 1m 4s\n",
      "463:\tlearn: 1630.0752637\ttotal: 56.1s\tremaining: 1m 4s\n",
      "464:\tlearn: 1629.7387260\ttotal: 56.2s\tremaining: 1m 4s\n",
      "465:\tlearn: 1629.4715633\ttotal: 56.3s\tremaining: 1m 4s\n",
      "466:\tlearn: 1629.2081073\ttotal: 56.4s\tremaining: 1m 4s\n",
      "467:\tlearn: 1629.0229039\ttotal: 56.6s\tremaining: 1m 4s\n",
      "468:\tlearn: 1628.9106543\ttotal: 56.7s\tremaining: 1m 4s\n",
      "469:\tlearn: 1628.7746402\ttotal: 56.8s\tremaining: 1m 4s\n",
      "470:\tlearn: 1628.6798830\ttotal: 56.9s\tremaining: 1m 3s\n",
      "471:\tlearn: 1628.5238177\ttotal: 57s\tremaining: 1m 3s\n",
      "472:\tlearn: 1628.2551870\ttotal: 57.2s\tremaining: 1m 3s\n",
      "473:\tlearn: 1628.0636578\ttotal: 57.2s\tremaining: 1m 3s\n",
      "474:\tlearn: 1627.8829926\ttotal: 57.4s\tremaining: 1m 3s\n",
      "475:\tlearn: 1627.6597792\ttotal: 57.6s\tremaining: 1m 3s\n",
      "476:\tlearn: 1627.5096525\ttotal: 57.7s\tremaining: 1m 3s\n",
      "477:\tlearn: 1627.2365918\ttotal: 57.8s\tremaining: 1m 3s\n",
      "478:\tlearn: 1627.0981253\ttotal: 58s\tremaining: 1m 3s\n",
      "479:\tlearn: 1626.8162411\ttotal: 58.1s\tremaining: 1m 2s\n",
      "480:\tlearn: 1626.6361259\ttotal: 58.2s\tremaining: 1m 2s\n",
      "481:\tlearn: 1626.2589376\ttotal: 58.3s\tremaining: 1m 2s\n",
      "482:\tlearn: 1626.2010587\ttotal: 58.4s\tremaining: 1m 2s\n",
      "483:\tlearn: 1625.9125499\ttotal: 58.5s\tremaining: 1m 2s\n",
      "484:\tlearn: 1625.7178603\ttotal: 58.6s\tremaining: 1m 2s\n",
      "485:\tlearn: 1625.4659576\ttotal: 58.7s\tremaining: 1m 2s\n",
      "486:\tlearn: 1625.2439334\ttotal: 58.9s\tremaining: 1m 2s\n",
      "487:\tlearn: 1625.0827603\ttotal: 59.1s\tremaining: 1m 1s\n",
      "488:\tlearn: 1624.9953520\ttotal: 59.2s\tremaining: 1m 1s\n",
      "489:\tlearn: 1624.8514583\ttotal: 59.4s\tremaining: 1m 1s\n",
      "490:\tlearn: 1624.6904261\ttotal: 59.5s\tremaining: 1m 1s\n",
      "491:\tlearn: 1624.3567026\ttotal: 59.7s\tremaining: 1m 1s\n",
      "492:\tlearn: 1624.0027827\ttotal: 59.9s\tremaining: 1m 1s\n",
      "493:\tlearn: 1623.8391996\ttotal: 60s\tremaining: 1m 1s\n",
      "494:\tlearn: 1623.7140309\ttotal: 1m\tremaining: 1m 1s\n",
      "495:\tlearn: 1623.4989492\ttotal: 1m\tremaining: 1m 1s\n",
      "496:\tlearn: 1623.2264154\ttotal: 1m\tremaining: 1m 1s\n",
      "497:\tlearn: 1623.0374473\ttotal: 1m\tremaining: 1m 1s\n",
      "498:\tlearn: 1622.8247713\ttotal: 1m\tremaining: 1m\n",
      "499:\tlearn: 1622.7018078\ttotal: 1m\tremaining: 1m\n",
      "500:\tlearn: 1622.6096799\ttotal: 1m\tremaining: 1m\n",
      "501:\tlearn: 1622.3548657\ttotal: 1m\tremaining: 1m\n",
      "502:\tlearn: 1622.1997228\ttotal: 1m 1s\tremaining: 1m\n",
      "503:\tlearn: 1622.0019509\ttotal: 1m 1s\tremaining: 1m\n",
      "504:\tlearn: 1621.8610579\ttotal: 1m 1s\tremaining: 1m\n",
      "505:\tlearn: 1621.7099164\ttotal: 1m 1s\tremaining: 60s\n",
      "506:\tlearn: 1621.4976586\ttotal: 1m 1s\tremaining: 59.8s\n",
      "507:\tlearn: 1621.3823875\ttotal: 1m 1s\tremaining: 59.7s\n",
      "508:\tlearn: 1621.1546337\ttotal: 1m 1s\tremaining: 59.6s\n",
      "509:\tlearn: 1620.9279540\ttotal: 1m 1s\tremaining: 59.4s\n",
      "510:\tlearn: 1620.7327207\ttotal: 1m 1s\tremaining: 59.3s\n",
      "511:\tlearn: 1620.5509569\ttotal: 1m 2s\tremaining: 59.2s\n",
      "512:\tlearn: 1620.4523953\ttotal: 1m 2s\tremaining: 59.1s\n",
      "513:\tlearn: 1620.3139023\ttotal: 1m 2s\tremaining: 59s\n",
      "514:\tlearn: 1620.1671894\ttotal: 1m 2s\tremaining: 58.9s\n",
      "515:\tlearn: 1619.9650285\ttotal: 1m 2s\tremaining: 58.8s\n",
      "516:\tlearn: 1619.8225096\ttotal: 1m 2s\tremaining: 58.7s\n",
      "517:\tlearn: 1619.6347960\ttotal: 1m 2s\tremaining: 58.6s\n",
      "518:\tlearn: 1619.5433046\ttotal: 1m 3s\tremaining: 58.4s\n",
      "519:\tlearn: 1619.4006802\ttotal: 1m 3s\tremaining: 58.3s\n",
      "520:\tlearn: 1619.0443732\ttotal: 1m 3s\tremaining: 58.1s\n",
      "521:\tlearn: 1618.9147498\ttotal: 1m 3s\tremaining: 58s\n",
      "522:\tlearn: 1618.8130392\ttotal: 1m 3s\tremaining: 57.9s\n",
      "523:\tlearn: 1618.5364623\ttotal: 1m 3s\tremaining: 57.8s\n",
      "524:\tlearn: 1618.3041586\ttotal: 1m 3s\tremaining: 57.7s\n",
      "525:\tlearn: 1618.2138517\ttotal: 1m 3s\tremaining: 57.5s\n",
      "526:\tlearn: 1618.1378049\ttotal: 1m 3s\tremaining: 57.4s\n",
      "527:\tlearn: 1617.9188995\ttotal: 1m 4s\tremaining: 57.3s\n",
      "528:\tlearn: 1617.6711470\ttotal: 1m 4s\tremaining: 57.2s\n",
      "529:\tlearn: 1617.5236376\ttotal: 1m 4s\tremaining: 57s\n",
      "530:\tlearn: 1617.3402531\ttotal: 1m 4s\tremaining: 56.9s\n",
      "531:\tlearn: 1617.2555803\ttotal: 1m 4s\tremaining: 56.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532:\tlearn: 1616.9742148\ttotal: 1m 4s\tremaining: 56.7s\n",
      "533:\tlearn: 1616.8878281\ttotal: 1m 4s\tremaining: 56.5s\n",
      "534:\tlearn: 1616.8269405\ttotal: 1m 4s\tremaining: 56.4s\n",
      "535:\tlearn: 1616.3359461\ttotal: 1m 4s\tremaining: 56.2s\n",
      "536:\tlearn: 1616.2333763\ttotal: 1m 5s\tremaining: 56.2s\n",
      "537:\tlearn: 1616.0292223\ttotal: 1m 5s\tremaining: 56s\n",
      "538:\tlearn: 1615.9161682\ttotal: 1m 5s\tremaining: 55.9s\n",
      "539:\tlearn: 1615.6400076\ttotal: 1m 5s\tremaining: 55.8s\n",
      "540:\tlearn: 1615.5243216\ttotal: 1m 5s\tremaining: 55.7s\n",
      "541:\tlearn: 1615.4146023\ttotal: 1m 5s\tremaining: 55.6s\n",
      "542:\tlearn: 1615.1805255\ttotal: 1m 5s\tremaining: 55.4s\n",
      "543:\tlearn: 1614.9223448\ttotal: 1m 6s\tremaining: 55.3s\n",
      "544:\tlearn: 1614.5856519\ttotal: 1m 6s\tremaining: 55.2s\n",
      "545:\tlearn: 1614.3974995\ttotal: 1m 6s\tremaining: 55.1s\n",
      "546:\tlearn: 1614.1646443\ttotal: 1m 6s\tremaining: 55s\n",
      "547:\tlearn: 1613.9458428\ttotal: 1m 6s\tremaining: 54.9s\n",
      "548:\tlearn: 1613.7070862\ttotal: 1m 6s\tremaining: 54.7s\n",
      "549:\tlearn: 1613.5282930\ttotal: 1m 6s\tremaining: 54.6s\n",
      "550:\tlearn: 1613.4365894\ttotal: 1m 6s\tremaining: 54.5s\n",
      "551:\tlearn: 1613.1499658\ttotal: 1m 6s\tremaining: 54.4s\n",
      "552:\tlearn: 1612.9915874\ttotal: 1m 7s\tremaining: 54.2s\n",
      "553:\tlearn: 1612.8104505\ttotal: 1m 7s\tremaining: 54.1s\n",
      "554:\tlearn: 1612.8036194\ttotal: 1m 7s\tremaining: 54s\n",
      "555:\tlearn: 1612.7648057\ttotal: 1m 7s\tremaining: 53.9s\n",
      "556:\tlearn: 1612.4662091\ttotal: 1m 7s\tremaining: 53.8s\n",
      "557:\tlearn: 1612.2612575\ttotal: 1m 7s\tremaining: 53.7s\n",
      "558:\tlearn: 1612.1284935\ttotal: 1m 7s\tremaining: 53.5s\n",
      "559:\tlearn: 1612.0515564\ttotal: 1m 7s\tremaining: 53.4s\n",
      "560:\tlearn: 1611.9665290\ttotal: 1m 8s\tremaining: 53.3s\n",
      "561:\tlearn: 1611.9313280\ttotal: 1m 8s\tremaining: 53.1s\n",
      "562:\tlearn: 1611.8241695\ttotal: 1m 8s\tremaining: 53s\n",
      "563:\tlearn: 1611.7346818\ttotal: 1m 8s\tremaining: 52.9s\n",
      "564:\tlearn: 1611.6546314\ttotal: 1m 8s\tremaining: 52.7s\n",
      "565:\tlearn: 1611.5128867\ttotal: 1m 8s\tremaining: 52.6s\n",
      "566:\tlearn: 1611.2791120\ttotal: 1m 8s\tremaining: 52.5s\n",
      "567:\tlearn: 1611.1338278\ttotal: 1m 8s\tremaining: 52.4s\n",
      "568:\tlearn: 1611.0828316\ttotal: 1m 8s\tremaining: 52.2s\n",
      "569:\tlearn: 1610.9418245\ttotal: 1m 9s\tremaining: 52.1s\n",
      "570:\tlearn: 1610.7274983\ttotal: 1m 9s\tremaining: 52s\n",
      "571:\tlearn: 1610.5985357\ttotal: 1m 9s\tremaining: 51.9s\n",
      "572:\tlearn: 1610.3580607\ttotal: 1m 9s\tremaining: 51.7s\n",
      "573:\tlearn: 1610.2503989\ttotal: 1m 9s\tremaining: 51.6s\n",
      "574:\tlearn: 1610.0500608\ttotal: 1m 9s\tremaining: 51.5s\n",
      "575:\tlearn: 1609.8989194\ttotal: 1m 9s\tremaining: 51.4s\n",
      "576:\tlearn: 1609.7306329\ttotal: 1m 9s\tremaining: 51.3s\n",
      "577:\tlearn: 1609.6488552\ttotal: 1m 10s\tremaining: 51.1s\n",
      "578:\tlearn: 1609.5837395\ttotal: 1m 10s\tremaining: 51s\n",
      "579:\tlearn: 1609.4025639\ttotal: 1m 10s\tremaining: 50.9s\n",
      "580:\tlearn: 1609.2023913\ttotal: 1m 10s\tremaining: 50.7s\n",
      "581:\tlearn: 1608.4377247\ttotal: 1m 10s\tremaining: 50.6s\n",
      "582:\tlearn: 1608.3480408\ttotal: 1m 10s\tremaining: 50.5s\n",
      "583:\tlearn: 1608.3026786\ttotal: 1m 10s\tremaining: 50.3s\n",
      "584:\tlearn: 1608.1839099\ttotal: 1m 10s\tremaining: 50.2s\n",
      "585:\tlearn: 1608.0954710\ttotal: 1m 10s\tremaining: 50.1s\n",
      "586:\tlearn: 1607.7847256\ttotal: 1m 11s\tremaining: 50s\n",
      "587:\tlearn: 1607.6025116\ttotal: 1m 11s\tremaining: 49.9s\n",
      "588:\tlearn: 1607.5088758\ttotal: 1m 11s\tremaining: 49.8s\n",
      "589:\tlearn: 1607.4280570\ttotal: 1m 11s\tremaining: 49.6s\n",
      "590:\tlearn: 1607.2103396\ttotal: 1m 11s\tremaining: 49.5s\n",
      "591:\tlearn: 1607.0948012\ttotal: 1m 11s\tremaining: 49.4s\n",
      "592:\tlearn: 1607.0134061\ttotal: 1m 11s\tremaining: 49.3s\n",
      "593:\tlearn: 1606.8694063\ttotal: 1m 11s\tremaining: 49.2s\n",
      "594:\tlearn: 1606.6737687\ttotal: 1m 12s\tremaining: 49.1s\n",
      "595:\tlearn: 1606.4260260\ttotal: 1m 12s\tremaining: 48.9s\n",
      "596:\tlearn: 1606.3136889\ttotal: 1m 12s\tremaining: 48.8s\n",
      "597:\tlearn: 1606.0888283\ttotal: 1m 12s\tremaining: 48.7s\n",
      "598:\tlearn: 1605.9017259\ttotal: 1m 12s\tremaining: 48.6s\n",
      "599:\tlearn: 1605.7994735\ttotal: 1m 12s\tremaining: 48.4s\n",
      "600:\tlearn: 1605.7304949\ttotal: 1m 12s\tremaining: 48.3s\n",
      "601:\tlearn: 1605.0839427\ttotal: 1m 12s\tremaining: 48.2s\n",
      "602:\tlearn: 1604.9234393\ttotal: 1m 13s\tremaining: 48.1s\n",
      "603:\tlearn: 1604.8053830\ttotal: 1m 13s\tremaining: 48s\n",
      "604:\tlearn: 1604.7324959\ttotal: 1m 13s\tremaining: 47.9s\n",
      "605:\tlearn: 1604.6865079\ttotal: 1m 13s\tremaining: 47.8s\n",
      "606:\tlearn: 1604.5655288\ttotal: 1m 13s\tremaining: 47.6s\n",
      "607:\tlearn: 1604.4753763\ttotal: 1m 13s\tremaining: 47.5s\n",
      "608:\tlearn: 1604.4509581\ttotal: 1m 13s\tremaining: 47.4s\n",
      "609:\tlearn: 1604.2963708\ttotal: 1m 13s\tremaining: 47.2s\n",
      "610:\tlearn: 1604.1905370\ttotal: 1m 13s\tremaining: 47.1s\n",
      "611:\tlearn: 1604.0529872\ttotal: 1m 14s\tremaining: 47s\n",
      "612:\tlearn: 1603.8468781\ttotal: 1m 14s\tremaining: 46.9s\n",
      "613:\tlearn: 1603.7325879\ttotal: 1m 14s\tremaining: 46.8s\n",
      "614:\tlearn: 1603.6745637\ttotal: 1m 14s\tremaining: 46.6s\n",
      "615:\tlearn: 1603.4810296\ttotal: 1m 14s\tremaining: 46.5s\n",
      "616:\tlearn: 1603.4422946\ttotal: 1m 14s\tremaining: 46.4s\n",
      "617:\tlearn: 1603.2969102\ttotal: 1m 14s\tremaining: 46.3s\n",
      "618:\tlearn: 1603.0415053\ttotal: 1m 15s\tremaining: 46.2s\n",
      "619:\tlearn: 1602.8560315\ttotal: 1m 15s\tremaining: 46.1s\n",
      "620:\tlearn: 1602.7846217\ttotal: 1m 15s\tremaining: 45.9s\n",
      "621:\tlearn: 1602.5145555\ttotal: 1m 15s\tremaining: 45.8s\n",
      "622:\tlearn: 1602.2662227\ttotal: 1m 15s\tremaining: 45.7s\n",
      "623:\tlearn: 1602.0852602\ttotal: 1m 15s\tremaining: 45.6s\n",
      "624:\tlearn: 1601.9824900\ttotal: 1m 15s\tremaining: 45.5s\n",
      "625:\tlearn: 1601.6863753\ttotal: 1m 15s\tremaining: 45.4s\n",
      "626:\tlearn: 1601.6004756\ttotal: 1m 16s\tremaining: 45.2s\n",
      "627:\tlearn: 1601.4187120\ttotal: 1m 16s\tremaining: 45.1s\n",
      "628:\tlearn: 1601.3226700\ttotal: 1m 16s\tremaining: 45s\n",
      "629:\tlearn: 1601.2507850\ttotal: 1m 16s\tremaining: 44.9s\n",
      "630:\tlearn: 1601.0128610\ttotal: 1m 16s\tremaining: 44.7s\n",
      "631:\tlearn: 1600.9257633\ttotal: 1m 16s\tremaining: 44.6s\n",
      "632:\tlearn: 1600.8875945\ttotal: 1m 16s\tremaining: 44.5s\n",
      "633:\tlearn: 1600.7689016\ttotal: 1m 16s\tremaining: 44.4s\n",
      "634:\tlearn: 1600.5948687\ttotal: 1m 16s\tremaining: 44.2s\n",
      "635:\tlearn: 1600.4857066\ttotal: 1m 17s\tremaining: 44.1s\n",
      "636:\tlearn: 1600.3074282\ttotal: 1m 17s\tremaining: 44s\n",
      "637:\tlearn: 1600.1009225\ttotal: 1m 17s\tremaining: 43.9s\n",
      "638:\tlearn: 1599.9734692\ttotal: 1m 17s\tremaining: 43.8s\n",
      "639:\tlearn: 1599.8415914\ttotal: 1m 17s\tremaining: 43.7s\n",
      "640:\tlearn: 1599.5729377\ttotal: 1m 17s\tremaining: 43.6s\n",
      "641:\tlearn: 1599.4192344\ttotal: 1m 17s\tremaining: 43.4s\n",
      "642:\tlearn: 1599.3506345\ttotal: 1m 18s\tremaining: 43.3s\n",
      "643:\tlearn: 1599.2710288\ttotal: 1m 18s\tremaining: 43.2s\n",
      "644:\tlearn: 1599.0946008\ttotal: 1m 18s\tremaining: 43.1s\n",
      "645:\tlearn: 1598.9457836\ttotal: 1m 18s\tremaining: 43s\n",
      "646:\tlearn: 1598.8708805\ttotal: 1m 18s\tremaining: 42.9s\n",
      "647:\tlearn: 1598.7022769\ttotal: 1m 18s\tremaining: 42.7s\n",
      "648:\tlearn: 1598.5745420\ttotal: 1m 18s\tremaining: 42.6s\n",
      "649:\tlearn: 1598.3962103\ttotal: 1m 18s\tremaining: 42.5s\n",
      "650:\tlearn: 1597.7529379\ttotal: 1m 19s\tremaining: 42.4s\n",
      "651:\tlearn: 1597.5579636\ttotal: 1m 19s\tremaining: 42.2s\n",
      "652:\tlearn: 1597.4375679\ttotal: 1m 19s\tremaining: 42.1s\n",
      "653:\tlearn: 1597.2694835\ttotal: 1m 19s\tremaining: 42s\n",
      "654:\tlearn: 1597.2059940\ttotal: 1m 19s\tremaining: 41.9s\n",
      "655:\tlearn: 1597.0702797\ttotal: 1m 19s\tremaining: 41.8s\n",
      "656:\tlearn: 1596.8554130\ttotal: 1m 19s\tremaining: 41.6s\n",
      "657:\tlearn: 1596.7287934\ttotal: 1m 19s\tremaining: 41.5s\n",
      "658:\tlearn: 1596.6452954\ttotal: 1m 19s\tremaining: 41.4s\n",
      "659:\tlearn: 1596.5547501\ttotal: 1m 20s\tremaining: 41.3s\n",
      "660:\tlearn: 1596.4620380\ttotal: 1m 20s\tremaining: 41.1s\n",
      "661:\tlearn: 1596.3049825\ttotal: 1m 20s\tremaining: 41s\n",
      "662:\tlearn: 1596.1406379\ttotal: 1m 20s\tremaining: 40.9s\n",
      "663:\tlearn: 1596.0119492\ttotal: 1m 20s\tremaining: 40.8s\n",
      "664:\tlearn: 1595.8465926\ttotal: 1m 20s\tremaining: 40.7s\n",
      "665:\tlearn: 1595.6641481\ttotal: 1m 20s\tremaining: 40.6s\n",
      "666:\tlearn: 1595.5695865\ttotal: 1m 21s\tremaining: 40.5s\n",
      "667:\tlearn: 1595.3765116\ttotal: 1m 21s\tremaining: 40.3s\n",
      "668:\tlearn: 1595.2580769\ttotal: 1m 21s\tremaining: 40.2s\n",
      "669:\tlearn: 1595.0796198\ttotal: 1m 21s\tremaining: 40.1s\n",
      "670:\tlearn: 1594.6160464\ttotal: 1m 21s\tremaining: 40s\n",
      "671:\tlearn: 1594.5483274\ttotal: 1m 21s\tremaining: 39.9s\n",
      "672:\tlearn: 1594.3842368\ttotal: 1m 21s\tremaining: 39.8s\n",
      "673:\tlearn: 1594.3421867\ttotal: 1m 21s\tremaining: 39.6s\n",
      "674:\tlearn: 1594.1495827\ttotal: 1m 22s\tremaining: 39.5s\n",
      "675:\tlearn: 1594.0116990\ttotal: 1m 22s\tremaining: 39.4s\n",
      "676:\tlearn: 1593.9236888\ttotal: 1m 22s\tremaining: 39.3s\n",
      "677:\tlearn: 1593.6969638\ttotal: 1m 22s\tremaining: 39.1s\n",
      "678:\tlearn: 1593.5279470\ttotal: 1m 22s\tremaining: 39s\n",
      "679:\tlearn: 1593.4249630\ttotal: 1m 22s\tremaining: 38.9s\n",
      "680:\tlearn: 1593.3793452\ttotal: 1m 22s\tremaining: 38.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681:\tlearn: 1593.1404407\ttotal: 1m 22s\tremaining: 38.6s\n",
      "682:\tlearn: 1592.9267307\ttotal: 1m 22s\tremaining: 38.5s\n",
      "683:\tlearn: 1592.7385064\ttotal: 1m 23s\tremaining: 38.4s\n",
      "684:\tlearn: 1592.6764813\ttotal: 1m 23s\tremaining: 38.3s\n",
      "685:\tlearn: 1592.6450594\ttotal: 1m 23s\tremaining: 38.2s\n",
      "686:\tlearn: 1592.4413446\ttotal: 1m 23s\tremaining: 38s\n",
      "687:\tlearn: 1592.3852394\ttotal: 1m 23s\tremaining: 37.9s\n",
      "688:\tlearn: 1592.2722098\ttotal: 1m 23s\tremaining: 37.8s\n",
      "689:\tlearn: 1592.2314820\ttotal: 1m 23s\tremaining: 37.7s\n",
      "690:\tlearn: 1592.1899751\ttotal: 1m 24s\tremaining: 37.6s\n",
      "691:\tlearn: 1592.1002382\ttotal: 1m 24s\tremaining: 37.4s\n",
      "692:\tlearn: 1591.9457539\ttotal: 1m 24s\tremaining: 37.3s\n",
      "693:\tlearn: 1591.8217786\ttotal: 1m 24s\tremaining: 37.2s\n",
      "694:\tlearn: 1591.7117783\ttotal: 1m 24s\tremaining: 37.1s\n",
      "695:\tlearn: 1591.4787893\ttotal: 1m 24s\tremaining: 37s\n",
      "696:\tlearn: 1591.4109047\ttotal: 1m 24s\tremaining: 36.8s\n",
      "697:\tlearn: 1591.3050931\ttotal: 1m 24s\tremaining: 36.7s\n",
      "698:\tlearn: 1591.2762676\ttotal: 1m 24s\tremaining: 36.6s\n",
      "699:\tlearn: 1591.0953365\ttotal: 1m 25s\tremaining: 36.5s\n",
      "700:\tlearn: 1591.0232435\ttotal: 1m 25s\tremaining: 36.3s\n",
      "701:\tlearn: 1590.9366021\ttotal: 1m 25s\tremaining: 36.2s\n",
      "702:\tlearn: 1590.8131141\ttotal: 1m 25s\tremaining: 36.1s\n",
      "703:\tlearn: 1590.7227085\ttotal: 1m 25s\tremaining: 36s\n",
      "704:\tlearn: 1590.5551541\ttotal: 1m 25s\tremaining: 35.8s\n",
      "705:\tlearn: 1590.4728681\ttotal: 1m 25s\tremaining: 35.7s\n",
      "706:\tlearn: 1590.4479844\ttotal: 1m 25s\tremaining: 35.6s\n",
      "707:\tlearn: 1590.2791326\ttotal: 1m 26s\tremaining: 35.5s\n",
      "708:\tlearn: 1590.1907357\ttotal: 1m 26s\tremaining: 35.4s\n",
      "709:\tlearn: 1590.0340694\ttotal: 1m 26s\tremaining: 35.2s\n",
      "710:\tlearn: 1589.8685469\ttotal: 1m 26s\tremaining: 35.1s\n",
      "711:\tlearn: 1589.8266236\ttotal: 1m 26s\tremaining: 35s\n",
      "712:\tlearn: 1589.8016434\ttotal: 1m 26s\tremaining: 34.9s\n",
      "713:\tlearn: 1589.6469313\ttotal: 1m 26s\tremaining: 34.7s\n",
      "714:\tlearn: 1589.5195666\ttotal: 1m 26s\tremaining: 34.6s\n",
      "715:\tlearn: 1589.4244421\ttotal: 1m 26s\tremaining: 34.5s\n",
      "716:\tlearn: 1589.1976365\ttotal: 1m 27s\tremaining: 34.4s\n",
      "717:\tlearn: 1589.1368582\ttotal: 1m 27s\tremaining: 34.3s\n",
      "718:\tlearn: 1588.9893572\ttotal: 1m 27s\tremaining: 34.1s\n",
      "719:\tlearn: 1588.7907642\ttotal: 1m 27s\tremaining: 34s\n",
      "720:\tlearn: 1588.6768618\ttotal: 1m 27s\tremaining: 33.9s\n",
      "721:\tlearn: 1588.3625523\ttotal: 1m 27s\tremaining: 33.8s\n",
      "722:\tlearn: 1588.2108230\ttotal: 1m 27s\tremaining: 33.6s\n",
      "723:\tlearn: 1588.0256878\ttotal: 1m 27s\tremaining: 33.5s\n",
      "724:\tlearn: 1587.8843550\ttotal: 1m 28s\tremaining: 33.4s\n",
      "725:\tlearn: 1587.8290801\ttotal: 1m 28s\tremaining: 33.3s\n",
      "726:\tlearn: 1587.7533422\ttotal: 1m 28s\tremaining: 33.2s\n",
      "727:\tlearn: 1587.4973696\ttotal: 1m 28s\tremaining: 33s\n",
      "728:\tlearn: 1587.4162220\ttotal: 1m 28s\tremaining: 32.9s\n",
      "729:\tlearn: 1587.3501855\ttotal: 1m 28s\tremaining: 32.8s\n",
      "730:\tlearn: 1587.2844851\ttotal: 1m 28s\tremaining: 32.7s\n",
      "731:\tlearn: 1587.1950794\ttotal: 1m 28s\tremaining: 32.5s\n",
      "732:\tlearn: 1586.9979360\ttotal: 1m 28s\tremaining: 32.4s\n",
      "733:\tlearn: 1586.9033396\ttotal: 1m 29s\tremaining: 32.3s\n",
      "734:\tlearn: 1586.7555976\ttotal: 1m 29s\tremaining: 32.2s\n",
      "735:\tlearn: 1586.5196488\ttotal: 1m 29s\tremaining: 32s\n",
      "736:\tlearn: 1586.4046698\ttotal: 1m 29s\tremaining: 31.9s\n",
      "737:\tlearn: 1586.3208261\ttotal: 1m 29s\tremaining: 31.8s\n",
      "738:\tlearn: 1585.9905799\ttotal: 1m 29s\tremaining: 31.7s\n",
      "739:\tlearn: 1585.8476213\ttotal: 1m 29s\tremaining: 31.6s\n",
      "740:\tlearn: 1585.7432886\ttotal: 1m 30s\tremaining: 31.5s\n",
      "741:\tlearn: 1585.6593426\ttotal: 1m 30s\tremaining: 31.3s\n",
      "742:\tlearn: 1585.5931584\ttotal: 1m 30s\tremaining: 31.2s\n",
      "743:\tlearn: 1585.4643961\ttotal: 1m 30s\tremaining: 31.1s\n",
      "744:\tlearn: 1585.3616685\ttotal: 1m 30s\tremaining: 31s\n",
      "745:\tlearn: 1585.3054358\ttotal: 1m 30s\tremaining: 30.8s\n",
      "746:\tlearn: 1585.1637581\ttotal: 1m 30s\tremaining: 30.7s\n",
      "747:\tlearn: 1585.1337956\ttotal: 1m 30s\tremaining: 30.6s\n",
      "748:\tlearn: 1584.9234889\ttotal: 1m 30s\tremaining: 30.5s\n",
      "749:\tlearn: 1584.6326211\ttotal: 1m 31s\tremaining: 30.3s\n",
      "750:\tlearn: 1584.4147028\ttotal: 1m 31s\tremaining: 30.2s\n",
      "751:\tlearn: 1584.1874180\ttotal: 1m 31s\tremaining: 30.1s\n",
      "752:\tlearn: 1584.0005684\ttotal: 1m 31s\tremaining: 30s\n",
      "753:\tlearn: 1583.7377684\ttotal: 1m 31s\tremaining: 29.8s\n",
      "754:\tlearn: 1583.6036870\ttotal: 1m 31s\tremaining: 29.7s\n",
      "755:\tlearn: 1583.5603834\ttotal: 1m 31s\tremaining: 29.6s\n",
      "756:\tlearn: 1583.3159481\ttotal: 1m 31s\tremaining: 29.5s\n",
      "757:\tlearn: 1583.1687394\ttotal: 1m 31s\tremaining: 29.4s\n",
      "758:\tlearn: 1583.1179082\ttotal: 1m 32s\tremaining: 29.2s\n",
      "759:\tlearn: 1583.0562636\ttotal: 1m 32s\tremaining: 29.1s\n",
      "760:\tlearn: 1582.8475456\ttotal: 1m 32s\tremaining: 29s\n",
      "761:\tlearn: 1582.7647830\ttotal: 1m 32s\tremaining: 28.9s\n",
      "762:\tlearn: 1582.6348198\ttotal: 1m 32s\tremaining: 28.8s\n",
      "763:\tlearn: 1582.4694261\ttotal: 1m 32s\tremaining: 28.6s\n",
      "764:\tlearn: 1582.3455893\ttotal: 1m 32s\tremaining: 28.5s\n",
      "765:\tlearn: 1582.1794138\ttotal: 1m 32s\tremaining: 28.4s\n",
      "766:\tlearn: 1582.0404967\ttotal: 1m 33s\tremaining: 28.3s\n",
      "767:\tlearn: 1581.8711658\ttotal: 1m 33s\tremaining: 28.2s\n",
      "768:\tlearn: 1581.7544438\ttotal: 1m 33s\tremaining: 28s\n",
      "769:\tlearn: 1581.3313794\ttotal: 1m 33s\tremaining: 27.9s\n",
      "770:\tlearn: 1581.1162026\ttotal: 1m 33s\tremaining: 27.8s\n",
      "771:\tlearn: 1581.0034780\ttotal: 1m 33s\tremaining: 27.7s\n",
      "772:\tlearn: 1580.9152690\ttotal: 1m 33s\tremaining: 27.6s\n",
      "773:\tlearn: 1580.6832718\ttotal: 1m 33s\tremaining: 27.4s\n",
      "774:\tlearn: 1580.5459338\ttotal: 1m 34s\tremaining: 27.3s\n",
      "775:\tlearn: 1580.4813076\ttotal: 1m 34s\tremaining: 27.2s\n",
      "776:\tlearn: 1580.3546562\ttotal: 1m 34s\tremaining: 27.1s\n",
      "777:\tlearn: 1580.2491159\ttotal: 1m 34s\tremaining: 26.9s\n",
      "778:\tlearn: 1580.1017741\ttotal: 1m 34s\tremaining: 26.8s\n",
      "779:\tlearn: 1579.9426379\ttotal: 1m 34s\tremaining: 26.7s\n",
      "780:\tlearn: 1579.8501047\ttotal: 1m 34s\tremaining: 26.6s\n",
      "781:\tlearn: 1579.7272553\ttotal: 1m 34s\tremaining: 26.5s\n",
      "782:\tlearn: 1579.5313660\ttotal: 1m 35s\tremaining: 26.3s\n",
      "783:\tlearn: 1579.4693711\ttotal: 1m 35s\tremaining: 26.2s\n",
      "784:\tlearn: 1579.2292055\ttotal: 1m 35s\tremaining: 26.1s\n",
      "785:\tlearn: 1579.0977051\ttotal: 1m 35s\tremaining: 26s\n",
      "786:\tlearn: 1578.9439617\ttotal: 1m 35s\tremaining: 25.9s\n",
      "787:\tlearn: 1578.7637036\ttotal: 1m 35s\tremaining: 25.7s\n",
      "788:\tlearn: 1578.6614022\ttotal: 1m 35s\tremaining: 25.6s\n",
      "789:\tlearn: 1578.6046666\ttotal: 1m 35s\tremaining: 25.5s\n",
      "790:\tlearn: 1578.4725770\ttotal: 1m 36s\tremaining: 25.4s\n",
      "791:\tlearn: 1578.1232275\ttotal: 1m 36s\tremaining: 25.2s\n",
      "792:\tlearn: 1578.0364878\ttotal: 1m 36s\tremaining: 25.1s\n",
      "793:\tlearn: 1577.9136963\ttotal: 1m 36s\tremaining: 25s\n",
      "794:\tlearn: 1577.8278497\ttotal: 1m 36s\tremaining: 24.9s\n",
      "795:\tlearn: 1577.7142510\ttotal: 1m 36s\tremaining: 24.8s\n",
      "796:\tlearn: 1577.6941402\ttotal: 1m 36s\tremaining: 24.6s\n",
      "797:\tlearn: 1577.5509204\ttotal: 1m 36s\tremaining: 24.5s\n",
      "798:\tlearn: 1577.4122725\ttotal: 1m 36s\tremaining: 24.4s\n",
      "799:\tlearn: 1577.0485192\ttotal: 1m 37s\tremaining: 24.3s\n",
      "800:\tlearn: 1576.8121631\ttotal: 1m 37s\tremaining: 24.1s\n",
      "801:\tlearn: 1576.7450107\ttotal: 1m 37s\tremaining: 24s\n",
      "802:\tlearn: 1576.6233072\ttotal: 1m 37s\tremaining: 23.9s\n",
      "803:\tlearn: 1576.5546144\ttotal: 1m 37s\tremaining: 23.8s\n",
      "804:\tlearn: 1576.4148882\ttotal: 1m 37s\tremaining: 23.7s\n",
      "805:\tlearn: 1576.2701038\ttotal: 1m 37s\tremaining: 23.5s\n",
      "806:\tlearn: 1576.2059045\ttotal: 1m 37s\tremaining: 23.4s\n",
      "807:\tlearn: 1576.1399350\ttotal: 1m 38s\tremaining: 23.3s\n",
      "808:\tlearn: 1576.0741623\ttotal: 1m 38s\tremaining: 23.2s\n",
      "809:\tlearn: 1575.9862843\ttotal: 1m 38s\tremaining: 23.1s\n",
      "810:\tlearn: 1575.7892434\ttotal: 1m 38s\tremaining: 23s\n",
      "811:\tlearn: 1575.7302081\ttotal: 1m 38s\tremaining: 22.8s\n",
      "812:\tlearn: 1575.5032916\ttotal: 1m 38s\tremaining: 22.7s\n",
      "813:\tlearn: 1575.3655636\ttotal: 1m 38s\tremaining: 22.6s\n",
      "814:\tlearn: 1575.2770949\ttotal: 1m 39s\tremaining: 22.5s\n",
      "815:\tlearn: 1575.1690317\ttotal: 1m 39s\tremaining: 22.4s\n",
      "816:\tlearn: 1575.1297429\ttotal: 1m 39s\tremaining: 22.3s\n",
      "817:\tlearn: 1575.0595069\ttotal: 1m 39s\tremaining: 22.2s\n",
      "818:\tlearn: 1574.9764512\ttotal: 1m 39s\tremaining: 22.1s\n",
      "819:\tlearn: 1574.9273521\ttotal: 1m 39s\tremaining: 21.9s\n",
      "820:\tlearn: 1574.8319976\ttotal: 1m 40s\tremaining: 21.8s\n",
      "821:\tlearn: 1574.7638893\ttotal: 1m 40s\tremaining: 21.7s\n",
      "822:\tlearn: 1574.6662402\ttotal: 1m 40s\tremaining: 21.6s\n",
      "823:\tlearn: 1574.5874675\ttotal: 1m 40s\tremaining: 21.4s\n",
      "824:\tlearn: 1574.4209448\ttotal: 1m 40s\tremaining: 21.3s\n",
      "825:\tlearn: 1574.2964213\ttotal: 1m 40s\tremaining: 21.2s\n",
      "826:\tlearn: 1574.1695815\ttotal: 1m 40s\tremaining: 21.1s\n",
      "827:\tlearn: 1574.1082320\ttotal: 1m 40s\tremaining: 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828:\tlearn: 1573.9196569\ttotal: 1m 41s\tremaining: 20.8s\n",
      "829:\tlearn: 1573.6619750\ttotal: 1m 41s\tremaining: 20.7s\n",
      "830:\tlearn: 1573.6207563\ttotal: 1m 41s\tremaining: 20.6s\n",
      "831:\tlearn: 1573.5635312\ttotal: 1m 41s\tremaining: 20.5s\n",
      "832:\tlearn: 1573.4350256\ttotal: 1m 41s\tremaining: 20.4s\n",
      "833:\tlearn: 1573.3718587\ttotal: 1m 41s\tremaining: 20.2s\n",
      "834:\tlearn: 1573.2995466\ttotal: 1m 41s\tremaining: 20.1s\n",
      "835:\tlearn: 1573.1606429\ttotal: 1m 41s\tremaining: 20s\n",
      "836:\tlearn: 1573.0051317\ttotal: 1m 42s\tremaining: 19.9s\n",
      "837:\tlearn: 1572.8895719\ttotal: 1m 42s\tremaining: 19.7s\n",
      "838:\tlearn: 1572.7293848\ttotal: 1m 42s\tremaining: 19.6s\n",
      "839:\tlearn: 1572.6162396\ttotal: 1m 42s\tremaining: 19.5s\n",
      "840:\tlearn: 1572.4732345\ttotal: 1m 42s\tremaining: 19.4s\n",
      "841:\tlearn: 1572.2349426\ttotal: 1m 42s\tremaining: 19.3s\n",
      "842:\tlearn: 1572.0433248\ttotal: 1m 42s\tremaining: 19.1s\n",
      "843:\tlearn: 1571.9409974\ttotal: 1m 42s\tremaining: 19s\n",
      "844:\tlearn: 1571.8083042\ttotal: 1m 43s\tremaining: 18.9s\n",
      "845:\tlearn: 1571.7442774\ttotal: 1m 43s\tremaining: 18.8s\n",
      "846:\tlearn: 1571.4773733\ttotal: 1m 43s\tremaining: 18.7s\n",
      "847:\tlearn: 1571.3706868\ttotal: 1m 43s\tremaining: 18.5s\n",
      "848:\tlearn: 1571.2175256\ttotal: 1m 43s\tremaining: 18.4s\n",
      "849:\tlearn: 1571.1309809\ttotal: 1m 43s\tremaining: 18.3s\n",
      "850:\tlearn: 1571.0277653\ttotal: 1m 43s\tremaining: 18.2s\n",
      "851:\tlearn: 1570.9942155\ttotal: 1m 43s\tremaining: 18.1s\n",
      "852:\tlearn: 1570.9090304\ttotal: 1m 44s\tremaining: 17.9s\n",
      "853:\tlearn: 1570.8065128\ttotal: 1m 44s\tremaining: 17.8s\n",
      "854:\tlearn: 1570.6833675\ttotal: 1m 44s\tremaining: 17.7s\n",
      "855:\tlearn: 1570.5673628\ttotal: 1m 44s\tremaining: 17.6s\n",
      "856:\tlearn: 1570.4743197\ttotal: 1m 44s\tremaining: 17.4s\n",
      "857:\tlearn: 1570.3445329\ttotal: 1m 44s\tremaining: 17.3s\n",
      "858:\tlearn: 1570.2103544\ttotal: 1m 44s\tremaining: 17.2s\n",
      "859:\tlearn: 1570.0715010\ttotal: 1m 44s\tremaining: 17.1s\n",
      "860:\tlearn: 1570.0067068\ttotal: 1m 45s\tremaining: 17s\n",
      "861:\tlearn: 1569.8758852\ttotal: 1m 45s\tremaining: 16.8s\n",
      "862:\tlearn: 1569.7978252\ttotal: 1m 45s\tremaining: 16.7s\n",
      "863:\tlearn: 1569.7355010\ttotal: 1m 45s\tremaining: 16.6s\n",
      "864:\tlearn: 1569.6812474\ttotal: 1m 45s\tremaining: 16.5s\n",
      "865:\tlearn: 1569.5497156\ttotal: 1m 45s\tremaining: 16.3s\n",
      "866:\tlearn: 1569.4080641\ttotal: 1m 45s\tremaining: 16.2s\n",
      "867:\tlearn: 1569.2857850\ttotal: 1m 45s\tremaining: 16.1s\n",
      "868:\tlearn: 1569.2120298\ttotal: 1m 45s\tremaining: 16s\n",
      "869:\tlearn: 1569.0348031\ttotal: 1m 46s\tremaining: 15.9s\n",
      "870:\tlearn: 1568.8464168\ttotal: 1m 46s\tremaining: 15.7s\n",
      "871:\tlearn: 1568.7393733\ttotal: 1m 46s\tremaining: 15.6s\n",
      "872:\tlearn: 1568.5493023\ttotal: 1m 46s\tremaining: 15.5s\n",
      "873:\tlearn: 1568.4616579\ttotal: 1m 46s\tremaining: 15.4s\n",
      "874:\tlearn: 1568.3175501\ttotal: 1m 46s\tremaining: 15.3s\n",
      "875:\tlearn: 1568.2673218\ttotal: 1m 46s\tremaining: 15.1s\n",
      "876:\tlearn: 1568.1157625\ttotal: 1m 47s\tremaining: 15s\n",
      "877:\tlearn: 1568.0448082\ttotal: 1m 47s\tremaining: 14.9s\n",
      "878:\tlearn: 1568.0349861\ttotal: 1m 47s\tremaining: 14.8s\n",
      "879:\tlearn: 1568.0270363\ttotal: 1m 47s\tremaining: 14.7s\n",
      "880:\tlearn: 1567.9112876\ttotal: 1m 47s\tremaining: 14.5s\n",
      "881:\tlearn: 1567.7623645\ttotal: 1m 47s\tremaining: 14.4s\n",
      "882:\tlearn: 1567.6057597\ttotal: 1m 47s\tremaining: 14.3s\n",
      "883:\tlearn: 1567.4297469\ttotal: 1m 47s\tremaining: 14.2s\n",
      "884:\tlearn: 1567.2932439\ttotal: 1m 48s\tremaining: 14s\n",
      "885:\tlearn: 1567.2206906\ttotal: 1m 48s\tremaining: 13.9s\n",
      "886:\tlearn: 1567.0539131\ttotal: 1m 48s\tremaining: 13.8s\n",
      "887:\tlearn: 1566.9394929\ttotal: 1m 48s\tremaining: 13.7s\n",
      "888:\tlearn: 1566.7532296\ttotal: 1m 48s\tremaining: 13.6s\n",
      "889:\tlearn: 1566.6419409\ttotal: 1m 48s\tremaining: 13.4s\n",
      "890:\tlearn: 1566.4613976\ttotal: 1m 48s\tremaining: 13.3s\n",
      "891:\tlearn: 1566.4149038\ttotal: 1m 48s\tremaining: 13.2s\n",
      "892:\tlearn: 1566.2921552\ttotal: 1m 49s\tremaining: 13.1s\n",
      "893:\tlearn: 1566.0993105\ttotal: 1m 49s\tremaining: 13s\n",
      "894:\tlearn: 1566.0247209\ttotal: 1m 49s\tremaining: 12.8s\n",
      "895:\tlearn: 1565.9943196\ttotal: 1m 49s\tremaining: 12.7s\n",
      "896:\tlearn: 1565.9194033\ttotal: 1m 49s\tremaining: 12.6s\n",
      "897:\tlearn: 1565.8303778\ttotal: 1m 49s\tremaining: 12.5s\n",
      "898:\tlearn: 1565.6405305\ttotal: 1m 49s\tremaining: 12.3s\n",
      "899:\tlearn: 1565.6126692\ttotal: 1m 49s\tremaining: 12.2s\n",
      "900:\tlearn: 1565.5886156\ttotal: 1m 50s\tremaining: 12.1s\n",
      "901:\tlearn: 1565.4684721\ttotal: 1m 50s\tremaining: 12s\n",
      "902:\tlearn: 1565.4053333\ttotal: 1m 50s\tremaining: 11.9s\n",
      "903:\tlearn: 1565.2814417\ttotal: 1m 50s\tremaining: 11.7s\n",
      "904:\tlearn: 1565.1544179\ttotal: 1m 50s\tremaining: 11.6s\n",
      "905:\tlearn: 1565.1057503\ttotal: 1m 50s\tremaining: 11.5s\n",
      "906:\tlearn: 1565.0426185\ttotal: 1m 50s\tremaining: 11.4s\n",
      "907:\tlearn: 1564.8955740\ttotal: 1m 51s\tremaining: 11.3s\n",
      "908:\tlearn: 1564.8032880\ttotal: 1m 51s\tremaining: 11.1s\n",
      "909:\tlearn: 1564.6827092\ttotal: 1m 51s\tremaining: 11s\n",
      "910:\tlearn: 1564.6333226\ttotal: 1m 51s\tremaining: 10.9s\n",
      "911:\tlearn: 1564.5495240\ttotal: 1m 51s\tremaining: 10.8s\n",
      "912:\tlearn: 1564.4697856\ttotal: 1m 51s\tremaining: 10.6s\n",
      "913:\tlearn: 1564.3750555\ttotal: 1m 51s\tremaining: 10.5s\n",
      "914:\tlearn: 1564.3235821\ttotal: 1m 51s\tremaining: 10.4s\n",
      "915:\tlearn: 1564.2231425\ttotal: 1m 52s\tremaining: 10.3s\n",
      "916:\tlearn: 1564.1007105\ttotal: 1m 52s\tremaining: 10.2s\n",
      "917:\tlearn: 1563.9698099\ttotal: 1m 52s\tremaining: 10s\n",
      "918:\tlearn: 1563.8172205\ttotal: 1m 52s\tremaining: 9.91s\n",
      "919:\tlearn: 1563.7132389\ttotal: 1m 52s\tremaining: 9.78s\n",
      "920:\tlearn: 1563.5495539\ttotal: 1m 52s\tremaining: 9.66s\n",
      "921:\tlearn: 1563.4346807\ttotal: 1m 52s\tremaining: 9.54s\n",
      "922:\tlearn: 1563.3455138\ttotal: 1m 52s\tremaining: 9.41s\n",
      "923:\tlearn: 1563.2491628\ttotal: 1m 52s\tremaining: 9.29s\n",
      "924:\tlearn: 1563.1884315\ttotal: 1m 53s\tremaining: 9.17s\n",
      "925:\tlearn: 1563.0830424\ttotal: 1m 53s\tremaining: 9.05s\n",
      "926:\tlearn: 1562.9456844\ttotal: 1m 53s\tremaining: 8.93s\n",
      "927:\tlearn: 1562.8835509\ttotal: 1m 53s\tremaining: 8.8s\n",
      "928:\tlearn: 1562.7333664\ttotal: 1m 53s\tremaining: 8.68s\n",
      "929:\tlearn: 1562.5908292\ttotal: 1m 53s\tremaining: 8.56s\n",
      "930:\tlearn: 1562.4796363\ttotal: 1m 53s\tremaining: 8.44s\n",
      "931:\tlearn: 1562.3922910\ttotal: 1m 54s\tremaining: 8.32s\n",
      "932:\tlearn: 1562.2253806\ttotal: 1m 54s\tremaining: 8.2s\n",
      "933:\tlearn: 1562.1017356\ttotal: 1m 54s\tremaining: 8.07s\n",
      "934:\tlearn: 1562.0097070\ttotal: 1m 54s\tremaining: 7.95s\n",
      "935:\tlearn: 1561.7619633\ttotal: 1m 54s\tremaining: 7.83s\n",
      "936:\tlearn: 1561.6166110\ttotal: 1m 54s\tremaining: 7.71s\n",
      "937:\tlearn: 1561.5576022\ttotal: 1m 54s\tremaining: 7.59s\n",
      "938:\tlearn: 1561.4397432\ttotal: 1m 54s\tremaining: 7.47s\n",
      "939:\tlearn: 1561.3267348\ttotal: 1m 55s\tremaining: 7.35s\n",
      "940:\tlearn: 1561.2730296\ttotal: 1m 55s\tremaining: 7.23s\n",
      "941:\tlearn: 1561.2194306\ttotal: 1m 55s\tremaining: 7.1s\n",
      "942:\tlearn: 1561.1759226\ttotal: 1m 55s\tremaining: 6.98s\n",
      "943:\tlearn: 1561.1202364\ttotal: 1m 55s\tremaining: 6.86s\n",
      "944:\tlearn: 1561.0062063\ttotal: 1m 55s\tremaining: 6.73s\n",
      "945:\tlearn: 1560.9041090\ttotal: 1m 55s\tremaining: 6.61s\n",
      "946:\tlearn: 1560.7623153\ttotal: 1m 56s\tremaining: 6.49s\n",
      "947:\tlearn: 1560.6953082\ttotal: 1m 56s\tremaining: 6.37s\n",
      "948:\tlearn: 1560.6001198\ttotal: 1m 56s\tremaining: 6.25s\n",
      "949:\tlearn: 1560.5391351\ttotal: 1m 56s\tremaining: 6.13s\n",
      "950:\tlearn: 1560.4469361\ttotal: 1m 56s\tremaining: 6s\n",
      "951:\tlearn: 1560.3261925\ttotal: 1m 56s\tremaining: 5.88s\n",
      "952:\tlearn: 1560.2209936\ttotal: 1m 56s\tremaining: 5.76s\n",
      "953:\tlearn: 1560.1192945\ttotal: 1m 57s\tremaining: 5.64s\n",
      "954:\tlearn: 1560.0449111\ttotal: 1m 57s\tremaining: 5.52s\n",
      "955:\tlearn: 1559.9519200\ttotal: 1m 57s\tremaining: 5.4s\n",
      "956:\tlearn: 1559.8619192\ttotal: 1m 57s\tremaining: 5.28s\n",
      "957:\tlearn: 1559.7744167\ttotal: 1m 57s\tremaining: 5.16s\n",
      "958:\tlearn: 1559.7039412\ttotal: 1m 57s\tremaining: 5.03s\n",
      "959:\tlearn: 1559.6335255\ttotal: 1m 57s\tremaining: 4.91s\n",
      "960:\tlearn: 1559.4781108\ttotal: 1m 58s\tremaining: 4.79s\n",
      "961:\tlearn: 1559.3213972\ttotal: 1m 58s\tremaining: 4.67s\n",
      "962:\tlearn: 1559.2327484\ttotal: 1m 58s\tremaining: 4.55s\n",
      "963:\tlearn: 1559.1049304\ttotal: 1m 58s\tremaining: 4.42s\n",
      "964:\tlearn: 1558.9916605\ttotal: 1m 58s\tremaining: 4.3s\n",
      "965:\tlearn: 1558.8538809\ttotal: 1m 58s\tremaining: 4.18s\n",
      "966:\tlearn: 1558.8076167\ttotal: 1m 58s\tremaining: 4.06s\n",
      "967:\tlearn: 1558.6644202\ttotal: 1m 58s\tremaining: 3.93s\n",
      "968:\tlearn: 1558.5439507\ttotal: 1m 59s\tremaining: 3.81s\n",
      "969:\tlearn: 1558.4568396\ttotal: 1m 59s\tremaining: 3.69s\n",
      "970:\tlearn: 1558.3669819\ttotal: 1m 59s\tremaining: 3.56s\n",
      "971:\tlearn: 1558.2858858\ttotal: 1m 59s\tremaining: 3.44s\n",
      "972:\tlearn: 1558.2001960\ttotal: 1m 59s\tremaining: 3.32s\n",
      "973:\tlearn: 1558.0470620\ttotal: 1m 59s\tremaining: 3.2s\n",
      "974:\tlearn: 1557.9794184\ttotal: 1m 59s\tremaining: 3.08s\n",
      "975:\tlearn: 1557.8490465\ttotal: 2m\tremaining: 2.95s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976:\tlearn: 1557.6499096\ttotal: 2m\tremaining: 2.83s\n",
      "977:\tlearn: 1557.5402830\ttotal: 2m\tremaining: 2.71s\n",
      "978:\tlearn: 1557.4911704\ttotal: 2m\tremaining: 2.58s\n",
      "979:\tlearn: 1557.4111384\ttotal: 2m\tremaining: 2.46s\n",
      "980:\tlearn: 1557.2840249\ttotal: 2m\tremaining: 2.34s\n",
      "981:\tlearn: 1557.1972340\ttotal: 2m\tremaining: 2.22s\n",
      "982:\tlearn: 1557.1483472\ttotal: 2m 1s\tremaining: 2.09s\n",
      "983:\tlearn: 1557.1050783\ttotal: 2m 1s\tremaining: 1.97s\n",
      "984:\tlearn: 1557.0303067\ttotal: 2m 1s\tremaining: 1.85s\n",
      "985:\tlearn: 1556.7786360\ttotal: 2m 1s\tremaining: 1.72s\n",
      "986:\tlearn: 1556.7030466\ttotal: 2m 1s\tremaining: 1.6s\n",
      "987:\tlearn: 1556.4153013\ttotal: 2m 1s\tremaining: 1.48s\n",
      "988:\tlearn: 1556.3175400\ttotal: 2m 1s\tremaining: 1.35s\n",
      "989:\tlearn: 1556.2410574\ttotal: 2m 1s\tremaining: 1.23s\n",
      "990:\tlearn: 1556.2255427\ttotal: 2m 2s\tremaining: 1.11s\n",
      "991:\tlearn: 1556.1762936\ttotal: 2m 2s\tremaining: 986ms\n",
      "992:\tlearn: 1556.0416343\ttotal: 2m 2s\tremaining: 862ms\n",
      "993:\tlearn: 1556.0094198\ttotal: 2m 2s\tremaining: 739ms\n",
      "994:\tlearn: 1555.9302949\ttotal: 2m 2s\tremaining: 616ms\n",
      "995:\tlearn: 1555.8248862\ttotal: 2m 2s\tremaining: 493ms\n",
      "996:\tlearn: 1555.7452876\ttotal: 2m 2s\tremaining: 370ms\n",
      "997:\tlearn: 1555.6831091\ttotal: 2m 3s\tremaining: 247ms\n",
      "998:\tlearn: 1555.6561104\ttotal: 2m 3s\tremaining: 123ms\n",
      "999:\tlearn: 1555.4670690\ttotal: 2m 3s\tremaining: 0us\n",
      "Learning rate set to 0.094301\n",
      "0:\tlearn: 4424.0678712\ttotal: 174ms\tremaining: 2m 54s\n",
      "1:\tlearn: 4160.6809972\ttotal: 328ms\tremaining: 2m 43s\n",
      "2:\tlearn: 3925.8512644\ttotal: 492ms\tremaining: 2m 43s\n",
      "3:\tlearn: 3714.0588186\ttotal: 660ms\tremaining: 2m 44s\n",
      "4:\tlearn: 3525.3098380\ttotal: 810ms\tremaining: 2m 41s\n",
      "5:\tlearn: 3359.2023592\ttotal: 938ms\tremaining: 2m 35s\n",
      "6:\tlearn: 3208.8508805\ttotal: 1.08s\tremaining: 2m 33s\n",
      "7:\tlearn: 3077.5989588\ttotal: 1.21s\tremaining: 2m 29s\n",
      "8:\tlearn: 2959.6615269\ttotal: 1.33s\tremaining: 2m 26s\n",
      "9:\tlearn: 2853.6053913\ttotal: 1.5s\tremaining: 2m 28s\n",
      "10:\tlearn: 2762.4536451\ttotal: 1.65s\tremaining: 2m 27s\n",
      "11:\tlearn: 2682.8366008\ttotal: 1.76s\tremaining: 2m 24s\n",
      "12:\tlearn: 2607.4037991\ttotal: 1.91s\tremaining: 2m 25s\n",
      "13:\tlearn: 2544.4004767\ttotal: 2.07s\tremaining: 2m 25s\n",
      "14:\tlearn: 2480.5232677\ttotal: 2.18s\tremaining: 2m 23s\n",
      "15:\tlearn: 2428.7067387\ttotal: 2.31s\tremaining: 2m 22s\n",
      "16:\tlearn: 2382.2654391\ttotal: 2.42s\tremaining: 2m 20s\n",
      "17:\tlearn: 2338.9042016\ttotal: 2.55s\tremaining: 2m 19s\n",
      "18:\tlearn: 2301.2168213\ttotal: 2.66s\tremaining: 2m 17s\n",
      "19:\tlearn: 2266.2533712\ttotal: 2.8s\tremaining: 2m 17s\n",
      "20:\tlearn: 2235.3943819\ttotal: 2.92s\tremaining: 2m 16s\n",
      "21:\tlearn: 2205.1796774\ttotal: 3.04s\tremaining: 2m 15s\n",
      "22:\tlearn: 2177.6950488\ttotal: 3.18s\tremaining: 2m 14s\n",
      "23:\tlearn: 2153.7709429\ttotal: 3.31s\tremaining: 2m 14s\n",
      "24:\tlearn: 2130.6028668\ttotal: 3.41s\tremaining: 2m 13s\n",
      "25:\tlearn: 2112.0673325\ttotal: 3.54s\tremaining: 2m 12s\n",
      "26:\tlearn: 2090.6722248\ttotal: 3.67s\tremaining: 2m 12s\n",
      "27:\tlearn: 2073.2853861\ttotal: 3.8s\tremaining: 2m 11s\n",
      "28:\tlearn: 2059.6594308\ttotal: 3.89s\tremaining: 2m 10s\n",
      "29:\tlearn: 2046.6956289\ttotal: 4.01s\tremaining: 2m 9s\n",
      "30:\tlearn: 2034.3359299\ttotal: 4.13s\tremaining: 2m 9s\n",
      "31:\tlearn: 2023.5259306\ttotal: 4.24s\tremaining: 2m 8s\n",
      "32:\tlearn: 2012.7047413\ttotal: 4.38s\tremaining: 2m 8s\n",
      "33:\tlearn: 2003.4584157\ttotal: 4.51s\tremaining: 2m 8s\n",
      "34:\tlearn: 1995.8767594\ttotal: 4.64s\tremaining: 2m 7s\n",
      "35:\tlearn: 1988.9935665\ttotal: 4.77s\tremaining: 2m 7s\n",
      "36:\tlearn: 1981.3653007\ttotal: 4.9s\tremaining: 2m 7s\n",
      "37:\tlearn: 1975.7113260\ttotal: 5.04s\tremaining: 2m 7s\n",
      "38:\tlearn: 1969.8387646\ttotal: 5.12s\tremaining: 2m 6s\n",
      "39:\tlearn: 1963.8315914\ttotal: 5.23s\tremaining: 2m 5s\n",
      "40:\tlearn: 1956.1992535\ttotal: 5.34s\tremaining: 2m 4s\n",
      "41:\tlearn: 1950.3593578\ttotal: 5.47s\tremaining: 2m 4s\n",
      "42:\tlearn: 1943.2428512\ttotal: 5.58s\tremaining: 2m 4s\n",
      "43:\tlearn: 1938.8716135\ttotal: 5.72s\tremaining: 2m 4s\n",
      "44:\tlearn: 1935.2398622\ttotal: 5.85s\tremaining: 2m 4s\n",
      "45:\tlearn: 1929.6392284\ttotal: 5.93s\tremaining: 2m 3s\n",
      "46:\tlearn: 1925.7641928\ttotal: 6.05s\tremaining: 2m 2s\n",
      "47:\tlearn: 1921.8807809\ttotal: 6.2s\tremaining: 2m 3s\n",
      "48:\tlearn: 1919.2404580\ttotal: 6.34s\tremaining: 2m 3s\n",
      "49:\tlearn: 1916.5662880\ttotal: 6.47s\tremaining: 2m 2s\n",
      "50:\tlearn: 1911.5882015\ttotal: 6.57s\tremaining: 2m 2s\n",
      "51:\tlearn: 1907.5990177\ttotal: 6.69s\tremaining: 2m 1s\n",
      "52:\tlearn: 1903.4659120\ttotal: 6.79s\tremaining: 2m 1s\n",
      "53:\tlearn: 1899.7529946\ttotal: 6.94s\tremaining: 2m 1s\n",
      "54:\tlearn: 1896.5368407\ttotal: 7.06s\tremaining: 2m 1s\n",
      "55:\tlearn: 1893.5723797\ttotal: 7.14s\tremaining: 2m\n",
      "56:\tlearn: 1891.5119053\ttotal: 7.29s\tremaining: 2m\n",
      "57:\tlearn: 1888.9992484\ttotal: 7.43s\tremaining: 2m\n",
      "58:\tlearn: 1886.8732048\ttotal: 7.55s\tremaining: 2m\n",
      "59:\tlearn: 1884.3635142\ttotal: 7.69s\tremaining: 2m\n",
      "60:\tlearn: 1882.0166227\ttotal: 7.79s\tremaining: 1m 59s\n",
      "61:\tlearn: 1879.3185466\ttotal: 7.89s\tremaining: 1m 59s\n",
      "62:\tlearn: 1876.0087053\ttotal: 8.02s\tremaining: 1m 59s\n",
      "63:\tlearn: 1873.8008258\ttotal: 8.15s\tremaining: 1m 59s\n",
      "64:\tlearn: 1870.7491543\ttotal: 8.26s\tremaining: 1m 58s\n",
      "65:\tlearn: 1867.8537217\ttotal: 8.38s\tremaining: 1m 58s\n",
      "66:\tlearn: 1864.8593118\ttotal: 8.5s\tremaining: 1m 58s\n",
      "67:\tlearn: 1862.6285578\ttotal: 8.6s\tremaining: 1m 57s\n",
      "68:\tlearn: 1860.6970245\ttotal: 8.72s\tremaining: 1m 57s\n",
      "69:\tlearn: 1859.0507525\ttotal: 8.84s\tremaining: 1m 57s\n",
      "70:\tlearn: 1857.8127975\ttotal: 8.95s\tremaining: 1m 57s\n",
      "71:\tlearn: 1855.3246657\ttotal: 9.07s\tremaining: 1m 56s\n",
      "72:\tlearn: 1853.5958763\ttotal: 9.19s\tremaining: 1m 56s\n",
      "73:\tlearn: 1852.2703489\ttotal: 9.32s\tremaining: 1m 56s\n",
      "74:\tlearn: 1849.7995986\ttotal: 9.4s\tremaining: 1m 55s\n",
      "75:\tlearn: 1846.6931697\ttotal: 9.51s\tremaining: 1m 55s\n",
      "76:\tlearn: 1845.5412637\ttotal: 9.63s\tremaining: 1m 55s\n",
      "77:\tlearn: 1842.8703254\ttotal: 9.74s\tremaining: 1m 55s\n",
      "78:\tlearn: 1841.3206895\ttotal: 9.88s\tremaining: 1m 55s\n",
      "79:\tlearn: 1839.8822873\ttotal: 10s\tremaining: 1m 55s\n",
      "80:\tlearn: 1837.3204223\ttotal: 10.1s\tremaining: 1m 55s\n",
      "81:\tlearn: 1836.2549708\ttotal: 10.3s\tremaining: 1m 55s\n",
      "82:\tlearn: 1835.1950599\ttotal: 10.4s\tremaining: 1m 55s\n",
      "83:\tlearn: 1833.3737854\ttotal: 10.5s\tremaining: 1m 54s\n",
      "84:\tlearn: 1830.9939431\ttotal: 10.6s\tremaining: 1m 54s\n",
      "85:\tlearn: 1829.1263844\ttotal: 10.7s\tremaining: 1m 54s\n",
      "86:\tlearn: 1827.8415495\ttotal: 10.8s\tremaining: 1m 53s\n",
      "87:\tlearn: 1825.9185833\ttotal: 10.9s\tremaining: 1m 53s\n",
      "88:\tlearn: 1824.0241270\ttotal: 11s\tremaining: 1m 53s\n",
      "89:\tlearn: 1822.7581891\ttotal: 11.2s\tremaining: 1m 52s\n",
      "90:\tlearn: 1821.4111642\ttotal: 11.3s\tremaining: 1m 52s\n",
      "91:\tlearn: 1819.4113195\ttotal: 11.4s\tremaining: 1m 52s\n",
      "92:\tlearn: 1818.1898820\ttotal: 11.5s\tremaining: 1m 52s\n",
      "93:\tlearn: 1815.6458413\ttotal: 11.6s\tremaining: 1m 51s\n",
      "94:\tlearn: 1813.8511245\ttotal: 11.8s\tremaining: 1m 52s\n",
      "95:\tlearn: 1811.8704088\ttotal: 11.9s\tremaining: 1m 52s\n",
      "96:\tlearn: 1810.6705590\ttotal: 12s\tremaining: 1m 51s\n",
      "97:\tlearn: 1809.8269526\ttotal: 12.2s\tremaining: 1m 51s\n",
      "98:\tlearn: 1808.9688233\ttotal: 12.3s\tremaining: 1m 51s\n",
      "99:\tlearn: 1807.5975543\ttotal: 12.4s\tremaining: 1m 51s\n",
      "100:\tlearn: 1806.2968308\ttotal: 12.5s\tremaining: 1m 51s\n",
      "101:\tlearn: 1805.4107218\ttotal: 12.6s\tremaining: 1m 51s\n",
      "102:\tlearn: 1804.5346144\ttotal: 12.8s\tremaining: 1m 51s\n",
      "103:\tlearn: 1803.8162267\ttotal: 12.9s\tremaining: 1m 51s\n",
      "104:\tlearn: 1802.8933086\ttotal: 13s\tremaining: 1m 50s\n",
      "105:\tlearn: 1801.4521339\ttotal: 13.1s\tremaining: 1m 50s\n",
      "106:\tlearn: 1799.8959713\ttotal: 13.2s\tremaining: 1m 50s\n",
      "107:\tlearn: 1798.5857825\ttotal: 13.4s\tremaining: 1m 50s\n",
      "108:\tlearn: 1797.6820096\ttotal: 13.5s\tremaining: 1m 50s\n",
      "109:\tlearn: 1796.3414069\ttotal: 13.6s\tremaining: 1m 49s\n",
      "110:\tlearn: 1794.7483879\ttotal: 13.7s\tremaining: 1m 49s\n",
      "111:\tlearn: 1793.9006342\ttotal: 13.8s\tremaining: 1m 49s\n",
      "112:\tlearn: 1792.4571603\ttotal: 13.9s\tremaining: 1m 49s\n",
      "113:\tlearn: 1791.1099993\ttotal: 14.1s\tremaining: 1m 49s\n",
      "114:\tlearn: 1789.8458626\ttotal: 14.1s\tremaining: 1m 48s\n",
      "115:\tlearn: 1788.6547928\ttotal: 14.3s\tremaining: 1m 48s\n",
      "116:\tlearn: 1787.8086214\ttotal: 14.4s\tremaining: 1m 48s\n",
      "117:\tlearn: 1787.2767473\ttotal: 14.5s\tremaining: 1m 48s\n",
      "118:\tlearn: 1786.4490443\ttotal: 14.7s\tremaining: 1m 48s\n",
      "119:\tlearn: 1785.9863920\ttotal: 14.8s\tremaining: 1m 48s\n",
      "120:\tlearn: 1784.9215699\ttotal: 14.9s\tremaining: 1m 48s\n",
      "121:\tlearn: 1783.2919379\ttotal: 15s\tremaining: 1m 47s\n",
      "122:\tlearn: 1782.4208410\ttotal: 15.2s\tremaining: 1m 48s\n",
      "123:\tlearn: 1781.6509085\ttotal: 15.3s\tremaining: 1m 47s\n",
      "124:\tlearn: 1780.4973773\ttotal: 15.4s\tremaining: 1m 47s\n",
      "125:\tlearn: 1779.3840459\ttotal: 15.5s\tremaining: 1m 47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126:\tlearn: 1776.9117672\ttotal: 15.6s\tremaining: 1m 47s\n",
      "127:\tlearn: 1775.6772760\ttotal: 15.7s\tremaining: 1m 47s\n",
      "128:\tlearn: 1775.2663429\ttotal: 15.8s\tremaining: 1m 46s\n",
      "129:\tlearn: 1774.3493576\ttotal: 15.9s\tremaining: 1m 46s\n",
      "130:\tlearn: 1773.7690564\ttotal: 16.1s\tremaining: 1m 46s\n",
      "131:\tlearn: 1772.7965996\ttotal: 16.2s\tremaining: 1m 46s\n",
      "132:\tlearn: 1771.7983253\ttotal: 16.3s\tremaining: 1m 46s\n",
      "133:\tlearn: 1771.2527696\ttotal: 16.4s\tremaining: 1m 46s\n",
      "134:\tlearn: 1769.9552494\ttotal: 16.5s\tremaining: 1m 45s\n",
      "135:\tlearn: 1768.9205799\ttotal: 16.6s\tremaining: 1m 45s\n",
      "136:\tlearn: 1767.2729602\ttotal: 16.7s\tremaining: 1m 45s\n",
      "137:\tlearn: 1766.3686173\ttotal: 16.9s\tremaining: 1m 45s\n",
      "138:\tlearn: 1764.8442577\ttotal: 17s\tremaining: 1m 45s\n",
      "139:\tlearn: 1764.1954091\ttotal: 17.1s\tremaining: 1m 44s\n",
      "140:\tlearn: 1762.6874838\ttotal: 17.2s\tremaining: 1m 44s\n",
      "141:\tlearn: 1762.2421267\ttotal: 17.3s\tremaining: 1m 44s\n",
      "142:\tlearn: 1761.3267402\ttotal: 17.5s\tremaining: 1m 44s\n",
      "143:\tlearn: 1760.4083986\ttotal: 17.6s\tremaining: 1m 44s\n",
      "144:\tlearn: 1759.6821826\ttotal: 17.7s\tremaining: 1m 44s\n",
      "145:\tlearn: 1758.8196531\ttotal: 17.8s\tremaining: 1m 44s\n",
      "146:\tlearn: 1757.6843808\ttotal: 17.9s\tremaining: 1m 44s\n",
      "147:\tlearn: 1757.0680459\ttotal: 18.1s\tremaining: 1m 44s\n",
      "148:\tlearn: 1755.9687739\ttotal: 18.2s\tremaining: 1m 44s\n",
      "149:\tlearn: 1755.0223031\ttotal: 18.4s\tremaining: 1m 44s\n",
      "150:\tlearn: 1754.6322633\ttotal: 18.5s\tremaining: 1m 44s\n",
      "151:\tlearn: 1753.6539237\ttotal: 18.6s\tremaining: 1m 43s\n",
      "152:\tlearn: 1752.1664799\ttotal: 18.7s\tremaining: 1m 43s\n",
      "153:\tlearn: 1751.4191985\ttotal: 18.9s\tremaining: 1m 43s\n",
      "154:\tlearn: 1750.5735244\ttotal: 19s\tremaining: 1m 43s\n",
      "155:\tlearn: 1749.5913435\ttotal: 19.1s\tremaining: 1m 43s\n",
      "156:\tlearn: 1748.2468650\ttotal: 19.2s\tremaining: 1m 43s\n",
      "157:\tlearn: 1747.2993710\ttotal: 19.3s\tremaining: 1m 43s\n",
      "158:\tlearn: 1746.4375207\ttotal: 19.4s\tremaining: 1m 42s\n",
      "159:\tlearn: 1746.0304415\ttotal: 19.6s\tremaining: 1m 42s\n",
      "160:\tlearn: 1745.4469916\ttotal: 19.7s\tremaining: 1m 42s\n",
      "161:\tlearn: 1744.9533591\ttotal: 19.8s\tremaining: 1m 42s\n",
      "162:\tlearn: 1744.5533261\ttotal: 20s\tremaining: 1m 42s\n",
      "163:\tlearn: 1744.2072891\ttotal: 20.1s\tremaining: 1m 42s\n",
      "164:\tlearn: 1743.3730404\ttotal: 20.2s\tremaining: 1m 42s\n",
      "165:\tlearn: 1742.7538874\ttotal: 20.3s\tremaining: 1m 41s\n",
      "166:\tlearn: 1741.7932915\ttotal: 20.4s\tremaining: 1m 41s\n",
      "167:\tlearn: 1741.4799354\ttotal: 20.5s\tremaining: 1m 41s\n",
      "168:\tlearn: 1740.8548566\ttotal: 20.6s\tremaining: 1m 41s\n",
      "169:\tlearn: 1740.7829630\ttotal: 20.8s\tremaining: 1m 41s\n",
      "170:\tlearn: 1740.1696254\ttotal: 20.9s\tremaining: 1m 41s\n",
      "171:\tlearn: 1739.8918475\ttotal: 21s\tremaining: 1m 41s\n",
      "172:\tlearn: 1739.3992022\ttotal: 21.2s\tremaining: 1m 41s\n",
      "173:\tlearn: 1739.3197236\ttotal: 21.3s\tremaining: 1m 41s\n",
      "174:\tlearn: 1738.7139680\ttotal: 21.5s\tremaining: 1m 41s\n",
      "175:\tlearn: 1738.2660083\ttotal: 21.6s\tremaining: 1m 40s\n",
      "176:\tlearn: 1737.5094708\ttotal: 21.7s\tremaining: 1m 40s\n",
      "177:\tlearn: 1737.2987612\ttotal: 21.8s\tremaining: 1m 40s\n",
      "178:\tlearn: 1736.5993197\ttotal: 21.9s\tremaining: 1m 40s\n",
      "179:\tlearn: 1735.6006417\ttotal: 22s\tremaining: 1m 40s\n",
      "180:\tlearn: 1734.9217539\ttotal: 22.2s\tremaining: 1m 40s\n",
      "181:\tlearn: 1734.3575077\ttotal: 22.3s\tremaining: 1m 40s\n",
      "182:\tlearn: 1734.3137640\ttotal: 22.4s\tremaining: 1m 39s\n",
      "183:\tlearn: 1733.5874502\ttotal: 22.5s\tremaining: 1m 39s\n",
      "184:\tlearn: 1732.7706318\ttotal: 22.6s\tremaining: 1m 39s\n",
      "185:\tlearn: 1731.7410220\ttotal: 22.7s\tremaining: 1m 39s\n",
      "186:\tlearn: 1730.7922415\ttotal: 22.8s\tremaining: 1m 39s\n",
      "187:\tlearn: 1730.6036924\ttotal: 23s\tremaining: 1m 39s\n",
      "188:\tlearn: 1729.8987066\ttotal: 23.1s\tremaining: 1m 39s\n",
      "189:\tlearn: 1729.2456848\ttotal: 23.2s\tremaining: 1m 39s\n",
      "190:\tlearn: 1728.3374726\ttotal: 23.3s\tremaining: 1m 38s\n",
      "191:\tlearn: 1728.2360463\ttotal: 23.5s\tremaining: 1m 38s\n",
      "192:\tlearn: 1727.8634438\ttotal: 23.6s\tremaining: 1m 38s\n",
      "193:\tlearn: 1726.8351882\ttotal: 23.7s\tremaining: 1m 38s\n",
      "194:\tlearn: 1726.0069546\ttotal: 23.8s\tremaining: 1m 38s\n",
      "195:\tlearn: 1725.3376214\ttotal: 24s\tremaining: 1m 38s\n",
      "196:\tlearn: 1724.7788220\ttotal: 24.1s\tremaining: 1m 38s\n",
      "197:\tlearn: 1724.1236717\ttotal: 24.2s\tremaining: 1m 38s\n",
      "198:\tlearn: 1723.9548362\ttotal: 24.4s\tremaining: 1m 38s\n",
      "199:\tlearn: 1723.8712370\ttotal: 24.5s\tremaining: 1m 37s\n",
      "200:\tlearn: 1722.9469633\ttotal: 24.6s\tremaining: 1m 37s\n",
      "201:\tlearn: 1722.2016626\ttotal: 24.7s\tremaining: 1m 37s\n",
      "202:\tlearn: 1721.4187018\ttotal: 24.9s\tremaining: 1m 37s\n",
      "203:\tlearn: 1721.3126069\ttotal: 24.9s\tremaining: 1m 37s\n",
      "204:\tlearn: 1721.0820549\ttotal: 25.1s\tremaining: 1m 37s\n",
      "205:\tlearn: 1720.1629738\ttotal: 25.2s\tremaining: 1m 37s\n",
      "206:\tlearn: 1719.5756594\ttotal: 25.3s\tremaining: 1m 37s\n",
      "207:\tlearn: 1719.3362072\ttotal: 25.4s\tremaining: 1m 36s\n",
      "208:\tlearn: 1718.7970360\ttotal: 25.6s\tremaining: 1m 36s\n",
      "209:\tlearn: 1718.2970970\ttotal: 25.7s\tremaining: 1m 36s\n",
      "210:\tlearn: 1717.8214909\ttotal: 25.8s\tremaining: 1m 36s\n",
      "211:\tlearn: 1716.9848090\ttotal: 25.9s\tremaining: 1m 36s\n",
      "212:\tlearn: 1716.4078367\ttotal: 26.1s\tremaining: 1m 36s\n",
      "213:\tlearn: 1715.9796447\ttotal: 26.2s\tremaining: 1m 36s\n",
      "214:\tlearn: 1715.8544159\ttotal: 26.3s\tremaining: 1m 36s\n",
      "215:\tlearn: 1715.0293372\ttotal: 26.4s\tremaining: 1m 35s\n",
      "216:\tlearn: 1714.8275196\ttotal: 26.6s\tremaining: 1m 35s\n",
      "217:\tlearn: 1714.5277657\ttotal: 26.7s\tremaining: 1m 35s\n",
      "218:\tlearn: 1714.0136386\ttotal: 26.8s\tremaining: 1m 35s\n",
      "219:\tlearn: 1713.3184060\ttotal: 26.9s\tremaining: 1m 35s\n",
      "220:\tlearn: 1712.8155456\ttotal: 27s\tremaining: 1m 35s\n",
      "221:\tlearn: 1712.2982123\ttotal: 27.2s\tremaining: 1m 35s\n",
      "222:\tlearn: 1711.9132606\ttotal: 27.3s\tremaining: 1m 35s\n",
      "223:\tlearn: 1711.4743181\ttotal: 27.4s\tremaining: 1m 34s\n",
      "224:\tlearn: 1710.6009338\ttotal: 27.6s\tremaining: 1m 34s\n",
      "225:\tlearn: 1710.1537567\ttotal: 27.7s\tremaining: 1m 34s\n",
      "226:\tlearn: 1709.6966614\ttotal: 27.8s\tremaining: 1m 34s\n",
      "227:\tlearn: 1709.1690294\ttotal: 27.9s\tremaining: 1m 34s\n",
      "228:\tlearn: 1708.5977755\ttotal: 28.1s\tremaining: 1m 34s\n",
      "229:\tlearn: 1707.8145057\ttotal: 28.2s\tremaining: 1m 34s\n",
      "230:\tlearn: 1707.5136459\ttotal: 28.3s\tremaining: 1m 34s\n",
      "231:\tlearn: 1707.0848459\ttotal: 28.4s\tremaining: 1m 34s\n",
      "232:\tlearn: 1706.6087301\ttotal: 28.5s\tremaining: 1m 33s\n",
      "233:\tlearn: 1706.2431621\ttotal: 28.6s\tremaining: 1m 33s\n",
      "234:\tlearn: 1705.7307745\ttotal: 28.8s\tremaining: 1m 33s\n",
      "235:\tlearn: 1705.3290510\ttotal: 28.9s\tremaining: 1m 33s\n",
      "236:\tlearn: 1704.3832838\ttotal: 29s\tremaining: 1m 33s\n",
      "237:\tlearn: 1703.8262135\ttotal: 29.1s\tremaining: 1m 33s\n",
      "238:\tlearn: 1703.3428671\ttotal: 29.3s\tremaining: 1m 33s\n",
      "239:\tlearn: 1702.7453520\ttotal: 29.4s\tremaining: 1m 33s\n",
      "240:\tlearn: 1702.3452839\ttotal: 29.5s\tremaining: 1m 32s\n",
      "241:\tlearn: 1702.0662266\ttotal: 29.7s\tremaining: 1m 32s\n",
      "242:\tlearn: 1701.5923289\ttotal: 29.8s\tremaining: 1m 32s\n",
      "243:\tlearn: 1701.2215318\ttotal: 29.9s\tremaining: 1m 32s\n",
      "244:\tlearn: 1701.0284276\ttotal: 30s\tremaining: 1m 32s\n",
      "245:\tlearn: 1700.4089266\ttotal: 30.2s\tremaining: 1m 32s\n",
      "246:\tlearn: 1699.8399218\ttotal: 30.3s\tremaining: 1m 32s\n",
      "247:\tlearn: 1699.6933995\ttotal: 30.4s\tremaining: 1m 32s\n",
      "248:\tlearn: 1699.4275697\ttotal: 30.5s\tremaining: 1m 32s\n",
      "249:\tlearn: 1698.7271783\ttotal: 30.7s\tremaining: 1m 32s\n",
      "250:\tlearn: 1698.3844045\ttotal: 30.8s\tremaining: 1m 32s\n",
      "251:\tlearn: 1698.1883026\ttotal: 30.9s\tremaining: 1m 31s\n",
      "252:\tlearn: 1697.0875725\ttotal: 31.1s\tremaining: 1m 31s\n",
      "253:\tlearn: 1696.5985039\ttotal: 31.2s\tremaining: 1m 31s\n",
      "254:\tlearn: 1695.9747786\ttotal: 31.3s\tremaining: 1m 31s\n",
      "255:\tlearn: 1695.3586905\ttotal: 31.5s\tremaining: 1m 31s\n",
      "256:\tlearn: 1694.8060630\ttotal: 31.6s\tremaining: 1m 31s\n",
      "257:\tlearn: 1694.6574905\ttotal: 31.7s\tremaining: 1m 31s\n",
      "258:\tlearn: 1694.3248179\ttotal: 31.8s\tremaining: 1m 31s\n",
      "259:\tlearn: 1694.1086157\ttotal: 31.9s\tremaining: 1m 30s\n",
      "260:\tlearn: 1693.6803143\ttotal: 32.1s\tremaining: 1m 30s\n",
      "261:\tlearn: 1693.3784776\ttotal: 32.2s\tremaining: 1m 30s\n",
      "262:\tlearn: 1693.0173539\ttotal: 32.3s\tremaining: 1m 30s\n",
      "263:\tlearn: 1692.5634729\ttotal: 32.4s\tremaining: 1m 30s\n",
      "264:\tlearn: 1692.2337126\ttotal: 32.6s\tremaining: 1m 30s\n",
      "265:\tlearn: 1692.1463092\ttotal: 32.7s\tremaining: 1m 30s\n",
      "266:\tlearn: 1691.8635613\ttotal: 32.8s\tremaining: 1m 30s\n",
      "267:\tlearn: 1691.4501065\ttotal: 32.9s\tremaining: 1m 29s\n",
      "268:\tlearn: 1691.0547315\ttotal: 33s\tremaining: 1m 29s\n",
      "269:\tlearn: 1690.6853765\ttotal: 33.1s\tremaining: 1m 29s\n",
      "270:\tlearn: 1690.2222363\ttotal: 33.2s\tremaining: 1m 29s\n",
      "271:\tlearn: 1689.7014563\ttotal: 33.4s\tremaining: 1m 29s\n",
      "272:\tlearn: 1689.3646287\ttotal: 33.5s\tremaining: 1m 29s\n",
      "273:\tlearn: 1689.2731588\ttotal: 33.6s\tremaining: 1m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274:\tlearn: 1689.0469299\ttotal: 33.7s\tremaining: 1m 28s\n",
      "275:\tlearn: 1688.6210901\ttotal: 33.8s\tremaining: 1m 28s\n",
      "276:\tlearn: 1688.1416390\ttotal: 34s\tremaining: 1m 28s\n",
      "277:\tlearn: 1687.6800861\ttotal: 34.1s\tremaining: 1m 28s\n",
      "278:\tlearn: 1687.1982098\ttotal: 34.2s\tremaining: 1m 28s\n",
      "279:\tlearn: 1686.8091063\ttotal: 34.3s\tremaining: 1m 28s\n",
      "280:\tlearn: 1686.1849843\ttotal: 34.4s\tremaining: 1m 28s\n",
      "281:\tlearn: 1685.9735783\ttotal: 34.6s\tremaining: 1m 27s\n",
      "282:\tlearn: 1685.6156545\ttotal: 34.7s\tremaining: 1m 27s\n",
      "283:\tlearn: 1685.3217820\ttotal: 34.8s\tremaining: 1m 27s\n",
      "284:\tlearn: 1684.8071562\ttotal: 34.9s\tremaining: 1m 27s\n",
      "285:\tlearn: 1684.6912823\ttotal: 35s\tremaining: 1m 27s\n",
      "286:\tlearn: 1684.4542284\ttotal: 35.1s\tremaining: 1m 27s\n",
      "287:\tlearn: 1684.0427449\ttotal: 35.3s\tremaining: 1m 27s\n",
      "288:\tlearn: 1683.4426644\ttotal: 35.4s\tremaining: 1m 26s\n",
      "289:\tlearn: 1682.9557228\ttotal: 35.5s\tremaining: 1m 26s\n",
      "290:\tlearn: 1682.5259616\ttotal: 35.6s\tremaining: 1m 26s\n",
      "291:\tlearn: 1682.1591191\ttotal: 35.7s\tremaining: 1m 26s\n",
      "292:\tlearn: 1681.5482471\ttotal: 35.8s\tremaining: 1m 26s\n",
      "293:\tlearn: 1681.2651260\ttotal: 36s\tremaining: 1m 26s\n",
      "294:\tlearn: 1681.0343210\ttotal: 36.1s\tremaining: 1m 26s\n",
      "295:\tlearn: 1680.8586596\ttotal: 36.2s\tremaining: 1m 26s\n",
      "296:\tlearn: 1680.5199622\ttotal: 36.3s\tremaining: 1m 25s\n",
      "297:\tlearn: 1680.1411511\ttotal: 36.5s\tremaining: 1m 25s\n",
      "298:\tlearn: 1679.7885330\ttotal: 36.6s\tremaining: 1m 25s\n",
      "299:\tlearn: 1679.5016730\ttotal: 36.7s\tremaining: 1m 25s\n",
      "300:\tlearn: 1678.9126324\ttotal: 36.8s\tremaining: 1m 25s\n",
      "301:\tlearn: 1678.6165343\ttotal: 36.9s\tremaining: 1m 25s\n",
      "302:\tlearn: 1678.0296757\ttotal: 37s\tremaining: 1m 25s\n",
      "303:\tlearn: 1677.7465924\ttotal: 37.1s\tremaining: 1m 24s\n",
      "304:\tlearn: 1677.2695454\ttotal: 37.2s\tremaining: 1m 24s\n",
      "305:\tlearn: 1677.0631067\ttotal: 37.3s\tremaining: 1m 24s\n",
      "306:\tlearn: 1676.6512660\ttotal: 37.4s\tremaining: 1m 24s\n",
      "307:\tlearn: 1676.0959844\ttotal: 37.5s\tremaining: 1m 24s\n",
      "308:\tlearn: 1675.7386003\ttotal: 37.7s\tremaining: 1m 24s\n",
      "309:\tlearn: 1675.4218753\ttotal: 37.8s\tremaining: 1m 24s\n",
      "310:\tlearn: 1675.0940810\ttotal: 37.9s\tremaining: 1m 24s\n",
      "311:\tlearn: 1674.8401910\ttotal: 38.1s\tremaining: 1m 23s\n",
      "312:\tlearn: 1674.6006367\ttotal: 38.2s\tremaining: 1m 23s\n",
      "313:\tlearn: 1674.1333747\ttotal: 38.3s\tremaining: 1m 23s\n",
      "314:\tlearn: 1673.8211813\ttotal: 38.5s\tremaining: 1m 23s\n",
      "315:\tlearn: 1673.5031889\ttotal: 38.6s\tremaining: 1m 23s\n",
      "316:\tlearn: 1673.2247543\ttotal: 38.8s\tremaining: 1m 23s\n",
      "317:\tlearn: 1672.8325547\ttotal: 38.9s\tremaining: 1m 23s\n",
      "318:\tlearn: 1672.4888292\ttotal: 39.1s\tremaining: 1m 23s\n",
      "319:\tlearn: 1671.8998410\ttotal: 39.2s\tremaining: 1m 23s\n",
      "320:\tlearn: 1671.5950199\ttotal: 39.3s\tremaining: 1m 23s\n",
      "321:\tlearn: 1671.1578366\ttotal: 39.4s\tremaining: 1m 22s\n",
      "322:\tlearn: 1670.9506714\ttotal: 39.5s\tremaining: 1m 22s\n",
      "323:\tlearn: 1670.6258983\ttotal: 39.6s\tremaining: 1m 22s\n",
      "324:\tlearn: 1670.3612224\ttotal: 39.7s\tremaining: 1m 22s\n",
      "325:\tlearn: 1670.2758573\ttotal: 39.8s\tremaining: 1m 22s\n",
      "326:\tlearn: 1669.8519318\ttotal: 39.9s\tremaining: 1m 22s\n",
      "327:\tlearn: 1669.6174949\ttotal: 40.1s\tremaining: 1m 22s\n",
      "328:\tlearn: 1669.1813880\ttotal: 40.2s\tremaining: 1m 21s\n",
      "329:\tlearn: 1668.9559218\ttotal: 40.3s\tremaining: 1m 21s\n",
      "330:\tlearn: 1668.8590945\ttotal: 40.5s\tremaining: 1m 21s\n",
      "331:\tlearn: 1668.4947618\ttotal: 40.6s\tremaining: 1m 21s\n",
      "332:\tlearn: 1668.2078904\ttotal: 40.7s\tremaining: 1m 21s\n",
      "333:\tlearn: 1667.9458928\ttotal: 40.8s\tremaining: 1m 21s\n",
      "334:\tlearn: 1667.8852297\ttotal: 40.9s\tremaining: 1m 21s\n",
      "335:\tlearn: 1667.6084860\ttotal: 41s\tremaining: 1m 21s\n",
      "336:\tlearn: 1667.5253012\ttotal: 41.2s\tremaining: 1m 21s\n",
      "337:\tlearn: 1667.3771838\ttotal: 41.3s\tremaining: 1m 20s\n",
      "338:\tlearn: 1667.1415255\ttotal: 41.4s\tremaining: 1m 20s\n",
      "339:\tlearn: 1666.9968551\ttotal: 41.5s\tremaining: 1m 20s\n",
      "340:\tlearn: 1666.7263549\ttotal: 41.7s\tremaining: 1m 20s\n",
      "341:\tlearn: 1666.3793812\ttotal: 41.8s\tremaining: 1m 20s\n",
      "342:\tlearn: 1666.1013856\ttotal: 41.9s\tremaining: 1m 20s\n",
      "343:\tlearn: 1665.7137531\ttotal: 42s\tremaining: 1m 20s\n",
      "344:\tlearn: 1665.6855227\ttotal: 42.1s\tremaining: 1m 20s\n",
      "345:\tlearn: 1665.4088676\ttotal: 42.2s\tremaining: 1m 19s\n",
      "346:\tlearn: 1665.0310528\ttotal: 42.4s\tremaining: 1m 19s\n",
      "347:\tlearn: 1664.8047671\ttotal: 42.4s\tremaining: 1m 19s\n",
      "348:\tlearn: 1664.4437253\ttotal: 42.6s\tremaining: 1m 19s\n",
      "349:\tlearn: 1663.9997139\ttotal: 42.7s\tremaining: 1m 19s\n",
      "350:\tlearn: 1663.6109757\ttotal: 42.8s\tremaining: 1m 19s\n",
      "351:\tlearn: 1663.3427185\ttotal: 42.9s\tremaining: 1m 18s\n",
      "352:\tlearn: 1662.9496311\ttotal: 43s\tremaining: 1m 18s\n",
      "353:\tlearn: 1662.7219437\ttotal: 43.1s\tremaining: 1m 18s\n",
      "354:\tlearn: 1662.3486297\ttotal: 43.3s\tremaining: 1m 18s\n",
      "355:\tlearn: 1661.4333560\ttotal: 43.4s\tremaining: 1m 18s\n",
      "356:\tlearn: 1661.1551972\ttotal: 43.6s\tremaining: 1m 18s\n",
      "357:\tlearn: 1660.8870724\ttotal: 43.7s\tremaining: 1m 18s\n",
      "358:\tlearn: 1660.4635514\ttotal: 43.8s\tremaining: 1m 18s\n",
      "359:\tlearn: 1660.3263419\ttotal: 43.9s\tremaining: 1m 18s\n",
      "360:\tlearn: 1659.8823695\ttotal: 44s\tremaining: 1m 17s\n",
      "361:\tlearn: 1659.6793355\ttotal: 44.2s\tremaining: 1m 17s\n",
      "362:\tlearn: 1659.3604042\ttotal: 44.3s\tremaining: 1m 17s\n",
      "363:\tlearn: 1659.1924795\ttotal: 44.4s\tremaining: 1m 17s\n",
      "364:\tlearn: 1659.0807635\ttotal: 44.5s\tremaining: 1m 17s\n",
      "365:\tlearn: 1658.8082790\ttotal: 44.6s\tremaining: 1m 17s\n",
      "366:\tlearn: 1658.4741244\ttotal: 44.8s\tremaining: 1m 17s\n",
      "367:\tlearn: 1658.2529934\ttotal: 44.9s\tremaining: 1m 17s\n",
      "368:\tlearn: 1657.9371595\ttotal: 45s\tremaining: 1m 16s\n",
      "369:\tlearn: 1657.4748310\ttotal: 45.1s\tremaining: 1m 16s\n",
      "370:\tlearn: 1657.3566860\ttotal: 45.2s\tremaining: 1m 16s\n",
      "371:\tlearn: 1657.1590475\ttotal: 45.4s\tremaining: 1m 16s\n",
      "372:\tlearn: 1656.7971999\ttotal: 45.5s\tremaining: 1m 16s\n",
      "373:\tlearn: 1656.1930781\ttotal: 45.6s\tremaining: 1m 16s\n",
      "374:\tlearn: 1656.0396116\ttotal: 45.7s\tremaining: 1m 16s\n",
      "375:\tlearn: 1655.6003700\ttotal: 45.9s\tremaining: 1m 16s\n",
      "376:\tlearn: 1655.1425156\ttotal: 46s\tremaining: 1m 16s\n",
      "377:\tlearn: 1654.8373466\ttotal: 46.1s\tremaining: 1m 15s\n",
      "378:\tlearn: 1654.5790603\ttotal: 46.2s\tremaining: 1m 15s\n",
      "379:\tlearn: 1654.2147252\ttotal: 46.4s\tremaining: 1m 15s\n",
      "380:\tlearn: 1653.9899429\ttotal: 46.5s\tremaining: 1m 15s\n",
      "381:\tlearn: 1653.8978836\ttotal: 46.6s\tremaining: 1m 15s\n",
      "382:\tlearn: 1653.4603594\ttotal: 46.7s\tremaining: 1m 15s\n",
      "383:\tlearn: 1653.1572731\ttotal: 46.9s\tremaining: 1m 15s\n",
      "384:\tlearn: 1652.8490183\ttotal: 47s\tremaining: 1m 15s\n",
      "385:\tlearn: 1652.5674955\ttotal: 47.1s\tremaining: 1m 14s\n",
      "386:\tlearn: 1652.4210996\ttotal: 47.1s\tremaining: 1m 14s\n",
      "387:\tlearn: 1652.0821836\ttotal: 47.2s\tremaining: 1m 14s\n",
      "388:\tlearn: 1651.9304547\ttotal: 47.3s\tremaining: 1m 14s\n",
      "389:\tlearn: 1651.8121838\ttotal: 47.5s\tremaining: 1m 14s\n",
      "390:\tlearn: 1651.6444600\ttotal: 47.6s\tremaining: 1m 14s\n",
      "391:\tlearn: 1651.3880508\ttotal: 47.7s\tremaining: 1m 13s\n",
      "392:\tlearn: 1651.0753606\ttotal: 47.8s\tremaining: 1m 13s\n",
      "393:\tlearn: 1650.9367484\ttotal: 47.9s\tremaining: 1m 13s\n",
      "394:\tlearn: 1650.8176721\ttotal: 48.1s\tremaining: 1m 13s\n",
      "395:\tlearn: 1650.5690191\ttotal: 48.2s\tremaining: 1m 13s\n",
      "396:\tlearn: 1650.2567773\ttotal: 48.3s\tremaining: 1m 13s\n",
      "397:\tlearn: 1650.1192327\ttotal: 48.4s\tremaining: 1m 13s\n",
      "398:\tlearn: 1649.7511157\ttotal: 48.6s\tremaining: 1m 13s\n",
      "399:\tlearn: 1649.5319683\ttotal: 48.7s\tremaining: 1m 13s\n",
      "400:\tlearn: 1649.2706516\ttotal: 48.9s\tremaining: 1m 12s\n",
      "401:\tlearn: 1648.9773897\ttotal: 49s\tremaining: 1m 12s\n",
      "402:\tlearn: 1648.8258964\ttotal: 49.1s\tremaining: 1m 12s\n",
      "403:\tlearn: 1648.5430356\ttotal: 49.2s\tremaining: 1m 12s\n",
      "404:\tlearn: 1648.3776525\ttotal: 49.3s\tremaining: 1m 12s\n",
      "405:\tlearn: 1648.0824328\ttotal: 49.4s\tremaining: 1m 12s\n",
      "406:\tlearn: 1647.8819124\ttotal: 49.5s\tremaining: 1m 12s\n",
      "407:\tlearn: 1647.6308158\ttotal: 49.7s\tremaining: 1m 12s\n",
      "408:\tlearn: 1647.3004907\ttotal: 49.8s\tremaining: 1m 11s\n",
      "409:\tlearn: 1647.0413600\ttotal: 49.9s\tremaining: 1m 11s\n",
      "410:\tlearn: 1646.8469517\ttotal: 50s\tremaining: 1m 11s\n",
      "411:\tlearn: 1646.4730803\ttotal: 50.1s\tremaining: 1m 11s\n",
      "412:\tlearn: 1646.2544041\ttotal: 50.3s\tremaining: 1m 11s\n",
      "413:\tlearn: 1646.0148603\ttotal: 50.4s\tremaining: 1m 11s\n",
      "414:\tlearn: 1645.8162002\ttotal: 50.5s\tremaining: 1m 11s\n",
      "415:\tlearn: 1645.4899009\ttotal: 50.6s\tremaining: 1m 11s\n",
      "416:\tlearn: 1645.4326262\ttotal: 50.8s\tremaining: 1m 10s\n",
      "417:\tlearn: 1645.1754092\ttotal: 50.9s\tremaining: 1m 10s\n",
      "418:\tlearn: 1644.9199695\ttotal: 51s\tremaining: 1m 10s\n",
      "419:\tlearn: 1644.8087255\ttotal: 51.2s\tremaining: 1m 10s\n",
      "420:\tlearn: 1644.5474541\ttotal: 51.3s\tremaining: 1m 10s\n",
      "421:\tlearn: 1644.3785132\ttotal: 51.5s\tremaining: 1m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422:\tlearn: 1644.2508177\ttotal: 51.6s\tremaining: 1m 10s\n",
      "423:\tlearn: 1644.0810618\ttotal: 51.7s\tremaining: 1m 10s\n",
      "424:\tlearn: 1643.8959780\ttotal: 51.9s\tremaining: 1m 10s\n",
      "425:\tlearn: 1643.8065097\ttotal: 52s\tremaining: 1m 10s\n",
      "426:\tlearn: 1643.6345235\ttotal: 52.1s\tremaining: 1m 9s\n",
      "427:\tlearn: 1643.4459169\ttotal: 52.2s\tremaining: 1m 9s\n",
      "428:\tlearn: 1643.2679663\ttotal: 52.3s\tremaining: 1m 9s\n",
      "429:\tlearn: 1642.9582425\ttotal: 52.5s\tremaining: 1m 9s\n",
      "430:\tlearn: 1642.6072435\ttotal: 52.6s\tremaining: 1m 9s\n",
      "431:\tlearn: 1642.4140916\ttotal: 52.7s\tremaining: 1m 9s\n",
      "432:\tlearn: 1642.1671035\ttotal: 52.9s\tremaining: 1m 9s\n",
      "433:\tlearn: 1642.0014157\ttotal: 53s\tremaining: 1m 9s\n",
      "434:\tlearn: 1641.8933759\ttotal: 53.2s\tremaining: 1m 9s\n",
      "435:\tlearn: 1641.7754169\ttotal: 53.3s\tremaining: 1m 8s\n",
      "436:\tlearn: 1641.5321407\ttotal: 53.5s\tremaining: 1m 8s\n",
      "437:\tlearn: 1641.4182462\ttotal: 53.6s\tremaining: 1m 8s\n",
      "438:\tlearn: 1641.0597923\ttotal: 53.7s\tremaining: 1m 8s\n",
      "439:\tlearn: 1640.7140577\ttotal: 53.9s\tremaining: 1m 8s\n",
      "440:\tlearn: 1640.6872741\ttotal: 54s\tremaining: 1m 8s\n",
      "441:\tlearn: 1640.4859251\ttotal: 54.1s\tremaining: 1m 8s\n",
      "442:\tlearn: 1640.2839001\ttotal: 54.3s\tremaining: 1m 8s\n",
      "443:\tlearn: 1640.0390227\ttotal: 54.4s\tremaining: 1m 8s\n",
      "444:\tlearn: 1639.9314212\ttotal: 54.5s\tremaining: 1m 7s\n",
      "445:\tlearn: 1639.6726839\ttotal: 54.6s\tremaining: 1m 7s\n",
      "446:\tlearn: 1639.6049997\ttotal: 54.8s\tremaining: 1m 7s\n",
      "447:\tlearn: 1639.1527515\ttotal: 54.9s\tremaining: 1m 7s\n",
      "448:\tlearn: 1638.9300515\ttotal: 55s\tremaining: 1m 7s\n",
      "449:\tlearn: 1638.8188475\ttotal: 55.2s\tremaining: 1m 7s\n",
      "450:\tlearn: 1638.5915059\ttotal: 55.3s\tremaining: 1m 7s\n",
      "451:\tlearn: 1638.2903520\ttotal: 55.5s\tremaining: 1m 7s\n",
      "452:\tlearn: 1638.1782298\ttotal: 55.6s\tremaining: 1m 7s\n",
      "453:\tlearn: 1638.0134075\ttotal: 55.8s\tremaining: 1m 7s\n",
      "454:\tlearn: 1637.7806682\ttotal: 55.9s\tremaining: 1m 6s\n",
      "455:\tlearn: 1637.4129671\ttotal: 56s\tremaining: 1m 6s\n",
      "456:\tlearn: 1637.2390301\ttotal: 56.1s\tremaining: 1m 6s\n",
      "457:\tlearn: 1637.0033650\ttotal: 56.3s\tremaining: 1m 6s\n",
      "458:\tlearn: 1636.5808587\ttotal: 56.4s\tremaining: 1m 6s\n",
      "459:\tlearn: 1636.3702464\ttotal: 56.5s\tremaining: 1m 6s\n",
      "460:\tlearn: 1636.0662151\ttotal: 56.6s\tremaining: 1m 6s\n",
      "461:\tlearn: 1636.0469993\ttotal: 56.7s\tremaining: 1m 5s\n",
      "462:\tlearn: 1635.8583463\ttotal: 56.8s\tremaining: 1m 5s\n",
      "463:\tlearn: 1635.7035666\ttotal: 56.9s\tremaining: 1m 5s\n",
      "464:\tlearn: 1634.9188082\ttotal: 57s\tremaining: 1m 5s\n",
      "465:\tlearn: 1634.7939990\ttotal: 57.2s\tremaining: 1m 5s\n",
      "466:\tlearn: 1634.6317436\ttotal: 57.3s\tremaining: 1m 5s\n",
      "467:\tlearn: 1634.4065034\ttotal: 57.5s\tremaining: 1m 5s\n",
      "468:\tlearn: 1634.1309593\ttotal: 57.6s\tremaining: 1m 5s\n",
      "469:\tlearn: 1633.6701984\ttotal: 57.7s\tremaining: 1m 5s\n",
      "470:\tlearn: 1633.4956113\ttotal: 57.8s\tremaining: 1m 4s\n",
      "471:\tlearn: 1633.3573417\ttotal: 57.9s\tremaining: 1m 4s\n",
      "472:\tlearn: 1633.2510235\ttotal: 58s\tremaining: 1m 4s\n",
      "473:\tlearn: 1632.7192107\ttotal: 58.1s\tremaining: 1m 4s\n",
      "474:\tlearn: 1632.5173878\ttotal: 58.3s\tremaining: 1m 4s\n",
      "475:\tlearn: 1632.4185718\ttotal: 58.4s\tremaining: 1m 4s\n",
      "476:\tlearn: 1632.3442470\ttotal: 58.5s\tremaining: 1m 4s\n",
      "477:\tlearn: 1632.2140639\ttotal: 58.6s\tremaining: 1m 4s\n",
      "478:\tlearn: 1632.0638279\ttotal: 58.8s\tremaining: 1m 3s\n",
      "479:\tlearn: 1631.9356158\ttotal: 58.9s\tremaining: 1m 3s\n",
      "480:\tlearn: 1631.6876064\ttotal: 59s\tremaining: 1m 3s\n",
      "481:\tlearn: 1631.5679471\ttotal: 59.1s\tremaining: 1m 3s\n",
      "482:\tlearn: 1631.3715484\ttotal: 59.2s\tremaining: 1m 3s\n",
      "483:\tlearn: 1631.1198532\ttotal: 59.3s\tremaining: 1m 3s\n",
      "484:\tlearn: 1631.0286802\ttotal: 59.4s\tremaining: 1m 3s\n",
      "485:\tlearn: 1630.8151691\ttotal: 59.5s\tremaining: 1m 2s\n",
      "486:\tlearn: 1630.5792748\ttotal: 59.7s\tremaining: 1m 2s\n",
      "487:\tlearn: 1630.2962632\ttotal: 59.8s\tremaining: 1m 2s\n",
      "488:\tlearn: 1630.0822203\ttotal: 59.9s\tremaining: 1m 2s\n",
      "489:\tlearn: 1629.7910577\ttotal: 1m\tremaining: 1m 2s\n",
      "490:\tlearn: 1629.5834323\ttotal: 1m\tremaining: 1m 2s\n",
      "491:\tlearn: 1629.4311413\ttotal: 1m\tremaining: 1m 2s\n",
      "492:\tlearn: 1629.2577219\ttotal: 1m\tremaining: 1m 2s\n",
      "493:\tlearn: 1628.9394993\ttotal: 1m\tremaining: 1m 2s\n",
      "494:\tlearn: 1628.7246093\ttotal: 1m\tremaining: 1m 1s\n",
      "495:\tlearn: 1628.5403755\ttotal: 1m\tremaining: 1m 1s\n",
      "496:\tlearn: 1628.2504731\ttotal: 1m\tremaining: 1m 1s\n",
      "497:\tlearn: 1628.0897920\ttotal: 1m\tremaining: 1m 1s\n",
      "498:\tlearn: 1627.8728453\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "499:\tlearn: 1627.6575151\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "500:\tlearn: 1627.5325599\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "501:\tlearn: 1627.4068456\ttotal: 1m 1s\tremaining: 1m\n",
      "502:\tlearn: 1627.1019281\ttotal: 1m 1s\tremaining: 1m\n",
      "503:\tlearn: 1626.8802355\ttotal: 1m 1s\tremaining: 1m\n",
      "504:\tlearn: 1626.5775520\ttotal: 1m 1s\tremaining: 1m\n",
      "505:\tlearn: 1626.2716260\ttotal: 1m 1s\tremaining: 1m\n",
      "506:\tlearn: 1626.1501051\ttotal: 1m 2s\tremaining: 1m\n",
      "507:\tlearn: 1625.9836772\ttotal: 1m 2s\tremaining: 1m\n",
      "508:\tlearn: 1625.7464592\ttotal: 1m 2s\tremaining: 1m\n",
      "509:\tlearn: 1625.5331286\ttotal: 1m 2s\tremaining: 59.9s\n",
      "510:\tlearn: 1625.4057308\ttotal: 1m 2s\tremaining: 59.8s\n",
      "511:\tlearn: 1625.3594998\ttotal: 1m 2s\tremaining: 59.7s\n",
      "512:\tlearn: 1624.8404663\ttotal: 1m 2s\tremaining: 59.6s\n",
      "513:\tlearn: 1624.6533559\ttotal: 1m 2s\tremaining: 59.5s\n",
      "514:\tlearn: 1624.5645976\ttotal: 1m 3s\tremaining: 59.4s\n",
      "515:\tlearn: 1624.4054923\ttotal: 1m 3s\tremaining: 59.2s\n",
      "516:\tlearn: 1624.1305151\ttotal: 1m 3s\tremaining: 59.1s\n",
      "517:\tlearn: 1623.8475167\ttotal: 1m 3s\tremaining: 59s\n",
      "518:\tlearn: 1623.5727599\ttotal: 1m 3s\tremaining: 58.9s\n",
      "519:\tlearn: 1623.4017906\ttotal: 1m 3s\tremaining: 58.8s\n",
      "520:\tlearn: 1623.1757812\ttotal: 1m 3s\tremaining: 58.6s\n",
      "521:\tlearn: 1622.8942382\ttotal: 1m 3s\tremaining: 58.5s\n",
      "522:\tlearn: 1622.7030959\ttotal: 1m 4s\tremaining: 58.4s\n",
      "523:\tlearn: 1622.6214710\ttotal: 1m 4s\tremaining: 58.3s\n",
      "524:\tlearn: 1622.4390171\ttotal: 1m 4s\tremaining: 58.1s\n",
      "525:\tlearn: 1622.2996502\ttotal: 1m 4s\tremaining: 58s\n",
      "526:\tlearn: 1622.0473891\ttotal: 1m 4s\tremaining: 57.9s\n",
      "527:\tlearn: 1621.8588437\ttotal: 1m 4s\tremaining: 57.8s\n",
      "528:\tlearn: 1621.6356426\ttotal: 1m 4s\tremaining: 57.7s\n",
      "529:\tlearn: 1621.3127825\ttotal: 1m 4s\tremaining: 57.5s\n",
      "530:\tlearn: 1621.2578695\ttotal: 1m 5s\tremaining: 57.4s\n",
      "531:\tlearn: 1621.2011753\ttotal: 1m 5s\tremaining: 57.3s\n",
      "532:\tlearn: 1620.9748399\ttotal: 1m 5s\tremaining: 57.1s\n",
      "533:\tlearn: 1620.8737571\ttotal: 1m 5s\tremaining: 57s\n",
      "534:\tlearn: 1620.6721319\ttotal: 1m 5s\tremaining: 56.9s\n",
      "535:\tlearn: 1620.4382146\ttotal: 1m 5s\tremaining: 56.8s\n",
      "536:\tlearn: 1620.3041122\ttotal: 1m 5s\tremaining: 56.7s\n",
      "537:\tlearn: 1620.0419680\ttotal: 1m 5s\tremaining: 56.5s\n",
      "538:\tlearn: 1619.8391234\ttotal: 1m 5s\tremaining: 56.4s\n",
      "539:\tlearn: 1619.5676779\ttotal: 1m 6s\tremaining: 56.3s\n",
      "540:\tlearn: 1619.4646570\ttotal: 1m 6s\tremaining: 56.1s\n",
      "541:\tlearn: 1619.3455480\ttotal: 1m 6s\tremaining: 56s\n",
      "542:\tlearn: 1619.0967005\ttotal: 1m 6s\tremaining: 55.9s\n",
      "543:\tlearn: 1619.0392488\ttotal: 1m 6s\tremaining: 55.8s\n",
      "544:\tlearn: 1618.9707778\ttotal: 1m 6s\tremaining: 55.7s\n",
      "545:\tlearn: 1618.8300542\ttotal: 1m 6s\tremaining: 55.5s\n",
      "546:\tlearn: 1618.7507733\ttotal: 1m 6s\tremaining: 55.4s\n",
      "547:\tlearn: 1618.5963102\ttotal: 1m 7s\tremaining: 55.3s\n",
      "548:\tlearn: 1618.4222361\ttotal: 1m 7s\tremaining: 55.2s\n",
      "549:\tlearn: 1618.1128935\ttotal: 1m 7s\tremaining: 55s\n",
      "550:\tlearn: 1617.9284351\ttotal: 1m 7s\tremaining: 54.9s\n",
      "551:\tlearn: 1617.8215524\ttotal: 1m 7s\tremaining: 54.8s\n",
      "552:\tlearn: 1617.7299141\ttotal: 1m 7s\tremaining: 54.7s\n",
      "553:\tlearn: 1617.4827209\ttotal: 1m 7s\tremaining: 54.5s\n",
      "554:\tlearn: 1617.3148473\ttotal: 1m 7s\tremaining: 54.4s\n",
      "555:\tlearn: 1617.1883202\ttotal: 1m 7s\tremaining: 54.3s\n",
      "556:\tlearn: 1616.9574635\ttotal: 1m 8s\tremaining: 54.2s\n",
      "557:\tlearn: 1616.7934090\ttotal: 1m 8s\tremaining: 54s\n",
      "558:\tlearn: 1616.7080172\ttotal: 1m 8s\tremaining: 53.9s\n",
      "559:\tlearn: 1616.5598977\ttotal: 1m 8s\tremaining: 53.8s\n",
      "560:\tlearn: 1616.4051007\ttotal: 1m 8s\tremaining: 53.7s\n",
      "561:\tlearn: 1616.3336074\ttotal: 1m 8s\tremaining: 53.5s\n",
      "562:\tlearn: 1616.1992709\ttotal: 1m 8s\tremaining: 53.4s\n",
      "563:\tlearn: 1615.9887227\ttotal: 1m 8s\tremaining: 53.3s\n",
      "564:\tlearn: 1615.7444100\ttotal: 1m 9s\tremaining: 53.1s\n",
      "565:\tlearn: 1615.4776649\ttotal: 1m 9s\tremaining: 53s\n",
      "566:\tlearn: 1615.3190602\ttotal: 1m 9s\tremaining: 52.9s\n",
      "567:\tlearn: 1615.2128863\ttotal: 1m 9s\tremaining: 52.7s\n",
      "568:\tlearn: 1615.1029024\ttotal: 1m 9s\tremaining: 52.6s\n",
      "569:\tlearn: 1614.9093576\ttotal: 1m 9s\tremaining: 52.5s\n",
      "570:\tlearn: 1614.8989077\ttotal: 1m 9s\tremaining: 52.4s\n",
      "571:\tlearn: 1614.7475800\ttotal: 1m 9s\tremaining: 52.2s\n",
      "572:\tlearn: 1614.6163628\ttotal: 1m 9s\tremaining: 52.1s\n",
      "573:\tlearn: 1614.4649131\ttotal: 1m 10s\tremaining: 52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574:\tlearn: 1614.3904038\ttotal: 1m 10s\tremaining: 51.9s\n",
      "575:\tlearn: 1614.2958468\ttotal: 1m 10s\tremaining: 51.7s\n",
      "576:\tlearn: 1614.1254115\ttotal: 1m 10s\tremaining: 51.6s\n",
      "577:\tlearn: 1613.9204328\ttotal: 1m 10s\tremaining: 51.5s\n",
      "578:\tlearn: 1613.7731454\ttotal: 1m 10s\tremaining: 51.4s\n",
      "579:\tlearn: 1613.6977245\ttotal: 1m 10s\tremaining: 51.3s\n",
      "580:\tlearn: 1613.5659904\ttotal: 1m 10s\tremaining: 51.1s\n",
      "581:\tlearn: 1613.4232592\ttotal: 1m 11s\tremaining: 51s\n",
      "582:\tlearn: 1613.1304453\ttotal: 1m 11s\tremaining: 50.9s\n",
      "583:\tlearn: 1612.9921859\ttotal: 1m 11s\tremaining: 50.7s\n",
      "584:\tlearn: 1612.8964231\ttotal: 1m 11s\tremaining: 50.6s\n",
      "585:\tlearn: 1612.7826122\ttotal: 1m 11s\tremaining: 50.5s\n",
      "586:\tlearn: 1612.5793279\ttotal: 1m 11s\tremaining: 50.3s\n",
      "587:\tlearn: 1612.4611860\ttotal: 1m 11s\tremaining: 50.2s\n",
      "588:\tlearn: 1612.3447182\ttotal: 1m 11s\tremaining: 50.1s\n",
      "589:\tlearn: 1612.1715953\ttotal: 1m 11s\tremaining: 49.9s\n",
      "590:\tlearn: 1612.0129075\ttotal: 1m 11s\tremaining: 49.8s\n",
      "591:\tlearn: 1611.8630454\ttotal: 1m 12s\tremaining: 49.7s\n",
      "592:\tlearn: 1611.7617571\ttotal: 1m 12s\tremaining: 49.5s\n",
      "593:\tlearn: 1611.6733517\ttotal: 1m 12s\tremaining: 49.4s\n",
      "594:\tlearn: 1611.4985110\ttotal: 1m 12s\tremaining: 49.3s\n",
      "595:\tlearn: 1611.4559592\ttotal: 1m 12s\tremaining: 49.1s\n",
      "596:\tlearn: 1611.3295200\ttotal: 1m 12s\tremaining: 49s\n",
      "597:\tlearn: 1611.2725247\ttotal: 1m 12s\tremaining: 48.9s\n",
      "598:\tlearn: 1611.1781819\ttotal: 1m 12s\tremaining: 48.8s\n",
      "599:\tlearn: 1610.9855914\ttotal: 1m 12s\tremaining: 48.6s\n",
      "600:\tlearn: 1610.8166657\ttotal: 1m 13s\tremaining: 48.5s\n",
      "601:\tlearn: 1610.6163567\ttotal: 1m 13s\tremaining: 48.4s\n",
      "602:\tlearn: 1610.5700763\ttotal: 1m 13s\tremaining: 48.3s\n",
      "603:\tlearn: 1610.3665099\ttotal: 1m 13s\tremaining: 48.1s\n",
      "604:\tlearn: 1610.1304225\ttotal: 1m 13s\tremaining: 48s\n",
      "605:\tlearn: 1609.9565409\ttotal: 1m 13s\tremaining: 47.9s\n",
      "606:\tlearn: 1609.7563572\ttotal: 1m 13s\tremaining: 47.8s\n",
      "607:\tlearn: 1609.4922738\ttotal: 1m 13s\tremaining: 47.6s\n",
      "608:\tlearn: 1609.4808362\ttotal: 1m 14s\tremaining: 47.5s\n",
      "609:\tlearn: 1609.3010188\ttotal: 1m 14s\tremaining: 47.4s\n",
      "610:\tlearn: 1609.1396033\ttotal: 1m 14s\tremaining: 47.3s\n",
      "611:\tlearn: 1609.0180725\ttotal: 1m 14s\tremaining: 47.1s\n",
      "612:\tlearn: 1608.9294766\ttotal: 1m 14s\tremaining: 47s\n",
      "613:\tlearn: 1608.7189121\ttotal: 1m 14s\tremaining: 46.9s\n",
      "614:\tlearn: 1608.6363620\ttotal: 1m 14s\tremaining: 46.7s\n",
      "615:\tlearn: 1608.5154658\ttotal: 1m 14s\tremaining: 46.6s\n",
      "616:\tlearn: 1608.3339464\ttotal: 1m 14s\tremaining: 46.5s\n",
      "617:\tlearn: 1608.2966513\ttotal: 1m 15s\tremaining: 46.4s\n",
      "618:\tlearn: 1608.1164555\ttotal: 1m 15s\tremaining: 46.2s\n",
      "619:\tlearn: 1608.0587245\ttotal: 1m 15s\tremaining: 46.1s\n",
      "620:\tlearn: 1607.8943914\ttotal: 1m 15s\tremaining: 46s\n",
      "621:\tlearn: 1607.6227048\ttotal: 1m 15s\tremaining: 45.9s\n",
      "622:\tlearn: 1607.3959795\ttotal: 1m 15s\tremaining: 45.8s\n",
      "623:\tlearn: 1607.2671076\ttotal: 1m 15s\tremaining: 45.6s\n",
      "624:\tlearn: 1607.1798089\ttotal: 1m 15s\tremaining: 45.5s\n",
      "625:\tlearn: 1607.0751235\ttotal: 1m 15s\tremaining: 45.4s\n",
      "626:\tlearn: 1606.9449606\ttotal: 1m 16s\tremaining: 45.2s\n",
      "627:\tlearn: 1606.8704010\ttotal: 1m 16s\tremaining: 45.1s\n",
      "628:\tlearn: 1606.7203730\ttotal: 1m 16s\tremaining: 45s\n",
      "629:\tlearn: 1606.6212143\ttotal: 1m 16s\tremaining: 44.9s\n",
      "630:\tlearn: 1606.4674640\ttotal: 1m 16s\tremaining: 44.8s\n",
      "631:\tlearn: 1606.3678297\ttotal: 1m 16s\tremaining: 44.7s\n",
      "632:\tlearn: 1606.1774432\ttotal: 1m 16s\tremaining: 44.5s\n",
      "633:\tlearn: 1606.0943405\ttotal: 1m 16s\tremaining: 44.4s\n",
      "634:\tlearn: 1606.0166915\ttotal: 1m 17s\tremaining: 44.3s\n",
      "635:\tlearn: 1605.7735164\ttotal: 1m 17s\tremaining: 44.2s\n",
      "636:\tlearn: 1605.5276908\ttotal: 1m 17s\tremaining: 44.1s\n",
      "637:\tlearn: 1605.3990500\ttotal: 1m 17s\tremaining: 43.9s\n",
      "638:\tlearn: 1605.2833986\ttotal: 1m 17s\tremaining: 43.8s\n",
      "639:\tlearn: 1605.1727642\ttotal: 1m 17s\tremaining: 43.7s\n",
      "640:\tlearn: 1604.7775730\ttotal: 1m 17s\tremaining: 43.6s\n",
      "641:\tlearn: 1604.6101090\ttotal: 1m 17s\tremaining: 43.4s\n",
      "642:\tlearn: 1604.5265993\ttotal: 1m 17s\tremaining: 43.3s\n",
      "643:\tlearn: 1604.4698770\ttotal: 1m 18s\tremaining: 43.2s\n",
      "644:\tlearn: 1604.3147659\ttotal: 1m 18s\tremaining: 43.1s\n",
      "645:\tlearn: 1604.1672280\ttotal: 1m 18s\tremaining: 42.9s\n",
      "646:\tlearn: 1604.0580490\ttotal: 1m 18s\tremaining: 42.8s\n",
      "647:\tlearn: 1603.9629512\ttotal: 1m 18s\tremaining: 42.7s\n",
      "648:\tlearn: 1603.9453107\ttotal: 1m 18s\tremaining: 42.6s\n",
      "649:\tlearn: 1603.6104239\ttotal: 1m 18s\tremaining: 42.4s\n",
      "650:\tlearn: 1603.4498270\ttotal: 1m 18s\tremaining: 42.3s\n",
      "651:\tlearn: 1603.2481614\ttotal: 1m 19s\tremaining: 42.2s\n",
      "652:\tlearn: 1603.2208868\ttotal: 1m 19s\tremaining: 42.1s\n",
      "653:\tlearn: 1603.1208768\ttotal: 1m 19s\tremaining: 41.9s\n",
      "654:\tlearn: 1602.9431839\ttotal: 1m 19s\tremaining: 41.8s\n",
      "655:\tlearn: 1602.7615332\ttotal: 1m 19s\tremaining: 41.7s\n",
      "656:\tlearn: 1602.6738673\ttotal: 1m 19s\tremaining: 41.6s\n",
      "657:\tlearn: 1602.6588569\ttotal: 1m 19s\tremaining: 41.5s\n",
      "658:\tlearn: 1602.5565526\ttotal: 1m 19s\tremaining: 41.4s\n",
      "659:\tlearn: 1602.4538607\ttotal: 1m 19s\tremaining: 41.2s\n",
      "660:\tlearn: 1602.3731449\ttotal: 1m 20s\tremaining: 41.1s\n",
      "661:\tlearn: 1602.1673521\ttotal: 1m 20s\tremaining: 40.9s\n",
      "662:\tlearn: 1602.1292516\ttotal: 1m 20s\tremaining: 40.8s\n",
      "663:\tlearn: 1602.0485496\ttotal: 1m 20s\tremaining: 40.7s\n",
      "664:\tlearn: 1601.8438998\ttotal: 1m 20s\tremaining: 40.6s\n",
      "665:\tlearn: 1601.8415870\ttotal: 1m 20s\tremaining: 40.4s\n",
      "666:\tlearn: 1601.6978807\ttotal: 1m 20s\tremaining: 40.3s\n",
      "667:\tlearn: 1601.5122619\ttotal: 1m 20s\tremaining: 40.2s\n",
      "668:\tlearn: 1601.4672099\ttotal: 1m 20s\tremaining: 40s\n",
      "669:\tlearn: 1601.4104186\ttotal: 1m 21s\tremaining: 39.9s\n",
      "670:\tlearn: 1601.2614029\ttotal: 1m 21s\tremaining: 39.8s\n",
      "671:\tlearn: 1601.1608361\ttotal: 1m 21s\tremaining: 39.7s\n",
      "672:\tlearn: 1601.0792995\ttotal: 1m 21s\tremaining: 39.5s\n",
      "673:\tlearn: 1600.9013278\ttotal: 1m 21s\tremaining: 39.4s\n",
      "674:\tlearn: 1600.6469557\ttotal: 1m 21s\tremaining: 39.3s\n",
      "675:\tlearn: 1600.5696972\ttotal: 1m 21s\tremaining: 39.2s\n",
      "676:\tlearn: 1600.4876395\ttotal: 1m 21s\tremaining: 39s\n",
      "677:\tlearn: 1600.4051656\ttotal: 1m 21s\tremaining: 38.9s\n",
      "678:\tlearn: 1600.3339570\ttotal: 1m 22s\tremaining: 38.8s\n",
      "679:\tlearn: 1600.1989338\ttotal: 1m 22s\tremaining: 38.7s\n",
      "680:\tlearn: 1600.1208007\ttotal: 1m 22s\tremaining: 38.5s\n",
      "681:\tlearn: 1599.9583382\ttotal: 1m 22s\tremaining: 38.4s\n",
      "682:\tlearn: 1599.8779965\ttotal: 1m 22s\tremaining: 38.3s\n",
      "683:\tlearn: 1599.8733657\ttotal: 1m 22s\tremaining: 38.1s\n",
      "684:\tlearn: 1599.7609777\ttotal: 1m 22s\tremaining: 38s\n",
      "685:\tlearn: 1599.7170608\ttotal: 1m 22s\tremaining: 37.9s\n",
      "686:\tlearn: 1599.5285929\ttotal: 1m 22s\tremaining: 37.8s\n",
      "687:\tlearn: 1599.3724947\ttotal: 1m 23s\tremaining: 37.6s\n",
      "688:\tlearn: 1599.2900605\ttotal: 1m 23s\tremaining: 37.5s\n",
      "689:\tlearn: 1599.0854994\ttotal: 1m 23s\tremaining: 37.4s\n",
      "690:\tlearn: 1599.0703059\ttotal: 1m 23s\tremaining: 37.3s\n",
      "691:\tlearn: 1598.5630650\ttotal: 1m 23s\tremaining: 37.2s\n",
      "692:\tlearn: 1598.5198286\ttotal: 1m 23s\tremaining: 37.1s\n",
      "693:\tlearn: 1598.4763956\ttotal: 1m 23s\tremaining: 36.9s\n",
      "694:\tlearn: 1598.3465968\ttotal: 1m 23s\tremaining: 36.8s\n",
      "695:\tlearn: 1598.2273497\ttotal: 1m 24s\tremaining: 36.7s\n",
      "696:\tlearn: 1597.9590070\ttotal: 1m 24s\tremaining: 36.6s\n",
      "697:\tlearn: 1597.8138267\ttotal: 1m 24s\tremaining: 36.4s\n",
      "698:\tlearn: 1597.6892548\ttotal: 1m 24s\tremaining: 36.3s\n",
      "699:\tlearn: 1597.5909062\ttotal: 1m 24s\tremaining: 36.2s\n",
      "700:\tlearn: 1597.2904908\ttotal: 1m 24s\tremaining: 36.1s\n",
      "701:\tlearn: 1597.0937167\ttotal: 1m 24s\tremaining: 35.9s\n",
      "702:\tlearn: 1596.9175016\ttotal: 1m 24s\tremaining: 35.8s\n",
      "703:\tlearn: 1596.9076010\ttotal: 1m 24s\tremaining: 35.7s\n",
      "704:\tlearn: 1596.7527380\ttotal: 1m 25s\tremaining: 35.6s\n",
      "705:\tlearn: 1596.6990964\ttotal: 1m 25s\tremaining: 35.5s\n",
      "706:\tlearn: 1596.3906999\ttotal: 1m 25s\tremaining: 35.3s\n",
      "707:\tlearn: 1596.3145909\ttotal: 1m 25s\tremaining: 35.2s\n",
      "708:\tlearn: 1596.2133075\ttotal: 1m 25s\tremaining: 35.1s\n",
      "709:\tlearn: 1596.1032955\ttotal: 1m 25s\tremaining: 35s\n",
      "710:\tlearn: 1596.0627891\ttotal: 1m 25s\tremaining: 34.9s\n",
      "711:\tlearn: 1595.8993227\ttotal: 1m 25s\tremaining: 34.8s\n",
      "712:\tlearn: 1595.7601168\ttotal: 1m 26s\tremaining: 34.6s\n",
      "713:\tlearn: 1595.6098147\ttotal: 1m 26s\tremaining: 34.5s\n",
      "714:\tlearn: 1595.4504874\ttotal: 1m 26s\tremaining: 34.4s\n",
      "715:\tlearn: 1595.3146767\ttotal: 1m 26s\tremaining: 34.3s\n",
      "716:\tlearn: 1595.0674616\ttotal: 1m 26s\tremaining: 34.1s\n",
      "717:\tlearn: 1595.0613566\ttotal: 1m 26s\tremaining: 34s\n",
      "718:\tlearn: 1594.9183736\ttotal: 1m 26s\tremaining: 33.9s\n",
      "719:\tlearn: 1594.7082708\ttotal: 1m 26s\tremaining: 33.7s\n",
      "720:\tlearn: 1594.5837051\ttotal: 1m 26s\tremaining: 33.6s\n",
      "721:\tlearn: 1594.4125222\ttotal: 1m 27s\tremaining: 33.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722:\tlearn: 1594.2345711\ttotal: 1m 27s\tremaining: 33.4s\n",
      "723:\tlearn: 1594.0159687\ttotal: 1m 27s\tremaining: 33.3s\n",
      "724:\tlearn: 1593.8993984\ttotal: 1m 27s\tremaining: 33.1s\n",
      "725:\tlearn: 1593.8523847\ttotal: 1m 27s\tremaining: 33s\n",
      "726:\tlearn: 1593.8106134\ttotal: 1m 27s\tremaining: 32.9s\n",
      "727:\tlearn: 1593.6339200\ttotal: 1m 27s\tremaining: 32.8s\n",
      "728:\tlearn: 1593.3785348\ttotal: 1m 27s\tremaining: 32.6s\n",
      "729:\tlearn: 1593.2773876\ttotal: 1m 27s\tremaining: 32.5s\n",
      "730:\tlearn: 1593.2395678\ttotal: 1m 28s\tremaining: 32.4s\n",
      "731:\tlearn: 1593.0539704\ttotal: 1m 28s\tremaining: 32.3s\n",
      "732:\tlearn: 1592.9594832\ttotal: 1m 28s\tremaining: 32.2s\n",
      "733:\tlearn: 1592.7989699\ttotal: 1m 28s\tremaining: 32s\n",
      "734:\tlearn: 1592.7247244\ttotal: 1m 28s\tremaining: 31.9s\n",
      "735:\tlearn: 1592.6751121\ttotal: 1m 28s\tremaining: 31.8s\n",
      "736:\tlearn: 1592.5770056\ttotal: 1m 28s\tremaining: 31.7s\n",
      "737:\tlearn: 1592.4142905\ttotal: 1m 28s\tremaining: 31.6s\n",
      "738:\tlearn: 1592.2749973\ttotal: 1m 29s\tremaining: 31.5s\n",
      "739:\tlearn: 1592.1415324\ttotal: 1m 29s\tremaining: 31.3s\n",
      "740:\tlearn: 1592.0436268\ttotal: 1m 29s\tremaining: 31.2s\n",
      "741:\tlearn: 1591.9666373\ttotal: 1m 29s\tremaining: 31.1s\n",
      "742:\tlearn: 1591.7296543\ttotal: 1m 29s\tremaining: 31s\n",
      "743:\tlearn: 1591.6386885\ttotal: 1m 29s\tremaining: 30.8s\n",
      "744:\tlearn: 1591.4294552\ttotal: 1m 29s\tremaining: 30.7s\n",
      "745:\tlearn: 1590.9914514\ttotal: 1m 29s\tremaining: 30.6s\n",
      "746:\tlearn: 1590.8733354\ttotal: 1m 29s\tremaining: 30.5s\n",
      "747:\tlearn: 1590.8362571\ttotal: 1m 30s\tremaining: 30.3s\n",
      "748:\tlearn: 1590.6496121\ttotal: 1m 30s\tremaining: 30.2s\n",
      "749:\tlearn: 1590.5448528\ttotal: 1m 30s\tremaining: 30.1s\n",
      "750:\tlearn: 1590.4625284\ttotal: 1m 30s\tremaining: 30s\n",
      "751:\tlearn: 1590.4213847\ttotal: 1m 30s\tremaining: 29.9s\n",
      "752:\tlearn: 1590.3057215\ttotal: 1m 30s\tremaining: 29.7s\n",
      "753:\tlearn: 1590.2075163\ttotal: 1m 30s\tremaining: 29.6s\n",
      "754:\tlearn: 1590.0993026\ttotal: 1m 30s\tremaining: 29.5s\n",
      "755:\tlearn: 1589.9303995\ttotal: 1m 31s\tremaining: 29.4s\n",
      "756:\tlearn: 1589.8778737\ttotal: 1m 31s\tremaining: 29.3s\n",
      "757:\tlearn: 1589.6507786\ttotal: 1m 31s\tremaining: 29.1s\n",
      "758:\tlearn: 1589.6045017\ttotal: 1m 31s\tremaining: 29s\n",
      "759:\tlearn: 1589.4605393\ttotal: 1m 31s\tremaining: 28.9s\n",
      "760:\tlearn: 1589.3304588\ttotal: 1m 31s\tremaining: 28.8s\n",
      "761:\tlearn: 1589.2485851\ttotal: 1m 31s\tremaining: 28.6s\n",
      "762:\tlearn: 1589.1553783\ttotal: 1m 31s\tremaining: 28.5s\n",
      "763:\tlearn: 1588.7856492\ttotal: 1m 31s\tremaining: 28.4s\n",
      "764:\tlearn: 1588.6991151\ttotal: 1m 32s\tremaining: 28.3s\n",
      "765:\tlearn: 1588.6075730\ttotal: 1m 32s\tremaining: 28.2s\n",
      "766:\tlearn: 1588.4928982\ttotal: 1m 32s\tremaining: 28s\n",
      "767:\tlearn: 1588.3839921\ttotal: 1m 32s\tremaining: 27.9s\n",
      "768:\tlearn: 1588.3177216\ttotal: 1m 32s\tremaining: 27.8s\n",
      "769:\tlearn: 1588.1946752\ttotal: 1m 32s\tremaining: 27.7s\n",
      "770:\tlearn: 1588.1301593\ttotal: 1m 32s\tremaining: 27.6s\n",
      "771:\tlearn: 1588.0748780\ttotal: 1m 32s\tremaining: 27.4s\n",
      "772:\tlearn: 1587.9927881\ttotal: 1m 33s\tremaining: 27.3s\n",
      "773:\tlearn: 1587.8945184\ttotal: 1m 33s\tremaining: 27.2s\n",
      "774:\tlearn: 1587.8046544\ttotal: 1m 33s\tremaining: 27.1s\n",
      "775:\tlearn: 1587.7612578\ttotal: 1m 33s\tremaining: 27s\n",
      "776:\tlearn: 1587.6616425\ttotal: 1m 33s\tremaining: 26.8s\n",
      "777:\tlearn: 1587.5825271\ttotal: 1m 33s\tremaining: 26.7s\n",
      "778:\tlearn: 1587.4883476\ttotal: 1m 33s\tremaining: 26.6s\n",
      "779:\tlearn: 1587.2985335\ttotal: 1m 33s\tremaining: 26.5s\n",
      "780:\tlearn: 1587.2229662\ttotal: 1m 34s\tremaining: 26.4s\n",
      "781:\tlearn: 1587.0299152\ttotal: 1m 34s\tremaining: 26.3s\n",
      "782:\tlearn: 1586.8857515\ttotal: 1m 34s\tremaining: 26.1s\n",
      "783:\tlearn: 1586.7888330\ttotal: 1m 34s\tremaining: 26s\n",
      "784:\tlearn: 1586.5625669\ttotal: 1m 34s\tremaining: 25.9s\n",
      "785:\tlearn: 1586.4460265\ttotal: 1m 34s\tremaining: 25.8s\n",
      "786:\tlearn: 1586.3263652\ttotal: 1m 34s\tremaining: 25.7s\n",
      "787:\tlearn: 1586.1456496\ttotal: 1m 35s\tremaining: 25.6s\n",
      "788:\tlearn: 1585.9822282\ttotal: 1m 35s\tremaining: 25.4s\n",
      "789:\tlearn: 1585.9322767\ttotal: 1m 35s\tremaining: 25.3s\n",
      "790:\tlearn: 1585.8633601\ttotal: 1m 35s\tremaining: 25.2s\n",
      "791:\tlearn: 1585.7576085\ttotal: 1m 35s\tremaining: 25.1s\n",
      "792:\tlearn: 1585.6402342\ttotal: 1m 35s\tremaining: 25s\n",
      "793:\tlearn: 1585.5277445\ttotal: 1m 35s\tremaining: 24.8s\n",
      "794:\tlearn: 1585.4387322\ttotal: 1m 35s\tremaining: 24.7s\n",
      "795:\tlearn: 1585.4073390\ttotal: 1m 35s\tremaining: 24.6s\n",
      "796:\tlearn: 1585.3060021\ttotal: 1m 36s\tremaining: 24.5s\n",
      "797:\tlearn: 1585.1805577\ttotal: 1m 36s\tremaining: 24.3s\n",
      "798:\tlearn: 1585.1179534\ttotal: 1m 36s\tremaining: 24.2s\n",
      "799:\tlearn: 1584.9517193\ttotal: 1m 36s\tremaining: 24.1s\n",
      "800:\tlearn: 1584.8807759\ttotal: 1m 36s\tremaining: 24s\n",
      "801:\tlearn: 1584.7010034\ttotal: 1m 36s\tremaining: 23.9s\n",
      "802:\tlearn: 1584.6504181\ttotal: 1m 36s\tremaining: 23.8s\n",
      "803:\tlearn: 1584.5094813\ttotal: 1m 36s\tremaining: 23.6s\n",
      "804:\tlearn: 1584.4375866\ttotal: 1m 37s\tremaining: 23.5s\n",
      "805:\tlearn: 1584.4188206\ttotal: 1m 37s\tremaining: 23.4s\n",
      "806:\tlearn: 1584.1597659\ttotal: 1m 37s\tremaining: 23.3s\n",
      "807:\tlearn: 1584.1217645\ttotal: 1m 37s\tremaining: 23.2s\n",
      "808:\tlearn: 1584.0872671\ttotal: 1m 37s\tremaining: 23s\n",
      "809:\tlearn: 1583.9647711\ttotal: 1m 37s\tremaining: 22.9s\n",
      "810:\tlearn: 1583.8576244\ttotal: 1m 37s\tremaining: 22.8s\n",
      "811:\tlearn: 1583.7086581\ttotal: 1m 37s\tremaining: 22.7s\n",
      "812:\tlearn: 1583.6126893\ttotal: 1m 38s\tremaining: 22.5s\n",
      "813:\tlearn: 1583.2732887\ttotal: 1m 38s\tremaining: 22.4s\n",
      "814:\tlearn: 1583.0813219\ttotal: 1m 38s\tremaining: 22.3s\n",
      "815:\tlearn: 1582.9951513\ttotal: 1m 38s\tremaining: 22.2s\n",
      "816:\tlearn: 1582.8367875\ttotal: 1m 38s\tremaining: 22.1s\n",
      "817:\tlearn: 1582.7848364\ttotal: 1m 38s\tremaining: 21.9s\n",
      "818:\tlearn: 1582.6046713\ttotal: 1m 38s\tremaining: 21.8s\n",
      "819:\tlearn: 1582.4761388\ttotal: 1m 38s\tremaining: 21.7s\n",
      "820:\tlearn: 1582.3759875\ttotal: 1m 38s\tremaining: 21.6s\n",
      "821:\tlearn: 1582.3488260\ttotal: 1m 39s\tremaining: 21.4s\n",
      "822:\tlearn: 1582.1389401\ttotal: 1m 39s\tremaining: 21.3s\n",
      "823:\tlearn: 1581.8810638\ttotal: 1m 39s\tremaining: 21.2s\n",
      "824:\tlearn: 1581.8433846\ttotal: 1m 39s\tremaining: 21.1s\n",
      "825:\tlearn: 1581.8162784\ttotal: 1m 39s\tremaining: 21s\n",
      "826:\tlearn: 1581.7716151\ttotal: 1m 39s\tremaining: 20.8s\n",
      "827:\tlearn: 1581.6020653\ttotal: 1m 39s\tremaining: 20.7s\n",
      "828:\tlearn: 1581.4768565\ttotal: 1m 39s\tremaining: 20.6s\n",
      "829:\tlearn: 1581.3833020\ttotal: 1m 39s\tremaining: 20.5s\n",
      "830:\tlearn: 1581.2948656\ttotal: 1m 40s\tremaining: 20.4s\n",
      "831:\tlearn: 1581.2500440\ttotal: 1m 40s\tremaining: 20.2s\n",
      "832:\tlearn: 1581.1450104\ttotal: 1m 40s\tremaining: 20.1s\n",
      "833:\tlearn: 1581.0417357\ttotal: 1m 40s\tremaining: 20s\n",
      "834:\tlearn: 1580.8307227\ttotal: 1m 40s\tremaining: 19.9s\n",
      "835:\tlearn: 1580.5920269\ttotal: 1m 40s\tremaining: 19.7s\n",
      "836:\tlearn: 1580.4631624\ttotal: 1m 40s\tremaining: 19.6s\n",
      "837:\tlearn: 1580.3447703\ttotal: 1m 40s\tremaining: 19.5s\n",
      "838:\tlearn: 1580.2747924\ttotal: 1m 41s\tremaining: 19.4s\n",
      "839:\tlearn: 1580.1186130\ttotal: 1m 41s\tremaining: 19.3s\n",
      "840:\tlearn: 1580.0082286\ttotal: 1m 41s\tremaining: 19.1s\n",
      "841:\tlearn: 1579.9077166\ttotal: 1m 41s\tremaining: 19s\n",
      "842:\tlearn: 1579.6175102\ttotal: 1m 41s\tremaining: 18.9s\n",
      "843:\tlearn: 1579.4672564\ttotal: 1m 41s\tremaining: 18.8s\n",
      "844:\tlearn: 1579.3386215\ttotal: 1m 41s\tremaining: 18.7s\n",
      "845:\tlearn: 1579.1495809\ttotal: 1m 41s\tremaining: 18.5s\n",
      "846:\tlearn: 1579.0419888\ttotal: 1m 41s\tremaining: 18.4s\n",
      "847:\tlearn: 1578.7332865\ttotal: 1m 42s\tremaining: 18.3s\n",
      "848:\tlearn: 1578.6245056\ttotal: 1m 42s\tremaining: 18.2s\n",
      "849:\tlearn: 1578.4649012\ttotal: 1m 42s\tremaining: 18s\n",
      "850:\tlearn: 1578.3329208\ttotal: 1m 42s\tremaining: 17.9s\n",
      "851:\tlearn: 1578.2683220\ttotal: 1m 42s\tremaining: 17.8s\n",
      "852:\tlearn: 1578.1728709\ttotal: 1m 42s\tremaining: 17.7s\n",
      "853:\tlearn: 1578.1006495\ttotal: 1m 42s\tremaining: 17.6s\n",
      "854:\tlearn: 1577.8947713\ttotal: 1m 42s\tremaining: 17.4s\n",
      "855:\tlearn: 1577.8620470\ttotal: 1m 42s\tremaining: 17.3s\n",
      "856:\tlearn: 1577.8215334\ttotal: 1m 43s\tremaining: 17.2s\n",
      "857:\tlearn: 1577.6783206\ttotal: 1m 43s\tremaining: 17.1s\n",
      "858:\tlearn: 1577.5181788\ttotal: 1m 43s\tremaining: 17s\n",
      "859:\tlearn: 1577.3496447\ttotal: 1m 43s\tremaining: 16.8s\n",
      "860:\tlearn: 1577.3002383\ttotal: 1m 43s\tremaining: 16.7s\n",
      "861:\tlearn: 1577.2603737\ttotal: 1m 43s\tremaining: 16.6s\n",
      "862:\tlearn: 1577.1269274\ttotal: 1m 43s\tremaining: 16.5s\n",
      "863:\tlearn: 1576.8701218\ttotal: 1m 44s\tremaining: 16.4s\n",
      "864:\tlearn: 1576.7368329\ttotal: 1m 44s\tremaining: 16.3s\n",
      "865:\tlearn: 1576.5614988\ttotal: 1m 44s\tremaining: 16.1s\n",
      "866:\tlearn: 1576.5218933\ttotal: 1m 44s\tremaining: 16s\n",
      "867:\tlearn: 1576.3717455\ttotal: 1m 44s\tremaining: 15.9s\n",
      "868:\tlearn: 1576.2539426\ttotal: 1m 44s\tremaining: 15.8s\n",
      "869:\tlearn: 1576.1102388\ttotal: 1m 44s\tremaining: 15.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870:\tlearn: 1576.0278760\ttotal: 1m 44s\tremaining: 15.5s\n",
      "871:\tlearn: 1575.9015240\ttotal: 1m 44s\tremaining: 15.4s\n",
      "872:\tlearn: 1575.8175097\ttotal: 1m 45s\tremaining: 15.3s\n",
      "873:\tlearn: 1575.7056677\ttotal: 1m 45s\tremaining: 15.2s\n",
      "874:\tlearn: 1575.6088372\ttotal: 1m 45s\tremaining: 15s\n",
      "875:\tlearn: 1575.4350563\ttotal: 1m 45s\tremaining: 14.9s\n",
      "876:\tlearn: 1575.2802499\ttotal: 1m 45s\tremaining: 14.8s\n",
      "877:\tlearn: 1575.1803442\ttotal: 1m 45s\tremaining: 14.7s\n",
      "878:\tlearn: 1575.1028734\ttotal: 1m 45s\tremaining: 14.6s\n",
      "879:\tlearn: 1575.0426781\ttotal: 1m 45s\tremaining: 14.4s\n",
      "880:\tlearn: 1574.9586112\ttotal: 1m 46s\tremaining: 14.3s\n",
      "881:\tlearn: 1574.8971508\ttotal: 1m 46s\tremaining: 14.2s\n",
      "882:\tlearn: 1574.7747750\ttotal: 1m 46s\tremaining: 14.1s\n",
      "883:\tlearn: 1574.6021948\ttotal: 1m 46s\tremaining: 14s\n",
      "884:\tlearn: 1574.4785427\ttotal: 1m 46s\tremaining: 13.8s\n",
      "885:\tlearn: 1574.3408396\ttotal: 1m 46s\tremaining: 13.7s\n",
      "886:\tlearn: 1574.2812629\ttotal: 1m 46s\tremaining: 13.6s\n",
      "887:\tlearn: 1574.1233394\ttotal: 1m 46s\tremaining: 13.5s\n",
      "888:\tlearn: 1574.0666586\ttotal: 1m 47s\tremaining: 13.4s\n",
      "889:\tlearn: 1573.9368403\ttotal: 1m 47s\tremaining: 13.2s\n",
      "890:\tlearn: 1573.8763045\ttotal: 1m 47s\tremaining: 13.1s\n",
      "891:\tlearn: 1573.7519176\ttotal: 1m 47s\tremaining: 13s\n",
      "892:\tlearn: 1573.6853685\ttotal: 1m 47s\tremaining: 12.9s\n",
      "893:\tlearn: 1573.5891022\ttotal: 1m 47s\tremaining: 12.8s\n",
      "894:\tlearn: 1573.4930226\ttotal: 1m 47s\tremaining: 12.6s\n",
      "895:\tlearn: 1573.3456655\ttotal: 1m 47s\tremaining: 12.5s\n",
      "896:\tlearn: 1573.2033048\ttotal: 1m 47s\tremaining: 12.4s\n",
      "897:\tlearn: 1573.1595914\ttotal: 1m 48s\tremaining: 12.3s\n",
      "898:\tlearn: 1573.0421735\ttotal: 1m 48s\tremaining: 12.2s\n",
      "899:\tlearn: 1572.9694173\ttotal: 1m 48s\tremaining: 12s\n",
      "900:\tlearn: 1572.9312405\ttotal: 1m 48s\tremaining: 11.9s\n",
      "901:\tlearn: 1572.8934666\ttotal: 1m 48s\tremaining: 11.8s\n",
      "902:\tlearn: 1572.6791973\ttotal: 1m 48s\tremaining: 11.7s\n",
      "903:\tlearn: 1572.4758528\ttotal: 1m 48s\tremaining: 11.5s\n",
      "904:\tlearn: 1572.3316203\ttotal: 1m 48s\tremaining: 11.4s\n",
      "905:\tlearn: 1572.2902475\ttotal: 1m 48s\tremaining: 11.3s\n",
      "906:\tlearn: 1572.1859484\ttotal: 1m 48s\tremaining: 11.2s\n",
      "907:\tlearn: 1572.0219591\ttotal: 1m 49s\tremaining: 11.1s\n",
      "908:\tlearn: 1571.8518047\ttotal: 1m 49s\tremaining: 10.9s\n",
      "909:\tlearn: 1571.7881670\ttotal: 1m 49s\tremaining: 10.8s\n",
      "910:\tlearn: 1571.6631990\ttotal: 1m 49s\tremaining: 10.7s\n",
      "911:\tlearn: 1571.6526563\ttotal: 1m 49s\tremaining: 10.6s\n",
      "912:\tlearn: 1571.5323512\ttotal: 1m 49s\tremaining: 10.5s\n",
      "913:\tlearn: 1571.4736533\ttotal: 1m 49s\tremaining: 10.3s\n",
      "914:\tlearn: 1571.3887592\ttotal: 1m 49s\tremaining: 10.2s\n",
      "915:\tlearn: 1571.2991806\ttotal: 1m 50s\tremaining: 10.1s\n",
      "916:\tlearn: 1571.0775290\ttotal: 1m 50s\tremaining: 9.97s\n",
      "917:\tlearn: 1571.0236540\ttotal: 1m 50s\tremaining: 9.85s\n",
      "918:\tlearn: 1570.9475533\ttotal: 1m 50s\tremaining: 9.73s\n",
      "919:\tlearn: 1570.8417617\ttotal: 1m 50s\tremaining: 9.61s\n",
      "920:\tlearn: 1570.7591729\ttotal: 1m 50s\tremaining: 9.48s\n",
      "921:\tlearn: 1570.7519740\ttotal: 1m 50s\tremaining: 9.37s\n",
      "922:\tlearn: 1570.5442454\ttotal: 1m 50s\tremaining: 9.24s\n",
      "923:\tlearn: 1570.5014511\ttotal: 1m 50s\tremaining: 9.12s\n",
      "924:\tlearn: 1570.3358269\ttotal: 1m 51s\tremaining: 9s\n",
      "925:\tlearn: 1570.2172428\ttotal: 1m 51s\tremaining: 8.88s\n",
      "926:\tlearn: 1570.0900586\ttotal: 1m 51s\tremaining: 8.76s\n",
      "927:\tlearn: 1570.0507692\ttotal: 1m 51s\tremaining: 8.64s\n",
      "928:\tlearn: 1569.8584459\ttotal: 1m 51s\tremaining: 8.52s\n",
      "929:\tlearn: 1569.7581897\ttotal: 1m 51s\tremaining: 8.4s\n",
      "930:\tlearn: 1569.7277984\ttotal: 1m 51s\tremaining: 8.28s\n",
      "931:\tlearn: 1569.5600021\ttotal: 1m 51s\tremaining: 8.16s\n",
      "932:\tlearn: 1569.4471905\ttotal: 1m 51s\tremaining: 8.04s\n",
      "933:\tlearn: 1569.3492262\ttotal: 1m 52s\tremaining: 7.92s\n",
      "934:\tlearn: 1569.3466635\ttotal: 1m 52s\tremaining: 7.79s\n",
      "935:\tlearn: 1569.2428004\ttotal: 1m 52s\tremaining: 7.67s\n",
      "936:\tlearn: 1569.1403773\ttotal: 1m 52s\tremaining: 7.55s\n",
      "937:\tlearn: 1569.0495440\ttotal: 1m 52s\tremaining: 7.44s\n",
      "938:\tlearn: 1568.9731946\ttotal: 1m 52s\tremaining: 7.32s\n",
      "939:\tlearn: 1568.9032556\ttotal: 1m 52s\tremaining: 7.2s\n",
      "940:\tlearn: 1568.8944835\ttotal: 1m 52s\tremaining: 7.08s\n",
      "941:\tlearn: 1568.7683717\ttotal: 1m 53s\tremaining: 6.96s\n",
      "942:\tlearn: 1568.6411555\ttotal: 1m 53s\tremaining: 6.84s\n",
      "943:\tlearn: 1568.6242302\ttotal: 1m 53s\tremaining: 6.72s\n",
      "944:\tlearn: 1568.5315823\ttotal: 1m 53s\tremaining: 6.6s\n",
      "945:\tlearn: 1568.4706937\ttotal: 1m 53s\tremaining: 6.48s\n",
      "946:\tlearn: 1568.4303256\ttotal: 1m 53s\tremaining: 6.36s\n",
      "947:\tlearn: 1568.3792988\ttotal: 1m 53s\tremaining: 6.24s\n",
      "948:\tlearn: 1568.1099446\ttotal: 1m 53s\tremaining: 6.12s\n",
      "949:\tlearn: 1568.0179681\ttotal: 1m 53s\tremaining: 6s\n",
      "950:\tlearn: 1567.9311909\ttotal: 1m 54s\tremaining: 5.88s\n",
      "951:\tlearn: 1567.7931153\ttotal: 1m 54s\tremaining: 5.76s\n",
      "952:\tlearn: 1567.6992775\ttotal: 1m 54s\tremaining: 5.64s\n",
      "953:\tlearn: 1567.5483072\ttotal: 1m 54s\tremaining: 5.52s\n",
      "954:\tlearn: 1567.5221381\ttotal: 1m 54s\tremaining: 5.4s\n",
      "955:\tlearn: 1567.4138506\ttotal: 1m 54s\tremaining: 5.28s\n",
      "956:\tlearn: 1567.2612139\ttotal: 1m 54s\tremaining: 5.16s\n",
      "957:\tlearn: 1567.2316903\ttotal: 1m 55s\tremaining: 5.04s\n",
      "958:\tlearn: 1567.1686266\ttotal: 1m 55s\tremaining: 4.92s\n",
      "959:\tlearn: 1567.1116813\ttotal: 1m 55s\tremaining: 4.8s\n",
      "960:\tlearn: 1567.0401405\ttotal: 1m 55s\tremaining: 4.68s\n",
      "961:\tlearn: 1566.9018581\ttotal: 1m 55s\tremaining: 4.56s\n",
      "962:\tlearn: 1566.8936329\ttotal: 1m 55s\tremaining: 4.44s\n",
      "963:\tlearn: 1566.6719730\ttotal: 1m 55s\tremaining: 4.32s\n",
      "964:\tlearn: 1566.5183617\ttotal: 1m 55s\tremaining: 4.2s\n",
      "965:\tlearn: 1566.4532684\ttotal: 1m 55s\tremaining: 4.08s\n",
      "966:\tlearn: 1566.3606556\ttotal: 1m 56s\tremaining: 3.96s\n",
      "967:\tlearn: 1566.2504641\ttotal: 1m 56s\tremaining: 3.84s\n",
      "968:\tlearn: 1566.1856370\ttotal: 1m 56s\tremaining: 3.72s\n",
      "969:\tlearn: 1566.1709821\ttotal: 1m 56s\tremaining: 3.6s\n",
      "970:\tlearn: 1565.9959091\ttotal: 1m 56s\tremaining: 3.48s\n",
      "971:\tlearn: 1565.8958081\ttotal: 1m 56s\tremaining: 3.36s\n",
      "972:\tlearn: 1565.8000525\ttotal: 1m 56s\tremaining: 3.24s\n",
      "973:\tlearn: 1565.7644624\ttotal: 1m 57s\tremaining: 3.12s\n",
      "974:\tlearn: 1565.7636183\ttotal: 1m 57s\tremaining: 3s\n",
      "975:\tlearn: 1565.6412335\ttotal: 1m 57s\tremaining: 2.88s\n",
      "976:\tlearn: 1565.5735920\ttotal: 1m 57s\tremaining: 2.76s\n",
      "977:\tlearn: 1565.5187711\ttotal: 1m 57s\tremaining: 2.64s\n",
      "978:\tlearn: 1565.3559852\ttotal: 1m 57s\tremaining: 2.52s\n",
      "979:\tlearn: 1565.2334339\ttotal: 1m 57s\tremaining: 2.4s\n",
      "980:\tlearn: 1565.1202083\ttotal: 1m 57s\tremaining: 2.28s\n",
      "981:\tlearn: 1565.0311452\ttotal: 1m 57s\tremaining: 2.16s\n",
      "982:\tlearn: 1564.8838381\ttotal: 1m 58s\tremaining: 2.04s\n",
      "983:\tlearn: 1564.7609274\ttotal: 1m 58s\tremaining: 1.92s\n",
      "984:\tlearn: 1564.7534675\ttotal: 1m 58s\tremaining: 1.8s\n",
      "985:\tlearn: 1564.6530303\ttotal: 1m 58s\tremaining: 1.68s\n",
      "986:\tlearn: 1564.4948245\ttotal: 1m 58s\tremaining: 1.56s\n",
      "987:\tlearn: 1564.4374095\ttotal: 1m 58s\tremaining: 1.44s\n",
      "988:\tlearn: 1564.3207207\ttotal: 1m 58s\tremaining: 1.32s\n",
      "989:\tlearn: 1564.3183577\ttotal: 1m 58s\tremaining: 1.2s\n",
      "990:\tlearn: 1564.1754093\ttotal: 1m 59s\tremaining: 1.08s\n",
      "991:\tlearn: 1564.0224607\ttotal: 1m 59s\tremaining: 961ms\n",
      "992:\tlearn: 1564.0093562\ttotal: 1m 59s\tremaining: 841ms\n",
      "993:\tlearn: 1563.8830605\ttotal: 1m 59s\tremaining: 721ms\n",
      "994:\tlearn: 1563.8756130\ttotal: 1m 59s\tremaining: 601ms\n",
      "995:\tlearn: 1563.8569285\ttotal: 1m 59s\tremaining: 480ms\n",
      "996:\tlearn: 1563.7643692\ttotal: 1m 59s\tremaining: 360ms\n",
      "997:\tlearn: 1563.6720902\ttotal: 1m 59s\tremaining: 240ms\n",
      "998:\tlearn: 1563.6120206\ttotal: 2m\tremaining: 120ms\n",
      "999:\tlearn: 1563.5315705\ttotal: 2m\tremaining: 0us\n",
      "Learning rate set to 0.094301\n",
      "0:\tlearn: 4416.1245891\ttotal: 161ms\tremaining: 2m 40s\n",
      "1:\tlearn: 4150.7830769\ttotal: 303ms\tremaining: 2m 31s\n",
      "2:\tlearn: 3915.8850790\ttotal: 460ms\tremaining: 2m 32s\n",
      "3:\tlearn: 3704.1700793\ttotal: 627ms\tremaining: 2m 36s\n",
      "4:\tlearn: 3518.2072756\ttotal: 770ms\tremaining: 2m 33s\n",
      "5:\tlearn: 3346.4002741\ttotal: 898ms\tremaining: 2m 28s\n",
      "6:\tlearn: 3201.9831317\ttotal: 1.02s\tremaining: 2m 24s\n",
      "7:\tlearn: 3067.9253584\ttotal: 1.18s\tremaining: 2m 25s\n",
      "8:\tlearn: 2950.5564019\ttotal: 1.32s\tremaining: 2m 25s\n",
      "9:\tlearn: 2843.4273304\ttotal: 1.48s\tremaining: 2m 26s\n",
      "10:\tlearn: 2752.3783189\ttotal: 1.62s\tremaining: 2m 25s\n",
      "11:\tlearn: 2672.4802774\ttotal: 1.77s\tremaining: 2m 25s\n",
      "12:\tlearn: 2600.4580053\ttotal: 1.92s\tremaining: 2m 25s\n",
      "13:\tlearn: 2526.8606497\ttotal: 2.05s\tremaining: 2m 24s\n",
      "14:\tlearn: 2467.7770130\ttotal: 2.19s\tremaining: 2m 23s\n",
      "15:\tlearn: 2413.9266370\ttotal: 2.32s\tremaining: 2m 22s\n",
      "16:\tlearn: 2363.9237210\ttotal: 2.44s\tremaining: 2m 21s\n",
      "17:\tlearn: 2321.6417940\ttotal: 2.58s\tremaining: 2m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:\tlearn: 2286.6512344\ttotal: 2.74s\tremaining: 2m 21s\n",
      "19:\tlearn: 2252.8397556\ttotal: 2.85s\tremaining: 2m 19s\n",
      "20:\tlearn: 2223.9181643\ttotal: 3s\tremaining: 2m 19s\n",
      "21:\tlearn: 2198.9698451\ttotal: 3.12s\tremaining: 2m 18s\n",
      "22:\tlearn: 2170.7142070\ttotal: 3.24s\tremaining: 2m 17s\n",
      "23:\tlearn: 2147.1372507\ttotal: 3.35s\tremaining: 2m 16s\n",
      "24:\tlearn: 2128.7751270\ttotal: 3.46s\tremaining: 2m 14s\n",
      "25:\tlearn: 2108.3714190\ttotal: 3.6s\tremaining: 2m 14s\n",
      "26:\tlearn: 2088.6729606\ttotal: 3.7s\tremaining: 2m 13s\n",
      "27:\tlearn: 2071.6102059\ttotal: 3.82s\tremaining: 2m 12s\n",
      "28:\tlearn: 2057.3827886\ttotal: 3.92s\tremaining: 2m 11s\n",
      "29:\tlearn: 2043.7551693\ttotal: 4.01s\tremaining: 2m 9s\n",
      "30:\tlearn: 2032.3496677\ttotal: 4.13s\tremaining: 2m 9s\n",
      "31:\tlearn: 2022.2879325\ttotal: 4.25s\tremaining: 2m 8s\n",
      "32:\tlearn: 2011.9254004\ttotal: 4.38s\tremaining: 2m 8s\n",
      "33:\tlearn: 2000.3576235\ttotal: 4.5s\tremaining: 2m 7s\n",
      "34:\tlearn: 1991.8916512\ttotal: 4.61s\tremaining: 2m 7s\n",
      "35:\tlearn: 1980.6483640\ttotal: 4.71s\tremaining: 2m 5s\n",
      "36:\tlearn: 1972.8855156\ttotal: 4.82s\tremaining: 2m 5s\n",
      "37:\tlearn: 1964.8168943\ttotal: 4.89s\tremaining: 2m 3s\n",
      "38:\tlearn: 1958.5834093\ttotal: 5s\tremaining: 2m 3s\n",
      "39:\tlearn: 1954.1353109\ttotal: 5.09s\tremaining: 2m 2s\n",
      "40:\tlearn: 1948.5654484\ttotal: 5.2s\tremaining: 2m 1s\n",
      "41:\tlearn: 1944.0478456\ttotal: 5.33s\tremaining: 2m 1s\n",
      "42:\tlearn: 1936.7629454\ttotal: 5.42s\tremaining: 2m\n",
      "43:\tlearn: 1932.1612040\ttotal: 5.51s\tremaining: 1m 59s\n",
      "44:\tlearn: 1927.6848612\ttotal: 5.63s\tremaining: 1m 59s\n",
      "45:\tlearn: 1923.7441481\ttotal: 5.74s\tremaining: 1m 59s\n",
      "46:\tlearn: 1919.0894266\ttotal: 5.83s\tremaining: 1m 58s\n",
      "47:\tlearn: 1915.4612071\ttotal: 5.96s\tremaining: 1m 58s\n",
      "48:\tlearn: 1911.9649057\ttotal: 6.09s\tremaining: 1m 58s\n",
      "49:\tlearn: 1908.8384570\ttotal: 6.2s\tremaining: 1m 57s\n",
      "50:\tlearn: 1903.9774763\ttotal: 6.32s\tremaining: 1m 57s\n",
      "51:\tlearn: 1900.9903513\ttotal: 6.43s\tremaining: 1m 57s\n",
      "52:\tlearn: 1897.6521806\ttotal: 6.55s\tremaining: 1m 57s\n",
      "53:\tlearn: 1895.3445496\ttotal: 6.66s\tremaining: 1m 56s\n",
      "54:\tlearn: 1892.8046845\ttotal: 6.77s\tremaining: 1m 56s\n",
      "55:\tlearn: 1889.7959858\ttotal: 6.86s\tremaining: 1m 55s\n",
      "56:\tlearn: 1886.4599158\ttotal: 6.97s\tremaining: 1m 55s\n",
      "57:\tlearn: 1884.1360900\ttotal: 7.09s\tremaining: 1m 55s\n",
      "58:\tlearn: 1882.3124445\ttotal: 7.2s\tremaining: 1m 54s\n",
      "59:\tlearn: 1880.1771670\ttotal: 7.32s\tremaining: 1m 54s\n",
      "60:\tlearn: 1876.0046261\ttotal: 7.41s\tremaining: 1m 54s\n",
      "61:\tlearn: 1873.3706925\ttotal: 7.53s\tremaining: 1m 53s\n",
      "62:\tlearn: 1871.0212231\ttotal: 7.63s\tremaining: 1m 53s\n",
      "63:\tlearn: 1868.8667025\ttotal: 7.77s\tremaining: 1m 53s\n",
      "64:\tlearn: 1866.9346932\ttotal: 7.91s\tremaining: 1m 53s\n",
      "65:\tlearn: 1864.8039854\ttotal: 8.06s\tremaining: 1m 54s\n",
      "66:\tlearn: 1862.7749634\ttotal: 8.17s\tremaining: 1m 53s\n",
      "67:\tlearn: 1860.6710036\ttotal: 8.25s\tremaining: 1m 53s\n",
      "68:\tlearn: 1859.0566396\ttotal: 8.37s\tremaining: 1m 53s\n",
      "69:\tlearn: 1857.8826231\ttotal: 8.49s\tremaining: 1m 52s\n",
      "70:\tlearn: 1855.9596113\ttotal: 8.61s\tremaining: 1m 52s\n",
      "71:\tlearn: 1854.5827173\ttotal: 8.73s\tremaining: 1m 52s\n",
      "72:\tlearn: 1852.3546422\ttotal: 8.87s\tremaining: 1m 52s\n",
      "73:\tlearn: 1849.4071473\ttotal: 8.97s\tremaining: 1m 52s\n",
      "74:\tlearn: 1846.8281015\ttotal: 9.12s\tremaining: 1m 52s\n",
      "75:\tlearn: 1844.4006880\ttotal: 9.24s\tremaining: 1m 52s\n",
      "76:\tlearn: 1842.9819578\ttotal: 9.38s\tremaining: 1m 52s\n",
      "77:\tlearn: 1839.9278661\ttotal: 9.48s\tremaining: 1m 52s\n",
      "78:\tlearn: 1838.3639046\ttotal: 9.59s\tremaining: 1m 51s\n",
      "79:\tlearn: 1836.8939151\ttotal: 9.71s\tremaining: 1m 51s\n",
      "80:\tlearn: 1835.7502242\ttotal: 9.82s\tremaining: 1m 51s\n",
      "81:\tlearn: 1832.8786459\ttotal: 9.94s\tremaining: 1m 51s\n",
      "82:\tlearn: 1830.4474423\ttotal: 10s\tremaining: 1m 50s\n",
      "83:\tlearn: 1828.9202718\ttotal: 10.1s\tremaining: 1m 50s\n",
      "84:\tlearn: 1826.5948068\ttotal: 10.3s\tremaining: 1m 50s\n",
      "85:\tlearn: 1824.8255577\ttotal: 10.4s\tremaining: 1m 50s\n",
      "86:\tlearn: 1823.2167039\ttotal: 10.5s\tremaining: 1m 50s\n",
      "87:\tlearn: 1821.7379876\ttotal: 10.6s\tremaining: 1m 50s\n",
      "88:\tlearn: 1820.6177416\ttotal: 10.8s\tremaining: 1m 50s\n",
      "89:\tlearn: 1818.9636568\ttotal: 10.9s\tremaining: 1m 50s\n",
      "90:\tlearn: 1817.8748315\ttotal: 11s\tremaining: 1m 49s\n",
      "91:\tlearn: 1815.6129384\ttotal: 11.1s\tremaining: 1m 49s\n",
      "92:\tlearn: 1813.4953250\ttotal: 11.3s\tremaining: 1m 50s\n",
      "93:\tlearn: 1811.9491041\ttotal: 11.3s\tremaining: 1m 49s\n",
      "94:\tlearn: 1810.2401238\ttotal: 11.5s\tremaining: 1m 49s\n",
      "95:\tlearn: 1809.5521135\ttotal: 11.6s\tremaining: 1m 49s\n",
      "96:\tlearn: 1808.8291679\ttotal: 11.7s\tremaining: 1m 48s\n",
      "97:\tlearn: 1807.4562713\ttotal: 11.8s\tremaining: 1m 48s\n",
      "98:\tlearn: 1806.1868656\ttotal: 11.9s\tremaining: 1m 48s\n",
      "99:\tlearn: 1804.8410616\ttotal: 12s\tremaining: 1m 48s\n",
      "100:\tlearn: 1802.7366040\ttotal: 12.2s\tremaining: 1m 48s\n",
      "101:\tlearn: 1801.7774549\ttotal: 12.3s\tremaining: 1m 47s\n",
      "102:\tlearn: 1800.5949393\ttotal: 12.4s\tremaining: 1m 48s\n",
      "103:\tlearn: 1799.3370746\ttotal: 12.5s\tremaining: 1m 48s\n",
      "104:\tlearn: 1797.0743235\ttotal: 12.6s\tremaining: 1m 47s\n",
      "105:\tlearn: 1796.1624976\ttotal: 12.8s\tremaining: 1m 47s\n",
      "106:\tlearn: 1795.2228647\ttotal: 12.9s\tremaining: 1m 47s\n",
      "107:\tlearn: 1793.5803020\ttotal: 13s\tremaining: 1m 47s\n",
      "108:\tlearn: 1792.4632426\ttotal: 13.1s\tremaining: 1m 47s\n",
      "109:\tlearn: 1791.1871515\ttotal: 13.3s\tremaining: 1m 47s\n",
      "110:\tlearn: 1789.9601637\ttotal: 13.4s\tremaining: 1m 47s\n",
      "111:\tlearn: 1788.9232023\ttotal: 13.5s\tremaining: 1m 46s\n",
      "112:\tlearn: 1788.1940092\ttotal: 13.6s\tremaining: 1m 46s\n",
      "113:\tlearn: 1787.0191887\ttotal: 13.7s\tremaining: 1m 46s\n",
      "114:\tlearn: 1785.4141553\ttotal: 13.8s\tremaining: 1m 46s\n",
      "115:\tlearn: 1784.6894866\ttotal: 13.9s\tremaining: 1m 46s\n",
      "116:\tlearn: 1783.7300098\ttotal: 14s\tremaining: 1m 45s\n",
      "117:\tlearn: 1782.4565785\ttotal: 14.2s\tremaining: 1m 45s\n",
      "118:\tlearn: 1780.1342195\ttotal: 14.3s\tremaining: 1m 45s\n",
      "119:\tlearn: 1778.8896257\ttotal: 14.4s\tremaining: 1m 45s\n",
      "120:\tlearn: 1778.5218152\ttotal: 14.5s\tremaining: 1m 45s\n",
      "121:\tlearn: 1777.7291485\ttotal: 14.6s\tremaining: 1m 45s\n",
      "122:\tlearn: 1776.9360088\ttotal: 14.8s\tremaining: 1m 45s\n",
      "123:\tlearn: 1775.5942802\ttotal: 14.9s\tremaining: 1m 45s\n",
      "124:\tlearn: 1775.0581597\ttotal: 15s\tremaining: 1m 45s\n",
      "125:\tlearn: 1774.1815638\ttotal: 15.1s\tremaining: 1m 44s\n",
      "126:\tlearn: 1773.6518973\ttotal: 15.3s\tremaining: 1m 44s\n",
      "127:\tlearn: 1772.3435903\ttotal: 15.4s\tremaining: 1m 44s\n",
      "128:\tlearn: 1770.7159126\ttotal: 15.5s\tremaining: 1m 44s\n",
      "129:\tlearn: 1769.0898817\ttotal: 15.6s\tremaining: 1m 44s\n",
      "130:\tlearn: 1768.6835551\ttotal: 15.7s\tremaining: 1m 44s\n",
      "131:\tlearn: 1767.7736838\ttotal: 15.8s\tremaining: 1m 44s\n",
      "132:\tlearn: 1767.1675736\ttotal: 16s\tremaining: 1m 44s\n",
      "133:\tlearn: 1766.4417319\ttotal: 16.1s\tremaining: 1m 43s\n",
      "134:\tlearn: 1765.7135500\ttotal: 16.2s\tremaining: 1m 43s\n",
      "135:\tlearn: 1764.8947185\ttotal: 16.3s\tremaining: 1m 43s\n",
      "136:\tlearn: 1763.2875456\ttotal: 16.4s\tremaining: 1m 43s\n",
      "137:\tlearn: 1762.0316572\ttotal: 16.5s\tremaining: 1m 43s\n",
      "138:\tlearn: 1761.3175748\ttotal: 16.7s\tremaining: 1m 43s\n",
      "139:\tlearn: 1760.1305999\ttotal: 16.8s\tremaining: 1m 43s\n",
      "140:\tlearn: 1758.9954540\ttotal: 16.9s\tremaining: 1m 42s\n",
      "141:\tlearn: 1757.9643311\ttotal: 17s\tremaining: 1m 42s\n",
      "142:\tlearn: 1757.0395482\ttotal: 17.1s\tremaining: 1m 42s\n",
      "143:\tlearn: 1756.0195178\ttotal: 17.2s\tremaining: 1m 42s\n",
      "144:\tlearn: 1755.4264247\ttotal: 17.3s\tremaining: 1m 42s\n",
      "145:\tlearn: 1754.9947994\ttotal: 17.5s\tremaining: 1m 42s\n",
      "146:\tlearn: 1754.3842038\ttotal: 17.6s\tremaining: 1m 42s\n",
      "147:\tlearn: 1753.9537251\ttotal: 17.7s\tremaining: 1m 41s\n",
      "148:\tlearn: 1753.1456225\ttotal: 17.8s\tremaining: 1m 41s\n",
      "149:\tlearn: 1752.3885649\ttotal: 17.9s\tremaining: 1m 41s\n",
      "150:\tlearn: 1751.9706674\ttotal: 18.1s\tremaining: 1m 41s\n",
      "151:\tlearn: 1751.3739174\ttotal: 18.2s\tremaining: 1m 41s\n",
      "152:\tlearn: 1750.9275827\ttotal: 18.3s\tremaining: 1m 41s\n",
      "153:\tlearn: 1750.2013230\ttotal: 18.4s\tremaining: 1m 41s\n",
      "154:\tlearn: 1749.7782689\ttotal: 18.5s\tremaining: 1m 41s\n",
      "155:\tlearn: 1748.9074707\ttotal: 18.7s\tremaining: 1m 40s\n",
      "156:\tlearn: 1747.1392955\ttotal: 18.8s\tremaining: 1m 40s\n",
      "157:\tlearn: 1746.8472362\ttotal: 18.9s\tremaining: 1m 40s\n",
      "158:\tlearn: 1745.7076227\ttotal: 19s\tremaining: 1m 40s\n",
      "159:\tlearn: 1745.1567202\ttotal: 19.1s\tremaining: 1m 40s\n",
      "160:\tlearn: 1744.7131564\ttotal: 19.3s\tremaining: 1m 40s\n",
      "161:\tlearn: 1743.3020421\ttotal: 19.4s\tremaining: 1m 40s\n",
      "162:\tlearn: 1742.3592299\ttotal: 19.5s\tremaining: 1m 40s\n",
      "163:\tlearn: 1741.5413026\ttotal: 19.6s\tremaining: 1m 40s\n",
      "164:\tlearn: 1740.7234984\ttotal: 19.7s\tremaining: 1m 39s\n",
      "165:\tlearn: 1740.4935415\ttotal: 19.8s\tremaining: 1m 39s\n",
      "166:\tlearn: 1740.1286828\ttotal: 20s\tremaining: 1m 39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167:\tlearn: 1739.1009884\ttotal: 20.1s\tremaining: 1m 39s\n",
      "168:\tlearn: 1738.7408966\ttotal: 20.2s\tremaining: 1m 39s\n",
      "169:\tlearn: 1738.1121329\ttotal: 20.3s\tremaining: 1m 39s\n",
      "170:\tlearn: 1737.8032386\ttotal: 20.4s\tremaining: 1m 38s\n",
      "171:\tlearn: 1736.9781354\ttotal: 20.5s\tremaining: 1m 38s\n",
      "172:\tlearn: 1736.3302448\ttotal: 20.6s\tremaining: 1m 38s\n",
      "173:\tlearn: 1735.1702969\ttotal: 20.7s\tremaining: 1m 38s\n",
      "174:\tlearn: 1734.6137101\ttotal: 20.9s\tremaining: 1m 38s\n",
      "175:\tlearn: 1733.9592935\ttotal: 21s\tremaining: 1m 38s\n",
      "176:\tlearn: 1733.0432095\ttotal: 21.1s\tremaining: 1m 37s\n",
      "177:\tlearn: 1732.4918300\ttotal: 21.2s\tremaining: 1m 37s\n",
      "178:\tlearn: 1732.3077494\ttotal: 21.3s\tremaining: 1m 37s\n",
      "179:\tlearn: 1732.0371213\ttotal: 21.4s\tremaining: 1m 37s\n",
      "180:\tlearn: 1731.4324470\ttotal: 21.5s\tremaining: 1m 37s\n",
      "181:\tlearn: 1731.0014414\ttotal: 21.6s\tremaining: 1m 37s\n",
      "182:\tlearn: 1730.6634548\ttotal: 21.8s\tremaining: 1m 37s\n",
      "183:\tlearn: 1729.9458521\ttotal: 21.9s\tremaining: 1m 37s\n",
      "184:\tlearn: 1728.9537029\ttotal: 22s\tremaining: 1m 37s\n",
      "185:\tlearn: 1727.9596612\ttotal: 22.2s\tremaining: 1m 36s\n",
      "186:\tlearn: 1727.3600286\ttotal: 22.3s\tremaining: 1m 36s\n",
      "187:\tlearn: 1726.5323871\ttotal: 22.4s\tremaining: 1m 36s\n",
      "188:\tlearn: 1725.7514158\ttotal: 22.5s\tremaining: 1m 36s\n",
      "189:\tlearn: 1725.5942849\ttotal: 22.6s\tremaining: 1m 36s\n",
      "190:\tlearn: 1724.9380496\ttotal: 22.7s\tremaining: 1m 36s\n",
      "191:\tlearn: 1723.9899947\ttotal: 22.9s\tremaining: 1m 36s\n",
      "192:\tlearn: 1723.3321358\ttotal: 23s\tremaining: 1m 36s\n",
      "193:\tlearn: 1723.0249910\ttotal: 23.1s\tremaining: 1m 35s\n",
      "194:\tlearn: 1722.5500157\ttotal: 23.2s\tremaining: 1m 35s\n",
      "195:\tlearn: 1722.0342653\ttotal: 23.3s\tremaining: 1m 35s\n",
      "196:\tlearn: 1721.4559511\ttotal: 23.4s\tremaining: 1m 35s\n",
      "197:\tlearn: 1720.5922079\ttotal: 23.6s\tremaining: 1m 35s\n",
      "198:\tlearn: 1719.6699909\ttotal: 23.7s\tremaining: 1m 35s\n",
      "199:\tlearn: 1719.2412449\ttotal: 23.8s\tremaining: 1m 35s\n",
      "200:\tlearn: 1718.6539316\ttotal: 23.9s\tremaining: 1m 35s\n",
      "201:\tlearn: 1717.7191344\ttotal: 24.1s\tremaining: 1m 35s\n",
      "202:\tlearn: 1717.0996827\ttotal: 24.2s\tremaining: 1m 35s\n",
      "203:\tlearn: 1716.4616400\ttotal: 24.3s\tremaining: 1m 34s\n",
      "204:\tlearn: 1715.4838349\ttotal: 24.4s\tremaining: 1m 34s\n",
      "205:\tlearn: 1714.7269413\ttotal: 24.6s\tremaining: 1m 34s\n",
      "206:\tlearn: 1714.6164392\ttotal: 24.7s\tremaining: 1m 34s\n",
      "207:\tlearn: 1713.8331930\ttotal: 24.8s\tremaining: 1m 34s\n",
      "208:\tlearn: 1713.0644001\ttotal: 24.9s\tremaining: 1m 34s\n",
      "209:\tlearn: 1712.2653802\ttotal: 25s\tremaining: 1m 34s\n",
      "210:\tlearn: 1711.5741661\ttotal: 25.1s\tremaining: 1m 33s\n",
      "211:\tlearn: 1711.0053336\ttotal: 25.3s\tremaining: 1m 33s\n",
      "212:\tlearn: 1710.1053477\ttotal: 25.4s\tremaining: 1m 33s\n",
      "213:\tlearn: 1709.8202532\ttotal: 25.5s\tremaining: 1m 33s\n",
      "214:\tlearn: 1709.3173523\ttotal: 25.6s\tremaining: 1m 33s\n",
      "215:\tlearn: 1708.5255023\ttotal: 25.7s\tremaining: 1m 33s\n",
      "216:\tlearn: 1708.0218880\ttotal: 25.8s\tremaining: 1m 33s\n",
      "217:\tlearn: 1707.3215587\ttotal: 26s\tremaining: 1m 33s\n",
      "218:\tlearn: 1707.1907733\ttotal: 26.1s\tremaining: 1m 32s\n",
      "219:\tlearn: 1706.3870979\ttotal: 26.2s\tremaining: 1m 32s\n",
      "220:\tlearn: 1705.9717921\ttotal: 26.3s\tremaining: 1m 32s\n",
      "221:\tlearn: 1705.6230954\ttotal: 26.4s\tremaining: 1m 32s\n",
      "222:\tlearn: 1705.1113968\ttotal: 26.5s\tremaining: 1m 32s\n",
      "223:\tlearn: 1704.7906306\ttotal: 26.6s\tremaining: 1m 32s\n",
      "224:\tlearn: 1704.0297658\ttotal: 26.8s\tremaining: 1m 32s\n",
      "225:\tlearn: 1703.4803193\ttotal: 26.9s\tremaining: 1m 32s\n",
      "226:\tlearn: 1703.3105114\ttotal: 27s\tremaining: 1m 31s\n",
      "227:\tlearn: 1702.7185322\ttotal: 27.1s\tremaining: 1m 31s\n",
      "228:\tlearn: 1702.1225832\ttotal: 27.2s\tremaining: 1m 31s\n",
      "229:\tlearn: 1701.7290590\ttotal: 27.3s\tremaining: 1m 31s\n",
      "230:\tlearn: 1701.2832601\ttotal: 27.5s\tremaining: 1m 31s\n",
      "231:\tlearn: 1700.9743370\ttotal: 27.5s\tremaining: 1m 31s\n",
      "232:\tlearn: 1700.3413235\ttotal: 27.6s\tremaining: 1m 30s\n",
      "233:\tlearn: 1699.8119704\ttotal: 27.7s\tremaining: 1m 30s\n",
      "234:\tlearn: 1699.5305781\ttotal: 27.8s\tremaining: 1m 30s\n",
      "235:\tlearn: 1699.1314575\ttotal: 27.9s\tremaining: 1m 30s\n",
      "236:\tlearn: 1698.7266137\ttotal: 28s\tremaining: 1m 30s\n",
      "237:\tlearn: 1697.9046762\ttotal: 28.1s\tremaining: 1m 30s\n",
      "238:\tlearn: 1697.5167338\ttotal: 28.2s\tremaining: 1m 29s\n",
      "239:\tlearn: 1696.9679412\ttotal: 28.4s\tremaining: 1m 29s\n",
      "240:\tlearn: 1696.4583984\ttotal: 28.5s\tremaining: 1m 29s\n",
      "241:\tlearn: 1696.1153149\ttotal: 28.6s\tremaining: 1m 29s\n",
      "242:\tlearn: 1695.6660438\ttotal: 28.7s\tremaining: 1m 29s\n",
      "243:\tlearn: 1695.5412904\ttotal: 28.8s\tremaining: 1m 29s\n",
      "244:\tlearn: 1695.3092276\ttotal: 29s\tremaining: 1m 29s\n",
      "245:\tlearn: 1694.8836429\ttotal: 29.1s\tremaining: 1m 29s\n",
      "246:\tlearn: 1694.4121883\ttotal: 29.2s\tremaining: 1m 28s\n",
      "247:\tlearn: 1693.6707149\ttotal: 29.3s\tremaining: 1m 28s\n",
      "248:\tlearn: 1693.4273743\ttotal: 29.4s\tremaining: 1m 28s\n",
      "249:\tlearn: 1693.2432864\ttotal: 29.5s\tremaining: 1m 28s\n",
      "250:\tlearn: 1693.0543621\ttotal: 29.6s\tremaining: 1m 28s\n",
      "251:\tlearn: 1692.5434915\ttotal: 29.7s\tremaining: 1m 28s\n",
      "252:\tlearn: 1692.2244864\ttotal: 29.9s\tremaining: 1m 28s\n",
      "253:\tlearn: 1691.9446449\ttotal: 30s\tremaining: 1m 28s\n",
      "254:\tlearn: 1691.6607792\ttotal: 30.1s\tremaining: 1m 27s\n",
      "255:\tlearn: 1691.3858378\ttotal: 30.2s\tremaining: 1m 27s\n",
      "256:\tlearn: 1690.8783572\ttotal: 30.3s\tremaining: 1m 27s\n",
      "257:\tlearn: 1690.6252598\ttotal: 30.4s\tremaining: 1m 27s\n",
      "258:\tlearn: 1690.0786122\ttotal: 30.5s\tremaining: 1m 27s\n",
      "259:\tlearn: 1689.3916644\ttotal: 30.7s\tremaining: 1m 27s\n",
      "260:\tlearn: 1688.6981816\ttotal: 30.8s\tremaining: 1m 27s\n",
      "261:\tlearn: 1688.1787966\ttotal: 30.9s\tremaining: 1m 26s\n",
      "262:\tlearn: 1687.9557786\ttotal: 31s\tremaining: 1m 26s\n",
      "263:\tlearn: 1687.8164772\ttotal: 31.1s\tremaining: 1m 26s\n",
      "264:\tlearn: 1687.3294317\ttotal: 31.2s\tremaining: 1m 26s\n",
      "265:\tlearn: 1687.0993507\ttotal: 31.3s\tremaining: 1m 26s\n",
      "266:\tlearn: 1686.7580327\ttotal: 31.4s\tremaining: 1m 26s\n",
      "267:\tlearn: 1686.0975251\ttotal: 31.5s\tremaining: 1m 26s\n",
      "268:\tlearn: 1685.6456687\ttotal: 31.6s\tremaining: 1m 25s\n",
      "269:\tlearn: 1685.1444525\ttotal: 31.7s\tremaining: 1m 25s\n",
      "270:\tlearn: 1684.7588634\ttotal: 31.9s\tremaining: 1m 25s\n",
      "271:\tlearn: 1684.4464145\ttotal: 31.9s\tremaining: 1m 25s\n",
      "272:\tlearn: 1683.9580009\ttotal: 32.1s\tremaining: 1m 25s\n",
      "273:\tlearn: 1683.8342773\ttotal: 32.2s\tremaining: 1m 25s\n",
      "274:\tlearn: 1683.6982554\ttotal: 32.3s\tremaining: 1m 25s\n",
      "275:\tlearn: 1683.2994004\ttotal: 32.4s\tremaining: 1m 24s\n",
      "276:\tlearn: 1682.8550975\ttotal: 32.5s\tremaining: 1m 24s\n",
      "277:\tlearn: 1682.5535384\ttotal: 32.6s\tremaining: 1m 24s\n",
      "278:\tlearn: 1682.2141865\ttotal: 32.7s\tremaining: 1m 24s\n",
      "279:\tlearn: 1681.9711912\ttotal: 32.9s\tremaining: 1m 24s\n",
      "280:\tlearn: 1681.3856416\ttotal: 33s\tremaining: 1m 24s\n",
      "281:\tlearn: 1681.0251129\ttotal: 33.1s\tremaining: 1m 24s\n",
      "282:\tlearn: 1680.6390208\ttotal: 33.2s\tremaining: 1m 24s\n",
      "283:\tlearn: 1680.3930116\ttotal: 33.3s\tremaining: 1m 24s\n",
      "284:\tlearn: 1680.2243962\ttotal: 33.4s\tremaining: 1m 23s\n",
      "285:\tlearn: 1679.8997418\ttotal: 33.6s\tremaining: 1m 23s\n",
      "286:\tlearn: 1679.5205376\ttotal: 33.7s\tremaining: 1m 23s\n",
      "287:\tlearn: 1679.0861718\ttotal: 33.8s\tremaining: 1m 23s\n",
      "288:\tlearn: 1678.7590340\ttotal: 33.9s\tremaining: 1m 23s\n",
      "289:\tlearn: 1678.2586909\ttotal: 34s\tremaining: 1m 23s\n",
      "290:\tlearn: 1678.0704222\ttotal: 34.2s\tremaining: 1m 23s\n",
      "291:\tlearn: 1677.7595522\ttotal: 34.3s\tremaining: 1m 23s\n",
      "292:\tlearn: 1677.4785505\ttotal: 34.4s\tremaining: 1m 23s\n",
      "293:\tlearn: 1677.3381334\ttotal: 34.5s\tremaining: 1m 22s\n",
      "294:\tlearn: 1676.9156998\ttotal: 34.6s\tremaining: 1m 22s\n",
      "295:\tlearn: 1676.7387862\ttotal: 34.7s\tremaining: 1m 22s\n",
      "296:\tlearn: 1676.5506573\ttotal: 34.9s\tremaining: 1m 22s\n",
      "297:\tlearn: 1676.1851863\ttotal: 35s\tremaining: 1m 22s\n",
      "298:\tlearn: 1676.0016292\ttotal: 35.1s\tremaining: 1m 22s\n",
      "299:\tlearn: 1675.6366824\ttotal: 35.2s\tremaining: 1m 22s\n",
      "300:\tlearn: 1675.2452652\ttotal: 35.3s\tremaining: 1m 22s\n",
      "301:\tlearn: 1674.7893707\ttotal: 35.5s\tremaining: 1m 21s\n",
      "302:\tlearn: 1674.4626359\ttotal: 35.6s\tremaining: 1m 21s\n",
      "303:\tlearn: 1674.1472323\ttotal: 35.7s\tremaining: 1m 21s\n",
      "304:\tlearn: 1673.6448145\ttotal: 35.9s\tremaining: 1m 21s\n",
      "305:\tlearn: 1673.4267147\ttotal: 36s\tremaining: 1m 21s\n",
      "306:\tlearn: 1673.1362452\ttotal: 36.1s\tremaining: 1m 21s\n",
      "307:\tlearn: 1672.7703324\ttotal: 36.2s\tremaining: 1m 21s\n",
      "308:\tlearn: 1672.4874060\ttotal: 36.3s\tremaining: 1m 21s\n",
      "309:\tlearn: 1672.1392261\ttotal: 36.5s\tremaining: 1m 21s\n",
      "310:\tlearn: 1671.7868746\ttotal: 36.6s\tremaining: 1m 21s\n",
      "311:\tlearn: 1670.9835796\ttotal: 36.7s\tremaining: 1m 20s\n",
      "312:\tlearn: 1670.7632583\ttotal: 36.8s\tremaining: 1m 20s\n",
      "313:\tlearn: 1670.4984426\ttotal: 37s\tremaining: 1m 20s\n",
      "314:\tlearn: 1670.1809357\ttotal: 37.1s\tremaining: 1m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315:\tlearn: 1669.9969412\ttotal: 37.2s\tremaining: 1m 20s\n",
      "316:\tlearn: 1669.8200787\ttotal: 37.3s\tremaining: 1m 20s\n",
      "317:\tlearn: 1669.5313480\ttotal: 37.4s\tremaining: 1m 20s\n",
      "318:\tlearn: 1669.1192552\ttotal: 37.6s\tremaining: 1m 20s\n",
      "319:\tlearn: 1668.8314190\ttotal: 37.7s\tremaining: 1m 20s\n",
      "320:\tlearn: 1668.5525836\ttotal: 37.8s\tremaining: 1m 19s\n",
      "321:\tlearn: 1668.1795610\ttotal: 37.9s\tremaining: 1m 19s\n",
      "322:\tlearn: 1668.0678285\ttotal: 38s\tremaining: 1m 19s\n",
      "323:\tlearn: 1667.6892281\ttotal: 38.1s\tremaining: 1m 19s\n",
      "324:\tlearn: 1667.2731939\ttotal: 38.2s\tremaining: 1m 19s\n",
      "325:\tlearn: 1666.9297539\ttotal: 38.3s\tremaining: 1m 19s\n",
      "326:\tlearn: 1666.6044997\ttotal: 38.4s\tremaining: 1m 19s\n",
      "327:\tlearn: 1666.4789684\ttotal: 38.5s\tremaining: 1m 18s\n",
      "328:\tlearn: 1666.2149443\ttotal: 38.6s\tremaining: 1m 18s\n",
      "329:\tlearn: 1665.9619367\ttotal: 38.7s\tremaining: 1m 18s\n",
      "330:\tlearn: 1665.7148701\ttotal: 38.8s\tremaining: 1m 18s\n",
      "331:\tlearn: 1665.5671833\ttotal: 38.9s\tremaining: 1m 18s\n",
      "332:\tlearn: 1665.2843247\ttotal: 39s\tremaining: 1m 18s\n",
      "333:\tlearn: 1665.0574654\ttotal: 39.1s\tremaining: 1m 18s\n",
      "334:\tlearn: 1664.9467531\ttotal: 39.2s\tremaining: 1m 17s\n",
      "335:\tlearn: 1664.7921070\ttotal: 39.3s\tremaining: 1m 17s\n",
      "336:\tlearn: 1664.4153169\ttotal: 39.4s\tremaining: 1m 17s\n",
      "337:\tlearn: 1663.8925663\ttotal: 39.6s\tremaining: 1m 17s\n",
      "338:\tlearn: 1663.4783341\ttotal: 39.7s\tremaining: 1m 17s\n",
      "339:\tlearn: 1663.2544432\ttotal: 39.9s\tremaining: 1m 17s\n",
      "340:\tlearn: 1662.9953644\ttotal: 40s\tremaining: 1m 17s\n",
      "341:\tlearn: 1662.3865572\ttotal: 40.1s\tremaining: 1m 17s\n",
      "342:\tlearn: 1662.0688889\ttotal: 40.2s\tremaining: 1m 16s\n",
      "343:\tlearn: 1661.4135285\ttotal: 40.3s\tremaining: 1m 16s\n",
      "344:\tlearn: 1661.1729264\ttotal: 40.4s\tremaining: 1m 16s\n",
      "345:\tlearn: 1660.9847157\ttotal: 40.5s\tremaining: 1m 16s\n",
      "346:\tlearn: 1660.8859563\ttotal: 40.6s\tremaining: 1m 16s\n",
      "347:\tlearn: 1660.4370162\ttotal: 40.8s\tremaining: 1m 16s\n",
      "348:\tlearn: 1659.9999948\ttotal: 40.8s\tremaining: 1m 16s\n",
      "349:\tlearn: 1659.6452955\ttotal: 41s\tremaining: 1m 16s\n",
      "350:\tlearn: 1659.3954922\ttotal: 41.1s\tremaining: 1m 15s\n",
      "351:\tlearn: 1658.9754188\ttotal: 41.2s\tremaining: 1m 15s\n",
      "352:\tlearn: 1658.7745122\ttotal: 41.3s\tremaining: 1m 15s\n",
      "353:\tlearn: 1658.5020343\ttotal: 41.4s\tremaining: 1m 15s\n",
      "354:\tlearn: 1658.1015931\ttotal: 41.5s\tremaining: 1m 15s\n",
      "355:\tlearn: 1657.8475096\ttotal: 41.7s\tremaining: 1m 15s\n",
      "356:\tlearn: 1657.6731532\ttotal: 41.8s\tremaining: 1m 15s\n",
      "357:\tlearn: 1657.3478125\ttotal: 41.9s\tremaining: 1m 15s\n",
      "358:\tlearn: 1657.1253350\ttotal: 41.9s\tremaining: 1m 14s\n",
      "359:\tlearn: 1656.8879131\ttotal: 42.1s\tremaining: 1m 14s\n",
      "360:\tlearn: 1656.6484542\ttotal: 42.2s\tremaining: 1m 14s\n",
      "361:\tlearn: 1656.2766192\ttotal: 42.3s\tremaining: 1m 14s\n",
      "362:\tlearn: 1655.8282220\ttotal: 42.4s\tremaining: 1m 14s\n",
      "363:\tlearn: 1655.5789151\ttotal: 42.5s\tremaining: 1m 14s\n",
      "364:\tlearn: 1655.0714461\ttotal: 42.6s\tremaining: 1m 14s\n",
      "365:\tlearn: 1654.9069146\ttotal: 42.8s\tremaining: 1m 14s\n",
      "366:\tlearn: 1654.7232577\ttotal: 42.9s\tremaining: 1m 13s\n",
      "367:\tlearn: 1654.5404270\ttotal: 43s\tremaining: 1m 13s\n",
      "368:\tlearn: 1654.1223335\ttotal: 43.1s\tremaining: 1m 13s\n",
      "369:\tlearn: 1653.8191143\ttotal: 43.3s\tremaining: 1m 13s\n",
      "370:\tlearn: 1653.6575828\ttotal: 43.4s\tremaining: 1m 13s\n",
      "371:\tlearn: 1653.4961591\ttotal: 43.5s\tremaining: 1m 13s\n",
      "372:\tlearn: 1653.3032721\ttotal: 43.6s\tremaining: 1m 13s\n",
      "373:\tlearn: 1652.9870234\ttotal: 43.7s\tremaining: 1m 13s\n",
      "374:\tlearn: 1652.8680916\ttotal: 43.8s\tremaining: 1m 13s\n",
      "375:\tlearn: 1652.5180196\ttotal: 43.9s\tremaining: 1m 12s\n",
      "376:\tlearn: 1652.3961110\ttotal: 44s\tremaining: 1m 12s\n",
      "377:\tlearn: 1652.2013407\ttotal: 44.1s\tremaining: 1m 12s\n",
      "378:\tlearn: 1652.0365934\ttotal: 44.3s\tremaining: 1m 12s\n",
      "379:\tlearn: 1651.6832341\ttotal: 44.4s\tremaining: 1m 12s\n",
      "380:\tlearn: 1651.4053959\ttotal: 44.5s\tremaining: 1m 12s\n",
      "381:\tlearn: 1651.3370283\ttotal: 44.6s\tremaining: 1m 12s\n",
      "382:\tlearn: 1651.0055587\ttotal: 44.7s\tremaining: 1m 12s\n",
      "383:\tlearn: 1650.6716826\ttotal: 44.8s\tremaining: 1m 11s\n",
      "384:\tlearn: 1650.3191991\ttotal: 45s\tremaining: 1m 11s\n",
      "385:\tlearn: 1649.9069390\ttotal: 45.1s\tremaining: 1m 11s\n",
      "386:\tlearn: 1649.3832964\ttotal: 45.2s\tremaining: 1m 11s\n",
      "387:\tlearn: 1649.1803206\ttotal: 45.4s\tremaining: 1m 11s\n",
      "388:\tlearn: 1648.9174588\ttotal: 45.5s\tremaining: 1m 11s\n",
      "389:\tlearn: 1648.7573112\ttotal: 45.6s\tremaining: 1m 11s\n",
      "390:\tlearn: 1648.3086583\ttotal: 45.7s\tremaining: 1m 11s\n",
      "391:\tlearn: 1648.0129461\ttotal: 45.8s\tremaining: 1m 11s\n",
      "392:\tlearn: 1647.5264916\ttotal: 45.9s\tremaining: 1m 10s\n",
      "393:\tlearn: 1647.0518571\ttotal: 46.1s\tremaining: 1m 10s\n",
      "394:\tlearn: 1646.4877008\ttotal: 46.2s\tremaining: 1m 10s\n",
      "395:\tlearn: 1646.2244962\ttotal: 46.3s\tremaining: 1m 10s\n",
      "396:\tlearn: 1646.0690514\ttotal: 46.4s\tremaining: 1m 10s\n",
      "397:\tlearn: 1645.7415996\ttotal: 46.5s\tremaining: 1m 10s\n",
      "398:\tlearn: 1645.5942629\ttotal: 46.7s\tremaining: 1m 10s\n",
      "399:\tlearn: 1645.3724577\ttotal: 46.8s\tremaining: 1m 10s\n",
      "400:\tlearn: 1645.1497597\ttotal: 46.9s\tremaining: 1m 10s\n",
      "401:\tlearn: 1644.9078264\ttotal: 47s\tremaining: 1m 9s\n",
      "402:\tlearn: 1644.5775280\ttotal: 47.2s\tremaining: 1m 9s\n",
      "403:\tlearn: 1644.2130504\ttotal: 47.3s\tremaining: 1m 9s\n",
      "404:\tlearn: 1644.0635884\ttotal: 47.4s\tremaining: 1m 9s\n",
      "405:\tlearn: 1643.8473401\ttotal: 47.5s\tremaining: 1m 9s\n",
      "406:\tlearn: 1643.6072952\ttotal: 47.7s\tremaining: 1m 9s\n",
      "407:\tlearn: 1643.2845770\ttotal: 47.8s\tremaining: 1m 9s\n",
      "408:\tlearn: 1643.0114478\ttotal: 47.9s\tremaining: 1m 9s\n",
      "409:\tlearn: 1642.8616035\ttotal: 48.1s\tremaining: 1m 9s\n",
      "410:\tlearn: 1642.5102688\ttotal: 48.2s\tremaining: 1m 9s\n",
      "411:\tlearn: 1642.2333454\ttotal: 48.4s\tremaining: 1m 9s\n",
      "412:\tlearn: 1641.8836090\ttotal: 48.5s\tremaining: 1m 8s\n",
      "413:\tlearn: 1641.8248052\ttotal: 48.6s\tremaining: 1m 8s\n",
      "414:\tlearn: 1641.6571096\ttotal: 48.7s\tremaining: 1m 8s\n",
      "415:\tlearn: 1641.3033118\ttotal: 48.9s\tremaining: 1m 8s\n",
      "416:\tlearn: 1640.9033487\ttotal: 49s\tremaining: 1m 8s\n",
      "417:\tlearn: 1640.7590235\ttotal: 49.2s\tremaining: 1m 8s\n",
      "418:\tlearn: 1640.6652589\ttotal: 49.3s\tremaining: 1m 8s\n",
      "419:\tlearn: 1640.5043885\ttotal: 49.4s\tremaining: 1m 8s\n",
      "420:\tlearn: 1640.3243243\ttotal: 49.5s\tremaining: 1m 8s\n",
      "421:\tlearn: 1640.1972199\ttotal: 49.6s\tremaining: 1m 7s\n",
      "422:\tlearn: 1639.9520812\ttotal: 49.8s\tremaining: 1m 7s\n",
      "423:\tlearn: 1639.7184539\ttotal: 49.9s\tremaining: 1m 7s\n",
      "424:\tlearn: 1639.6502171\ttotal: 50.1s\tremaining: 1m 7s\n",
      "425:\tlearn: 1639.3152616\ttotal: 50.2s\tremaining: 1m 7s\n",
      "426:\tlearn: 1638.5400662\ttotal: 50.3s\tremaining: 1m 7s\n",
      "427:\tlearn: 1638.3480938\ttotal: 50.5s\tremaining: 1m 7s\n",
      "428:\tlearn: 1638.0179366\ttotal: 50.6s\tremaining: 1m 7s\n",
      "429:\tlearn: 1637.6428287\ttotal: 50.7s\tremaining: 1m 7s\n",
      "430:\tlearn: 1637.4873043\ttotal: 50.9s\tremaining: 1m 7s\n",
      "431:\tlearn: 1637.4279813\ttotal: 51s\tremaining: 1m 7s\n",
      "432:\tlearn: 1637.2464434\ttotal: 51.1s\tremaining: 1m 6s\n",
      "433:\tlearn: 1637.1600030\ttotal: 51.3s\tremaining: 1m 6s\n",
      "434:\tlearn: 1637.1227353\ttotal: 51.4s\tremaining: 1m 6s\n",
      "435:\tlearn: 1636.6936950\ttotal: 51.6s\tremaining: 1m 6s\n",
      "436:\tlearn: 1636.4302782\ttotal: 51.7s\tremaining: 1m 6s\n",
      "437:\tlearn: 1636.2916980\ttotal: 51.8s\tremaining: 1m 6s\n",
      "438:\tlearn: 1636.1355875\ttotal: 52s\tremaining: 1m 6s\n",
      "439:\tlearn: 1636.0309952\ttotal: 52.1s\tremaining: 1m 6s\n",
      "440:\tlearn: 1635.7302479\ttotal: 52.3s\tremaining: 1m 6s\n",
      "441:\tlearn: 1635.6432948\ttotal: 52.4s\tremaining: 1m 6s\n",
      "442:\tlearn: 1635.4990305\ttotal: 52.6s\tremaining: 1m 6s\n",
      "443:\tlearn: 1635.2834913\ttotal: 52.7s\tremaining: 1m 5s\n",
      "444:\tlearn: 1635.1497798\ttotal: 52.9s\tremaining: 1m 5s\n",
      "445:\tlearn: 1635.0081953\ttotal: 53s\tremaining: 1m 5s\n",
      "446:\tlearn: 1634.8095761\ttotal: 53.1s\tremaining: 1m 5s\n",
      "447:\tlearn: 1634.7643977\ttotal: 53.3s\tremaining: 1m 5s\n",
      "448:\tlearn: 1634.6292747\ttotal: 53.4s\tremaining: 1m 5s\n",
      "449:\tlearn: 1634.4368925\ttotal: 53.6s\tremaining: 1m 5s\n",
      "450:\tlearn: 1634.1662911\ttotal: 53.7s\tremaining: 1m 5s\n",
      "451:\tlearn: 1634.0445415\ttotal: 53.8s\tremaining: 1m 5s\n",
      "452:\tlearn: 1633.7934432\ttotal: 54s\tremaining: 1m 5s\n",
      "453:\tlearn: 1633.5258572\ttotal: 54.1s\tremaining: 1m 5s\n",
      "454:\tlearn: 1633.2464140\ttotal: 54.2s\tremaining: 1m 4s\n",
      "455:\tlearn: 1632.9176328\ttotal: 54.4s\tremaining: 1m 4s\n",
      "456:\tlearn: 1632.6773636\ttotal: 54.5s\tremaining: 1m 4s\n",
      "457:\tlearn: 1632.5393517\ttotal: 54.6s\tremaining: 1m 4s\n",
      "458:\tlearn: 1632.3043590\ttotal: 54.8s\tremaining: 1m 4s\n",
      "459:\tlearn: 1632.0336925\ttotal: 54.9s\tremaining: 1m 4s\n",
      "460:\tlearn: 1631.6414693\ttotal: 55.1s\tremaining: 1m 4s\n",
      "461:\tlearn: 1631.3411875\ttotal: 55.2s\tremaining: 1m 4s\n",
      "462:\tlearn: 1631.1900062\ttotal: 55.3s\tremaining: 1m 4s\n",
      "463:\tlearn: 1630.9460412\ttotal: 55.5s\tremaining: 1m 4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464:\tlearn: 1630.9117626\ttotal: 55.6s\tremaining: 1m 3s\n",
      "465:\tlearn: 1630.6421139\ttotal: 55.7s\tremaining: 1m 3s\n",
      "466:\tlearn: 1630.3273420\ttotal: 55.9s\tremaining: 1m 3s\n",
      "467:\tlearn: 1629.9571778\ttotal: 56s\tremaining: 1m 3s\n",
      "468:\tlearn: 1629.6338301\ttotal: 56.2s\tremaining: 1m 3s\n",
      "469:\tlearn: 1629.3681566\ttotal: 56.3s\tremaining: 1m 3s\n",
      "470:\tlearn: 1628.9791936\ttotal: 56.4s\tremaining: 1m 3s\n",
      "471:\tlearn: 1628.6437342\ttotal: 56.5s\tremaining: 1m 3s\n",
      "472:\tlearn: 1628.5037265\ttotal: 56.7s\tremaining: 1m 3s\n",
      "473:\tlearn: 1628.2386059\ttotal: 56.9s\tremaining: 1m 3s\n",
      "474:\tlearn: 1627.9777227\ttotal: 57s\tremaining: 1m 2s\n",
      "475:\tlearn: 1627.6785523\ttotal: 57.1s\tremaining: 1m 2s\n",
      "476:\tlearn: 1627.3408836\ttotal: 57.2s\tremaining: 1m 2s\n",
      "477:\tlearn: 1627.1162003\ttotal: 57.3s\tremaining: 1m 2s\n",
      "478:\tlearn: 1626.8085595\ttotal: 57.4s\tremaining: 1m 2s\n",
      "479:\tlearn: 1626.6525256\ttotal: 57.6s\tremaining: 1m 2s\n",
      "480:\tlearn: 1626.2310269\ttotal: 57.7s\tremaining: 1m 2s\n",
      "481:\tlearn: 1626.0511582\ttotal: 57.8s\tremaining: 1m 2s\n",
      "482:\tlearn: 1625.9435300\ttotal: 57.9s\tremaining: 1m 2s\n",
      "483:\tlearn: 1625.6868145\ttotal: 58s\tremaining: 1m 1s\n",
      "484:\tlearn: 1625.4625666\ttotal: 58.2s\tremaining: 1m 1s\n",
      "485:\tlearn: 1625.0052049\ttotal: 58.3s\tremaining: 1m 1s\n",
      "486:\tlearn: 1624.7953452\ttotal: 58.4s\tremaining: 1m 1s\n",
      "487:\tlearn: 1624.4998777\ttotal: 58.5s\tremaining: 1m 1s\n",
      "488:\tlearn: 1624.2145507\ttotal: 58.6s\tremaining: 1m 1s\n",
      "489:\tlearn: 1623.9366166\ttotal: 58.7s\tremaining: 1m 1s\n",
      "490:\tlearn: 1623.8754513\ttotal: 58.8s\tremaining: 1m\n",
      "491:\tlearn: 1623.7597874\ttotal: 58.9s\tremaining: 1m\n",
      "492:\tlearn: 1623.5624517\ttotal: 59.1s\tremaining: 1m\n",
      "493:\tlearn: 1623.4188545\ttotal: 59.2s\tremaining: 1m\n",
      "494:\tlearn: 1623.1824124\ttotal: 59.3s\tremaining: 1m\n",
      "495:\tlearn: 1622.9370372\ttotal: 59.5s\tremaining: 1m\n",
      "496:\tlearn: 1622.6852986\ttotal: 59.6s\tremaining: 1m\n",
      "497:\tlearn: 1622.5858595\ttotal: 59.8s\tremaining: 1m\n",
      "498:\tlearn: 1622.4549756\ttotal: 59.9s\tremaining: 1m\n",
      "499:\tlearn: 1621.9765805\ttotal: 1m\tremaining: 1m\n",
      "500:\tlearn: 1621.7209642\ttotal: 1m\tremaining: 59.9s\n",
      "501:\tlearn: 1621.4413259\ttotal: 1m\tremaining: 59.7s\n",
      "502:\tlearn: 1621.2857245\ttotal: 1m\tremaining: 59.6s\n",
      "503:\tlearn: 1621.0240958\ttotal: 1m\tremaining: 59.5s\n",
      "504:\tlearn: 1620.9342899\ttotal: 1m\tremaining: 59.3s\n",
      "505:\tlearn: 1620.7976164\ttotal: 1m\tremaining: 59.2s\n",
      "506:\tlearn: 1620.4940243\ttotal: 1m\tremaining: 59.1s\n",
      "507:\tlearn: 1620.2896447\ttotal: 1m\tremaining: 59s\n",
      "508:\tlearn: 1620.2115826\ttotal: 1m 1s\tremaining: 58.9s\n",
      "509:\tlearn: 1620.0616841\ttotal: 1m 1s\tremaining: 58.7s\n",
      "510:\tlearn: 1619.8214399\ttotal: 1m 1s\tremaining: 58.6s\n",
      "511:\tlearn: 1619.5950354\ttotal: 1m 1s\tremaining: 58.5s\n",
      "512:\tlearn: 1619.5274073\ttotal: 1m 1s\tremaining: 58.4s\n",
      "513:\tlearn: 1619.3935109\ttotal: 1m 1s\tremaining: 58.2s\n",
      "514:\tlearn: 1619.0776897\ttotal: 1m 1s\tremaining: 58.1s\n",
      "515:\tlearn: 1618.9216811\ttotal: 1m 1s\tremaining: 58s\n",
      "516:\tlearn: 1618.7391735\ttotal: 1m 1s\tremaining: 57.8s\n",
      "517:\tlearn: 1618.6304863\ttotal: 1m 1s\tremaining: 57.7s\n",
      "518:\tlearn: 1618.5672957\ttotal: 1m 2s\tremaining: 57.5s\n",
      "519:\tlearn: 1618.2766117\ttotal: 1m 2s\tremaining: 57.4s\n",
      "520:\tlearn: 1618.0504732\ttotal: 1m 2s\tremaining: 57.3s\n",
      "521:\tlearn: 1617.9487101\ttotal: 1m 2s\tremaining: 57.2s\n",
      "522:\tlearn: 1617.6477598\ttotal: 1m 2s\tremaining: 57s\n",
      "523:\tlearn: 1617.3123404\ttotal: 1m 2s\tremaining: 57s\n",
      "524:\tlearn: 1617.1564234\ttotal: 1m 2s\tremaining: 56.8s\n",
      "525:\tlearn: 1617.0662128\ttotal: 1m 2s\tremaining: 56.7s\n",
      "526:\tlearn: 1616.9606015\ttotal: 1m 3s\tremaining: 56.6s\n",
      "527:\tlearn: 1616.8210213\ttotal: 1m 3s\tremaining: 56.5s\n",
      "528:\tlearn: 1616.5855037\ttotal: 1m 3s\tremaining: 56.3s\n",
      "529:\tlearn: 1616.4760337\ttotal: 1m 3s\tremaining: 56.2s\n",
      "530:\tlearn: 1616.3745113\ttotal: 1m 3s\tremaining: 56.1s\n",
      "531:\tlearn: 1616.2737078\ttotal: 1m 3s\tremaining: 56s\n",
      "532:\tlearn: 1615.9096230\ttotal: 1m 3s\tremaining: 55.9s\n",
      "533:\tlearn: 1615.8368359\ttotal: 1m 3s\tremaining: 55.7s\n",
      "534:\tlearn: 1615.6619767\ttotal: 1m 3s\tremaining: 55.6s\n",
      "535:\tlearn: 1615.5274248\ttotal: 1m 4s\tremaining: 55.5s\n",
      "536:\tlearn: 1615.3513192\ttotal: 1m 4s\tremaining: 55.4s\n",
      "537:\tlearn: 1615.2808749\ttotal: 1m 4s\tremaining: 55.3s\n",
      "538:\tlearn: 1615.1367560\ttotal: 1m 4s\tremaining: 55.1s\n",
      "539:\tlearn: 1614.9031937\ttotal: 1m 4s\tremaining: 55s\n",
      "540:\tlearn: 1614.6345004\ttotal: 1m 4s\tremaining: 54.9s\n",
      "541:\tlearn: 1614.4321205\ttotal: 1m 4s\tremaining: 54.8s\n",
      "542:\tlearn: 1614.0224970\ttotal: 1m 4s\tremaining: 54.7s\n",
      "543:\tlearn: 1613.8777780\ttotal: 1m 5s\tremaining: 54.6s\n",
      "544:\tlearn: 1613.6512324\ttotal: 1m 5s\tremaining: 54.4s\n",
      "545:\tlearn: 1613.0183987\ttotal: 1m 5s\tremaining: 54.3s\n",
      "546:\tlearn: 1612.8489532\ttotal: 1m 5s\tremaining: 54.2s\n",
      "547:\tlearn: 1612.6151822\ttotal: 1m 5s\tremaining: 54.1s\n",
      "548:\tlearn: 1612.4702597\ttotal: 1m 5s\tremaining: 54s\n",
      "549:\tlearn: 1612.2839818\ttotal: 1m 5s\tremaining: 53.9s\n",
      "550:\tlearn: 1612.2213422\ttotal: 1m 5s\tremaining: 53.7s\n",
      "551:\tlearn: 1612.0667661\ttotal: 1m 6s\tremaining: 53.6s\n",
      "552:\tlearn: 1611.9483984\ttotal: 1m 6s\tremaining: 53.5s\n",
      "553:\tlearn: 1611.7236614\ttotal: 1m 6s\tremaining: 53.4s\n",
      "554:\tlearn: 1611.1799277\ttotal: 1m 6s\tremaining: 53.3s\n",
      "555:\tlearn: 1611.0729771\ttotal: 1m 6s\tremaining: 53.2s\n",
      "556:\tlearn: 1611.0120168\ttotal: 1m 6s\tremaining: 53.1s\n",
      "557:\tlearn: 1610.7660613\ttotal: 1m 6s\tremaining: 53s\n",
      "558:\tlearn: 1610.4300873\ttotal: 1m 6s\tremaining: 52.8s\n",
      "559:\tlearn: 1610.1436902\ttotal: 1m 7s\tremaining: 52.7s\n",
      "560:\tlearn: 1610.0208459\ttotal: 1m 7s\tremaining: 52.6s\n",
      "561:\tlearn: 1609.7497409\ttotal: 1m 7s\tremaining: 52.5s\n",
      "562:\tlearn: 1609.5455308\ttotal: 1m 7s\tremaining: 52.4s\n",
      "563:\tlearn: 1609.2584612\ttotal: 1m 7s\tremaining: 52.3s\n",
      "564:\tlearn: 1609.0819244\ttotal: 1m 7s\tremaining: 52.2s\n",
      "565:\tlearn: 1608.9726961\ttotal: 1m 7s\tremaining: 52.1s\n",
      "566:\tlearn: 1608.9440827\ttotal: 1m 8s\tremaining: 52s\n",
      "567:\tlearn: 1608.8615858\ttotal: 1m 8s\tremaining: 51.8s\n",
      "568:\tlearn: 1608.7192973\ttotal: 1m 8s\tremaining: 51.7s\n",
      "569:\tlearn: 1608.5380362\ttotal: 1m 8s\tremaining: 51.6s\n",
      "570:\tlearn: 1608.2300203\ttotal: 1m 8s\tremaining: 51.5s\n",
      "571:\tlearn: 1608.1857385\ttotal: 1m 8s\tremaining: 51.4s\n",
      "572:\tlearn: 1608.1454754\ttotal: 1m 8s\tremaining: 51.2s\n",
      "573:\tlearn: 1608.0896167\ttotal: 1m 8s\tremaining: 51.1s\n",
      "574:\tlearn: 1607.8773557\ttotal: 1m 9s\tremaining: 51s\n",
      "575:\tlearn: 1607.7482132\ttotal: 1m 9s\tremaining: 50.9s\n",
      "576:\tlearn: 1607.2391463\ttotal: 1m 9s\tremaining: 50.8s\n",
      "577:\tlearn: 1607.0689379\ttotal: 1m 9s\tremaining: 50.7s\n",
      "578:\tlearn: 1606.8053471\ttotal: 1m 9s\tremaining: 50.6s\n",
      "579:\tlearn: 1606.6076097\ttotal: 1m 9s\tremaining: 50.5s\n",
      "580:\tlearn: 1606.3998701\ttotal: 1m 9s\tremaining: 50.4s\n",
      "581:\tlearn: 1606.2641726\ttotal: 1m 9s\tremaining: 50.2s\n",
      "582:\tlearn: 1606.1720038\ttotal: 1m 10s\tremaining: 50.1s\n",
      "583:\tlearn: 1605.9422555\ttotal: 1m 10s\tremaining: 50s\n",
      "584:\tlearn: 1605.6679350\ttotal: 1m 10s\tremaining: 49.9s\n",
      "585:\tlearn: 1605.4720482\ttotal: 1m 10s\tremaining: 49.8s\n",
      "586:\tlearn: 1605.3823514\ttotal: 1m 10s\tremaining: 49.7s\n",
      "587:\tlearn: 1605.2253774\ttotal: 1m 10s\tremaining: 49.6s\n",
      "588:\tlearn: 1605.0897470\ttotal: 1m 10s\tremaining: 49.5s\n",
      "589:\tlearn: 1605.0177680\ttotal: 1m 11s\tremaining: 49.4s\n",
      "590:\tlearn: 1604.7917316\ttotal: 1m 11s\tremaining: 49.3s\n",
      "591:\tlearn: 1604.5892145\ttotal: 1m 11s\tremaining: 49.2s\n",
      "592:\tlearn: 1604.3952230\ttotal: 1m 11s\tremaining: 49s\n",
      "593:\tlearn: 1604.3237154\ttotal: 1m 11s\tremaining: 48.9s\n",
      "594:\tlearn: 1604.0695695\ttotal: 1m 11s\tremaining: 48.8s\n",
      "595:\tlearn: 1603.9606282\ttotal: 1m 11s\tremaining: 48.7s\n",
      "596:\tlearn: 1603.8584989\ttotal: 1m 12s\tremaining: 48.6s\n",
      "597:\tlearn: 1603.6725243\ttotal: 1m 12s\tremaining: 48.5s\n",
      "598:\tlearn: 1603.5577973\ttotal: 1m 12s\tremaining: 48.4s\n",
      "599:\tlearn: 1603.5263880\ttotal: 1m 12s\tremaining: 48.3s\n",
      "600:\tlearn: 1603.2186908\ttotal: 1m 12s\tremaining: 48.2s\n",
      "601:\tlearn: 1603.0895357\ttotal: 1m 12s\tremaining: 48s\n",
      "602:\tlearn: 1602.9707382\ttotal: 1m 12s\tremaining: 47.9s\n",
      "603:\tlearn: 1602.8721854\ttotal: 1m 12s\tremaining: 47.8s\n",
      "604:\tlearn: 1602.7713087\ttotal: 1m 13s\tremaining: 47.7s\n",
      "605:\tlearn: 1602.5851808\ttotal: 1m 13s\tremaining: 47.6s\n",
      "606:\tlearn: 1602.5347598\ttotal: 1m 13s\tremaining: 47.5s\n",
      "607:\tlearn: 1602.4033202\ttotal: 1m 13s\tremaining: 47.4s\n",
      "608:\tlearn: 1602.1552494\ttotal: 1m 13s\tremaining: 47.3s\n",
      "609:\tlearn: 1601.9776332\ttotal: 1m 13s\tremaining: 47.1s\n",
      "610:\tlearn: 1601.8375032\ttotal: 1m 13s\tremaining: 47s\n",
      "611:\tlearn: 1601.5682641\ttotal: 1m 14s\tremaining: 46.9s\n",
      "612:\tlearn: 1601.5073607\ttotal: 1m 14s\tremaining: 46.8s\n",
      "613:\tlearn: 1601.3670248\ttotal: 1m 14s\tremaining: 46.7s\n",
      "614:\tlearn: 1601.1305749\ttotal: 1m 14s\tremaining: 46.6s\n",
      "615:\tlearn: 1600.8949639\ttotal: 1m 14s\tremaining: 46.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616:\tlearn: 1600.6924527\ttotal: 1m 14s\tremaining: 46.4s\n",
      "617:\tlearn: 1600.5161860\ttotal: 1m 14s\tremaining: 46.3s\n",
      "618:\tlearn: 1600.3426808\ttotal: 1m 15s\tremaining: 46.2s\n",
      "619:\tlearn: 1600.2338160\ttotal: 1m 15s\tremaining: 46.1s\n",
      "620:\tlearn: 1600.1545617\ttotal: 1m 15s\tremaining: 46s\n",
      "621:\tlearn: 1599.8349455\ttotal: 1m 15s\tremaining: 45.8s\n",
      "622:\tlearn: 1599.6610453\ttotal: 1m 15s\tremaining: 45.7s\n",
      "623:\tlearn: 1599.5515170\ttotal: 1m 15s\tremaining: 45.6s\n",
      "624:\tlearn: 1599.3065965\ttotal: 1m 15s\tremaining: 45.5s\n",
      "625:\tlearn: 1599.1251387\ttotal: 1m 16s\tremaining: 45.4s\n",
      "626:\tlearn: 1598.9171893\ttotal: 1m 16s\tremaining: 45.3s\n",
      "627:\tlearn: 1598.8594568\ttotal: 1m 16s\tremaining: 45.2s\n",
      "628:\tlearn: 1598.8040608\ttotal: 1m 16s\tremaining: 45.1s\n",
      "629:\tlearn: 1598.7543542\ttotal: 1m 16s\tremaining: 45s\n",
      "630:\tlearn: 1598.6696634\ttotal: 1m 16s\tremaining: 44.9s\n",
      "631:\tlearn: 1598.5408714\ttotal: 1m 16s\tremaining: 44.8s\n",
      "632:\tlearn: 1598.3264210\ttotal: 1m 17s\tremaining: 44.7s\n",
      "633:\tlearn: 1598.2562631\ttotal: 1m 17s\tremaining: 44.5s\n",
      "634:\tlearn: 1598.1981323\ttotal: 1m 17s\tremaining: 44.4s\n",
      "635:\tlearn: 1598.0615520\ttotal: 1m 17s\tremaining: 44.3s\n",
      "636:\tlearn: 1597.9760978\ttotal: 1m 17s\tremaining: 44.3s\n",
      "637:\tlearn: 1597.8945254\ttotal: 1m 17s\tremaining: 44.2s\n",
      "638:\tlearn: 1597.7781874\ttotal: 1m 17s\tremaining: 44.1s\n",
      "639:\tlearn: 1597.6826897\ttotal: 1m 18s\tremaining: 43.9s\n",
      "640:\tlearn: 1597.4502386\ttotal: 1m 18s\tremaining: 43.8s\n",
      "641:\tlearn: 1597.3148012\ttotal: 1m 18s\tremaining: 43.7s\n",
      "642:\tlearn: 1597.2449214\ttotal: 1m 18s\tremaining: 43.6s\n",
      "643:\tlearn: 1597.0144773\ttotal: 1m 18s\tremaining: 43.5s\n",
      "644:\tlearn: 1596.9022222\ttotal: 1m 18s\tremaining: 43.4s\n",
      "645:\tlearn: 1596.8129680\ttotal: 1m 18s\tremaining: 43.3s\n",
      "646:\tlearn: 1596.6996872\ttotal: 1m 19s\tremaining: 43.1s\n",
      "647:\tlearn: 1596.5477964\ttotal: 1m 19s\tremaining: 43s\n",
      "648:\tlearn: 1596.4674733\ttotal: 1m 19s\tremaining: 42.9s\n",
      "649:\tlearn: 1596.3214036\ttotal: 1m 19s\tremaining: 42.8s\n",
      "650:\tlearn: 1596.1988238\ttotal: 1m 19s\tremaining: 42.7s\n",
      "651:\tlearn: 1596.0476668\ttotal: 1m 19s\tremaining: 42.5s\n",
      "652:\tlearn: 1595.9812819\ttotal: 1m 19s\tremaining: 42.4s\n",
      "653:\tlearn: 1595.7768888\ttotal: 1m 19s\tremaining: 42.3s\n",
      "654:\tlearn: 1595.7677883\ttotal: 1m 20s\tremaining: 42.2s\n",
      "655:\tlearn: 1595.5918983\ttotal: 1m 20s\tremaining: 42.1s\n",
      "656:\tlearn: 1595.4637006\ttotal: 1m 20s\tremaining: 42s\n",
      "657:\tlearn: 1595.3430834\ttotal: 1m 20s\tremaining: 41.9s\n",
      "658:\tlearn: 1595.2422459\ttotal: 1m 20s\tremaining: 41.7s\n",
      "659:\tlearn: 1595.0682633\ttotal: 1m 20s\tremaining: 41.6s\n",
      "660:\tlearn: 1594.7578635\ttotal: 1m 20s\tremaining: 41.5s\n",
      "661:\tlearn: 1594.6980265\ttotal: 1m 21s\tremaining: 41.4s\n",
      "662:\tlearn: 1594.4168384\ttotal: 1m 21s\tremaining: 41.3s\n",
      "663:\tlearn: 1594.2858751\ttotal: 1m 21s\tremaining: 41.1s\n",
      "664:\tlearn: 1593.9761045\ttotal: 1m 21s\tremaining: 41s\n",
      "665:\tlearn: 1593.8330505\ttotal: 1m 21s\tremaining: 40.9s\n",
      "666:\tlearn: 1593.7802683\ttotal: 1m 21s\tremaining: 40.8s\n",
      "667:\tlearn: 1593.5708728\ttotal: 1m 21s\tremaining: 40.6s\n",
      "668:\tlearn: 1593.4944402\ttotal: 1m 21s\tremaining: 40.5s\n",
      "669:\tlearn: 1593.2903393\ttotal: 1m 21s\tremaining: 40.4s\n",
      "670:\tlearn: 1593.1960099\ttotal: 1m 22s\tremaining: 40.3s\n",
      "671:\tlearn: 1593.0257509\ttotal: 1m 22s\tremaining: 40.1s\n",
      "672:\tlearn: 1592.8218960\ttotal: 1m 22s\tremaining: 40s\n",
      "673:\tlearn: 1592.7709861\ttotal: 1m 22s\tremaining: 39.9s\n",
      "674:\tlearn: 1592.6371872\ttotal: 1m 22s\tremaining: 39.7s\n",
      "675:\tlearn: 1592.2594647\ttotal: 1m 22s\tremaining: 39.6s\n",
      "676:\tlearn: 1592.1293995\ttotal: 1m 22s\tremaining: 39.5s\n",
      "677:\tlearn: 1592.0006898\ttotal: 1m 22s\tremaining: 39.4s\n",
      "678:\tlearn: 1591.9926159\ttotal: 1m 22s\tremaining: 39.2s\n",
      "679:\tlearn: 1591.7875722\ttotal: 1m 23s\tremaining: 39.1s\n",
      "680:\tlearn: 1591.7508740\ttotal: 1m 23s\tremaining: 39s\n",
      "681:\tlearn: 1591.6495303\ttotal: 1m 23s\tremaining: 38.9s\n",
      "682:\tlearn: 1591.5479738\ttotal: 1m 23s\tremaining: 38.7s\n",
      "683:\tlearn: 1591.5246697\ttotal: 1m 23s\tremaining: 38.6s\n",
      "684:\tlearn: 1591.3829382\ttotal: 1m 23s\tremaining: 38.5s\n",
      "685:\tlearn: 1591.2903978\ttotal: 1m 23s\tremaining: 38.3s\n",
      "686:\tlearn: 1591.1899054\ttotal: 1m 23s\tremaining: 38.2s\n",
      "687:\tlearn: 1591.0782832\ttotal: 1m 24s\tremaining: 38.1s\n",
      "688:\tlearn: 1591.0185003\ttotal: 1m 24s\tremaining: 38s\n",
      "689:\tlearn: 1590.8293087\ttotal: 1m 24s\tremaining: 37.8s\n",
      "690:\tlearn: 1590.7847160\ttotal: 1m 24s\tremaining: 37.7s\n",
      "691:\tlearn: 1590.6270008\ttotal: 1m 24s\tremaining: 37.6s\n",
      "692:\tlearn: 1590.6226463\ttotal: 1m 24s\tremaining: 37.5s\n",
      "693:\tlearn: 1590.5119415\ttotal: 1m 24s\tremaining: 37.4s\n",
      "694:\tlearn: 1590.4604223\ttotal: 1m 24s\tremaining: 37.2s\n",
      "695:\tlearn: 1590.3952593\ttotal: 1m 24s\tremaining: 37.1s\n",
      "696:\tlearn: 1590.2989385\ttotal: 1m 25s\tremaining: 37s\n",
      "697:\tlearn: 1590.1112784\ttotal: 1m 25s\tremaining: 36.9s\n",
      "698:\tlearn: 1589.8646272\ttotal: 1m 25s\tremaining: 36.7s\n",
      "699:\tlearn: 1589.7083091\ttotal: 1m 25s\tremaining: 36.6s\n",
      "700:\tlearn: 1589.6031860\ttotal: 1m 25s\tremaining: 36.5s\n",
      "701:\tlearn: 1589.4499849\ttotal: 1m 25s\tremaining: 36.4s\n",
      "702:\tlearn: 1589.2438192\ttotal: 1m 25s\tremaining: 36.3s\n",
      "703:\tlearn: 1589.1406167\ttotal: 1m 26s\tremaining: 36.2s\n",
      "704:\tlearn: 1589.0230736\ttotal: 1m 26s\tremaining: 36s\n",
      "705:\tlearn: 1588.8760009\ttotal: 1m 26s\tremaining: 35.9s\n",
      "706:\tlearn: 1588.6738030\ttotal: 1m 26s\tremaining: 35.8s\n",
      "707:\tlearn: 1588.4201532\ttotal: 1m 26s\tremaining: 35.7s\n",
      "708:\tlearn: 1588.2735828\ttotal: 1m 26s\tremaining: 35.6s\n",
      "709:\tlearn: 1588.1559249\ttotal: 1m 26s\tremaining: 35.4s\n",
      "710:\tlearn: 1588.0270046\ttotal: 1m 26s\tremaining: 35.3s\n",
      "711:\tlearn: 1587.9590363\ttotal: 1m 26s\tremaining: 35.2s\n",
      "712:\tlearn: 1587.8922538\ttotal: 1m 27s\tremaining: 35.1s\n",
      "713:\tlearn: 1587.8278738\ttotal: 1m 27s\tremaining: 34.9s\n",
      "714:\tlearn: 1587.6397688\ttotal: 1m 27s\tremaining: 34.8s\n",
      "715:\tlearn: 1587.4577533\ttotal: 1m 27s\tremaining: 34.7s\n",
      "716:\tlearn: 1587.3694850\ttotal: 1m 27s\tremaining: 34.6s\n",
      "717:\tlearn: 1587.2097448\ttotal: 1m 27s\tremaining: 34.5s\n",
      "718:\tlearn: 1587.1487029\ttotal: 1m 27s\tremaining: 34.3s\n",
      "719:\tlearn: 1586.9189129\ttotal: 1m 28s\tremaining: 34.2s\n",
      "720:\tlearn: 1586.8470669\ttotal: 1m 28s\tremaining: 34.1s\n",
      "721:\tlearn: 1586.7755442\ttotal: 1m 28s\tremaining: 34s\n",
      "722:\tlearn: 1586.7525005\ttotal: 1m 28s\tremaining: 33.8s\n",
      "723:\tlearn: 1586.7067864\ttotal: 1m 28s\tremaining: 33.7s\n",
      "724:\tlearn: 1586.4943010\ttotal: 1m 28s\tremaining: 33.6s\n",
      "725:\tlearn: 1586.4830883\ttotal: 1m 28s\tremaining: 33.5s\n",
      "726:\tlearn: 1586.3762779\ttotal: 1m 28s\tremaining: 33.3s\n",
      "727:\tlearn: 1586.2214245\ttotal: 1m 28s\tremaining: 33.2s\n",
      "728:\tlearn: 1585.9070179\ttotal: 1m 29s\tremaining: 33.1s\n",
      "729:\tlearn: 1585.7399625\ttotal: 1m 29s\tremaining: 33s\n",
      "730:\tlearn: 1585.5754464\ttotal: 1m 29s\tremaining: 32.8s\n",
      "731:\tlearn: 1585.2413207\ttotal: 1m 29s\tremaining: 32.7s\n",
      "732:\tlearn: 1585.0508712\ttotal: 1m 29s\tremaining: 32.6s\n",
      "733:\tlearn: 1584.8715289\ttotal: 1m 29s\tremaining: 32.4s\n",
      "734:\tlearn: 1584.7565823\ttotal: 1m 29s\tremaining: 32.3s\n",
      "735:\tlearn: 1584.7502516\ttotal: 1m 29s\tremaining: 32.2s\n",
      "736:\tlearn: 1584.5248853\ttotal: 1m 29s\tremaining: 32.1s\n",
      "737:\tlearn: 1584.4361031\ttotal: 1m 29s\tremaining: 31.9s\n",
      "738:\tlearn: 1584.2920867\ttotal: 1m 30s\tremaining: 31.8s\n",
      "739:\tlearn: 1584.1666437\ttotal: 1m 30s\tremaining: 31.7s\n",
      "740:\tlearn: 1584.1216190\ttotal: 1m 30s\tremaining: 31.6s\n",
      "741:\tlearn: 1583.9334437\ttotal: 1m 30s\tremaining: 31.4s\n",
      "742:\tlearn: 1583.6444487\ttotal: 1m 30s\tremaining: 31.3s\n",
      "743:\tlearn: 1583.4172705\ttotal: 1m 30s\tremaining: 31.2s\n",
      "744:\tlearn: 1583.3086816\ttotal: 1m 30s\tremaining: 31.1s\n",
      "745:\tlearn: 1583.1959870\ttotal: 1m 30s\tremaining: 30.9s\n",
      "746:\tlearn: 1583.0037557\ttotal: 1m 31s\tremaining: 30.8s\n",
      "747:\tlearn: 1582.8535953\ttotal: 1m 31s\tremaining: 30.7s\n",
      "748:\tlearn: 1582.5379228\ttotal: 1m 31s\tremaining: 30.6s\n",
      "749:\tlearn: 1582.4820565\ttotal: 1m 31s\tremaining: 30.5s\n",
      "750:\tlearn: 1582.4102613\ttotal: 1m 31s\tremaining: 30.3s\n",
      "751:\tlearn: 1582.3260108\ttotal: 1m 31s\tremaining: 30.2s\n",
      "752:\tlearn: 1582.3048411\ttotal: 1m 31s\tremaining: 30.1s\n",
      "753:\tlearn: 1582.2207952\ttotal: 1m 31s\tremaining: 30s\n",
      "754:\tlearn: 1582.1829988\ttotal: 1m 31s\tremaining: 29.8s\n",
      "755:\tlearn: 1581.9435117\ttotal: 1m 32s\tremaining: 29.7s\n",
      "756:\tlearn: 1581.8811480\ttotal: 1m 32s\tremaining: 29.6s\n",
      "757:\tlearn: 1581.7515602\ttotal: 1m 32s\tremaining: 29.5s\n",
      "758:\tlearn: 1581.5158740\ttotal: 1m 32s\tremaining: 29.4s\n",
      "759:\tlearn: 1581.5055478\ttotal: 1m 32s\tremaining: 29.2s\n",
      "760:\tlearn: 1581.4014366\ttotal: 1m 32s\tremaining: 29.1s\n",
      "761:\tlearn: 1581.3112013\ttotal: 1m 32s\tremaining: 29s\n",
      "762:\tlearn: 1581.2527032\ttotal: 1m 32s\tremaining: 28.9s\n",
      "763:\tlearn: 1581.0395230\ttotal: 1m 33s\tremaining: 28.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764:\tlearn: 1580.7908149\ttotal: 1m 33s\tremaining: 28.7s\n",
      "765:\tlearn: 1580.7135283\ttotal: 1m 33s\tremaining: 28.5s\n",
      "766:\tlearn: 1580.6261097\ttotal: 1m 33s\tremaining: 28.4s\n",
      "767:\tlearn: 1580.4529959\ttotal: 1m 33s\tremaining: 28.3s\n",
      "768:\tlearn: 1580.2462600\ttotal: 1m 33s\tremaining: 28.2s\n",
      "769:\tlearn: 1579.9879649\ttotal: 1m 33s\tremaining: 28.1s\n",
      "770:\tlearn: 1579.9388675\ttotal: 1m 34s\tremaining: 27.9s\n",
      "771:\tlearn: 1579.8184161\ttotal: 1m 34s\tremaining: 27.8s\n",
      "772:\tlearn: 1579.6503603\ttotal: 1m 34s\tremaining: 27.7s\n",
      "773:\tlearn: 1579.5414268\ttotal: 1m 34s\tremaining: 27.6s\n",
      "774:\tlearn: 1579.4565309\ttotal: 1m 34s\tremaining: 27.4s\n",
      "775:\tlearn: 1579.4125604\ttotal: 1m 34s\tremaining: 27.3s\n",
      "776:\tlearn: 1579.3253533\ttotal: 1m 34s\tremaining: 27.2s\n",
      "777:\tlearn: 1579.1340605\ttotal: 1m 34s\tremaining: 27.1s\n",
      "778:\tlearn: 1579.0705822\ttotal: 1m 34s\tremaining: 26.9s\n",
      "779:\tlearn: 1578.9635281\ttotal: 1m 35s\tremaining: 26.8s\n",
      "780:\tlearn: 1578.8501416\ttotal: 1m 35s\tremaining: 26.7s\n",
      "781:\tlearn: 1578.7394179\ttotal: 1m 35s\tremaining: 26.6s\n",
      "782:\tlearn: 1578.5436237\ttotal: 1m 35s\tremaining: 26.5s\n",
      "783:\tlearn: 1578.3601516\ttotal: 1m 35s\tremaining: 26.3s\n",
      "784:\tlearn: 1578.2371362\ttotal: 1m 35s\tremaining: 26.2s\n",
      "785:\tlearn: 1578.2044833\ttotal: 1m 35s\tremaining: 26.1s\n",
      "786:\tlearn: 1578.1439159\ttotal: 1m 35s\tremaining: 26s\n",
      "787:\tlearn: 1578.0332164\ttotal: 1m 36s\tremaining: 25.8s\n",
      "788:\tlearn: 1577.9549556\ttotal: 1m 36s\tremaining: 25.7s\n",
      "789:\tlearn: 1577.9242677\ttotal: 1m 36s\tremaining: 25.6s\n",
      "790:\tlearn: 1577.8600740\ttotal: 1m 36s\tremaining: 25.5s\n",
      "791:\tlearn: 1577.7449998\ttotal: 1m 36s\tremaining: 25.4s\n",
      "792:\tlearn: 1577.5068766\ttotal: 1m 36s\tremaining: 25.2s\n",
      "793:\tlearn: 1577.3574375\ttotal: 1m 36s\tremaining: 25.1s\n",
      "794:\tlearn: 1577.2655694\ttotal: 1m 36s\tremaining: 25s\n",
      "795:\tlearn: 1577.1947678\ttotal: 1m 37s\tremaining: 24.9s\n",
      "796:\tlearn: 1577.1109517\ttotal: 1m 37s\tremaining: 24.8s\n",
      "797:\tlearn: 1577.0496171\ttotal: 1m 37s\tremaining: 24.6s\n",
      "798:\tlearn: 1576.9038483\ttotal: 1m 37s\tremaining: 24.5s\n",
      "799:\tlearn: 1576.8180366\ttotal: 1m 37s\tremaining: 24.4s\n",
      "800:\tlearn: 1576.7347819\ttotal: 1m 37s\tremaining: 24.3s\n",
      "801:\tlearn: 1576.5374899\ttotal: 1m 37s\tremaining: 24.2s\n",
      "802:\tlearn: 1576.4659160\ttotal: 1m 37s\tremaining: 24s\n",
      "803:\tlearn: 1576.3310930\ttotal: 1m 38s\tremaining: 23.9s\n",
      "804:\tlearn: 1576.3052460\ttotal: 1m 38s\tremaining: 23.8s\n",
      "805:\tlearn: 1576.2127612\ttotal: 1m 38s\tremaining: 23.7s\n",
      "806:\tlearn: 1576.0353703\ttotal: 1m 38s\tremaining: 23.5s\n",
      "807:\tlearn: 1575.9237631\ttotal: 1m 38s\tremaining: 23.4s\n",
      "808:\tlearn: 1575.7867263\ttotal: 1m 38s\tremaining: 23.3s\n",
      "809:\tlearn: 1575.6665472\ttotal: 1m 38s\tremaining: 23.2s\n",
      "810:\tlearn: 1575.5685157\ttotal: 1m 38s\tremaining: 23s\n",
      "811:\tlearn: 1575.3526432\ttotal: 1m 38s\tremaining: 22.9s\n",
      "812:\tlearn: 1575.3388668\ttotal: 1m 39s\tremaining: 22.8s\n",
      "813:\tlearn: 1575.2493996\ttotal: 1m 39s\tremaining: 22.7s\n",
      "814:\tlearn: 1575.1483317\ttotal: 1m 39s\tremaining: 22.5s\n",
      "815:\tlearn: 1575.0285163\ttotal: 1m 39s\tremaining: 22.4s\n",
      "816:\tlearn: 1574.9314575\ttotal: 1m 39s\tremaining: 22.3s\n",
      "817:\tlearn: 1574.8293459\ttotal: 1m 39s\tremaining: 22.2s\n",
      "818:\tlearn: 1574.7583584\ttotal: 1m 39s\tremaining: 22s\n",
      "819:\tlearn: 1574.6048074\ttotal: 1m 39s\tremaining: 21.9s\n",
      "820:\tlearn: 1574.5896354\ttotal: 1m 39s\tremaining: 21.8s\n",
      "821:\tlearn: 1574.4441157\ttotal: 1m 40s\tremaining: 21.7s\n",
      "822:\tlearn: 1574.2662258\ttotal: 1m 40s\tremaining: 21.5s\n",
      "823:\tlearn: 1574.0529754\ttotal: 1m 40s\tremaining: 21.4s\n",
      "824:\tlearn: 1573.9818234\ttotal: 1m 40s\tremaining: 21.3s\n",
      "825:\tlearn: 1573.8950064\ttotal: 1m 40s\tremaining: 21.2s\n",
      "826:\tlearn: 1573.8714729\ttotal: 1m 40s\tremaining: 21s\n",
      "827:\tlearn: 1573.8406330\ttotal: 1m 40s\tremaining: 20.9s\n",
      "828:\tlearn: 1573.6680193\ttotal: 1m 40s\tremaining: 20.8s\n",
      "829:\tlearn: 1573.6482044\ttotal: 1m 40s\tremaining: 20.7s\n",
      "830:\tlearn: 1573.6438595\ttotal: 1m 41s\tremaining: 20.5s\n",
      "831:\tlearn: 1573.4898807\ttotal: 1m 41s\tremaining: 20.4s\n",
      "832:\tlearn: 1573.4776639\ttotal: 1m 41s\tremaining: 20.3s\n",
      "833:\tlearn: 1573.4241896\ttotal: 1m 41s\tremaining: 20.2s\n",
      "834:\tlearn: 1573.2593231\ttotal: 1m 41s\tremaining: 20.1s\n",
      "835:\tlearn: 1573.1381057\ttotal: 1m 41s\tremaining: 19.9s\n",
      "836:\tlearn: 1573.0532570\ttotal: 1m 41s\tremaining: 19.8s\n",
      "837:\tlearn: 1572.9858272\ttotal: 1m 41s\tremaining: 19.7s\n",
      "838:\tlearn: 1572.7940954\ttotal: 1m 42s\tremaining: 19.6s\n",
      "839:\tlearn: 1572.6816004\ttotal: 1m 42s\tremaining: 19.5s\n",
      "840:\tlearn: 1572.6103545\ttotal: 1m 42s\tremaining: 19.3s\n",
      "841:\tlearn: 1572.4399280\ttotal: 1m 42s\tremaining: 19.2s\n",
      "842:\tlearn: 1572.3505922\ttotal: 1m 42s\tremaining: 19.1s\n",
      "843:\tlearn: 1572.2587500\ttotal: 1m 42s\tremaining: 19s\n",
      "844:\tlearn: 1572.0361784\ttotal: 1m 42s\tremaining: 18.8s\n",
      "845:\tlearn: 1571.9170530\ttotal: 1m 42s\tremaining: 18.7s\n",
      "846:\tlearn: 1571.9049322\ttotal: 1m 42s\tremaining: 18.6s\n",
      "847:\tlearn: 1571.8223916\ttotal: 1m 43s\tremaining: 18.5s\n",
      "848:\tlearn: 1571.7506724\ttotal: 1m 43s\tremaining: 18.3s\n",
      "849:\tlearn: 1571.6740039\ttotal: 1m 43s\tremaining: 18.2s\n",
      "850:\tlearn: 1571.5401993\ttotal: 1m 43s\tremaining: 18.1s\n",
      "851:\tlearn: 1571.4342344\ttotal: 1m 43s\tremaining: 18s\n",
      "852:\tlearn: 1571.3154184\ttotal: 1m 43s\tremaining: 17.9s\n",
      "853:\tlearn: 1571.0903849\ttotal: 1m 43s\tremaining: 17.7s\n",
      "854:\tlearn: 1570.9583635\ttotal: 1m 43s\tremaining: 17.6s\n",
      "855:\tlearn: 1570.8261607\ttotal: 1m 43s\tremaining: 17.5s\n",
      "856:\tlearn: 1570.6934880\ttotal: 1m 44s\tremaining: 17.4s\n",
      "857:\tlearn: 1570.5681046\ttotal: 1m 44s\tremaining: 17.3s\n",
      "858:\tlearn: 1570.4899339\ttotal: 1m 44s\tremaining: 17.1s\n",
      "859:\tlearn: 1570.3929776\ttotal: 1m 44s\tremaining: 17s\n",
      "860:\tlearn: 1570.3068949\ttotal: 1m 44s\tremaining: 16.9s\n",
      "861:\tlearn: 1570.2603755\ttotal: 1m 44s\tremaining: 16.8s\n",
      "862:\tlearn: 1570.1906871\ttotal: 1m 44s\tremaining: 16.6s\n",
      "863:\tlearn: 1569.9975113\ttotal: 1m 44s\tremaining: 16.5s\n",
      "864:\tlearn: 1569.9277335\ttotal: 1m 45s\tremaining: 16.4s\n",
      "865:\tlearn: 1569.8102325\ttotal: 1m 45s\tremaining: 16.3s\n",
      "866:\tlearn: 1569.7549040\ttotal: 1m 45s\tremaining: 16.2s\n",
      "867:\tlearn: 1569.6904626\ttotal: 1m 45s\tremaining: 16s\n",
      "868:\tlearn: 1569.5222634\ttotal: 1m 45s\tremaining: 15.9s\n",
      "869:\tlearn: 1569.4951629\ttotal: 1m 45s\tremaining: 15.8s\n",
      "870:\tlearn: 1569.4149040\ttotal: 1m 45s\tremaining: 15.7s\n",
      "871:\tlearn: 1569.2546189\ttotal: 1m 45s\tremaining: 15.6s\n",
      "872:\tlearn: 1569.0630716\ttotal: 1m 46s\tremaining: 15.4s\n",
      "873:\tlearn: 1568.9423060\ttotal: 1m 46s\tremaining: 15.3s\n",
      "874:\tlearn: 1568.9223340\ttotal: 1m 46s\tremaining: 15.2s\n",
      "875:\tlearn: 1568.9043305\ttotal: 1m 46s\tremaining: 15.1s\n",
      "876:\tlearn: 1568.7630661\ttotal: 1m 46s\tremaining: 14.9s\n",
      "877:\tlearn: 1568.6929615\ttotal: 1m 46s\tremaining: 14.8s\n",
      "878:\tlearn: 1568.5420513\ttotal: 1m 46s\tremaining: 14.7s\n",
      "879:\tlearn: 1568.3927951\ttotal: 1m 46s\tremaining: 14.6s\n",
      "880:\tlearn: 1568.3820449\ttotal: 1m 47s\tremaining: 14.5s\n",
      "881:\tlearn: 1568.2014412\ttotal: 1m 47s\tremaining: 14.3s\n",
      "882:\tlearn: 1568.0423161\ttotal: 1m 47s\tremaining: 14.2s\n",
      "883:\tlearn: 1568.0030147\ttotal: 1m 47s\tremaining: 14.1s\n",
      "884:\tlearn: 1567.9255573\ttotal: 1m 47s\tremaining: 14s\n",
      "885:\tlearn: 1567.8591990\ttotal: 1m 47s\tremaining: 13.9s\n",
      "886:\tlearn: 1567.7746864\ttotal: 1m 47s\tremaining: 13.7s\n",
      "887:\tlearn: 1567.6532018\ttotal: 1m 47s\tremaining: 13.6s\n",
      "888:\tlearn: 1567.5479532\ttotal: 1m 48s\tremaining: 13.5s\n",
      "889:\tlearn: 1567.3855169\ttotal: 1m 48s\tremaining: 13.4s\n",
      "890:\tlearn: 1567.1513053\ttotal: 1m 48s\tremaining: 13.2s\n",
      "891:\tlearn: 1567.1088090\ttotal: 1m 48s\tremaining: 13.1s\n",
      "892:\tlearn: 1566.9203722\ttotal: 1m 48s\tremaining: 13s\n",
      "893:\tlearn: 1566.8093382\ttotal: 1m 48s\tremaining: 12.9s\n",
      "894:\tlearn: 1566.6620263\ttotal: 1m 48s\tremaining: 12.8s\n",
      "895:\tlearn: 1566.5320244\ttotal: 1m 48s\tremaining: 12.6s\n",
      "896:\tlearn: 1566.3936082\ttotal: 1m 49s\tremaining: 12.5s\n",
      "897:\tlearn: 1566.3125465\ttotal: 1m 49s\tremaining: 12.4s\n",
      "898:\tlearn: 1566.2106447\ttotal: 1m 49s\tremaining: 12.3s\n",
      "899:\tlearn: 1566.1869410\ttotal: 1m 49s\tremaining: 12.2s\n",
      "900:\tlearn: 1566.0641936\ttotal: 1m 49s\tremaining: 12s\n",
      "901:\tlearn: 1566.0080506\ttotal: 1m 49s\tremaining: 11.9s\n",
      "902:\tlearn: 1565.9952309\ttotal: 1m 49s\tremaining: 11.8s\n",
      "903:\tlearn: 1565.9771056\ttotal: 1m 49s\tremaining: 11.7s\n",
      "904:\tlearn: 1565.8612903\ttotal: 1m 50s\tremaining: 11.6s\n",
      "905:\tlearn: 1565.7753349\ttotal: 1m 50s\tremaining: 11.4s\n",
      "906:\tlearn: 1565.6461438\ttotal: 1m 50s\tremaining: 11.3s\n",
      "907:\tlearn: 1565.5633596\ttotal: 1m 50s\tremaining: 11.2s\n",
      "908:\tlearn: 1565.4390430\ttotal: 1m 50s\tremaining: 11.1s\n",
      "909:\tlearn: 1565.2809072\ttotal: 1m 50s\tremaining: 10.9s\n",
      "910:\tlearn: 1565.0927315\ttotal: 1m 50s\tremaining: 10.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911:\tlearn: 1564.9941264\ttotal: 1m 50s\tremaining: 10.7s\n",
      "912:\tlearn: 1564.9355421\ttotal: 1m 51s\tremaining: 10.6s\n",
      "913:\tlearn: 1564.8624312\ttotal: 1m 51s\tremaining: 10.5s\n",
      "914:\tlearn: 1564.7761377\ttotal: 1m 51s\tremaining: 10.3s\n",
      "915:\tlearn: 1564.7557942\ttotal: 1m 51s\tremaining: 10.2s\n",
      "916:\tlearn: 1564.5870812\ttotal: 1m 51s\tremaining: 10.1s\n",
      "917:\tlearn: 1564.4550585\ttotal: 1m 51s\tremaining: 9.98s\n",
      "918:\tlearn: 1564.2322415\ttotal: 1m 51s\tremaining: 9.86s\n",
      "919:\tlearn: 1564.1032194\ttotal: 1m 52s\tremaining: 9.74s\n",
      "920:\tlearn: 1563.9708540\ttotal: 1m 52s\tremaining: 9.62s\n",
      "921:\tlearn: 1563.8434435\ttotal: 1m 52s\tremaining: 9.5s\n",
      "922:\tlearn: 1563.4828987\ttotal: 1m 52s\tremaining: 9.38s\n",
      "923:\tlearn: 1563.4663890\ttotal: 1m 52s\tremaining: 9.25s\n",
      "924:\tlearn: 1563.3928732\ttotal: 1m 52s\tremaining: 9.13s\n",
      "925:\tlearn: 1563.2866249\ttotal: 1m 52s\tremaining: 9.01s\n",
      "926:\tlearn: 1563.2534747\ttotal: 1m 52s\tremaining: 8.89s\n",
      "927:\tlearn: 1563.1791352\ttotal: 1m 53s\tremaining: 8.77s\n",
      "928:\tlearn: 1563.1239807\ttotal: 1m 53s\tremaining: 8.64s\n",
      "929:\tlearn: 1562.9697778\ttotal: 1m 53s\tremaining: 8.53s\n",
      "930:\tlearn: 1562.8317165\ttotal: 1m 53s\tremaining: 8.4s\n",
      "931:\tlearn: 1562.7535870\ttotal: 1m 53s\tremaining: 8.28s\n",
      "932:\tlearn: 1562.6563289\ttotal: 1m 53s\tremaining: 8.16s\n",
      "933:\tlearn: 1562.6083431\ttotal: 1m 53s\tremaining: 8.04s\n",
      "934:\tlearn: 1562.4427835\ttotal: 1m 53s\tremaining: 7.92s\n",
      "935:\tlearn: 1562.3785047\ttotal: 1m 53s\tremaining: 7.79s\n",
      "936:\tlearn: 1562.3034922\ttotal: 1m 54s\tremaining: 7.67s\n",
      "937:\tlearn: 1562.2505215\ttotal: 1m 54s\tremaining: 7.55s\n",
      "938:\tlearn: 1562.1528583\ttotal: 1m 54s\tremaining: 7.43s\n",
      "939:\tlearn: 1562.1158701\ttotal: 1m 54s\tremaining: 7.31s\n",
      "940:\tlearn: 1562.0762908\ttotal: 1m 54s\tremaining: 7.18s\n",
      "941:\tlearn: 1561.8800274\ttotal: 1m 54s\tremaining: 7.06s\n",
      "942:\tlearn: 1561.5800930\ttotal: 1m 54s\tremaining: 6.94s\n",
      "943:\tlearn: 1561.3881530\ttotal: 1m 54s\tremaining: 6.82s\n",
      "944:\tlearn: 1561.2975737\ttotal: 1m 55s\tremaining: 6.7s\n",
      "945:\tlearn: 1561.1982991\ttotal: 1m 55s\tremaining: 6.58s\n",
      "946:\tlearn: 1561.1060946\ttotal: 1m 55s\tremaining: 6.46s\n",
      "947:\tlearn: 1560.9807423\ttotal: 1m 55s\tremaining: 6.33s\n",
      "948:\tlearn: 1560.9363208\ttotal: 1m 55s\tremaining: 6.21s\n",
      "949:\tlearn: 1560.8880450\ttotal: 1m 55s\tremaining: 6.09s\n",
      "950:\tlearn: 1560.8369554\ttotal: 1m 55s\tremaining: 5.97s\n",
      "951:\tlearn: 1560.6751938\ttotal: 1m 55s\tremaining: 5.85s\n",
      "952:\tlearn: 1560.4402925\ttotal: 1m 56s\tremaining: 5.72s\n",
      "953:\tlearn: 1560.3731867\ttotal: 1m 56s\tremaining: 5.6s\n",
      "954:\tlearn: 1560.2567215\ttotal: 1m 56s\tremaining: 5.48s\n",
      "955:\tlearn: 1560.1378473\ttotal: 1m 56s\tremaining: 5.36s\n",
      "956:\tlearn: 1560.0895268\ttotal: 1m 56s\tremaining: 5.23s\n",
      "957:\tlearn: 1560.0610589\ttotal: 1m 56s\tremaining: 5.11s\n",
      "958:\tlearn: 1559.9879830\ttotal: 1m 56s\tremaining: 4.99s\n",
      "959:\tlearn: 1559.9230913\ttotal: 1m 56s\tremaining: 4.87s\n",
      "960:\tlearn: 1559.7295912\ttotal: 1m 56s\tremaining: 4.75s\n",
      "961:\tlearn: 1559.6859759\ttotal: 1m 57s\tremaining: 4.62s\n",
      "962:\tlearn: 1559.6319906\ttotal: 1m 57s\tremaining: 4.5s\n",
      "963:\tlearn: 1559.4348241\ttotal: 1m 57s\tremaining: 4.38s\n",
      "964:\tlearn: 1559.4317062\ttotal: 1m 57s\tremaining: 4.26s\n",
      "965:\tlearn: 1559.4111256\ttotal: 1m 57s\tremaining: 4.13s\n",
      "966:\tlearn: 1559.3261339\ttotal: 1m 57s\tremaining: 4.01s\n",
      "967:\tlearn: 1559.2294302\ttotal: 1m 57s\tremaining: 3.89s\n",
      "968:\tlearn: 1559.1732525\ttotal: 1m 57s\tremaining: 3.77s\n",
      "969:\tlearn: 1558.9593416\ttotal: 1m 58s\tremaining: 3.65s\n",
      "970:\tlearn: 1558.9240416\ttotal: 1m 58s\tremaining: 3.53s\n",
      "971:\tlearn: 1558.8263193\ttotal: 1m 58s\tremaining: 3.41s\n",
      "972:\tlearn: 1558.6794515\ttotal: 1m 58s\tremaining: 3.28s\n",
      "973:\tlearn: 1558.6200329\ttotal: 1m 58s\tremaining: 3.16s\n",
      "974:\tlearn: 1558.5750266\ttotal: 1m 58s\tremaining: 3.04s\n",
      "975:\tlearn: 1558.5005158\ttotal: 1m 58s\tremaining: 2.92s\n",
      "976:\tlearn: 1558.4251037\ttotal: 1m 58s\tremaining: 2.8s\n",
      "977:\tlearn: 1558.3466320\ttotal: 1m 59s\tremaining: 2.68s\n",
      "978:\tlearn: 1558.2935830\ttotal: 1m 59s\tremaining: 2.55s\n",
      "979:\tlearn: 1558.1033279\ttotal: 1m 59s\tremaining: 2.43s\n",
      "980:\tlearn: 1558.0141060\ttotal: 1m 59s\tremaining: 2.31s\n",
      "981:\tlearn: 1557.9575813\ttotal: 1m 59s\tremaining: 2.19s\n",
      "982:\tlearn: 1557.7546897\ttotal: 1m 59s\tremaining: 2.07s\n",
      "983:\tlearn: 1557.6278845\ttotal: 1m 59s\tremaining: 1.95s\n",
      "984:\tlearn: 1557.5289016\ttotal: 1m 59s\tremaining: 1.82s\n",
      "985:\tlearn: 1557.2936141\ttotal: 1m 59s\tremaining: 1.7s\n",
      "986:\tlearn: 1557.0870397\ttotal: 2m\tremaining: 1.58s\n",
      "987:\tlearn: 1557.0259770\ttotal: 2m\tremaining: 1.46s\n",
      "988:\tlearn: 1556.9055832\ttotal: 2m\tremaining: 1.34s\n",
      "989:\tlearn: 1556.8406247\ttotal: 2m\tremaining: 1.22s\n",
      "990:\tlearn: 1556.7780021\ttotal: 2m\tremaining: 1.09s\n",
      "991:\tlearn: 1556.7734934\ttotal: 2m\tremaining: 972ms\n",
      "992:\tlearn: 1556.7085115\ttotal: 2m\tremaining: 851ms\n",
      "993:\tlearn: 1556.5243690\ttotal: 2m\tremaining: 729ms\n",
      "994:\tlearn: 1556.4299351\ttotal: 2m\tremaining: 608ms\n",
      "995:\tlearn: 1556.2729849\ttotal: 2m 1s\tremaining: 486ms\n",
      "996:\tlearn: 1556.2078372\ttotal: 2m 1s\tremaining: 365ms\n",
      "997:\tlearn: 1556.1386761\ttotal: 2m 1s\tremaining: 243ms\n",
      "998:\tlearn: 1556.1194488\ttotal: 2m 1s\tremaining: 122ms\n",
      "999:\tlearn: 1556.0849913\ttotal: 2m 1s\tremaining: 0us\n",
      "Cross-Validation RMSE Scores: [1626.99374828 1627.92393505 1637.89675239 1633.42193331 1650.49501073]\n",
      "Mean Cross-Validation RMSE: 1635.3462759531292\n",
      "Standard Deviation of Cross-Validation RMSE: 8.538712464354974\n",
      "Learning rate set to 0.09011\n",
      "0:\tlearn: 4439.0309390\ttotal: 122ms\tremaining: 2m 2s\n",
      "1:\tlearn: 4183.1857065\ttotal: 247ms\tremaining: 2m 3s\n",
      "2:\tlearn: 3958.2517756\ttotal: 359ms\tremaining: 1m 59s\n",
      "3:\tlearn: 3754.4519296\ttotal: 458ms\tremaining: 1m 54s\n",
      "4:\tlearn: 3568.2004963\ttotal: 577ms\tremaining: 1m 54s\n",
      "5:\tlearn: 3410.3632506\ttotal: 699ms\tremaining: 1m 55s\n",
      "6:\tlearn: 3258.1853450\ttotal: 780ms\tremaining: 1m 50s\n",
      "7:\tlearn: 3122.7577510\ttotal: 861ms\tremaining: 1m 46s\n",
      "8:\tlearn: 3008.2612613\ttotal: 958ms\tremaining: 1m 45s\n",
      "9:\tlearn: 2903.3173328\ttotal: 1.04s\tremaining: 1m 43s\n",
      "10:\tlearn: 2807.9436959\ttotal: 1.17s\tremaining: 1m 44s\n",
      "11:\tlearn: 2723.8699282\ttotal: 1.28s\tremaining: 1m 45s\n",
      "12:\tlearn: 2650.7624603\ttotal: 1.38s\tremaining: 1m 44s\n",
      "13:\tlearn: 2581.0282408\ttotal: 1.46s\tremaining: 1m 43s\n",
      "14:\tlearn: 2518.6728009\ttotal: 1.55s\tremaining: 1m 42s\n",
      "15:\tlearn: 2465.9671416\ttotal: 1.66s\tremaining: 1m 42s\n",
      "16:\tlearn: 2411.7876462\ttotal: 1.75s\tremaining: 1m 41s\n",
      "17:\tlearn: 2367.7072170\ttotal: 1.84s\tremaining: 1m 40s\n",
      "18:\tlearn: 2324.6971211\ttotal: 1.92s\tremaining: 1m 39s\n",
      "19:\tlearn: 2291.1727071\ttotal: 2s\tremaining: 1m 38s\n",
      "20:\tlearn: 2260.2122636\ttotal: 2.12s\tremaining: 1m 38s\n",
      "21:\tlearn: 2228.2297704\ttotal: 2.22s\tremaining: 1m 38s\n",
      "22:\tlearn: 2199.9204712\ttotal: 2.34s\tremaining: 1m 39s\n",
      "23:\tlearn: 2176.2211753\ttotal: 2.44s\tremaining: 1m 39s\n",
      "24:\tlearn: 2152.8621846\ttotal: 2.54s\tremaining: 1m 39s\n",
      "25:\tlearn: 2132.2876395\ttotal: 2.67s\tremaining: 1m 39s\n",
      "26:\tlearn: 2115.0776499\ttotal: 2.78s\tremaining: 1m 40s\n",
      "27:\tlearn: 2099.2746273\ttotal: 2.88s\tremaining: 1m 39s\n",
      "28:\tlearn: 2083.4596998\ttotal: 2.98s\tremaining: 1m 39s\n",
      "29:\tlearn: 2070.8757539\ttotal: 3.07s\tremaining: 1m 39s\n",
      "30:\tlearn: 2057.2352015\ttotal: 3.17s\tremaining: 1m 39s\n",
      "31:\tlearn: 2045.5709992\ttotal: 3.26s\tremaining: 1m 38s\n",
      "32:\tlearn: 2035.2485800\ttotal: 3.35s\tremaining: 1m 38s\n",
      "33:\tlearn: 2026.0857140\ttotal: 3.43s\tremaining: 1m 37s\n",
      "34:\tlearn: 2017.8172308\ttotal: 3.51s\tremaining: 1m 36s\n",
      "35:\tlearn: 2009.4013542\ttotal: 3.6s\tremaining: 1m 36s\n",
      "36:\tlearn: 2002.1234739\ttotal: 3.67s\tremaining: 1m 35s\n",
      "37:\tlearn: 1995.3670512\ttotal: 3.74s\tremaining: 1m 34s\n",
      "38:\tlearn: 1989.1619430\ttotal: 3.81s\tremaining: 1m 33s\n",
      "39:\tlearn: 1983.1468517\ttotal: 3.92s\tremaining: 1m 34s\n",
      "40:\tlearn: 1974.7708144\ttotal: 3.99s\tremaining: 1m 33s\n",
      "41:\tlearn: 1969.6969383\ttotal: 4.07s\tremaining: 1m 32s\n",
      "42:\tlearn: 1964.1932010\ttotal: 4.15s\tremaining: 1m 32s\n",
      "43:\tlearn: 1959.6918610\ttotal: 4.22s\tremaining: 1m 31s\n",
      "44:\tlearn: 1955.1027424\ttotal: 4.3s\tremaining: 1m 31s\n",
      "45:\tlearn: 1950.7831381\ttotal: 4.4s\tremaining: 1m 31s\n",
      "46:\tlearn: 1946.3518706\ttotal: 4.51s\tremaining: 1m 31s\n",
      "47:\tlearn: 1940.2909683\ttotal: 4.58s\tremaining: 1m 30s\n",
      "48:\tlearn: 1936.3337508\ttotal: 4.68s\tremaining: 1m 30s\n",
      "49:\tlearn: 1932.8231698\ttotal: 4.76s\tremaining: 1m 30s\n",
      "50:\tlearn: 1929.0788029\ttotal: 4.83s\tremaining: 1m 29s\n",
      "51:\tlearn: 1924.4458189\ttotal: 4.92s\tremaining: 1m 29s\n",
      "52:\tlearn: 1921.0548712\ttotal: 5.03s\tremaining: 1m 29s\n",
      "53:\tlearn: 1917.7075342\ttotal: 5.14s\tremaining: 1m 30s\n",
      "54:\tlearn: 1914.3661953\ttotal: 5.25s\tremaining: 1m 30s\n",
      "55:\tlearn: 1911.9741621\ttotal: 5.34s\tremaining: 1m 30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56:\tlearn: 1909.2447800\ttotal: 5.44s\tremaining: 1m 29s\n",
      "57:\tlearn: 1906.8993386\ttotal: 5.52s\tremaining: 1m 29s\n",
      "58:\tlearn: 1904.7829709\ttotal: 5.62s\tremaining: 1m 29s\n",
      "59:\tlearn: 1902.9279446\ttotal: 5.7s\tremaining: 1m 29s\n",
      "60:\tlearn: 1900.7081860\ttotal: 5.79s\tremaining: 1m 29s\n",
      "61:\tlearn: 1898.2844694\ttotal: 5.88s\tremaining: 1m 28s\n",
      "62:\tlearn: 1894.6430549\ttotal: 5.95s\tremaining: 1m 28s\n",
      "63:\tlearn: 1892.0939928\ttotal: 6.01s\tremaining: 1m 27s\n",
      "64:\tlearn: 1890.6510035\ttotal: 6.09s\tremaining: 1m 27s\n",
      "65:\tlearn: 1887.3224198\ttotal: 6.21s\tremaining: 1m 27s\n",
      "66:\tlearn: 1884.4316487\ttotal: 6.28s\tremaining: 1m 27s\n",
      "67:\tlearn: 1881.0577055\ttotal: 6.36s\tremaining: 1m 27s\n",
      "68:\tlearn: 1878.6416981\ttotal: 6.43s\tremaining: 1m 26s\n",
      "69:\tlearn: 1876.4463022\ttotal: 6.5s\tremaining: 1m 26s\n",
      "70:\tlearn: 1874.2208426\ttotal: 6.6s\tremaining: 1m 26s\n",
      "71:\tlearn: 1872.7101993\ttotal: 6.68s\tremaining: 1m 26s\n",
      "72:\tlearn: 1870.2166582\ttotal: 6.78s\tremaining: 1m 26s\n",
      "73:\tlearn: 1868.9861434\ttotal: 6.87s\tremaining: 1m 25s\n",
      "74:\tlearn: 1867.0250447\ttotal: 6.96s\tremaining: 1m 25s\n",
      "75:\tlearn: 1864.1655772\ttotal: 7.03s\tremaining: 1m 25s\n",
      "76:\tlearn: 1861.5410867\ttotal: 7.12s\tremaining: 1m 25s\n",
      "77:\tlearn: 1859.5283166\ttotal: 7.23s\tremaining: 1m 25s\n",
      "78:\tlearn: 1858.0236739\ttotal: 7.33s\tremaining: 1m 25s\n",
      "79:\tlearn: 1856.7680154\ttotal: 7.42s\tremaining: 1m 25s\n",
      "80:\tlearn: 1854.9947664\ttotal: 7.52s\tremaining: 1m 25s\n",
      "81:\tlearn: 1853.3806170\ttotal: 7.63s\tremaining: 1m 25s\n",
      "82:\tlearn: 1851.3861190\ttotal: 7.7s\tremaining: 1m 25s\n",
      "83:\tlearn: 1849.9246783\ttotal: 7.79s\tremaining: 1m 24s\n",
      "84:\tlearn: 1848.5560665\ttotal: 7.88s\tremaining: 1m 24s\n",
      "85:\tlearn: 1846.6457070\ttotal: 7.98s\tremaining: 1m 24s\n",
      "86:\tlearn: 1845.4335774\ttotal: 8.07s\tremaining: 1m 24s\n",
      "87:\tlearn: 1843.7551038\ttotal: 8.16s\tremaining: 1m 24s\n",
      "88:\tlearn: 1842.3095026\ttotal: 8.28s\tremaining: 1m 24s\n",
      "89:\tlearn: 1841.0329763\ttotal: 8.37s\tremaining: 1m 24s\n",
      "90:\tlearn: 1839.4783190\ttotal: 8.44s\tremaining: 1m 24s\n",
      "91:\tlearn: 1837.3138341\ttotal: 8.55s\tremaining: 1m 24s\n",
      "92:\tlearn: 1834.5475959\ttotal: 8.63s\tremaining: 1m 24s\n",
      "93:\tlearn: 1833.3550817\ttotal: 8.71s\tremaining: 1m 23s\n",
      "94:\tlearn: 1831.5095482\ttotal: 8.81s\tremaining: 1m 23s\n",
      "95:\tlearn: 1830.5303238\ttotal: 8.89s\tremaining: 1m 23s\n",
      "96:\tlearn: 1829.2316204\ttotal: 8.98s\tremaining: 1m 23s\n",
      "97:\tlearn: 1827.3527758\ttotal: 9.07s\tremaining: 1m 23s\n",
      "98:\tlearn: 1825.3019148\ttotal: 9.17s\tremaining: 1m 23s\n",
      "99:\tlearn: 1824.2165203\ttotal: 9.27s\tremaining: 1m 23s\n",
      "100:\tlearn: 1823.0974482\ttotal: 9.37s\tremaining: 1m 23s\n",
      "101:\tlearn: 1821.8098569\ttotal: 9.43s\tremaining: 1m 23s\n",
      "102:\tlearn: 1820.2478657\ttotal: 9.51s\tremaining: 1m 22s\n",
      "103:\tlearn: 1819.4251548\ttotal: 9.56s\tremaining: 1m 22s\n",
      "104:\tlearn: 1818.2651868\ttotal: 9.68s\tremaining: 1m 22s\n",
      "105:\tlearn: 1816.7188035\ttotal: 9.77s\tremaining: 1m 22s\n",
      "106:\tlearn: 1815.4942864\ttotal: 9.85s\tremaining: 1m 22s\n",
      "107:\tlearn: 1813.8279775\ttotal: 9.96s\tremaining: 1m 22s\n",
      "108:\tlearn: 1812.9645913\ttotal: 10.1s\tremaining: 1m 22s\n",
      "109:\tlearn: 1810.3360671\ttotal: 10.1s\tremaining: 1m 21s\n",
      "110:\tlearn: 1808.8403845\ttotal: 10.2s\tremaining: 1m 21s\n",
      "111:\tlearn: 1807.6973048\ttotal: 10.3s\tremaining: 1m 21s\n",
      "112:\tlearn: 1807.0214270\ttotal: 10.4s\tremaining: 1m 21s\n",
      "113:\tlearn: 1805.0179440\ttotal: 10.5s\tremaining: 1m 21s\n",
      "114:\tlearn: 1804.0514762\ttotal: 10.6s\tremaining: 1m 21s\n",
      "115:\tlearn: 1803.3878611\ttotal: 10.7s\tremaining: 1m 21s\n",
      "116:\tlearn: 1802.1032440\ttotal: 10.8s\tremaining: 1m 21s\n",
      "117:\tlearn: 1801.1183343\ttotal: 10.8s\tremaining: 1m 21s\n",
      "118:\tlearn: 1800.0042140\ttotal: 10.9s\tremaining: 1m 20s\n",
      "119:\tlearn: 1798.6199727\ttotal: 11s\tremaining: 1m 20s\n",
      "120:\tlearn: 1797.7646052\ttotal: 11s\tremaining: 1m 20s\n",
      "121:\tlearn: 1796.6090844\ttotal: 11.1s\tremaining: 1m 20s\n",
      "122:\tlearn: 1795.2816506\ttotal: 11.2s\tremaining: 1m 19s\n",
      "123:\tlearn: 1793.9851487\ttotal: 11.3s\tremaining: 1m 19s\n",
      "124:\tlearn: 1793.3026381\ttotal: 11.4s\tremaining: 1m 19s\n",
      "125:\tlearn: 1792.4703486\ttotal: 11.5s\tremaining: 1m 19s\n",
      "126:\tlearn: 1790.6631537\ttotal: 11.6s\tremaining: 1m 19s\n",
      "127:\tlearn: 1789.9609007\ttotal: 11.7s\tremaining: 1m 19s\n",
      "128:\tlearn: 1787.5664672\ttotal: 11.7s\tremaining: 1m 19s\n",
      "129:\tlearn: 1787.1673893\ttotal: 11.8s\tremaining: 1m 19s\n",
      "130:\tlearn: 1785.2123811\ttotal: 11.9s\tremaining: 1m 18s\n",
      "131:\tlearn: 1784.5871591\ttotal: 12s\tremaining: 1m 19s\n",
      "132:\tlearn: 1783.4132353\ttotal: 12.1s\tremaining: 1m 18s\n",
      "133:\tlearn: 1782.1645095\ttotal: 12.2s\tremaining: 1m 18s\n",
      "134:\tlearn: 1781.3639134\ttotal: 12.3s\tremaining: 1m 18s\n",
      "135:\tlearn: 1780.4389556\ttotal: 12.4s\tremaining: 1m 18s\n",
      "136:\tlearn: 1779.8487226\ttotal: 12.5s\tremaining: 1m 18s\n",
      "137:\tlearn: 1778.5341267\ttotal: 12.6s\tremaining: 1m 18s\n",
      "138:\tlearn: 1778.0894551\ttotal: 12.7s\tremaining: 1m 18s\n",
      "139:\tlearn: 1777.0703039\ttotal: 12.8s\tremaining: 1m 18s\n",
      "140:\tlearn: 1776.0590554\ttotal: 12.9s\tremaining: 1m 18s\n",
      "141:\tlearn: 1774.7405815\ttotal: 13s\tremaining: 1m 18s\n",
      "142:\tlearn: 1774.0379267\ttotal: 13.1s\tremaining: 1m 18s\n",
      "143:\tlearn: 1773.5246837\ttotal: 13.2s\tremaining: 1m 18s\n",
      "144:\tlearn: 1772.4803140\ttotal: 13.3s\tremaining: 1m 18s\n",
      "145:\tlearn: 1771.3143475\ttotal: 13.4s\tremaining: 1m 18s\n",
      "146:\tlearn: 1770.8671878\ttotal: 13.5s\tremaining: 1m 18s\n",
      "147:\tlearn: 1769.1013658\ttotal: 13.6s\tremaining: 1m 18s\n",
      "148:\tlearn: 1767.9807759\ttotal: 13.6s\tremaining: 1m 17s\n",
      "149:\tlearn: 1767.5628408\ttotal: 13.7s\tremaining: 1m 17s\n",
      "150:\tlearn: 1766.3366132\ttotal: 13.8s\tremaining: 1m 17s\n",
      "151:\tlearn: 1765.8414079\ttotal: 13.9s\tremaining: 1m 17s\n",
      "152:\tlearn: 1764.8242775\ttotal: 14s\tremaining: 1m 17s\n",
      "153:\tlearn: 1763.8906309\ttotal: 14.1s\tremaining: 1m 17s\n",
      "154:\tlearn: 1762.9273443\ttotal: 14.2s\tremaining: 1m 17s\n",
      "155:\tlearn: 1762.3237174\ttotal: 14.3s\tremaining: 1m 17s\n",
      "156:\tlearn: 1761.3799509\ttotal: 14.4s\tremaining: 1m 17s\n",
      "157:\tlearn: 1760.2888571\ttotal: 14.5s\tremaining: 1m 17s\n",
      "158:\tlearn: 1759.7907858\ttotal: 14.6s\tremaining: 1m 17s\n",
      "159:\tlearn: 1758.4470333\ttotal: 14.7s\tremaining: 1m 17s\n",
      "160:\tlearn: 1757.3327880\ttotal: 14.8s\tremaining: 1m 17s\n",
      "161:\tlearn: 1756.5566970\ttotal: 14.9s\tremaining: 1m 17s\n",
      "162:\tlearn: 1756.1676007\ttotal: 15s\tremaining: 1m 17s\n",
      "163:\tlearn: 1755.0877113\ttotal: 15.1s\tremaining: 1m 17s\n",
      "164:\tlearn: 1754.3205688\ttotal: 15.2s\tremaining: 1m 17s\n",
      "165:\tlearn: 1753.7575514\ttotal: 15.3s\tremaining: 1m 16s\n",
      "166:\tlearn: 1753.7314023\ttotal: 15.4s\tremaining: 1m 16s\n",
      "167:\tlearn: 1753.2506342\ttotal: 15.5s\tremaining: 1m 16s\n",
      "168:\tlearn: 1752.3165837\ttotal: 15.6s\tremaining: 1m 16s\n",
      "169:\tlearn: 1751.6151273\ttotal: 15.7s\tremaining: 1m 16s\n",
      "170:\tlearn: 1750.9238667\ttotal: 15.8s\tremaining: 1m 16s\n",
      "171:\tlearn: 1750.1004502\ttotal: 15.8s\tremaining: 1m 16s\n",
      "172:\tlearn: 1749.6568967\ttotal: 15.9s\tremaining: 1m 16s\n",
      "173:\tlearn: 1749.2297715\ttotal: 16s\tremaining: 1m 16s\n",
      "174:\tlearn: 1748.3140595\ttotal: 16.1s\tremaining: 1m 16s\n",
      "175:\tlearn: 1746.7905034\ttotal: 16.2s\tremaining: 1m 15s\n",
      "176:\tlearn: 1745.9147020\ttotal: 16.3s\tremaining: 1m 15s\n",
      "177:\tlearn: 1745.0334064\ttotal: 16.4s\tremaining: 1m 15s\n",
      "178:\tlearn: 1744.7185491\ttotal: 16.5s\tremaining: 1m 15s\n",
      "179:\tlearn: 1743.8785305\ttotal: 16.6s\tremaining: 1m 15s\n",
      "180:\tlearn: 1743.5078343\ttotal: 16.7s\tremaining: 1m 15s\n",
      "181:\tlearn: 1742.3054013\ttotal: 16.8s\tremaining: 1m 15s\n",
      "182:\tlearn: 1741.5991246\ttotal: 16.9s\tremaining: 1m 15s\n",
      "183:\tlearn: 1741.2420291\ttotal: 17s\tremaining: 1m 15s\n",
      "184:\tlearn: 1740.6252018\ttotal: 17.1s\tremaining: 1m 15s\n",
      "185:\tlearn: 1740.6141825\ttotal: 17.1s\tremaining: 1m 15s\n",
      "186:\tlearn: 1740.1852632\ttotal: 17.2s\tremaining: 1m 14s\n",
      "187:\tlearn: 1739.7059070\ttotal: 17.3s\tremaining: 1m 14s\n",
      "188:\tlearn: 1739.1705110\ttotal: 17.4s\tremaining: 1m 14s\n",
      "189:\tlearn: 1739.1512845\ttotal: 17.5s\tremaining: 1m 14s\n",
      "190:\tlearn: 1738.6733783\ttotal: 17.6s\tremaining: 1m 14s\n",
      "191:\tlearn: 1737.7626809\ttotal: 17.6s\tremaining: 1m 14s\n",
      "192:\tlearn: 1737.6122743\ttotal: 17.8s\tremaining: 1m 14s\n",
      "193:\tlearn: 1736.6636754\ttotal: 17.8s\tremaining: 1m 14s\n",
      "194:\tlearn: 1735.7618141\ttotal: 17.9s\tremaining: 1m 13s\n",
      "195:\tlearn: 1735.1972867\ttotal: 18s\tremaining: 1m 13s\n",
      "196:\tlearn: 1734.3567232\ttotal: 18.1s\tremaining: 1m 13s\n",
      "197:\tlearn: 1734.0387307\ttotal: 18.2s\tremaining: 1m 13s\n",
      "198:\tlearn: 1733.7833985\ttotal: 18.3s\tremaining: 1m 13s\n",
      "199:\tlearn: 1733.2877927\ttotal: 18.4s\tremaining: 1m 13s\n",
      "200:\tlearn: 1733.1127724\ttotal: 18.4s\tremaining: 1m 13s\n",
      "201:\tlearn: 1732.0529822\ttotal: 18.5s\tremaining: 1m 13s\n",
      "202:\tlearn: 1731.4116623\ttotal: 18.6s\tremaining: 1m 13s\n",
      "203:\tlearn: 1730.5637329\ttotal: 18.7s\tremaining: 1m 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204:\tlearn: 1730.3936429\ttotal: 18.8s\tremaining: 1m 12s\n",
      "205:\tlearn: 1729.7420883\ttotal: 18.9s\tremaining: 1m 12s\n",
      "206:\tlearn: 1729.5357337\ttotal: 19s\tremaining: 1m 12s\n",
      "207:\tlearn: 1728.7871967\ttotal: 19.1s\tremaining: 1m 12s\n",
      "208:\tlearn: 1728.1770930\ttotal: 19.1s\tremaining: 1m 12s\n",
      "209:\tlearn: 1728.1626350\ttotal: 19.2s\tremaining: 1m 12s\n",
      "210:\tlearn: 1727.7026589\ttotal: 19.3s\tremaining: 1m 12s\n",
      "211:\tlearn: 1726.8252372\ttotal: 19.4s\tremaining: 1m 11s\n",
      "212:\tlearn: 1726.4758743\ttotal: 19.5s\tremaining: 1m 11s\n",
      "213:\tlearn: 1726.2821177\ttotal: 19.6s\tremaining: 1m 11s\n",
      "214:\tlearn: 1725.4582783\ttotal: 19.6s\tremaining: 1m 11s\n",
      "215:\tlearn: 1725.4453089\ttotal: 19.7s\tremaining: 1m 11s\n",
      "216:\tlearn: 1724.6262613\ttotal: 19.8s\tremaining: 1m 11s\n",
      "217:\tlearn: 1724.2395995\ttotal: 19.9s\tremaining: 1m 11s\n",
      "218:\tlearn: 1723.5915655\ttotal: 19.9s\tremaining: 1m 11s\n",
      "219:\tlearn: 1723.0480436\ttotal: 20s\tremaining: 1m 11s\n",
      "220:\tlearn: 1722.3046896\ttotal: 20.1s\tremaining: 1m 10s\n",
      "221:\tlearn: 1722.2926579\ttotal: 20.2s\tremaining: 1m 10s\n",
      "222:\tlearn: 1721.9472446\ttotal: 20.3s\tremaining: 1m 10s\n",
      "223:\tlearn: 1721.1643739\ttotal: 20.4s\tremaining: 1m 10s\n",
      "224:\tlearn: 1720.3661267\ttotal: 20.4s\tremaining: 1m 10s\n",
      "225:\tlearn: 1719.7036328\ttotal: 20.5s\tremaining: 1m 10s\n",
      "226:\tlearn: 1719.6927243\ttotal: 20.6s\tremaining: 1m 10s\n",
      "227:\tlearn: 1718.7362403\ttotal: 20.7s\tremaining: 1m 10s\n",
      "228:\tlearn: 1718.4338892\ttotal: 20.8s\tremaining: 1m 9s\n",
      "229:\tlearn: 1718.2169739\ttotal: 20.9s\tremaining: 1m 9s\n",
      "230:\tlearn: 1717.7354279\ttotal: 21s\tremaining: 1m 9s\n",
      "231:\tlearn: 1717.2072357\ttotal: 21.1s\tremaining: 1m 9s\n",
      "232:\tlearn: 1716.5633243\ttotal: 21.2s\tremaining: 1m 9s\n",
      "233:\tlearn: 1715.9481942\ttotal: 21.3s\tremaining: 1m 9s\n",
      "234:\tlearn: 1715.7420558\ttotal: 21.4s\tremaining: 1m 9s\n",
      "235:\tlearn: 1715.0006233\ttotal: 21.5s\tremaining: 1m 9s\n",
      "236:\tlearn: 1714.2822471\ttotal: 21.6s\tremaining: 1m 9s\n",
      "237:\tlearn: 1714.0544423\ttotal: 21.6s\tremaining: 1m 9s\n",
      "238:\tlearn: 1713.7487831\ttotal: 21.7s\tremaining: 1m 9s\n",
      "239:\tlearn: 1713.1454762\ttotal: 21.8s\tremaining: 1m 9s\n",
      "240:\tlearn: 1712.6589583\ttotal: 22s\tremaining: 1m 9s\n",
      "241:\tlearn: 1712.6485488\ttotal: 22s\tremaining: 1m 8s\n",
      "242:\tlearn: 1712.1855323\ttotal: 22.1s\tremaining: 1m 8s\n",
      "243:\tlearn: 1711.8058977\ttotal: 22.2s\tremaining: 1m 8s\n",
      "244:\tlearn: 1711.3066986\ttotal: 22.3s\tremaining: 1m 8s\n",
      "245:\tlearn: 1711.2976198\ttotal: 22.4s\tremaining: 1m 8s\n",
      "246:\tlearn: 1711.1246372\ttotal: 22.5s\tremaining: 1m 8s\n",
      "247:\tlearn: 1710.9487687\ttotal: 22.6s\tremaining: 1m 8s\n",
      "248:\tlearn: 1710.6073957\ttotal: 22.7s\tremaining: 1m 8s\n",
      "249:\tlearn: 1710.3106422\ttotal: 22.7s\tremaining: 1m 8s\n",
      "250:\tlearn: 1710.0335905\ttotal: 22.8s\tremaining: 1m 8s\n",
      "251:\tlearn: 1709.2862327\ttotal: 22.9s\tremaining: 1m 8s\n",
      "252:\tlearn: 1708.6536618\ttotal: 23s\tremaining: 1m 8s\n",
      "253:\tlearn: 1707.9916728\ttotal: 23.1s\tremaining: 1m 7s\n",
      "254:\tlearn: 1707.0991833\ttotal: 23.2s\tremaining: 1m 7s\n",
      "255:\tlearn: 1706.6461628\ttotal: 23.3s\tremaining: 1m 7s\n",
      "256:\tlearn: 1706.3401996\ttotal: 23.4s\tremaining: 1m 7s\n",
      "257:\tlearn: 1705.9286671\ttotal: 23.5s\tremaining: 1m 7s\n",
      "258:\tlearn: 1705.7354484\ttotal: 23.6s\tremaining: 1m 7s\n",
      "259:\tlearn: 1705.0055304\ttotal: 23.6s\tremaining: 1m 7s\n",
      "260:\tlearn: 1704.6886315\ttotal: 23.7s\tremaining: 1m 7s\n",
      "261:\tlearn: 1704.1091397\ttotal: 23.8s\tremaining: 1m 7s\n",
      "262:\tlearn: 1703.4197026\ttotal: 23.9s\tremaining: 1m 7s\n",
      "263:\tlearn: 1702.5898766\ttotal: 24s\tremaining: 1m 6s\n",
      "264:\tlearn: 1702.2489237\ttotal: 24.1s\tremaining: 1m 6s\n",
      "265:\tlearn: 1701.8166489\ttotal: 24.2s\tremaining: 1m 6s\n",
      "266:\tlearn: 1701.4037865\ttotal: 24.3s\tremaining: 1m 6s\n",
      "267:\tlearn: 1701.1263661\ttotal: 24.3s\tremaining: 1m 6s\n",
      "268:\tlearn: 1700.7336336\ttotal: 24.5s\tremaining: 1m 6s\n",
      "269:\tlearn: 1700.7277930\ttotal: 24.5s\tremaining: 1m 6s\n",
      "270:\tlearn: 1700.1844306\ttotal: 24.6s\tremaining: 1m 6s\n",
      "271:\tlearn: 1700.1703769\ttotal: 24.7s\tremaining: 1m 6s\n",
      "272:\tlearn: 1700.1579434\ttotal: 24.8s\tremaining: 1m 5s\n",
      "273:\tlearn: 1699.6139544\ttotal: 24.8s\tremaining: 1m 5s\n",
      "274:\tlearn: 1699.3277635\ttotal: 24.9s\tremaining: 1m 5s\n",
      "275:\tlearn: 1698.6361329\ttotal: 25s\tremaining: 1m 5s\n",
      "276:\tlearn: 1698.2477669\ttotal: 25.1s\tremaining: 1m 5s\n",
      "277:\tlearn: 1697.8248957\ttotal: 25.2s\tremaining: 1m 5s\n",
      "278:\tlearn: 1697.4646189\ttotal: 25.3s\tremaining: 1m 5s\n",
      "279:\tlearn: 1697.0212700\ttotal: 25.4s\tremaining: 1m 5s\n",
      "280:\tlearn: 1696.6116404\ttotal: 25.5s\tremaining: 1m 5s\n",
      "281:\tlearn: 1696.2029497\ttotal: 25.6s\tremaining: 1m 5s\n",
      "282:\tlearn: 1696.0392915\ttotal: 25.6s\tremaining: 1m 4s\n",
      "283:\tlearn: 1696.0285997\ttotal: 25.7s\tremaining: 1m 4s\n",
      "284:\tlearn: 1695.9723206\ttotal: 25.8s\tremaining: 1m 4s\n",
      "285:\tlearn: 1695.5211044\ttotal: 25.9s\tremaining: 1m 4s\n",
      "286:\tlearn: 1695.0843715\ttotal: 25.9s\tremaining: 1m 4s\n",
      "287:\tlearn: 1694.6665541\ttotal: 26s\tremaining: 1m 4s\n",
      "288:\tlearn: 1694.4138592\ttotal: 26.1s\tremaining: 1m 4s\n",
      "289:\tlearn: 1694.0860346\ttotal: 26.2s\tremaining: 1m 4s\n",
      "290:\tlearn: 1693.6848430\ttotal: 26.3s\tremaining: 1m 4s\n",
      "291:\tlearn: 1693.3630189\ttotal: 26.4s\tremaining: 1m 3s\n",
      "292:\tlearn: 1692.9209165\ttotal: 26.5s\tremaining: 1m 3s\n",
      "293:\tlearn: 1692.9099516\ttotal: 26.5s\tremaining: 1m 3s\n",
      "294:\tlearn: 1692.6036303\ttotal: 26.6s\tremaining: 1m 3s\n",
      "295:\tlearn: 1692.1575447\ttotal: 26.7s\tremaining: 1m 3s\n",
      "296:\tlearn: 1691.7330831\ttotal: 26.8s\tremaining: 1m 3s\n",
      "297:\tlearn: 1691.3725745\ttotal: 26.9s\tremaining: 1m 3s\n",
      "298:\tlearn: 1691.1023944\ttotal: 27s\tremaining: 1m 3s\n",
      "299:\tlearn: 1690.7125447\ttotal: 27.1s\tremaining: 1m 3s\n",
      "300:\tlearn: 1690.1998255\ttotal: 27.2s\tremaining: 1m 3s\n",
      "301:\tlearn: 1689.6528422\ttotal: 27.2s\tremaining: 1m 2s\n",
      "302:\tlearn: 1689.4479183\ttotal: 27.3s\tremaining: 1m 2s\n",
      "303:\tlearn: 1689.1769958\ttotal: 27.4s\tremaining: 1m 2s\n",
      "304:\tlearn: 1688.8500000\ttotal: 27.5s\tremaining: 1m 2s\n",
      "305:\tlearn: 1688.7039477\ttotal: 27.6s\tremaining: 1m 2s\n",
      "306:\tlearn: 1688.6334663\ttotal: 27.6s\tremaining: 1m 2s\n",
      "307:\tlearn: 1687.9940060\ttotal: 27.7s\tremaining: 1m 2s\n",
      "308:\tlearn: 1687.6736040\ttotal: 27.8s\tremaining: 1m 2s\n",
      "309:\tlearn: 1686.9684445\ttotal: 27.9s\tremaining: 1m 2s\n",
      "310:\tlearn: 1686.8527796\ttotal: 28s\tremaining: 1m 1s\n",
      "311:\tlearn: 1686.4433576\ttotal: 28.1s\tremaining: 1m 1s\n",
      "312:\tlearn: 1686.0690556\ttotal: 28.2s\tremaining: 1m 1s\n",
      "313:\tlearn: 1685.6904501\ttotal: 28.3s\tremaining: 1m 1s\n",
      "314:\tlearn: 1685.0262358\ttotal: 28.4s\tremaining: 1m 1s\n",
      "315:\tlearn: 1684.3731671\ttotal: 28.4s\tremaining: 1m 1s\n",
      "316:\tlearn: 1683.8039757\ttotal: 28.6s\tremaining: 1m 1s\n",
      "317:\tlearn: 1683.6630906\ttotal: 28.6s\tremaining: 1m 1s\n",
      "318:\tlearn: 1683.3159975\ttotal: 28.7s\tremaining: 1m 1s\n",
      "319:\tlearn: 1683.0732434\ttotal: 28.8s\tremaining: 1m 1s\n",
      "320:\tlearn: 1682.9255480\ttotal: 28.9s\tremaining: 1m 1s\n",
      "321:\tlearn: 1682.6498307\ttotal: 29s\tremaining: 1m 1s\n",
      "322:\tlearn: 1682.1964569\ttotal: 29.1s\tremaining: 1m\n",
      "323:\tlearn: 1681.9460432\ttotal: 29.1s\tremaining: 1m\n",
      "324:\tlearn: 1681.6028939\ttotal: 29.2s\tremaining: 1m\n",
      "325:\tlearn: 1681.5059105\ttotal: 29.3s\tremaining: 1m\n",
      "326:\tlearn: 1681.1078763\ttotal: 29.4s\tremaining: 1m\n",
      "327:\tlearn: 1680.8614133\ttotal: 29.5s\tremaining: 1m\n",
      "328:\tlearn: 1680.6146151\ttotal: 29.6s\tremaining: 1m\n",
      "329:\tlearn: 1680.3350221\ttotal: 29.7s\tremaining: 1m\n",
      "330:\tlearn: 1680.1725187\ttotal: 29.8s\tremaining: 1m\n",
      "331:\tlearn: 1679.7638609\ttotal: 29.9s\tremaining: 1m\n",
      "332:\tlearn: 1679.4888274\ttotal: 30s\tremaining: 1m\n",
      "333:\tlearn: 1678.8916232\ttotal: 30s\tremaining: 59.9s\n",
      "334:\tlearn: 1678.5414875\ttotal: 30.1s\tremaining: 59.8s\n",
      "335:\tlearn: 1678.2068904\ttotal: 30.3s\tremaining: 59.8s\n",
      "336:\tlearn: 1677.7454404\ttotal: 30.3s\tremaining: 59.7s\n",
      "337:\tlearn: 1677.3742300\ttotal: 30.4s\tremaining: 59.6s\n",
      "338:\tlearn: 1677.2173272\ttotal: 30.5s\tremaining: 59.5s\n",
      "339:\tlearn: 1677.0999168\ttotal: 30.6s\tremaining: 59.4s\n",
      "340:\tlearn: 1676.8930395\ttotal: 30.7s\tremaining: 59.4s\n",
      "341:\tlearn: 1676.5413693\ttotal: 30.8s\tremaining: 59.3s\n",
      "342:\tlearn: 1676.3081647\ttotal: 30.9s\tremaining: 59.2s\n",
      "343:\tlearn: 1675.9465030\ttotal: 31s\tremaining: 59.1s\n",
      "344:\tlearn: 1675.4491428\ttotal: 31.1s\tremaining: 59s\n",
      "345:\tlearn: 1675.1331672\ttotal: 31.1s\tremaining: 58.9s\n",
      "346:\tlearn: 1674.8889872\ttotal: 31.2s\tremaining: 58.8s\n",
      "347:\tlearn: 1674.5217156\ttotal: 31.3s\tremaining: 58.7s\n",
      "348:\tlearn: 1674.1966186\ttotal: 31.4s\tremaining: 58.6s\n",
      "349:\tlearn: 1674.0902935\ttotal: 31.5s\tremaining: 58.5s\n",
      "350:\tlearn: 1673.7692292\ttotal: 31.6s\tremaining: 58.4s\n",
      "351:\tlearn: 1673.4825043\ttotal: 31.7s\tremaining: 58.3s\n",
      "352:\tlearn: 1672.9771976\ttotal: 31.8s\tremaining: 58.2s\n",
      "353:\tlearn: 1672.6651666\ttotal: 31.9s\tremaining: 58.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354:\tlearn: 1672.1926995\ttotal: 31.9s\tremaining: 58s\n",
      "355:\tlearn: 1671.8794605\ttotal: 32s\tremaining: 57.9s\n",
      "356:\tlearn: 1671.6625183\ttotal: 32.1s\tremaining: 57.8s\n",
      "357:\tlearn: 1671.3829306\ttotal: 32.2s\tremaining: 57.7s\n",
      "358:\tlearn: 1670.9986789\ttotal: 32.3s\tremaining: 57.6s\n",
      "359:\tlearn: 1670.6504048\ttotal: 32.4s\tremaining: 57.5s\n",
      "360:\tlearn: 1670.4235632\ttotal: 32.4s\tremaining: 57.4s\n",
      "361:\tlearn: 1670.2672195\ttotal: 32.5s\tremaining: 57.4s\n",
      "362:\tlearn: 1670.0768343\ttotal: 32.7s\tremaining: 57.3s\n",
      "363:\tlearn: 1669.9000600\ttotal: 32.7s\tremaining: 57.2s\n",
      "364:\tlearn: 1669.7859290\ttotal: 32.8s\tremaining: 57.1s\n",
      "365:\tlearn: 1669.3228931\ttotal: 32.9s\tremaining: 57.1s\n",
      "366:\tlearn: 1669.2167707\ttotal: 33s\tremaining: 57s\n",
      "367:\tlearn: 1668.1266715\ttotal: 33.1s\tremaining: 56.9s\n",
      "368:\tlearn: 1667.8979305\ttotal: 33.2s\tremaining: 56.8s\n",
      "369:\tlearn: 1667.5338916\ttotal: 33.3s\tremaining: 56.7s\n",
      "370:\tlearn: 1667.0983904\ttotal: 33.3s\tremaining: 56.5s\n",
      "371:\tlearn: 1666.6366620\ttotal: 33.4s\tremaining: 56.4s\n",
      "372:\tlearn: 1666.2957405\ttotal: 33.5s\tremaining: 56.4s\n",
      "373:\tlearn: 1666.0000036\ttotal: 33.6s\tremaining: 56.3s\n",
      "374:\tlearn: 1665.6515468\ttotal: 33.7s\tremaining: 56.2s\n",
      "375:\tlearn: 1665.1028433\ttotal: 33.8s\tremaining: 56.1s\n",
      "376:\tlearn: 1664.8276423\ttotal: 33.9s\tremaining: 56s\n",
      "377:\tlearn: 1664.4152941\ttotal: 34s\tremaining: 55.9s\n",
      "378:\tlearn: 1663.8776021\ttotal: 34.1s\tremaining: 55.8s\n",
      "379:\tlearn: 1663.4004317\ttotal: 34.1s\tremaining: 55.7s\n",
      "380:\tlearn: 1663.2041884\ttotal: 34.2s\tremaining: 55.6s\n",
      "381:\tlearn: 1662.6538952\ttotal: 34.3s\tremaining: 55.5s\n",
      "382:\tlearn: 1662.2055064\ttotal: 34.4s\tremaining: 55.4s\n",
      "383:\tlearn: 1662.0246502\ttotal: 34.5s\tremaining: 55.3s\n",
      "384:\tlearn: 1661.5923564\ttotal: 34.5s\tremaining: 55.1s\n",
      "385:\tlearn: 1661.3373769\ttotal: 34.6s\tremaining: 55s\n",
      "386:\tlearn: 1661.0602258\ttotal: 34.7s\tremaining: 55s\n",
      "387:\tlearn: 1660.7045450\ttotal: 34.8s\tremaining: 54.9s\n",
      "388:\tlearn: 1660.4978508\ttotal: 34.9s\tremaining: 54.8s\n",
      "389:\tlearn: 1660.3162238\ttotal: 35s\tremaining: 54.7s\n",
      "390:\tlearn: 1659.7616661\ttotal: 35.1s\tremaining: 54.7s\n",
      "391:\tlearn: 1659.4953019\ttotal: 35.2s\tremaining: 54.6s\n",
      "392:\tlearn: 1659.2874074\ttotal: 35.3s\tremaining: 54.5s\n",
      "393:\tlearn: 1659.1289791\ttotal: 35.4s\tremaining: 54.5s\n",
      "394:\tlearn: 1658.9013360\ttotal: 35.5s\tremaining: 54.3s\n",
      "395:\tlearn: 1658.5391778\ttotal: 35.6s\tremaining: 54.3s\n",
      "396:\tlearn: 1658.3047410\ttotal: 35.7s\tremaining: 54.2s\n",
      "397:\tlearn: 1658.1068821\ttotal: 35.8s\tremaining: 54.1s\n",
      "398:\tlearn: 1657.7172507\ttotal: 35.8s\tremaining: 54s\n",
      "399:\tlearn: 1657.3812539\ttotal: 35.9s\tremaining: 53.9s\n",
      "400:\tlearn: 1657.1664392\ttotal: 36s\tremaining: 53.7s\n",
      "401:\tlearn: 1656.7608151\ttotal: 36.1s\tremaining: 53.6s\n",
      "402:\tlearn: 1656.5166168\ttotal: 36.1s\tremaining: 53.5s\n",
      "403:\tlearn: 1656.1441677\ttotal: 36.2s\tremaining: 53.4s\n",
      "404:\tlearn: 1655.8061781\ttotal: 36.3s\tremaining: 53.4s\n",
      "405:\tlearn: 1655.5223049\ttotal: 36.4s\tremaining: 53.3s\n",
      "406:\tlearn: 1655.0889510\ttotal: 36.5s\tremaining: 53.2s\n",
      "407:\tlearn: 1654.7829905\ttotal: 36.6s\tremaining: 53.1s\n",
      "408:\tlearn: 1654.4753671\ttotal: 36.6s\tremaining: 53s\n",
      "409:\tlearn: 1654.0715807\ttotal: 36.7s\tremaining: 52.8s\n",
      "410:\tlearn: 1653.8650249\ttotal: 36.8s\tremaining: 52.7s\n",
      "411:\tlearn: 1653.5292476\ttotal: 36.9s\tremaining: 52.6s\n",
      "412:\tlearn: 1653.4463229\ttotal: 37s\tremaining: 52.5s\n",
      "413:\tlearn: 1653.1989898\ttotal: 37s\tremaining: 52.4s\n",
      "414:\tlearn: 1652.8400646\ttotal: 37.1s\tremaining: 52.3s\n",
      "415:\tlearn: 1652.6229384\ttotal: 37.2s\tremaining: 52.2s\n",
      "416:\tlearn: 1652.5645597\ttotal: 37.3s\tremaining: 52.1s\n",
      "417:\tlearn: 1652.1893139\ttotal: 37.3s\tremaining: 52s\n",
      "418:\tlearn: 1651.6660730\ttotal: 37.4s\tremaining: 51.9s\n",
      "419:\tlearn: 1651.4488269\ttotal: 37.5s\tremaining: 51.8s\n",
      "420:\tlearn: 1651.2626391\ttotal: 37.6s\tremaining: 51.7s\n",
      "421:\tlearn: 1650.9178569\ttotal: 37.7s\tremaining: 51.6s\n",
      "422:\tlearn: 1650.7748510\ttotal: 37.8s\tremaining: 51.5s\n",
      "423:\tlearn: 1650.4609385\ttotal: 37.9s\tremaining: 51.4s\n",
      "424:\tlearn: 1650.3744700\ttotal: 37.9s\tremaining: 51.3s\n",
      "425:\tlearn: 1650.2100333\ttotal: 38s\tremaining: 51.2s\n",
      "426:\tlearn: 1649.7116841\ttotal: 38.1s\tremaining: 51.1s\n",
      "427:\tlearn: 1649.4621425\ttotal: 38.2s\tremaining: 51s\n",
      "428:\tlearn: 1649.1802988\ttotal: 38.3s\tremaining: 50.9s\n",
      "429:\tlearn: 1649.1755566\ttotal: 38.3s\tremaining: 50.8s\n",
      "430:\tlearn: 1648.7945324\ttotal: 38.4s\tremaining: 50.7s\n",
      "431:\tlearn: 1648.5204757\ttotal: 38.5s\tremaining: 50.6s\n",
      "432:\tlearn: 1648.3953644\ttotal: 38.6s\tremaining: 50.5s\n",
      "433:\tlearn: 1648.2687641\ttotal: 38.6s\tremaining: 50.4s\n",
      "434:\tlearn: 1647.8453622\ttotal: 38.7s\tremaining: 50.3s\n",
      "435:\tlearn: 1647.5701062\ttotal: 38.8s\tremaining: 50.2s\n",
      "436:\tlearn: 1647.4571703\ttotal: 38.9s\tremaining: 50.2s\n",
      "437:\tlearn: 1647.0754464\ttotal: 39s\tremaining: 50.1s\n",
      "438:\tlearn: 1646.8822613\ttotal: 39.1s\tremaining: 50s\n",
      "439:\tlearn: 1646.7007525\ttotal: 39.2s\tremaining: 49.9s\n",
      "440:\tlearn: 1646.5012931\ttotal: 39.3s\tremaining: 49.8s\n",
      "441:\tlearn: 1646.1234661\ttotal: 39.4s\tremaining: 49.7s\n",
      "442:\tlearn: 1645.6665935\ttotal: 39.5s\tremaining: 49.6s\n",
      "443:\tlearn: 1645.4138541\ttotal: 39.6s\tremaining: 49.6s\n",
      "444:\tlearn: 1645.1809844\ttotal: 39.7s\tremaining: 49.5s\n",
      "445:\tlearn: 1644.9977103\ttotal: 39.8s\tremaining: 49.4s\n",
      "446:\tlearn: 1644.6548679\ttotal: 39.9s\tremaining: 49.3s\n",
      "447:\tlearn: 1644.5486248\ttotal: 39.9s\tremaining: 49.2s\n",
      "448:\tlearn: 1644.4317453\ttotal: 40s\tremaining: 49.1s\n",
      "449:\tlearn: 1644.1309661\ttotal: 40.1s\tremaining: 49s\n",
      "450:\tlearn: 1644.0497576\ttotal: 40.2s\tremaining: 48.9s\n",
      "451:\tlearn: 1643.8240268\ttotal: 40.3s\tremaining: 48.8s\n",
      "452:\tlearn: 1643.6929160\ttotal: 40.3s\tremaining: 48.7s\n",
      "453:\tlearn: 1643.2949348\ttotal: 40.4s\tremaining: 48.6s\n",
      "454:\tlearn: 1643.0900653\ttotal: 40.5s\tremaining: 48.5s\n",
      "455:\tlearn: 1642.9923707\ttotal: 40.6s\tremaining: 48.4s\n",
      "456:\tlearn: 1642.7991203\ttotal: 40.7s\tremaining: 48.3s\n",
      "457:\tlearn: 1642.5759135\ttotal: 40.7s\tremaining: 48.2s\n",
      "458:\tlearn: 1642.4166297\ttotal: 40.8s\tremaining: 48.1s\n",
      "459:\tlearn: 1642.0573031\ttotal: 40.9s\tremaining: 48s\n",
      "460:\tlearn: 1641.8828050\ttotal: 41s\tremaining: 48s\n",
      "461:\tlearn: 1641.7200761\ttotal: 41.1s\tremaining: 47.9s\n",
      "462:\tlearn: 1641.4517487\ttotal: 41.2s\tremaining: 47.8s\n",
      "463:\tlearn: 1641.2576459\ttotal: 41.3s\tremaining: 47.7s\n",
      "464:\tlearn: 1641.1683488\ttotal: 41.4s\tremaining: 47.6s\n",
      "465:\tlearn: 1640.8302572\ttotal: 41.5s\tremaining: 47.5s\n",
      "466:\tlearn: 1640.5794578\ttotal: 41.6s\tremaining: 47.4s\n",
      "467:\tlearn: 1640.1928040\ttotal: 41.6s\tremaining: 47.3s\n",
      "468:\tlearn: 1640.1267684\ttotal: 41.7s\tremaining: 47.3s\n",
      "469:\tlearn: 1639.9062844\ttotal: 41.8s\tremaining: 47.2s\n",
      "470:\tlearn: 1639.8010331\ttotal: 41.9s\tremaining: 47.1s\n",
      "471:\tlearn: 1639.6893368\ttotal: 42s\tremaining: 47s\n",
      "472:\tlearn: 1639.4561865\ttotal: 42.1s\tremaining: 46.9s\n",
      "473:\tlearn: 1638.9817867\ttotal: 42.2s\tremaining: 46.8s\n",
      "474:\tlearn: 1638.5906088\ttotal: 42.3s\tremaining: 46.7s\n",
      "475:\tlearn: 1638.3850736\ttotal: 42.4s\tremaining: 46.6s\n",
      "476:\tlearn: 1638.3471063\ttotal: 42.5s\tremaining: 46.6s\n",
      "477:\tlearn: 1638.2718039\ttotal: 42.5s\tremaining: 46.4s\n",
      "478:\tlearn: 1638.1608283\ttotal: 42.6s\tremaining: 46.4s\n",
      "479:\tlearn: 1638.0129866\ttotal: 42.7s\tremaining: 46.3s\n",
      "480:\tlearn: 1637.9023518\ttotal: 42.8s\tremaining: 46.2s\n",
      "481:\tlearn: 1637.8429616\ttotal: 42.9s\tremaining: 46.1s\n",
      "482:\tlearn: 1637.5127188\ttotal: 43s\tremaining: 46s\n",
      "483:\tlearn: 1637.4001274\ttotal: 43.1s\tremaining: 45.9s\n",
      "484:\tlearn: 1637.1661964\ttotal: 43.1s\tremaining: 45.8s\n",
      "485:\tlearn: 1637.1250422\ttotal: 43.2s\tremaining: 45.7s\n",
      "486:\tlearn: 1636.8604694\ttotal: 43.3s\tremaining: 45.6s\n",
      "487:\tlearn: 1636.6964517\ttotal: 43.4s\tremaining: 45.6s\n",
      "488:\tlearn: 1636.5084261\ttotal: 43.5s\tremaining: 45.5s\n",
      "489:\tlearn: 1636.4148392\ttotal: 43.6s\tremaining: 45.4s\n",
      "490:\tlearn: 1636.3306332\ttotal: 43.7s\tremaining: 45.3s\n",
      "491:\tlearn: 1636.1651656\ttotal: 43.8s\tremaining: 45.2s\n",
      "492:\tlearn: 1635.9739504\ttotal: 43.9s\tremaining: 45.1s\n",
      "493:\tlearn: 1635.7107599\ttotal: 44s\tremaining: 45.1s\n",
      "494:\tlearn: 1635.4481426\ttotal: 44.1s\tremaining: 45s\n",
      "495:\tlearn: 1635.3898275\ttotal: 44.2s\tremaining: 44.9s\n",
      "496:\tlearn: 1635.1861546\ttotal: 44.2s\tremaining: 44.8s\n",
      "497:\tlearn: 1635.1360358\ttotal: 44.3s\tremaining: 44.7s\n",
      "498:\tlearn: 1635.0909740\ttotal: 44.4s\tremaining: 44.6s\n",
      "499:\tlearn: 1635.0302453\ttotal: 44.5s\tremaining: 44.5s\n",
      "500:\tlearn: 1634.7904673\ttotal: 44.5s\tremaining: 44.4s\n",
      "501:\tlearn: 1634.5802574\ttotal: 44.6s\tremaining: 44.3s\n",
      "502:\tlearn: 1634.2712110\ttotal: 44.7s\tremaining: 44.2s\n",
      "503:\tlearn: 1634.0587308\ttotal: 44.8s\tremaining: 44.1s\n",
      "504:\tlearn: 1634.0109728\ttotal: 44.9s\tremaining: 44s\n",
      "505:\tlearn: 1633.7125836\ttotal: 45s\tremaining: 43.9s\n",
      "506:\tlearn: 1633.5466019\ttotal: 45.1s\tremaining: 43.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507:\tlearn: 1633.3168348\ttotal: 45.2s\tremaining: 43.7s\n",
      "508:\tlearn: 1633.1014820\ttotal: 45.3s\tremaining: 43.7s\n",
      "509:\tlearn: 1632.8719832\ttotal: 45.4s\tremaining: 43.6s\n",
      "510:\tlearn: 1632.6891880\ttotal: 45.4s\tremaining: 43.5s\n",
      "511:\tlearn: 1632.5324367\ttotal: 45.5s\tremaining: 43.4s\n",
      "512:\tlearn: 1632.3638245\ttotal: 45.6s\tremaining: 43.3s\n",
      "513:\tlearn: 1632.0655701\ttotal: 45.7s\tremaining: 43.2s\n",
      "514:\tlearn: 1631.8479431\ttotal: 45.8s\tremaining: 43.1s\n",
      "515:\tlearn: 1631.5577054\ttotal: 45.9s\tremaining: 43s\n",
      "516:\tlearn: 1631.5060067\ttotal: 46s\tremaining: 42.9s\n",
      "517:\tlearn: 1631.2988968\ttotal: 46s\tremaining: 42.8s\n",
      "518:\tlearn: 1631.0252277\ttotal: 46.1s\tremaining: 42.8s\n",
      "519:\tlearn: 1630.7219968\ttotal: 46.2s\tremaining: 42.7s\n",
      "520:\tlearn: 1630.6336172\ttotal: 46.3s\tremaining: 42.5s\n",
      "521:\tlearn: 1630.6119319\ttotal: 46.4s\tremaining: 42.5s\n",
      "522:\tlearn: 1630.4162174\ttotal: 46.5s\tremaining: 42.4s\n",
      "523:\tlearn: 1630.1590275\ttotal: 46.5s\tremaining: 42.3s\n",
      "524:\tlearn: 1629.8306229\ttotal: 46.7s\tremaining: 42.2s\n",
      "525:\tlearn: 1629.6517431\ttotal: 46.7s\tremaining: 42.1s\n",
      "526:\tlearn: 1629.4833979\ttotal: 46.8s\tremaining: 42s\n",
      "527:\tlearn: 1629.4387076\ttotal: 46.9s\tremaining: 41.9s\n",
      "528:\tlearn: 1629.2090258\ttotal: 47s\tremaining: 41.9s\n",
      "529:\tlearn: 1628.8939338\ttotal: 47.1s\tremaining: 41.8s\n",
      "530:\tlearn: 1628.8059548\ttotal: 47.2s\tremaining: 41.7s\n",
      "531:\tlearn: 1628.7606139\ttotal: 47.3s\tremaining: 41.6s\n",
      "532:\tlearn: 1628.7118613\ttotal: 47.4s\tremaining: 41.5s\n",
      "533:\tlearn: 1628.3862580\ttotal: 47.5s\tremaining: 41.4s\n",
      "534:\tlearn: 1628.2478850\ttotal: 47.6s\tremaining: 41.3s\n",
      "535:\tlearn: 1628.1911816\ttotal: 47.6s\tremaining: 41.2s\n",
      "536:\tlearn: 1627.9949000\ttotal: 47.7s\tremaining: 41.1s\n",
      "537:\tlearn: 1627.9377700\ttotal: 47.8s\tremaining: 41s\n",
      "538:\tlearn: 1627.8533121\ttotal: 47.9s\tremaining: 40.9s\n",
      "539:\tlearn: 1627.6337497\ttotal: 48s\tremaining: 40.8s\n",
      "540:\tlearn: 1627.4695505\ttotal: 48s\tremaining: 40.8s\n",
      "541:\tlearn: 1627.2238635\ttotal: 48.1s\tremaining: 40.7s\n",
      "542:\tlearn: 1627.0272976\ttotal: 48.2s\tremaining: 40.6s\n",
      "543:\tlearn: 1626.5759008\ttotal: 48.3s\tremaining: 40.5s\n",
      "544:\tlearn: 1626.3070468\ttotal: 48.4s\tremaining: 40.4s\n",
      "545:\tlearn: 1626.2134561\ttotal: 48.5s\tremaining: 40.3s\n",
      "546:\tlearn: 1626.0372336\ttotal: 48.6s\tremaining: 40.2s\n",
      "547:\tlearn: 1625.7570235\ttotal: 48.7s\tremaining: 40.1s\n",
      "548:\tlearn: 1625.6835488\ttotal: 48.7s\tremaining: 40s\n",
      "549:\tlearn: 1625.6187153\ttotal: 48.8s\tremaining: 39.9s\n",
      "550:\tlearn: 1625.3691495\ttotal: 48.8s\tremaining: 39.8s\n",
      "551:\tlearn: 1625.3325985\ttotal: 48.9s\tremaining: 39.7s\n",
      "552:\tlearn: 1625.3005412\ttotal: 49s\tremaining: 39.6s\n",
      "553:\tlearn: 1625.2158781\ttotal: 49.1s\tremaining: 39.5s\n",
      "554:\tlearn: 1624.9290202\ttotal: 49.2s\tremaining: 39.4s\n",
      "555:\tlearn: 1624.7762672\ttotal: 49.3s\tremaining: 39.3s\n",
      "556:\tlearn: 1624.6684042\ttotal: 49.3s\tremaining: 39.2s\n",
      "557:\tlearn: 1624.3684452\ttotal: 49.4s\tremaining: 39.2s\n",
      "558:\tlearn: 1624.1964943\ttotal: 49.5s\tremaining: 39.1s\n",
      "559:\tlearn: 1624.0837881\ttotal: 49.6s\tremaining: 39s\n",
      "560:\tlearn: 1623.8936920\ttotal: 49.7s\tremaining: 38.9s\n",
      "561:\tlearn: 1623.6347093\ttotal: 49.8s\tremaining: 38.8s\n",
      "562:\tlearn: 1623.4806754\ttotal: 49.9s\tremaining: 38.7s\n",
      "563:\tlearn: 1623.3381997\ttotal: 50s\tremaining: 38.6s\n",
      "564:\tlearn: 1623.0575091\ttotal: 50.1s\tremaining: 38.5s\n",
      "565:\tlearn: 1622.8252435\ttotal: 50.1s\tremaining: 38.4s\n",
      "566:\tlearn: 1622.7650315\ttotal: 50.2s\tremaining: 38.3s\n",
      "567:\tlearn: 1622.7478423\ttotal: 50.3s\tremaining: 38.3s\n",
      "568:\tlearn: 1622.4856159\ttotal: 50.4s\tremaining: 38.2s\n",
      "569:\tlearn: 1622.2640271\ttotal: 50.5s\tremaining: 38.1s\n",
      "570:\tlearn: 1622.1198376\ttotal: 50.6s\tremaining: 38s\n",
      "571:\tlearn: 1622.0295199\ttotal: 50.7s\tremaining: 37.9s\n",
      "572:\tlearn: 1621.8127221\ttotal: 50.7s\tremaining: 37.8s\n",
      "573:\tlearn: 1621.6607421\ttotal: 50.8s\tremaining: 37.7s\n",
      "574:\tlearn: 1621.4905916\ttotal: 50.9s\tremaining: 37.7s\n",
      "575:\tlearn: 1621.2849568\ttotal: 51.1s\tremaining: 37.6s\n",
      "576:\tlearn: 1621.1265118\ttotal: 51.1s\tremaining: 37.5s\n",
      "577:\tlearn: 1620.9964121\ttotal: 51.2s\tremaining: 37.4s\n",
      "578:\tlearn: 1620.8850040\ttotal: 51.3s\tremaining: 37.3s\n",
      "579:\tlearn: 1620.6807252\ttotal: 51.4s\tremaining: 37.2s\n",
      "580:\tlearn: 1620.3860683\ttotal: 51.5s\tremaining: 37.1s\n",
      "581:\tlearn: 1620.2122920\ttotal: 51.5s\tremaining: 37s\n",
      "582:\tlearn: 1620.1119920\ttotal: 51.6s\tremaining: 36.9s\n",
      "583:\tlearn: 1620.0016855\ttotal: 51.7s\tremaining: 36.8s\n",
      "584:\tlearn: 1619.7693972\ttotal: 51.8s\tremaining: 36.8s\n",
      "585:\tlearn: 1619.5247558\ttotal: 51.9s\tremaining: 36.7s\n",
      "586:\tlearn: 1619.3378795\ttotal: 52s\tremaining: 36.6s\n",
      "587:\tlearn: 1619.0298400\ttotal: 52.1s\tremaining: 36.5s\n",
      "588:\tlearn: 1618.7039361\ttotal: 52.2s\tremaining: 36.4s\n",
      "589:\tlearn: 1618.4802099\ttotal: 52.3s\tremaining: 36.3s\n",
      "590:\tlearn: 1618.1039751\ttotal: 52.4s\tremaining: 36.3s\n",
      "591:\tlearn: 1617.9060864\ttotal: 52.5s\tremaining: 36.2s\n",
      "592:\tlearn: 1617.8255739\ttotal: 52.6s\tremaining: 36.1s\n",
      "593:\tlearn: 1617.6418937\ttotal: 52.7s\tremaining: 36s\n",
      "594:\tlearn: 1617.3105359\ttotal: 52.8s\tremaining: 35.9s\n",
      "595:\tlearn: 1616.5015990\ttotal: 52.9s\tremaining: 35.8s\n",
      "596:\tlearn: 1616.2884161\ttotal: 53s\tremaining: 35.8s\n",
      "597:\tlearn: 1616.1989138\ttotal: 53.1s\tremaining: 35.7s\n",
      "598:\tlearn: 1616.1365769\ttotal: 53.2s\tremaining: 35.6s\n",
      "599:\tlearn: 1615.4611473\ttotal: 53.3s\tremaining: 35.5s\n",
      "600:\tlearn: 1615.2438236\ttotal: 53.4s\tremaining: 35.4s\n",
      "601:\tlearn: 1614.9234836\ttotal: 53.5s\tremaining: 35.3s\n",
      "602:\tlearn: 1614.7751297\ttotal: 53.6s\tremaining: 35.3s\n",
      "603:\tlearn: 1614.5374639\ttotal: 53.7s\tremaining: 35.2s\n",
      "604:\tlearn: 1614.3267877\ttotal: 53.8s\tremaining: 35.1s\n",
      "605:\tlearn: 1614.2914240\ttotal: 53.9s\tremaining: 35s\n",
      "606:\tlearn: 1614.1562166\ttotal: 54s\tremaining: 34.9s\n",
      "607:\tlearn: 1613.9094090\ttotal: 54s\tremaining: 34.8s\n",
      "608:\tlearn: 1613.7195857\ttotal: 54.1s\tremaining: 34.8s\n",
      "609:\tlearn: 1613.6721250\ttotal: 54.2s\tremaining: 34.7s\n",
      "610:\tlearn: 1613.3808295\ttotal: 54.3s\tremaining: 34.6s\n",
      "611:\tlearn: 1613.2808300\ttotal: 54.4s\tremaining: 34.5s\n",
      "612:\tlearn: 1613.1400150\ttotal: 54.5s\tremaining: 34.4s\n",
      "613:\tlearn: 1612.9876578\ttotal: 54.6s\tremaining: 34.3s\n",
      "614:\tlearn: 1612.8950004\ttotal: 54.7s\tremaining: 34.2s\n",
      "615:\tlearn: 1612.8008202\ttotal: 54.8s\tremaining: 34.2s\n",
      "616:\tlearn: 1612.5709066\ttotal: 54.9s\tremaining: 34.1s\n",
      "617:\tlearn: 1612.5417736\ttotal: 55s\tremaining: 34s\n",
      "618:\tlearn: 1612.4029384\ttotal: 55.1s\tremaining: 33.9s\n",
      "619:\tlearn: 1612.1814198\ttotal: 55.2s\tremaining: 33.8s\n",
      "620:\tlearn: 1612.0648862\ttotal: 55.3s\tremaining: 33.7s\n",
      "621:\tlearn: 1611.9021250\ttotal: 55.4s\tremaining: 33.7s\n",
      "622:\tlearn: 1611.8844925\ttotal: 55.5s\tremaining: 33.6s\n",
      "623:\tlearn: 1611.8310092\ttotal: 55.6s\tremaining: 33.5s\n",
      "624:\tlearn: 1611.7073350\ttotal: 55.7s\tremaining: 33.4s\n",
      "625:\tlearn: 1611.4654915\ttotal: 55.7s\tremaining: 33.3s\n",
      "626:\tlearn: 1611.1341661\ttotal: 55.8s\tremaining: 33.2s\n",
      "627:\tlearn: 1611.0051130\ttotal: 56s\tremaining: 33.1s\n",
      "628:\tlearn: 1610.7808350\ttotal: 56.1s\tremaining: 33.1s\n",
      "629:\tlearn: 1610.5794702\ttotal: 56.1s\tremaining: 33s\n",
      "630:\tlearn: 1610.3613886\ttotal: 56.3s\tremaining: 32.9s\n",
      "631:\tlearn: 1610.2643805\ttotal: 56.4s\tremaining: 32.8s\n",
      "632:\tlearn: 1610.0877812\ttotal: 56.4s\tremaining: 32.7s\n",
      "633:\tlearn: 1609.7942016\ttotal: 56.5s\tremaining: 32.6s\n",
      "634:\tlearn: 1609.5514751\ttotal: 56.7s\tremaining: 32.6s\n",
      "635:\tlearn: 1609.4003742\ttotal: 56.8s\tremaining: 32.5s\n",
      "636:\tlearn: 1609.2687555\ttotal: 56.9s\tremaining: 32.4s\n",
      "637:\tlearn: 1609.1538365\ttotal: 57s\tremaining: 32.3s\n",
      "638:\tlearn: 1609.0261008\ttotal: 57s\tremaining: 32.2s\n",
      "639:\tlearn: 1608.9301115\ttotal: 57.1s\tremaining: 32.1s\n",
      "640:\tlearn: 1608.8561267\ttotal: 57.2s\tremaining: 32s\n",
      "641:\tlearn: 1608.7121370\ttotal: 57.3s\tremaining: 31.9s\n",
      "642:\tlearn: 1608.5136767\ttotal: 57.4s\tremaining: 31.8s\n",
      "643:\tlearn: 1608.2211680\ttotal: 57.5s\tremaining: 31.8s\n",
      "644:\tlearn: 1608.0210752\ttotal: 57.5s\tremaining: 31.7s\n",
      "645:\tlearn: 1607.8510683\ttotal: 57.6s\tremaining: 31.6s\n",
      "646:\tlearn: 1607.6527071\ttotal: 57.7s\tremaining: 31.5s\n",
      "647:\tlearn: 1607.4906989\ttotal: 57.8s\tremaining: 31.4s\n",
      "648:\tlearn: 1607.3503264\ttotal: 57.9s\tremaining: 31.3s\n",
      "649:\tlearn: 1607.1372345\ttotal: 58s\tremaining: 31.2s\n",
      "650:\tlearn: 1606.9369071\ttotal: 58s\tremaining: 31.1s\n",
      "651:\tlearn: 1606.8314763\ttotal: 58.1s\tremaining: 31s\n",
      "652:\tlearn: 1606.6953763\ttotal: 58.2s\tremaining: 30.9s\n",
      "653:\tlearn: 1606.5503596\ttotal: 58.3s\tremaining: 30.9s\n",
      "654:\tlearn: 1606.4868409\ttotal: 58.4s\tremaining: 30.8s\n",
      "655:\tlearn: 1606.3161058\ttotal: 58.5s\tremaining: 30.7s\n",
      "656:\tlearn: 1606.2279948\ttotal: 58.6s\tremaining: 30.6s\n",
      "657:\tlearn: 1606.0106189\ttotal: 58.7s\tremaining: 30.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658:\tlearn: 1605.8200528\ttotal: 58.8s\tremaining: 30.4s\n",
      "659:\tlearn: 1605.5964280\ttotal: 58.9s\tremaining: 30.3s\n",
      "660:\tlearn: 1605.4965576\ttotal: 59s\tremaining: 30.3s\n",
      "661:\tlearn: 1605.3543609\ttotal: 59s\tremaining: 30.1s\n",
      "662:\tlearn: 1605.1288967\ttotal: 59.2s\tremaining: 30.1s\n",
      "663:\tlearn: 1604.9802990\ttotal: 59.3s\tremaining: 30s\n",
      "664:\tlearn: 1604.8411832\ttotal: 59.3s\tremaining: 29.9s\n",
      "665:\tlearn: 1604.7034347\ttotal: 59.4s\tremaining: 29.8s\n",
      "666:\tlearn: 1604.4834808\ttotal: 59.5s\tremaining: 29.7s\n",
      "667:\tlearn: 1604.3223659\ttotal: 59.6s\tremaining: 29.6s\n",
      "668:\tlearn: 1604.2729205\ttotal: 59.7s\tremaining: 29.5s\n",
      "669:\tlearn: 1604.1507377\ttotal: 59.8s\tremaining: 29.4s\n",
      "670:\tlearn: 1603.9866596\ttotal: 59.9s\tremaining: 29.4s\n",
      "671:\tlearn: 1603.9706850\ttotal: 60s\tremaining: 29.3s\n",
      "672:\tlearn: 1603.7821405\ttotal: 1m\tremaining: 29.2s\n",
      "673:\tlearn: 1603.7083039\ttotal: 1m\tremaining: 29.1s\n",
      "674:\tlearn: 1603.4535260\ttotal: 1m\tremaining: 29s\n",
      "675:\tlearn: 1603.4473813\ttotal: 1m\tremaining: 28.9s\n",
      "676:\tlearn: 1603.3787589\ttotal: 1m\tremaining: 28.9s\n",
      "677:\tlearn: 1603.3336865\ttotal: 1m\tremaining: 28.8s\n",
      "678:\tlearn: 1603.2921883\ttotal: 1m\tremaining: 28.7s\n",
      "679:\tlearn: 1603.1822342\ttotal: 1m\tremaining: 28.6s\n",
      "680:\tlearn: 1603.0044413\ttotal: 1m\tremaining: 28.5s\n",
      "681:\tlearn: 1602.8229032\ttotal: 1m\tremaining: 28.4s\n",
      "682:\tlearn: 1602.6498217\ttotal: 1m 1s\tremaining: 28.3s\n",
      "683:\tlearn: 1602.4913410\ttotal: 1m 1s\tremaining: 28.2s\n",
      "684:\tlearn: 1602.4315086\ttotal: 1m 1s\tremaining: 28.2s\n",
      "685:\tlearn: 1602.3962966\ttotal: 1m 1s\tremaining: 28.1s\n",
      "686:\tlearn: 1602.3055213\ttotal: 1m 1s\tremaining: 28s\n",
      "687:\tlearn: 1602.1608321\ttotal: 1m 1s\tremaining: 27.9s\n",
      "688:\tlearn: 1601.8383695\ttotal: 1m 1s\tremaining: 27.8s\n",
      "689:\tlearn: 1601.6015696\ttotal: 1m 1s\tremaining: 27.7s\n",
      "690:\tlearn: 1601.3730457\ttotal: 1m 1s\tremaining: 27.6s\n",
      "691:\tlearn: 1601.3287137\ttotal: 1m 1s\tremaining: 27.5s\n",
      "692:\tlearn: 1601.2244263\ttotal: 1m 1s\tremaining: 27.4s\n",
      "693:\tlearn: 1601.0272148\ttotal: 1m 1s\tremaining: 27.3s\n",
      "694:\tlearn: 1600.6963104\ttotal: 1m 2s\tremaining: 27.2s\n",
      "695:\tlearn: 1600.4491789\ttotal: 1m 2s\tremaining: 27.1s\n",
      "696:\tlearn: 1600.3172465\ttotal: 1m 2s\tremaining: 27.1s\n",
      "697:\tlearn: 1600.3030661\ttotal: 1m 2s\tremaining: 27s\n",
      "698:\tlearn: 1600.2473213\ttotal: 1m 2s\tremaining: 26.9s\n",
      "699:\tlearn: 1600.0194112\ttotal: 1m 2s\tremaining: 26.8s\n",
      "700:\tlearn: 1599.9244906\ttotal: 1m 2s\tremaining: 26.7s\n",
      "701:\tlearn: 1599.7186612\ttotal: 1m 2s\tremaining: 26.6s\n",
      "702:\tlearn: 1599.6043514\ttotal: 1m 2s\tremaining: 26.5s\n",
      "703:\tlearn: 1599.4387578\ttotal: 1m 2s\tremaining: 26.5s\n",
      "704:\tlearn: 1599.2628479\ttotal: 1m 3s\tremaining: 26.4s\n",
      "705:\tlearn: 1599.0921786\ttotal: 1m 3s\tremaining: 26.3s\n",
      "706:\tlearn: 1599.0102282\ttotal: 1m 3s\tremaining: 26.2s\n",
      "707:\tlearn: 1598.8381259\ttotal: 1m 3s\tremaining: 26.1s\n",
      "708:\tlearn: 1598.6334892\ttotal: 1m 3s\tremaining: 26s\n",
      "709:\tlearn: 1598.6265684\ttotal: 1m 3s\tremaining: 25.9s\n",
      "710:\tlearn: 1598.5149909\ttotal: 1m 3s\tremaining: 25.8s\n",
      "711:\tlearn: 1598.2771201\ttotal: 1m 3s\tremaining: 25.7s\n",
      "712:\tlearn: 1598.0823546\ttotal: 1m 3s\tremaining: 25.6s\n",
      "713:\tlearn: 1598.0208657\ttotal: 1m 3s\tremaining: 25.6s\n",
      "714:\tlearn: 1597.8658492\ttotal: 1m 3s\tremaining: 25.5s\n",
      "715:\tlearn: 1597.7809771\ttotal: 1m 3s\tremaining: 25.4s\n",
      "716:\tlearn: 1597.5611632\ttotal: 1m 4s\tremaining: 25.3s\n",
      "717:\tlearn: 1597.3625711\ttotal: 1m 4s\tremaining: 25.2s\n",
      "718:\tlearn: 1597.2681476\ttotal: 1m 4s\tremaining: 25.1s\n",
      "719:\tlearn: 1597.2206425\ttotal: 1m 4s\tremaining: 25s\n",
      "720:\tlearn: 1597.0321290\ttotal: 1m 4s\tremaining: 24.9s\n",
      "721:\tlearn: 1596.9256488\ttotal: 1m 4s\tremaining: 24.8s\n",
      "722:\tlearn: 1596.8059477\ttotal: 1m 4s\tremaining: 24.8s\n",
      "723:\tlearn: 1596.6936039\ttotal: 1m 4s\tremaining: 24.6s\n",
      "724:\tlearn: 1596.4835764\ttotal: 1m 4s\tremaining: 24.6s\n",
      "725:\tlearn: 1596.3077497\ttotal: 1m 4s\tremaining: 24.5s\n",
      "726:\tlearn: 1596.1832076\ttotal: 1m 4s\tremaining: 24.4s\n",
      "727:\tlearn: 1595.9835554\ttotal: 1m 5s\tremaining: 24.3s\n",
      "728:\tlearn: 1595.8553269\ttotal: 1m 5s\tremaining: 24.2s\n",
      "729:\tlearn: 1595.8003132\ttotal: 1m 5s\tremaining: 24.1s\n",
      "730:\tlearn: 1595.6564561\ttotal: 1m 5s\tremaining: 24s\n",
      "731:\tlearn: 1595.5372860\ttotal: 1m 5s\tremaining: 23.9s\n",
      "732:\tlearn: 1595.3290034\ttotal: 1m 5s\tremaining: 23.9s\n",
      "733:\tlearn: 1595.0736258\ttotal: 1m 5s\tremaining: 23.8s\n",
      "734:\tlearn: 1594.7971922\ttotal: 1m 5s\tremaining: 23.7s\n",
      "735:\tlearn: 1594.5422458\ttotal: 1m 5s\tremaining: 23.6s\n",
      "736:\tlearn: 1594.4199590\ttotal: 1m 5s\tremaining: 23.5s\n",
      "737:\tlearn: 1594.2249913\ttotal: 1m 5s\tremaining: 23.4s\n",
      "738:\tlearn: 1594.0889798\ttotal: 1m 6s\tremaining: 23.3s\n",
      "739:\tlearn: 1593.8293735\ttotal: 1m 6s\tremaining: 23.2s\n",
      "740:\tlearn: 1593.5507867\ttotal: 1m 6s\tremaining: 23.1s\n",
      "741:\tlearn: 1593.3753147\ttotal: 1m 6s\tremaining: 23.1s\n",
      "742:\tlearn: 1592.8984054\ttotal: 1m 6s\tremaining: 23s\n",
      "743:\tlearn: 1592.7274499\ttotal: 1m 6s\tremaining: 22.9s\n",
      "744:\tlearn: 1592.6053585\ttotal: 1m 6s\tremaining: 22.8s\n",
      "745:\tlearn: 1592.3689406\ttotal: 1m 6s\tremaining: 22.7s\n",
      "746:\tlearn: 1592.0616914\ttotal: 1m 6s\tremaining: 22.6s\n",
      "747:\tlearn: 1591.9038488\ttotal: 1m 6s\tremaining: 22.5s\n",
      "748:\tlearn: 1591.8516699\ttotal: 1m 6s\tremaining: 22.4s\n",
      "749:\tlearn: 1591.7181779\ttotal: 1m 6s\tremaining: 22.3s\n",
      "750:\tlearn: 1591.6039273\ttotal: 1m 7s\tremaining: 22.2s\n",
      "751:\tlearn: 1591.4022147\ttotal: 1m 7s\tremaining: 22.2s\n",
      "752:\tlearn: 1591.2854609\ttotal: 1m 7s\tremaining: 22.1s\n",
      "753:\tlearn: 1591.2641319\ttotal: 1m 7s\tremaining: 22s\n",
      "754:\tlearn: 1591.1544498\ttotal: 1m 7s\tremaining: 21.9s\n",
      "755:\tlearn: 1590.8999835\ttotal: 1m 7s\tremaining: 21.8s\n",
      "756:\tlearn: 1590.7959069\ttotal: 1m 7s\tremaining: 21.7s\n",
      "757:\tlearn: 1590.5707706\ttotal: 1m 7s\tremaining: 21.6s\n",
      "758:\tlearn: 1590.3247596\ttotal: 1m 7s\tremaining: 21.5s\n",
      "759:\tlearn: 1590.1631976\ttotal: 1m 7s\tremaining: 21.4s\n",
      "760:\tlearn: 1590.1022329\ttotal: 1m 7s\tremaining: 21.3s\n",
      "761:\tlearn: 1589.9578963\ttotal: 1m 8s\tremaining: 21.3s\n",
      "762:\tlearn: 1589.9471973\ttotal: 1m 8s\tremaining: 21.2s\n",
      "763:\tlearn: 1589.8397253\ttotal: 1m 8s\tremaining: 21.1s\n",
      "764:\tlearn: 1589.8000293\ttotal: 1m 8s\tremaining: 21s\n",
      "765:\tlearn: 1589.4884839\ttotal: 1m 8s\tremaining: 20.9s\n",
      "766:\tlearn: 1589.3769361\ttotal: 1m 8s\tremaining: 20.8s\n",
      "767:\tlearn: 1589.3016958\ttotal: 1m 8s\tremaining: 20.7s\n",
      "768:\tlearn: 1588.8774565\ttotal: 1m 8s\tremaining: 20.6s\n",
      "769:\tlearn: 1588.7097234\ttotal: 1m 8s\tremaining: 20.6s\n",
      "770:\tlearn: 1588.6949465\ttotal: 1m 8s\tremaining: 20.5s\n",
      "771:\tlearn: 1588.5486341\ttotal: 1m 9s\tremaining: 20.4s\n",
      "772:\tlearn: 1588.4003732\ttotal: 1m 9s\tremaining: 20.3s\n",
      "773:\tlearn: 1588.2227831\ttotal: 1m 9s\tremaining: 20.2s\n",
      "774:\tlearn: 1588.1684633\ttotal: 1m 9s\tremaining: 20.1s\n",
      "775:\tlearn: 1587.9988334\ttotal: 1m 9s\tremaining: 20s\n",
      "776:\tlearn: 1587.8976054\ttotal: 1m 9s\tremaining: 19.9s\n",
      "777:\tlearn: 1587.7986860\ttotal: 1m 9s\tremaining: 19.8s\n",
      "778:\tlearn: 1587.6723598\ttotal: 1m 9s\tremaining: 19.8s\n",
      "779:\tlearn: 1587.6126056\ttotal: 1m 9s\tremaining: 19.7s\n",
      "780:\tlearn: 1587.4867698\ttotal: 1m 9s\tremaining: 19.6s\n",
      "781:\tlearn: 1587.1686848\ttotal: 1m 9s\tremaining: 19.5s\n",
      "782:\tlearn: 1587.1017169\ttotal: 1m 9s\tremaining: 19.4s\n",
      "783:\tlearn: 1587.0709418\ttotal: 1m 10s\tremaining: 19.3s\n",
      "784:\tlearn: 1586.9305104\ttotal: 1m 10s\tremaining: 19.2s\n",
      "785:\tlearn: 1586.7688730\ttotal: 1m 10s\tremaining: 19.1s\n",
      "786:\tlearn: 1586.5239237\ttotal: 1m 10s\tremaining: 19s\n",
      "787:\tlearn: 1586.3877042\ttotal: 1m 10s\tremaining: 18.9s\n",
      "788:\tlearn: 1586.3440002\ttotal: 1m 10s\tremaining: 18.9s\n",
      "789:\tlearn: 1586.2572769\ttotal: 1m 10s\tremaining: 18.8s\n",
      "790:\tlearn: 1586.0297950\ttotal: 1m 10s\tremaining: 18.7s\n",
      "791:\tlearn: 1585.9455297\ttotal: 1m 10s\tremaining: 18.6s\n",
      "792:\tlearn: 1585.8844490\ttotal: 1m 10s\tremaining: 18.5s\n",
      "793:\tlearn: 1585.7665820\ttotal: 1m 10s\tremaining: 18.4s\n",
      "794:\tlearn: 1585.5763800\ttotal: 1m 10s\tremaining: 18.3s\n",
      "795:\tlearn: 1585.4443836\ttotal: 1m 11s\tremaining: 18.2s\n",
      "796:\tlearn: 1585.3986584\ttotal: 1m 11s\tremaining: 18.1s\n",
      "797:\tlearn: 1585.3083078\ttotal: 1m 11s\tremaining: 18s\n",
      "798:\tlearn: 1585.2639701\ttotal: 1m 11s\tremaining: 17.9s\n",
      "799:\tlearn: 1585.2401978\ttotal: 1m 11s\tremaining: 17.8s\n",
      "800:\tlearn: 1585.1591635\ttotal: 1m 11s\tremaining: 17.7s\n",
      "801:\tlearn: 1585.0368789\ttotal: 1m 11s\tremaining: 17.7s\n",
      "802:\tlearn: 1584.9017620\ttotal: 1m 11s\tremaining: 17.6s\n",
      "803:\tlearn: 1584.7896953\ttotal: 1m 11s\tremaining: 17.5s\n",
      "804:\tlearn: 1584.5539635\ttotal: 1m 11s\tremaining: 17.4s\n",
      "805:\tlearn: 1584.3881130\ttotal: 1m 11s\tremaining: 17.3s\n",
      "806:\tlearn: 1584.2633148\ttotal: 1m 11s\tremaining: 17.2s\n",
      "807:\tlearn: 1583.7625610\ttotal: 1m 12s\tremaining: 17.1s\n",
      "808:\tlearn: 1583.7285931\ttotal: 1m 12s\tremaining: 17s\n",
      "809:\tlearn: 1583.6941598\ttotal: 1m 12s\tremaining: 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810:\tlearn: 1583.5886624\ttotal: 1m 12s\tremaining: 16.9s\n",
      "811:\tlearn: 1583.4938771\ttotal: 1m 12s\tremaining: 16.8s\n",
      "812:\tlearn: 1583.4444285\ttotal: 1m 12s\tremaining: 16.7s\n",
      "813:\tlearn: 1583.2829007\ttotal: 1m 12s\tremaining: 16.6s\n",
      "814:\tlearn: 1583.1137221\ttotal: 1m 12s\tremaining: 16.5s\n",
      "815:\tlearn: 1583.0835190\ttotal: 1m 12s\tremaining: 16.4s\n",
      "816:\tlearn: 1582.9593115\ttotal: 1m 12s\tremaining: 16.3s\n",
      "817:\tlearn: 1582.8639993\ttotal: 1m 12s\tremaining: 16.2s\n",
      "818:\tlearn: 1582.7147043\ttotal: 1m 13s\tremaining: 16.2s\n",
      "819:\tlearn: 1582.5286096\ttotal: 1m 13s\tremaining: 16.1s\n",
      "820:\tlearn: 1582.4135302\ttotal: 1m 13s\tremaining: 16s\n",
      "821:\tlearn: 1582.3081548\ttotal: 1m 13s\tremaining: 15.9s\n",
      "822:\tlearn: 1582.1609072\ttotal: 1m 13s\tremaining: 15.8s\n",
      "823:\tlearn: 1581.9111418\ttotal: 1m 13s\tremaining: 15.7s\n",
      "824:\tlearn: 1581.7611409\ttotal: 1m 13s\tremaining: 15.6s\n",
      "825:\tlearn: 1581.6265289\ttotal: 1m 13s\tremaining: 15.5s\n",
      "826:\tlearn: 1581.5048422\ttotal: 1m 13s\tremaining: 15.5s\n",
      "827:\tlearn: 1581.2558844\ttotal: 1m 14s\tremaining: 15.4s\n",
      "828:\tlearn: 1581.1605140\ttotal: 1m 14s\tremaining: 15.3s\n",
      "829:\tlearn: 1581.0764623\ttotal: 1m 14s\tremaining: 15.2s\n",
      "830:\tlearn: 1580.9132370\ttotal: 1m 14s\tremaining: 15.1s\n",
      "831:\tlearn: 1580.8822598\ttotal: 1m 14s\tremaining: 15s\n",
      "832:\tlearn: 1580.8701430\ttotal: 1m 14s\tremaining: 14.9s\n",
      "833:\tlearn: 1580.7965460\ttotal: 1m 14s\tremaining: 14.8s\n",
      "834:\tlearn: 1580.6753201\ttotal: 1m 14s\tremaining: 14.8s\n",
      "835:\tlearn: 1580.4937834\ttotal: 1m 14s\tremaining: 14.7s\n",
      "836:\tlearn: 1580.3646468\ttotal: 1m 14s\tremaining: 14.6s\n",
      "837:\tlearn: 1580.3075340\ttotal: 1m 14s\tremaining: 14.5s\n",
      "838:\tlearn: 1580.1731053\ttotal: 1m 15s\tremaining: 14.4s\n",
      "839:\tlearn: 1580.0823082\ttotal: 1m 15s\tremaining: 14.3s\n",
      "840:\tlearn: 1580.0720577\ttotal: 1m 15s\tremaining: 14.2s\n",
      "841:\tlearn: 1579.9706477\ttotal: 1m 15s\tremaining: 14.1s\n",
      "842:\tlearn: 1579.8072838\ttotal: 1m 15s\tremaining: 14.1s\n",
      "843:\tlearn: 1579.6328905\ttotal: 1m 15s\tremaining: 14s\n",
      "844:\tlearn: 1579.5531265\ttotal: 1m 15s\tremaining: 13.9s\n",
      "845:\tlearn: 1579.3674988\ttotal: 1m 15s\tremaining: 13.8s\n",
      "846:\tlearn: 1579.3050423\ttotal: 1m 15s\tremaining: 13.7s\n",
      "847:\tlearn: 1579.2903880\ttotal: 1m 15s\tremaining: 13.6s\n",
      "848:\tlearn: 1579.1762314\ttotal: 1m 15s\tremaining: 13.5s\n",
      "849:\tlearn: 1578.7950115\ttotal: 1m 16s\tremaining: 13.4s\n",
      "850:\tlearn: 1578.6957772\ttotal: 1m 16s\tremaining: 13.3s\n",
      "851:\tlearn: 1578.5388576\ttotal: 1m 16s\tremaining: 13.2s\n",
      "852:\tlearn: 1578.4022557\ttotal: 1m 16s\tremaining: 13.2s\n",
      "853:\tlearn: 1578.2959836\ttotal: 1m 16s\tremaining: 13.1s\n",
      "854:\tlearn: 1578.1712772\ttotal: 1m 16s\tremaining: 13s\n",
      "855:\tlearn: 1578.1690823\ttotal: 1m 16s\tremaining: 12.9s\n",
      "856:\tlearn: 1578.0892394\ttotal: 1m 16s\tremaining: 12.8s\n",
      "857:\tlearn: 1578.0295617\ttotal: 1m 16s\tremaining: 12.7s\n",
      "858:\tlearn: 1578.0202369\ttotal: 1m 16s\tremaining: 12.6s\n",
      "859:\tlearn: 1578.0095155\ttotal: 1m 16s\tremaining: 12.5s\n",
      "860:\tlearn: 1577.9347532\ttotal: 1m 17s\tremaining: 12.4s\n",
      "861:\tlearn: 1577.7854946\ttotal: 1m 17s\tremaining: 12.4s\n",
      "862:\tlearn: 1577.7832462\ttotal: 1m 17s\tremaining: 12.3s\n",
      "863:\tlearn: 1577.6071334\ttotal: 1m 17s\tremaining: 12.2s\n",
      "864:\tlearn: 1577.6013977\ttotal: 1m 17s\tremaining: 12.1s\n",
      "865:\tlearn: 1577.5713810\ttotal: 1m 17s\tremaining: 12s\n",
      "866:\tlearn: 1577.3425626\ttotal: 1m 17s\tremaining: 11.9s\n",
      "867:\tlearn: 1577.1987040\ttotal: 1m 17s\tremaining: 11.8s\n",
      "868:\tlearn: 1577.0254873\ttotal: 1m 17s\tremaining: 11.7s\n",
      "869:\tlearn: 1576.7695692\ttotal: 1m 17s\tremaining: 11.6s\n",
      "870:\tlearn: 1576.6842711\ttotal: 1m 18s\tremaining: 11.6s\n",
      "871:\tlearn: 1576.5532603\ttotal: 1m 18s\tremaining: 11.5s\n",
      "872:\tlearn: 1576.4351828\ttotal: 1m 18s\tremaining: 11.4s\n",
      "873:\tlearn: 1576.1650593\ttotal: 1m 18s\tremaining: 11.3s\n",
      "874:\tlearn: 1576.0691047\ttotal: 1m 18s\tremaining: 11.2s\n",
      "875:\tlearn: 1575.9296232\ttotal: 1m 18s\tremaining: 11.1s\n",
      "876:\tlearn: 1575.8730721\ttotal: 1m 18s\tremaining: 11s\n",
      "877:\tlearn: 1575.7942742\ttotal: 1m 18s\tremaining: 10.9s\n",
      "878:\tlearn: 1575.6500190\ttotal: 1m 18s\tremaining: 10.8s\n",
      "879:\tlearn: 1575.5400297\ttotal: 1m 18s\tremaining: 10.8s\n",
      "880:\tlearn: 1575.3892797\ttotal: 1m 18s\tremaining: 10.7s\n",
      "881:\tlearn: 1575.1688960\ttotal: 1m 19s\tremaining: 10.6s\n",
      "882:\tlearn: 1575.0826143\ttotal: 1m 19s\tremaining: 10.5s\n",
      "883:\tlearn: 1575.0235577\ttotal: 1m 19s\tremaining: 10.4s\n",
      "884:\tlearn: 1574.8078185\ttotal: 1m 19s\tremaining: 10.3s\n",
      "885:\tlearn: 1574.6852502\ttotal: 1m 19s\tremaining: 10.2s\n",
      "886:\tlearn: 1574.5813372\ttotal: 1m 19s\tremaining: 10.1s\n",
      "887:\tlearn: 1574.4520078\ttotal: 1m 19s\tremaining: 10s\n",
      "888:\tlearn: 1574.4235035\ttotal: 1m 19s\tremaining: 9.95s\n",
      "889:\tlearn: 1574.2508692\ttotal: 1m 19s\tremaining: 9.86s\n",
      "890:\tlearn: 1574.0736053\ttotal: 1m 19s\tremaining: 9.77s\n",
      "891:\tlearn: 1574.0488444\ttotal: 1m 19s\tremaining: 9.69s\n",
      "892:\tlearn: 1573.8774291\ttotal: 1m 20s\tremaining: 9.6s\n",
      "893:\tlearn: 1573.6835643\ttotal: 1m 20s\tremaining: 9.5s\n",
      "894:\tlearn: 1573.6035548\ttotal: 1m 20s\tremaining: 9.41s\n",
      "895:\tlearn: 1573.5168545\ttotal: 1m 20s\tremaining: 9.32s\n",
      "896:\tlearn: 1573.4348256\ttotal: 1m 20s\tremaining: 9.23s\n",
      "897:\tlearn: 1573.1764316\ttotal: 1m 20s\tremaining: 9.14s\n",
      "898:\tlearn: 1573.0735171\ttotal: 1m 20s\tremaining: 9.05s\n",
      "899:\tlearn: 1572.8953673\ttotal: 1m 20s\tremaining: 8.96s\n",
      "900:\tlearn: 1572.8257088\ttotal: 1m 20s\tremaining: 8.87s\n",
      "901:\tlearn: 1572.6426689\ttotal: 1m 20s\tremaining: 8.79s\n",
      "902:\tlearn: 1572.5719246\ttotal: 1m 20s\tremaining: 8.7s\n",
      "903:\tlearn: 1572.5532724\ttotal: 1m 21s\tremaining: 8.61s\n",
      "904:\tlearn: 1572.4094531\ttotal: 1m 21s\tremaining: 8.52s\n",
      "905:\tlearn: 1572.3476157\ttotal: 1m 21s\tremaining: 8.43s\n",
      "906:\tlearn: 1572.3217505\ttotal: 1m 21s\tremaining: 8.34s\n",
      "907:\tlearn: 1572.2381491\ttotal: 1m 21s\tremaining: 8.25s\n",
      "908:\tlearn: 1572.1245260\ttotal: 1m 21s\tremaining: 8.16s\n",
      "909:\tlearn: 1572.0324629\ttotal: 1m 21s\tremaining: 8.07s\n",
      "910:\tlearn: 1571.9158732\ttotal: 1m 21s\tremaining: 7.98s\n",
      "911:\tlearn: 1571.7600726\ttotal: 1m 21s\tremaining: 7.89s\n",
      "912:\tlearn: 1571.7069429\ttotal: 1m 21s\tremaining: 7.8s\n",
      "913:\tlearn: 1571.6957170\ttotal: 1m 21s\tremaining: 7.71s\n",
      "914:\tlearn: 1571.5620751\ttotal: 1m 22s\tremaining: 7.62s\n",
      "915:\tlearn: 1571.4872414\ttotal: 1m 22s\tremaining: 7.54s\n",
      "916:\tlearn: 1571.4416196\ttotal: 1m 22s\tremaining: 7.45s\n",
      "917:\tlearn: 1571.3892048\ttotal: 1m 22s\tremaining: 7.36s\n",
      "918:\tlearn: 1571.2421322\ttotal: 1m 22s\tremaining: 7.26s\n",
      "919:\tlearn: 1571.1443555\ttotal: 1m 22s\tremaining: 7.17s\n",
      "920:\tlearn: 1571.1043204\ttotal: 1m 22s\tremaining: 7.09s\n",
      "921:\tlearn: 1571.0357129\ttotal: 1m 22s\tremaining: 7s\n",
      "922:\tlearn: 1570.9253626\ttotal: 1m 22s\tremaining: 6.91s\n",
      "923:\tlearn: 1570.8400800\ttotal: 1m 22s\tremaining: 6.82s\n",
      "924:\tlearn: 1570.7286631\ttotal: 1m 23s\tremaining: 6.73s\n",
      "925:\tlearn: 1570.6048940\ttotal: 1m 23s\tremaining: 6.64s\n",
      "926:\tlearn: 1570.4088864\ttotal: 1m 23s\tremaining: 6.55s\n",
      "927:\tlearn: 1570.3437001\ttotal: 1m 23s\tremaining: 6.46s\n",
      "928:\tlearn: 1570.2533251\ttotal: 1m 23s\tremaining: 6.37s\n",
      "929:\tlearn: 1570.1475330\ttotal: 1m 23s\tremaining: 6.28s\n",
      "930:\tlearn: 1570.0723062\ttotal: 1m 23s\tremaining: 6.19s\n",
      "931:\tlearn: 1569.9636551\ttotal: 1m 23s\tremaining: 6.1s\n",
      "932:\tlearn: 1569.7988839\ttotal: 1m 23s\tremaining: 6.01s\n",
      "933:\tlearn: 1569.7577925\ttotal: 1m 23s\tremaining: 5.92s\n",
      "934:\tlearn: 1569.6592103\ttotal: 1m 23s\tremaining: 5.83s\n",
      "935:\tlearn: 1569.4618763\ttotal: 1m 23s\tremaining: 5.74s\n",
      "936:\tlearn: 1569.3171809\ttotal: 1m 24s\tremaining: 5.65s\n",
      "937:\tlearn: 1569.2454567\ttotal: 1m 24s\tremaining: 5.56s\n",
      "938:\tlearn: 1569.1553521\ttotal: 1m 24s\tremaining: 5.47s\n",
      "939:\tlearn: 1569.0700843\ttotal: 1m 24s\tremaining: 5.38s\n",
      "940:\tlearn: 1568.8937994\ttotal: 1m 24s\tremaining: 5.29s\n",
      "941:\tlearn: 1568.8092297\ttotal: 1m 24s\tremaining: 5.21s\n",
      "942:\tlearn: 1568.6397161\ttotal: 1m 24s\tremaining: 5.12s\n",
      "943:\tlearn: 1568.4887049\ttotal: 1m 24s\tremaining: 5.03s\n",
      "944:\tlearn: 1568.4765060\ttotal: 1m 24s\tremaining: 4.94s\n",
      "945:\tlearn: 1568.4093889\ttotal: 1m 24s\tremaining: 4.85s\n",
      "946:\tlearn: 1568.4030724\ttotal: 1m 25s\tremaining: 4.76s\n",
      "947:\tlearn: 1568.2689115\ttotal: 1m 25s\tremaining: 4.67s\n",
      "948:\tlearn: 1567.9950223\ttotal: 1m 25s\tremaining: 4.58s\n",
      "949:\tlearn: 1567.8844235\ttotal: 1m 25s\tremaining: 4.49s\n",
      "950:\tlearn: 1567.7114525\ttotal: 1m 25s\tremaining: 4.4s\n",
      "951:\tlearn: 1567.6666091\ttotal: 1m 25s\tremaining: 4.31s\n",
      "952:\tlearn: 1567.6229611\ttotal: 1m 25s\tremaining: 4.22s\n",
      "953:\tlearn: 1567.5253484\ttotal: 1m 25s\tremaining: 4.13s\n",
      "954:\tlearn: 1567.3694786\ttotal: 1m 25s\tremaining: 4.04s\n",
      "955:\tlearn: 1567.1580903\ttotal: 1m 25s\tremaining: 3.95s\n",
      "956:\tlearn: 1567.1325845\ttotal: 1m 25s\tremaining: 3.86s\n",
      "957:\tlearn: 1567.0774357\ttotal: 1m 25s\tremaining: 3.77s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958:\tlearn: 1567.0666917\ttotal: 1m 26s\tremaining: 3.68s\n",
      "959:\tlearn: 1566.9438297\ttotal: 1m 26s\tremaining: 3.59s\n",
      "960:\tlearn: 1566.8147623\ttotal: 1m 26s\tremaining: 3.5s\n",
      "961:\tlearn: 1566.6310091\ttotal: 1m 26s\tremaining: 3.41s\n",
      "962:\tlearn: 1566.5068371\ttotal: 1m 26s\tremaining: 3.32s\n",
      "963:\tlearn: 1566.4531261\ttotal: 1m 26s\tremaining: 3.23s\n",
      "964:\tlearn: 1566.3544404\ttotal: 1m 26s\tremaining: 3.14s\n",
      "965:\tlearn: 1566.3030300\ttotal: 1m 26s\tremaining: 3.05s\n",
      "966:\tlearn: 1566.1523507\ttotal: 1m 26s\tremaining: 2.96s\n",
      "967:\tlearn: 1566.0480355\ttotal: 1m 26s\tremaining: 2.87s\n",
      "968:\tlearn: 1566.0372921\ttotal: 1m 26s\tremaining: 2.78s\n",
      "969:\tlearn: 1565.8007319\ttotal: 1m 27s\tremaining: 2.69s\n",
      "970:\tlearn: 1565.7816856\ttotal: 1m 27s\tremaining: 2.6s\n",
      "971:\tlearn: 1565.5809635\ttotal: 1m 27s\tremaining: 2.51s\n",
      "972:\tlearn: 1565.5740407\ttotal: 1m 27s\tremaining: 2.42s\n",
      "973:\tlearn: 1565.5037182\ttotal: 1m 27s\tremaining: 2.33s\n",
      "974:\tlearn: 1565.3404458\ttotal: 1m 27s\tremaining: 2.24s\n",
      "975:\tlearn: 1565.1883019\ttotal: 1m 27s\tremaining: 2.15s\n",
      "976:\tlearn: 1565.1143067\ttotal: 1m 27s\tremaining: 2.06s\n",
      "977:\tlearn: 1564.9383672\ttotal: 1m 27s\tremaining: 1.97s\n",
      "978:\tlearn: 1564.7660523\ttotal: 1m 27s\tremaining: 1.88s\n",
      "979:\tlearn: 1564.6399616\ttotal: 1m 27s\tremaining: 1.79s\n",
      "980:\tlearn: 1564.5823289\ttotal: 1m 28s\tremaining: 1.7s\n",
      "981:\tlearn: 1564.4474993\ttotal: 1m 28s\tremaining: 1.61s\n",
      "982:\tlearn: 1564.4379745\ttotal: 1m 28s\tremaining: 1.52s\n",
      "983:\tlearn: 1564.3314092\ttotal: 1m 28s\tremaining: 1.44s\n",
      "984:\tlearn: 1564.1617465\ttotal: 1m 28s\tremaining: 1.34s\n",
      "985:\tlearn: 1564.0276523\ttotal: 1m 28s\tremaining: 1.25s\n",
      "986:\tlearn: 1563.8982933\ttotal: 1m 28s\tremaining: 1.17s\n",
      "987:\tlearn: 1563.8026002\ttotal: 1m 28s\tremaining: 1.08s\n",
      "988:\tlearn: 1563.7106779\ttotal: 1m 28s\tremaining: 987ms\n",
      "989:\tlearn: 1563.6266942\ttotal: 1m 28s\tremaining: 897ms\n",
      "990:\tlearn: 1563.4616923\ttotal: 1m 28s\tremaining: 807ms\n",
      "991:\tlearn: 1563.3875623\ttotal: 1m 28s\tremaining: 717ms\n",
      "992:\tlearn: 1563.3567226\ttotal: 1m 29s\tremaining: 628ms\n",
      "993:\tlearn: 1563.2891846\ttotal: 1m 29s\tremaining: 538ms\n",
      "994:\tlearn: 1563.2168033\ttotal: 1m 29s\tremaining: 448ms\n",
      "995:\tlearn: 1563.2036528\ttotal: 1m 29s\tremaining: 359ms\n",
      "996:\tlearn: 1563.0879590\ttotal: 1m 29s\tremaining: 269ms\n",
      "997:\tlearn: 1563.0193254\ttotal: 1m 29s\tremaining: 179ms\n",
      "998:\tlearn: 1562.8562407\ttotal: 1m 29s\tremaining: 89.7ms\n",
      "999:\tlearn: 1562.7346537\ttotal: 1m 29s\tremaining: 0us\n",
      "Training time: 90.50532126426697 seconds\n",
      "Validation prediction time: 0.3365793228149414 seconds\n",
      "Validation RMSE: 1628.570386110235\n",
      "Test prediction time: 0.2583646774291992 seconds\n",
      "Test RMSE: 1645.7955711740635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 90.50532126426697,\n",
       " 'validation_time': 0.3365793228149414,\n",
       " 'validation_rmse': 1628.570386110235,\n",
       " 'test_prediction_time': 0.2583646774291992,\n",
       " 'test_rmse': 1645.7955711740635,\n",
       " 'cv_rmse_scores': array([1626.99374828, 1627.92393505, 1637.89675239, 1633.42193331,\n",
       "        1650.49501073]),\n",
       " 'mean_cv_rmse': 1635.3462759531292,\n",
       " 'std_cv_rmse': 8.538712464354974}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_eval(CatBoostRegressor, X, y, cv_splits=5, cat_features=categorical_features, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END bootstrap_type=Bayesian, border_count=124, depth=10, grow_policy=SymmetricTree, iterations=171, l2_leaf_reg=5, learning_rate=0.039643541684062936, min_data_in_leaf=3, random_strength=7; total time=   7.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=124, depth=10, grow_policy=SymmetricTree, iterations=171, l2_leaf_reg=5, learning_rate=0.039643541684062936, min_data_in_leaf=3, random_strength=7; total time=   7.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=124, depth=10, grow_policy=SymmetricTree, iterations=171, l2_leaf_reg=5, learning_rate=0.039643541684062936, min_data_in_leaf=3, random_strength=7; total time=   7.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=119, depth=8, grow_policy=Depthwise, iterations=459, l2_leaf_reg=8, learning_rate=0.13366880986028204, min_data_in_leaf=5, random_strength=2; total time=  26.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=119, depth=8, grow_policy=Depthwise, iterations=459, l2_leaf_reg=8, learning_rate=0.13366880986028204, min_data_in_leaf=5, random_strength=2; total time=  26.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=119, depth=8, grow_policy=Depthwise, iterations=459, l2_leaf_reg=8, learning_rate=0.13366880986028204, min_data_in_leaf=5, random_strength=2; total time=  26.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=189, depth=9, grow_policy=Depthwise, iterations=291, l2_leaf_reg=5, learning_rate=0.12732148682926614, min_data_in_leaf=10, random_strength=6; total time=  18.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=189, depth=9, grow_policy=Depthwise, iterations=291, l2_leaf_reg=5, learning_rate=0.12732148682926614, min_data_in_leaf=10, random_strength=6; total time=  18.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=189, depth=9, grow_policy=Depthwise, iterations=291, l2_leaf_reg=5, learning_rate=0.12732148682926614, min_data_in_leaf=10, random_strength=6; total time=  18.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=120, depth=4, grow_policy=SymmetricTree, iterations=158, l2_leaf_reg=3, learning_rate=0.08266777834076092, min_data_in_leaf=4, random_strength=9; total time=   3.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=120, depth=4, grow_policy=SymmetricTree, iterations=158, l2_leaf_reg=3, learning_rate=0.08266777834076092, min_data_in_leaf=4, random_strength=9; total time=   3.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=120, depth=4, grow_policy=SymmetricTree, iterations=158, l2_leaf_reg=3, learning_rate=0.08266777834076092, min_data_in_leaf=4, random_strength=9; total time=   3.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=82, depth=10, grow_policy=SymmetricTree, iterations=428, l2_leaf_reg=7, learning_rate=0.01252034262037464, min_data_in_leaf=9, random_strength=2; total time=  54.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=82, depth=10, grow_policy=SymmetricTree, iterations=428, l2_leaf_reg=7, learning_rate=0.01252034262037464, min_data_in_leaf=9, random_strength=2; total time=  52.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=82, depth=10, grow_policy=SymmetricTree, iterations=428, l2_leaf_reg=7, learning_rate=0.01252034262037464, min_data_in_leaf=9, random_strength=2; total time=  52.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=40, depth=5, grow_policy=SymmetricTree, iterations=485, l2_leaf_reg=4, learning_rate=0.05579483854494223, min_data_in_leaf=7, random_strength=8; total time=  20.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=40, depth=5, grow_policy=SymmetricTree, iterations=485, l2_leaf_reg=4, learning_rate=0.05579483854494223, min_data_in_leaf=7, random_strength=8; total time=  20.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=40, depth=5, grow_policy=SymmetricTree, iterations=485, l2_leaf_reg=4, learning_rate=0.05579483854494223, min_data_in_leaf=7, random_strength=8; total time=  19.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=66, depth=9, grow_policy=SymmetricTree, iterations=149, l2_leaf_reg=8, learning_rate=0.153518667960354, min_data_in_leaf=6, random_strength=6; total time=   5.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=66, depth=9, grow_policy=SymmetricTree, iterations=149, l2_leaf_reg=8, learning_rate=0.153518667960354, min_data_in_leaf=6, random_strength=6; total time=   5.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=66, depth=9, grow_policy=SymmetricTree, iterations=149, l2_leaf_reg=8, learning_rate=0.153518667960354, min_data_in_leaf=6, random_strength=6; total time=   5.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=35, depth=9, grow_policy=SymmetricTree, iterations=290, l2_leaf_reg=2, learning_rate=0.15727523643861177, min_data_in_leaf=2, random_strength=10; total time=  24.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=35, depth=9, grow_policy=SymmetricTree, iterations=290, l2_leaf_reg=2, learning_rate=0.15727523643861177, min_data_in_leaf=2, random_strength=10; total time=  24.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=35, depth=9, grow_policy=SymmetricTree, iterations=290, l2_leaf_reg=2, learning_rate=0.15727523643861177, min_data_in_leaf=2, random_strength=10; total time=  23.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=45, depth=10, grow_policy=Depthwise, iterations=370, l2_leaf_reg=8, learning_rate=0.11838435513702589, min_data_in_leaf=9, random_strength=8; total time=  25.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=45, depth=10, grow_policy=Depthwise, iterations=370, l2_leaf_reg=8, learning_rate=0.11838435513702589, min_data_in_leaf=9, random_strength=8; total time=  24.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=45, depth=10, grow_policy=Depthwise, iterations=370, l2_leaf_reg=8, learning_rate=0.11838435513702589, min_data_in_leaf=9, random_strength=8; total time=  24.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=113, depth=10, grow_policy=SymmetricTree, iterations=379, l2_leaf_reg=9, learning_rate=0.06337755684060234, min_data_in_leaf=9, random_strength=1; total time=  48.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=113, depth=10, grow_policy=SymmetricTree, iterations=379, l2_leaf_reg=9, learning_rate=0.06337755684060234, min_data_in_leaf=9, random_strength=1; total time=  47.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=113, depth=10, grow_policy=SymmetricTree, iterations=379, l2_leaf_reg=9, learning_rate=0.06337755684060234, min_data_in_leaf=9, random_strength=1; total time=  48.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=102, depth=4, grow_policy=Depthwise, iterations=228, l2_leaf_reg=8, learning_rate=0.011049202253484457, min_data_in_leaf=3, random_strength=1; total time=   7.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=102, depth=4, grow_policy=Depthwise, iterations=228, l2_leaf_reg=8, learning_rate=0.011049202253484457, min_data_in_leaf=3, random_strength=1; total time=   7.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=102, depth=4, grow_policy=Depthwise, iterations=228, l2_leaf_reg=8, learning_rate=0.011049202253484457, min_data_in_leaf=3, random_strength=1; total time=   7.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=194, depth=6, grow_policy=SymmetricTree, iterations=478, l2_leaf_reg=5, learning_rate=0.18599716691753632, min_data_in_leaf=10, random_strength=9; total time=  25.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=194, depth=6, grow_policy=SymmetricTree, iterations=478, l2_leaf_reg=5, learning_rate=0.18599716691753632, min_data_in_leaf=10, random_strength=9; total time=  25.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=194, depth=6, grow_policy=SymmetricTree, iterations=478, l2_leaf_reg=5, learning_rate=0.18599716691753632, min_data_in_leaf=10, random_strength=9; total time=  25.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=166, depth=4, grow_policy=Depthwise, iterations=367, l2_leaf_reg=2, learning_rate=0.02812792213317815, min_data_in_leaf=7, random_strength=7; total time=   9.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=166, depth=4, grow_policy=Depthwise, iterations=367, l2_leaf_reg=2, learning_rate=0.02812792213317815, min_data_in_leaf=7, random_strength=7; total time=   9.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=166, depth=4, grow_policy=Depthwise, iterations=367, l2_leaf_reg=2, learning_rate=0.02812792213317815, min_data_in_leaf=7, random_strength=7; total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap_type=Bernoulli, border_count=68, depth=6, grow_policy=Depthwise, iterations=459, l2_leaf_reg=6, learning_rate=0.17857042108950205, min_data_in_leaf=1, random_strength=3; total time=  15.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=68, depth=6, grow_policy=Depthwise, iterations=459, l2_leaf_reg=6, learning_rate=0.17857042108950205, min_data_in_leaf=1, random_strength=3; total time=  15.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=68, depth=6, grow_policy=Depthwise, iterations=459, l2_leaf_reg=6, learning_rate=0.17857042108950205, min_data_in_leaf=1, random_strength=3; total time=  15.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=162, depth=4, grow_policy=SymmetricTree, iterations=317, l2_leaf_reg=7, learning_rate=0.1564837641913666, min_data_in_leaf=7, random_strength=9; total time=  12.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=162, depth=4, grow_policy=SymmetricTree, iterations=317, l2_leaf_reg=7, learning_rate=0.1564837641913666, min_data_in_leaf=7, random_strength=9; total time=  13.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=162, depth=4, grow_policy=SymmetricTree, iterations=317, l2_leaf_reg=7, learning_rate=0.1564837641913666, min_data_in_leaf=7, random_strength=9; total time=  12.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=46, depth=5, grow_policy=Depthwise, iterations=479, l2_leaf_reg=3, learning_rate=0.015971545280479508, min_data_in_leaf=7, random_strength=1; total time=  16.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=46, depth=5, grow_policy=Depthwise, iterations=479, l2_leaf_reg=3, learning_rate=0.015971545280479508, min_data_in_leaf=7, random_strength=1; total time=  16.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=46, depth=5, grow_policy=Depthwise, iterations=479, l2_leaf_reg=3, learning_rate=0.015971545280479508, min_data_in_leaf=7, random_strength=1; total time=  16.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=127, depth=7, grow_policy=Depthwise, iterations=330, l2_leaf_reg=4, learning_rate=0.1891421784060164, min_data_in_leaf=7, random_strength=3; total time=  14.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=127, depth=7, grow_policy=Depthwise, iterations=330, l2_leaf_reg=4, learning_rate=0.1891421784060164, min_data_in_leaf=7, random_strength=3; total time=  14.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=127, depth=7, grow_policy=Depthwise, iterations=330, l2_leaf_reg=4, learning_rate=0.1891421784060164, min_data_in_leaf=7, random_strength=3; total time=  14.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=59, depth=5, grow_policy=Depthwise, iterations=144, l2_leaf_reg=9, learning_rate=0.030043909367751413, min_data_in_leaf=4, random_strength=10; total time=   4.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=59, depth=5, grow_policy=Depthwise, iterations=144, l2_leaf_reg=9, learning_rate=0.030043909367751413, min_data_in_leaf=4, random_strength=10; total time=   4.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=59, depth=5, grow_policy=Depthwise, iterations=144, l2_leaf_reg=9, learning_rate=0.030043909367751413, min_data_in_leaf=4, random_strength=10; total time=   4.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=123, depth=4, grow_policy=SymmetricTree, iterations=289, l2_leaf_reg=1, learning_rate=0.06170512738308071, min_data_in_leaf=9, random_strength=4; total time=  11.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=123, depth=4, grow_policy=SymmetricTree, iterations=289, l2_leaf_reg=1, learning_rate=0.06170512738308071, min_data_in_leaf=9, random_strength=4; total time=  11.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=123, depth=4, grow_policy=SymmetricTree, iterations=289, l2_leaf_reg=1, learning_rate=0.06170512738308071, min_data_in_leaf=9, random_strength=4; total time=  10.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=34, depth=10, grow_policy=Depthwise, iterations=236, l2_leaf_reg=5, learning_rate=0.1415628462491514, min_data_in_leaf=10, random_strength=8; total time=  18.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=34, depth=10, grow_policy=Depthwise, iterations=236, l2_leaf_reg=5, learning_rate=0.1415628462491514, min_data_in_leaf=10, random_strength=8; total time=  18.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=34, depth=10, grow_policy=Depthwise, iterations=236, l2_leaf_reg=5, learning_rate=0.1415628462491514, min_data_in_leaf=10, random_strength=8; total time=  18.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=90, depth=9, grow_policy=Depthwise, iterations=195, l2_leaf_reg=8, learning_rate=0.1435736021900838, min_data_in_leaf=1, random_strength=1; total time=  13.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=90, depth=9, grow_policy=Depthwise, iterations=195, l2_leaf_reg=8, learning_rate=0.1435736021900838, min_data_in_leaf=1, random_strength=1; total time=  14.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=90, depth=9, grow_policy=Depthwise, iterations=195, l2_leaf_reg=8, learning_rate=0.1435736021900838, min_data_in_leaf=1, random_strength=1; total time=  13.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=83, depth=7, grow_policy=Depthwise, iterations=394, l2_leaf_reg=2, learning_rate=0.14533141208564399, min_data_in_leaf=5, random_strength=1; total time=  16.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=83, depth=7, grow_policy=Depthwise, iterations=394, l2_leaf_reg=2, learning_rate=0.14533141208564399, min_data_in_leaf=5, random_strength=1; total time=  16.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=83, depth=7, grow_policy=Depthwise, iterations=394, l2_leaf_reg=2, learning_rate=0.14533141208564399, min_data_in_leaf=5, random_strength=1; total time=  16.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=112, depth=6, grow_policy=SymmetricTree, iterations=101, l2_leaf_reg=2, learning_rate=0.08809703253046394, min_data_in_leaf=7, random_strength=5; total time=   2.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=112, depth=6, grow_policy=SymmetricTree, iterations=101, l2_leaf_reg=2, learning_rate=0.08809703253046394, min_data_in_leaf=7, random_strength=5; total time=   2.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=112, depth=6, grow_policy=SymmetricTree, iterations=101, l2_leaf_reg=2, learning_rate=0.08809703253046394, min_data_in_leaf=7, random_strength=5; total time=   2.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=160, depth=6, grow_policy=Depthwise, iterations=229, l2_leaf_reg=5, learning_rate=0.10299602445273696, min_data_in_leaf=6, random_strength=7; total time=   8.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=160, depth=6, grow_policy=Depthwise, iterations=229, l2_leaf_reg=5, learning_rate=0.10299602445273696, min_data_in_leaf=6, random_strength=7; total time=   8.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=160, depth=6, grow_policy=Depthwise, iterations=229, l2_leaf_reg=5, learning_rate=0.10299602445273696, min_data_in_leaf=6, random_strength=7; total time=   8.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=154, depth=4, grow_policy=SymmetricTree, iterations=393, l2_leaf_reg=8, learning_rate=0.0993571205447473, min_data_in_leaf=2, random_strength=6; total time=  13.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=154, depth=4, grow_policy=SymmetricTree, iterations=393, l2_leaf_reg=8, learning_rate=0.0993571205447473, min_data_in_leaf=2, random_strength=6; total time=  13.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=154, depth=4, grow_policy=SymmetricTree, iterations=393, l2_leaf_reg=8, learning_rate=0.0993571205447473, min_data_in_leaf=2, random_strength=6; total time=  13.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=170, depth=10, grow_policy=Depthwise, iterations=243, l2_leaf_reg=1, learning_rate=0.0386363333534316, min_data_in_leaf=6, random_strength=3; total time=  18.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=170, depth=10, grow_policy=Depthwise, iterations=243, l2_leaf_reg=1, learning_rate=0.0386363333534316, min_data_in_leaf=6, random_strength=3; total time=  19.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=170, depth=10, grow_policy=Depthwise, iterations=243, l2_leaf_reg=1, learning_rate=0.0386363333534316, min_data_in_leaf=6, random_strength=3; total time=  19.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=195, depth=6, grow_policy=Depthwise, iterations=246, l2_leaf_reg=4, learning_rate=0.13258283017779549, min_data_in_leaf=4, random_strength=9; total time=   9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap_type=Bernoulli, border_count=195, depth=6, grow_policy=Depthwise, iterations=246, l2_leaf_reg=4, learning_rate=0.13258283017779549, min_data_in_leaf=4, random_strength=9; total time=   8.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=195, depth=6, grow_policy=Depthwise, iterations=246, l2_leaf_reg=4, learning_rate=0.13258283017779549, min_data_in_leaf=4, random_strength=9; total time=   8.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=199, depth=10, grow_policy=Depthwise, iterations=459, l2_leaf_reg=1, learning_rate=0.13838112223746335, min_data_in_leaf=9, random_strength=9; total time=  39.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=199, depth=10, grow_policy=Depthwise, iterations=459, l2_leaf_reg=1, learning_rate=0.13838112223746335, min_data_in_leaf=9, random_strength=9; total time=  39.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=199, depth=10, grow_policy=Depthwise, iterations=459, l2_leaf_reg=1, learning_rate=0.13838112223746335, min_data_in_leaf=9, random_strength=9; total time=  40.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=182, depth=10, grow_policy=Depthwise, iterations=397, l2_leaf_reg=3, learning_rate=0.05342450414148694, min_data_in_leaf=10, random_strength=9; total time=  29.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=182, depth=10, grow_policy=Depthwise, iterations=397, l2_leaf_reg=3, learning_rate=0.05342450414148694, min_data_in_leaf=10, random_strength=9; total time=  29.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=182, depth=10, grow_policy=Depthwise, iterations=397, l2_leaf_reg=3, learning_rate=0.05342450414148694, min_data_in_leaf=10, random_strength=9; total time=  30.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=91, depth=4, grow_policy=Depthwise, iterations=484, l2_leaf_reg=5, learning_rate=0.1810794308610328, min_data_in_leaf=7, random_strength=9; total time=  12.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=91, depth=4, grow_policy=Depthwise, iterations=484, l2_leaf_reg=5, learning_rate=0.1810794308610328, min_data_in_leaf=7, random_strength=9; total time=  12.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=91, depth=4, grow_policy=Depthwise, iterations=484, l2_leaf_reg=5, learning_rate=0.1810794308610328, min_data_in_leaf=7, random_strength=9; total time=  12.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=130, depth=6, grow_policy=Depthwise, iterations=307, l2_leaf_reg=3, learning_rate=0.17270161545683757, min_data_in_leaf=6, random_strength=8; total time=  12.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=130, depth=6, grow_policy=Depthwise, iterations=307, l2_leaf_reg=3, learning_rate=0.17270161545683757, min_data_in_leaf=6, random_strength=8; total time=  12.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=130, depth=6, grow_policy=Depthwise, iterations=307, l2_leaf_reg=3, learning_rate=0.17270161545683757, min_data_in_leaf=6, random_strength=8; total time=  12.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=183, depth=7, grow_policy=SymmetricTree, iterations=212, l2_leaf_reg=8, learning_rate=0.1592147237116493, min_data_in_leaf=8, random_strength=4; total time=  15.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=183, depth=7, grow_policy=SymmetricTree, iterations=212, l2_leaf_reg=8, learning_rate=0.1592147237116493, min_data_in_leaf=8, random_strength=4; total time=  15.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=183, depth=7, grow_policy=SymmetricTree, iterations=212, l2_leaf_reg=8, learning_rate=0.1592147237116493, min_data_in_leaf=8, random_strength=4; total time=  15.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=143, depth=9, grow_policy=SymmetricTree, iterations=198, l2_leaf_reg=9, learning_rate=0.01096170093078155, min_data_in_leaf=2, random_strength=2; total time=   6.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=143, depth=9, grow_policy=SymmetricTree, iterations=198, l2_leaf_reg=9, learning_rate=0.01096170093078155, min_data_in_leaf=2, random_strength=2; total time=   6.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=143, depth=9, grow_policy=SymmetricTree, iterations=198, l2_leaf_reg=9, learning_rate=0.01096170093078155, min_data_in_leaf=2, random_strength=2; total time=   6.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=194, depth=8, grow_policy=SymmetricTree, iterations=260, l2_leaf_reg=4, learning_rate=0.05507732662439201, min_data_in_leaf=5, random_strength=4; total time=  19.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=194, depth=8, grow_policy=SymmetricTree, iterations=260, l2_leaf_reg=4, learning_rate=0.05507732662439201, min_data_in_leaf=5, random_strength=4; total time=  19.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=194, depth=8, grow_policy=SymmetricTree, iterations=260, l2_leaf_reg=4, learning_rate=0.05507732662439201, min_data_in_leaf=5, random_strength=4; total time=  18.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=159, depth=10, grow_policy=SymmetricTree, iterations=500, l2_leaf_reg=1, learning_rate=0.11308264380543086, min_data_in_leaf=3, random_strength=6; total time= 1.1min\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=159, depth=10, grow_policy=SymmetricTree, iterations=500, l2_leaf_reg=1, learning_rate=0.11308264380543086, min_data_in_leaf=3, random_strength=6; total time= 1.0min\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=159, depth=10, grow_policy=SymmetricTree, iterations=500, l2_leaf_reg=1, learning_rate=0.11308264380543086, min_data_in_leaf=3, random_strength=6; total time= 1.1min\n",
      "[CV] END bootstrap_type=Bayesian, border_count=53, depth=9, grow_policy=Depthwise, iterations=137, l2_leaf_reg=6, learning_rate=0.08468856768668448, min_data_in_leaf=6, random_strength=8; total time=  10.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=53, depth=9, grow_policy=Depthwise, iterations=137, l2_leaf_reg=6, learning_rate=0.08468856768668448, min_data_in_leaf=6, random_strength=8; total time=  10.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=53, depth=9, grow_policy=Depthwise, iterations=137, l2_leaf_reg=6, learning_rate=0.08468856768668448, min_data_in_leaf=6, random_strength=8; total time=   9.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=58, depth=5, grow_policy=SymmetricTree, iterations=385, l2_leaf_reg=1, learning_rate=0.11961173807900823, min_data_in_leaf=1, random_strength=5; total time=  17.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=58, depth=5, grow_policy=SymmetricTree, iterations=385, l2_leaf_reg=1, learning_rate=0.11961173807900823, min_data_in_leaf=1, random_strength=5; total time=  18.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=58, depth=5, grow_policy=SymmetricTree, iterations=385, l2_leaf_reg=1, learning_rate=0.11961173807900823, min_data_in_leaf=1, random_strength=5; total time=  18.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=92, depth=6, grow_policy=Depthwise, iterations=134, l2_leaf_reg=1, learning_rate=0.018284716633342413, min_data_in_leaf=5, random_strength=6; total time=   5.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=92, depth=6, grow_policy=Depthwise, iterations=134, l2_leaf_reg=1, learning_rate=0.018284716633342413, min_data_in_leaf=5, random_strength=6; total time=   5.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=92, depth=6, grow_policy=Depthwise, iterations=134, l2_leaf_reg=1, learning_rate=0.018284716633342413, min_data_in_leaf=5, random_strength=6; total time=   5.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=155, depth=4, grow_policy=SymmetricTree, iterations=379, l2_leaf_reg=1, learning_rate=0.11502534369874308, min_data_in_leaf=3, random_strength=1; total time=  14.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=155, depth=4, grow_policy=SymmetricTree, iterations=379, l2_leaf_reg=1, learning_rate=0.11502534369874308, min_data_in_leaf=3, random_strength=1; total time=  14.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=155, depth=4, grow_policy=SymmetricTree, iterations=379, l2_leaf_reg=1, learning_rate=0.11502534369874308, min_data_in_leaf=3, random_strength=1; total time=  14.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=191, depth=10, grow_policy=SymmetricTree, iterations=355, l2_leaf_reg=3, learning_rate=0.042203621870357574, min_data_in_leaf=9, random_strength=10; total time=  36.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap_type=Bernoulli, border_count=191, depth=10, grow_policy=SymmetricTree, iterations=355, l2_leaf_reg=3, learning_rate=0.042203621870357574, min_data_in_leaf=9, random_strength=10; total time=  39.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=191, depth=10, grow_policy=SymmetricTree, iterations=355, l2_leaf_reg=3, learning_rate=0.042203621870357574, min_data_in_leaf=9, random_strength=10; total time=  39.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=85, depth=5, grow_policy=SymmetricTree, iterations=459, l2_leaf_reg=8, learning_rate=0.04969455634691844, min_data_in_leaf=6, random_strength=7; total time=  22.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=85, depth=5, grow_policy=SymmetricTree, iterations=459, l2_leaf_reg=8, learning_rate=0.04969455634691844, min_data_in_leaf=6, random_strength=7; total time=  21.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=85, depth=5, grow_policy=SymmetricTree, iterations=459, l2_leaf_reg=8, learning_rate=0.04969455634691844, min_data_in_leaf=6, random_strength=7; total time=  22.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=158, depth=6, grow_policy=Depthwise, iterations=485, l2_leaf_reg=1, learning_rate=0.17124726103568816, min_data_in_leaf=9, random_strength=6; total time=  18.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=158, depth=6, grow_policy=Depthwise, iterations=485, l2_leaf_reg=1, learning_rate=0.17124726103568816, min_data_in_leaf=9, random_strength=6; total time=  17.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=158, depth=6, grow_policy=Depthwise, iterations=485, l2_leaf_reg=1, learning_rate=0.17124726103568816, min_data_in_leaf=9, random_strength=6; total time=  17.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=70, depth=8, grow_policy=Depthwise, iterations=346, l2_leaf_reg=3, learning_rate=0.058679319282947034, min_data_in_leaf=8, random_strength=10; total time=  18.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=70, depth=8, grow_policy=Depthwise, iterations=346, l2_leaf_reg=3, learning_rate=0.058679319282947034, min_data_in_leaf=8, random_strength=10; total time=  18.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=70, depth=8, grow_policy=Depthwise, iterations=346, l2_leaf_reg=3, learning_rate=0.058679319282947034, min_data_in_leaf=8, random_strength=10; total time=  18.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=88, depth=7, grow_policy=SymmetricTree, iterations=119, l2_leaf_reg=1, learning_rate=0.023478774229986257, min_data_in_leaf=3, random_strength=7; total time=   3.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=88, depth=7, grow_policy=SymmetricTree, iterations=119, l2_leaf_reg=1, learning_rate=0.023478774229986257, min_data_in_leaf=3, random_strength=7; total time=   3.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=88, depth=7, grow_policy=SymmetricTree, iterations=119, l2_leaf_reg=1, learning_rate=0.023478774229986257, min_data_in_leaf=3, random_strength=7; total time=   3.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=123, depth=5, grow_policy=Depthwise, iterations=387, l2_leaf_reg=7, learning_rate=0.1376849657060879, min_data_in_leaf=3, random_strength=9; total time=  13.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=123, depth=5, grow_policy=Depthwise, iterations=387, l2_leaf_reg=7, learning_rate=0.1376849657060879, min_data_in_leaf=3, random_strength=9; total time=  13.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=123, depth=5, grow_policy=Depthwise, iterations=387, l2_leaf_reg=7, learning_rate=0.1376849657060879, min_data_in_leaf=3, random_strength=9; total time=  13.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=94, depth=9, grow_policy=SymmetricTree, iterations=249, l2_leaf_reg=6, learning_rate=0.05754775849801417, min_data_in_leaf=10, random_strength=6; total time=  20.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=94, depth=9, grow_policy=SymmetricTree, iterations=249, l2_leaf_reg=6, learning_rate=0.05754775849801417, min_data_in_leaf=10, random_strength=6; total time=  20.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=94, depth=9, grow_policy=SymmetricTree, iterations=249, l2_leaf_reg=6, learning_rate=0.05754775849801417, min_data_in_leaf=10, random_strength=6; total time=  20.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=85, depth=6, grow_policy=Depthwise, iterations=200, l2_leaf_reg=1, learning_rate=0.16729511071964184, min_data_in_leaf=5, random_strength=7; total time=   8.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=85, depth=6, grow_policy=Depthwise, iterations=200, l2_leaf_reg=1, learning_rate=0.16729511071964184, min_data_in_leaf=5, random_strength=7; total time=   8.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=85, depth=6, grow_policy=Depthwise, iterations=200, l2_leaf_reg=1, learning_rate=0.16729511071964184, min_data_in_leaf=5, random_strength=7; total time=   8.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=37, depth=8, grow_policy=Depthwise, iterations=471, l2_leaf_reg=3, learning_rate=0.13111168128465925, min_data_in_leaf=4, random_strength=2; total time=  25.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=37, depth=8, grow_policy=Depthwise, iterations=471, l2_leaf_reg=3, learning_rate=0.13111168128465925, min_data_in_leaf=4, random_strength=2; total time=  25.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=37, depth=8, grow_policy=Depthwise, iterations=471, l2_leaf_reg=3, learning_rate=0.13111168128465925, min_data_in_leaf=4, random_strength=2; total time=  25.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=137, depth=9, grow_policy=SymmetricTree, iterations=244, l2_leaf_reg=8, learning_rate=0.0614581277397941, min_data_in_leaf=10, random_strength=7; total time=  19.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=137, depth=9, grow_policy=SymmetricTree, iterations=244, l2_leaf_reg=8, learning_rate=0.0614581277397941, min_data_in_leaf=10, random_strength=7; total time=  19.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=137, depth=9, grow_policy=SymmetricTree, iterations=244, l2_leaf_reg=8, learning_rate=0.0614581277397941, min_data_in_leaf=10, random_strength=7; total time=  19.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=148, depth=9, grow_policy=SymmetricTree, iterations=226, l2_leaf_reg=9, learning_rate=0.14081498114541963, min_data_in_leaf=1, random_strength=10; total time=  18.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=148, depth=9, grow_policy=SymmetricTree, iterations=226, l2_leaf_reg=9, learning_rate=0.14081498114541963, min_data_in_leaf=1, random_strength=10; total time=  19.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=148, depth=9, grow_policy=SymmetricTree, iterations=226, l2_leaf_reg=9, learning_rate=0.14081498114541963, min_data_in_leaf=1, random_strength=10; total time=  19.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=32, depth=10, grow_policy=Depthwise, iterations=195, l2_leaf_reg=6, learning_rate=0.14577322531301184, min_data_in_leaf=8, random_strength=5; total time=  13.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=32, depth=10, grow_policy=Depthwise, iterations=195, l2_leaf_reg=6, learning_rate=0.14577322531301184, min_data_in_leaf=8, random_strength=5; total time=  13.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=32, depth=10, grow_policy=Depthwise, iterations=195, l2_leaf_reg=6, learning_rate=0.14577322531301184, min_data_in_leaf=8, random_strength=5; total time=  13.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=47, depth=8, grow_policy=SymmetricTree, iterations=291, l2_leaf_reg=5, learning_rate=0.12622694178452692, min_data_in_leaf=7, random_strength=3; total time=  23.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=47, depth=8, grow_policy=SymmetricTree, iterations=291, l2_leaf_reg=5, learning_rate=0.12622694178452692, min_data_in_leaf=7, random_strength=3; total time=  22.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=47, depth=8, grow_policy=SymmetricTree, iterations=291, l2_leaf_reg=5, learning_rate=0.12622694178452692, min_data_in_leaf=7, random_strength=3; total time=  22.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=185, depth=6, grow_policy=SymmetricTree, iterations=185, l2_leaf_reg=9, learning_rate=0.0749571366761163, min_data_in_leaf=5, random_strength=1; total time=   3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap_type=Bernoulli, border_count=185, depth=6, grow_policy=SymmetricTree, iterations=185, l2_leaf_reg=9, learning_rate=0.0749571366761163, min_data_in_leaf=5, random_strength=1; total time=   3.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=185, depth=6, grow_policy=SymmetricTree, iterations=185, l2_leaf_reg=9, learning_rate=0.0749571366761163, min_data_in_leaf=5, random_strength=1; total time=   3.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=175, depth=5, grow_policy=Depthwise, iterations=440, l2_leaf_reg=7, learning_rate=0.07579782100698615, min_data_in_leaf=5, random_strength=7; total time=  12.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=175, depth=5, grow_policy=Depthwise, iterations=440, l2_leaf_reg=7, learning_rate=0.07579782100698615, min_data_in_leaf=5, random_strength=7; total time=  12.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=175, depth=5, grow_policy=Depthwise, iterations=440, l2_leaf_reg=7, learning_rate=0.07579782100698615, min_data_in_leaf=5, random_strength=7; total time=  12.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=41, depth=9, grow_policy=SymmetricTree, iterations=199, l2_leaf_reg=2, learning_rate=0.059569788434925657, min_data_in_leaf=10, random_strength=10; total time=   5.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=41, depth=9, grow_policy=SymmetricTree, iterations=199, l2_leaf_reg=2, learning_rate=0.059569788434925657, min_data_in_leaf=10, random_strength=10; total time=   5.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=41, depth=9, grow_policy=SymmetricTree, iterations=199, l2_leaf_reg=2, learning_rate=0.059569788434925657, min_data_in_leaf=10, random_strength=10; total time=   5.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=127, depth=4, grow_policy=Depthwise, iterations=424, l2_leaf_reg=4, learning_rate=0.12701172123408364, min_data_in_leaf=7, random_strength=2; total time=  11.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=127, depth=4, grow_policy=Depthwise, iterations=424, l2_leaf_reg=4, learning_rate=0.12701172123408364, min_data_in_leaf=7, random_strength=2; total time=  11.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=127, depth=4, grow_policy=Depthwise, iterations=424, l2_leaf_reg=4, learning_rate=0.12701172123408364, min_data_in_leaf=7, random_strength=2; total time=  11.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=159, depth=6, grow_policy=Depthwise, iterations=251, l2_leaf_reg=2, learning_rate=0.11893973791766732, min_data_in_leaf=1, random_strength=1; total time=  10.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=159, depth=6, grow_policy=Depthwise, iterations=251, l2_leaf_reg=2, learning_rate=0.11893973791766732, min_data_in_leaf=1, random_strength=1; total time=  10.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=159, depth=6, grow_policy=Depthwise, iterations=251, l2_leaf_reg=2, learning_rate=0.11893973791766732, min_data_in_leaf=1, random_strength=1; total time=  10.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=132, depth=7, grow_policy=SymmetricTree, iterations=164, l2_leaf_reg=1, learning_rate=0.1337821066529797, min_data_in_leaf=2, random_strength=3; total time=   4.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=132, depth=7, grow_policy=SymmetricTree, iterations=164, l2_leaf_reg=1, learning_rate=0.1337821066529797, min_data_in_leaf=2, random_strength=3; total time=   4.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=132, depth=7, grow_policy=SymmetricTree, iterations=164, l2_leaf_reg=1, learning_rate=0.1337821066529797, min_data_in_leaf=2, random_strength=3; total time=   4.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=66, depth=10, grow_policy=SymmetricTree, iterations=189, l2_leaf_reg=8, learning_rate=0.08322535798345736, min_data_in_leaf=10, random_strength=10; total time=   6.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=66, depth=10, grow_policy=SymmetricTree, iterations=189, l2_leaf_reg=8, learning_rate=0.08322535798345736, min_data_in_leaf=10, random_strength=10; total time=   6.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=66, depth=10, grow_policy=SymmetricTree, iterations=189, l2_leaf_reg=8, learning_rate=0.08322535798345736, min_data_in_leaf=10, random_strength=10; total time=   6.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=193, depth=6, grow_policy=SymmetricTree, iterations=490, l2_leaf_reg=4, learning_rate=0.1416491681514685, min_data_in_leaf=2, random_strength=8; total time=  25.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=193, depth=6, grow_policy=SymmetricTree, iterations=490, l2_leaf_reg=4, learning_rate=0.1416491681514685, min_data_in_leaf=2, random_strength=8; total time=  25.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=193, depth=6, grow_policy=SymmetricTree, iterations=490, l2_leaf_reg=4, learning_rate=0.1416491681514685, min_data_in_leaf=2, random_strength=8; total time=  25.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=52, depth=8, grow_policy=SymmetricTree, iterations=263, l2_leaf_reg=5, learning_rate=0.1526168028117631, min_data_in_leaf=3, random_strength=1; total time=  18.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=52, depth=8, grow_policy=SymmetricTree, iterations=263, l2_leaf_reg=5, learning_rate=0.1526168028117631, min_data_in_leaf=3, random_strength=1; total time=  19.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=52, depth=8, grow_policy=SymmetricTree, iterations=263, l2_leaf_reg=5, learning_rate=0.1526168028117631, min_data_in_leaf=3, random_strength=1; total time=  19.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=67, depth=5, grow_policy=SymmetricTree, iterations=195, l2_leaf_reg=8, learning_rate=0.1747521553698472, min_data_in_leaf=5, random_strength=1; total time=   4.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=67, depth=5, grow_policy=SymmetricTree, iterations=195, l2_leaf_reg=8, learning_rate=0.1747521553698472, min_data_in_leaf=5, random_strength=1; total time=   4.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=67, depth=5, grow_policy=SymmetricTree, iterations=195, l2_leaf_reg=8, learning_rate=0.1747521553698472, min_data_in_leaf=5, random_strength=1; total time=   4.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=44, depth=10, grow_policy=SymmetricTree, iterations=454, l2_leaf_reg=9, learning_rate=0.08176848837349601, min_data_in_leaf=1, random_strength=4; total time=  55.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=44, depth=10, grow_policy=SymmetricTree, iterations=454, l2_leaf_reg=9, learning_rate=0.08176848837349601, min_data_in_leaf=1, random_strength=4; total time=  56.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=44, depth=10, grow_policy=SymmetricTree, iterations=454, l2_leaf_reg=9, learning_rate=0.08176848837349601, min_data_in_leaf=1, random_strength=4; total time=  56.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=117, depth=8, grow_policy=SymmetricTree, iterations=118, l2_leaf_reg=1, learning_rate=0.020162206382000093, min_data_in_leaf=9, random_strength=3; total time=   3.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=117, depth=8, grow_policy=SymmetricTree, iterations=118, l2_leaf_reg=1, learning_rate=0.020162206382000093, min_data_in_leaf=9, random_strength=3; total time=   3.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=117, depth=8, grow_policy=SymmetricTree, iterations=118, l2_leaf_reg=1, learning_rate=0.020162206382000093, min_data_in_leaf=9, random_strength=3; total time=   3.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=40, depth=10, grow_policy=Depthwise, iterations=305, l2_leaf_reg=4, learning_rate=0.11895319874342436, min_data_in_leaf=5, random_strength=5; total time=  21.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=40, depth=10, grow_policy=Depthwise, iterations=305, l2_leaf_reg=4, learning_rate=0.11895319874342436, min_data_in_leaf=5, random_strength=5; total time=  21.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=40, depth=10, grow_policy=Depthwise, iterations=305, l2_leaf_reg=4, learning_rate=0.11895319874342436, min_data_in_leaf=5, random_strength=5; total time=  21.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=171, depth=4, grow_policy=Depthwise, iterations=478, l2_leaf_reg=5, learning_rate=0.15295116059315922, min_data_in_leaf=7, random_strength=9; total time=  13.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap_type=Bayesian, border_count=171, depth=4, grow_policy=Depthwise, iterations=478, l2_leaf_reg=5, learning_rate=0.15295116059315922, min_data_in_leaf=7, random_strength=9; total time=  12.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=171, depth=4, grow_policy=Depthwise, iterations=478, l2_leaf_reg=5, learning_rate=0.15295116059315922, min_data_in_leaf=7, random_strength=9; total time=  13.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=140, depth=8, grow_policy=Depthwise, iterations=285, l2_leaf_reg=7, learning_rate=0.19922693598576255, min_data_in_leaf=10, random_strength=5; total time=  16.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=140, depth=8, grow_policy=Depthwise, iterations=285, l2_leaf_reg=7, learning_rate=0.19922693598576255, min_data_in_leaf=10, random_strength=5; total time=  16.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=140, depth=8, grow_policy=Depthwise, iterations=285, l2_leaf_reg=7, learning_rate=0.19922693598576255, min_data_in_leaf=10, random_strength=5; total time=  16.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=106, depth=5, grow_policy=SymmetricTree, iterations=175, l2_leaf_reg=9, learning_rate=0.15468702002631973, min_data_in_leaf=1, random_strength=6; total time=   3.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=106, depth=5, grow_policy=SymmetricTree, iterations=175, l2_leaf_reg=9, learning_rate=0.15468702002631973, min_data_in_leaf=1, random_strength=6; total time=   3.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=106, depth=5, grow_policy=SymmetricTree, iterations=175, l2_leaf_reg=9, learning_rate=0.15468702002631973, min_data_in_leaf=1, random_strength=6; total time=   4.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=172, depth=5, grow_policy=SymmetricTree, iterations=382, l2_leaf_reg=2, learning_rate=0.025456268321960955, min_data_in_leaf=5, random_strength=6; total time=  17.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=172, depth=5, grow_policy=SymmetricTree, iterations=382, l2_leaf_reg=2, learning_rate=0.025456268321960955, min_data_in_leaf=5, random_strength=6; total time=  17.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=172, depth=5, grow_policy=SymmetricTree, iterations=382, l2_leaf_reg=2, learning_rate=0.025456268321960955, min_data_in_leaf=5, random_strength=6; total time=  17.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=167, depth=8, grow_policy=SymmetricTree, iterations=441, l2_leaf_reg=4, learning_rate=0.054970186799594964, min_data_in_leaf=7, random_strength=9; total time=  33.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=167, depth=8, grow_policy=SymmetricTree, iterations=441, l2_leaf_reg=4, learning_rate=0.054970186799594964, min_data_in_leaf=7, random_strength=9; total time=  33.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=167, depth=8, grow_policy=SymmetricTree, iterations=441, l2_leaf_reg=4, learning_rate=0.054970186799594964, min_data_in_leaf=7, random_strength=9; total time=  34.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=163, depth=7, grow_policy=Depthwise, iterations=351, l2_leaf_reg=3, learning_rate=0.15765791402621301, min_data_in_leaf=6, random_strength=7; total time=  16.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=163, depth=7, grow_policy=Depthwise, iterations=351, l2_leaf_reg=3, learning_rate=0.15765791402621301, min_data_in_leaf=6, random_strength=7; total time=  16.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=163, depth=7, grow_policy=Depthwise, iterations=351, l2_leaf_reg=3, learning_rate=0.15765791402621301, min_data_in_leaf=6, random_strength=7; total time=  16.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=121, depth=6, grow_policy=SymmetricTree, iterations=225, l2_leaf_reg=3, learning_rate=0.05819961303589636, min_data_in_leaf=2, random_strength=10; total time=  11.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=121, depth=6, grow_policy=SymmetricTree, iterations=225, l2_leaf_reg=3, learning_rate=0.05819961303589636, min_data_in_leaf=2, random_strength=10; total time=  11.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=121, depth=6, grow_policy=SymmetricTree, iterations=225, l2_leaf_reg=3, learning_rate=0.05819961303589636, min_data_in_leaf=2, random_strength=10; total time=  11.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=92, depth=10, grow_policy=SymmetricTree, iterations=100, l2_leaf_reg=3, learning_rate=0.12084006536846033, min_data_in_leaf=9, random_strength=1; total time=   4.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=92, depth=10, grow_policy=SymmetricTree, iterations=100, l2_leaf_reg=3, learning_rate=0.12084006536846033, min_data_in_leaf=9, random_strength=1; total time=   4.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=92, depth=10, grow_policy=SymmetricTree, iterations=100, l2_leaf_reg=3, learning_rate=0.12084006536846033, min_data_in_leaf=9, random_strength=1; total time=   4.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=87, depth=4, grow_policy=Depthwise, iterations=216, l2_leaf_reg=6, learning_rate=0.1624007573150795, min_data_in_leaf=5, random_strength=6; total time=   6.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=87, depth=4, grow_policy=Depthwise, iterations=216, l2_leaf_reg=6, learning_rate=0.1624007573150795, min_data_in_leaf=5, random_strength=6; total time=   6.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=87, depth=4, grow_policy=Depthwise, iterations=216, l2_leaf_reg=6, learning_rate=0.1624007573150795, min_data_in_leaf=5, random_strength=6; total time=   6.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=195, depth=6, grow_policy=SymmetricTree, iterations=119, l2_leaf_reg=9, learning_rate=0.10938859039232827, min_data_in_leaf=9, random_strength=1; total time=   3.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=195, depth=6, grow_policy=SymmetricTree, iterations=119, l2_leaf_reg=9, learning_rate=0.10938859039232827, min_data_in_leaf=9, random_strength=1; total time=   3.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=195, depth=6, grow_policy=SymmetricTree, iterations=119, l2_leaf_reg=9, learning_rate=0.10938859039232827, min_data_in_leaf=9, random_strength=1; total time=   3.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=174, depth=10, grow_policy=SymmetricTree, iterations=472, l2_leaf_reg=6, learning_rate=0.12101971926538904, min_data_in_leaf=7, random_strength=9; total time=  56.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=174, depth=10, grow_policy=SymmetricTree, iterations=472, l2_leaf_reg=6, learning_rate=0.12101971926538904, min_data_in_leaf=7, random_strength=9; total time=  56.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=174, depth=10, grow_policy=SymmetricTree, iterations=472, l2_leaf_reg=6, learning_rate=0.12101971926538904, min_data_in_leaf=7, random_strength=9; total time=  56.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=43, depth=5, grow_policy=Depthwise, iterations=371, l2_leaf_reg=8, learning_rate=0.08495914173554467, min_data_in_leaf=8, random_strength=5; total time=  12.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=43, depth=5, grow_policy=Depthwise, iterations=371, l2_leaf_reg=8, learning_rate=0.08495914173554467, min_data_in_leaf=8, random_strength=5; total time=  12.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=43, depth=5, grow_policy=Depthwise, iterations=371, l2_leaf_reg=8, learning_rate=0.08495914173554467, min_data_in_leaf=8, random_strength=5; total time=  12.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=153, depth=7, grow_policy=Depthwise, iterations=189, l2_leaf_reg=8, learning_rate=0.07713692332495004, min_data_in_leaf=2, random_strength=5; total time=   8.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=153, depth=7, grow_policy=Depthwise, iterations=189, l2_leaf_reg=8, learning_rate=0.07713692332495004, min_data_in_leaf=2, random_strength=5; total time=   8.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=153, depth=7, grow_policy=Depthwise, iterations=189, l2_leaf_reg=8, learning_rate=0.07713692332495004, min_data_in_leaf=2, random_strength=5; total time=   8.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=186, depth=9, grow_policy=SymmetricTree, iterations=244, l2_leaf_reg=9, learning_rate=0.06881024709440227, min_data_in_leaf=4, random_strength=3; total time=  23.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap_type=Bayesian, border_count=186, depth=9, grow_policy=SymmetricTree, iterations=244, l2_leaf_reg=9, learning_rate=0.06881024709440227, min_data_in_leaf=4, random_strength=3; total time=  25.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=186, depth=9, grow_policy=SymmetricTree, iterations=244, l2_leaf_reg=9, learning_rate=0.06881024709440227, min_data_in_leaf=4, random_strength=3; total time=  24.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=165, depth=5, grow_policy=SymmetricTree, iterations=355, l2_leaf_reg=5, learning_rate=0.12654888722780008, min_data_in_leaf=2, random_strength=10; total time=  17.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=165, depth=5, grow_policy=SymmetricTree, iterations=355, l2_leaf_reg=5, learning_rate=0.12654888722780008, min_data_in_leaf=2, random_strength=10; total time=  17.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=165, depth=5, grow_policy=SymmetricTree, iterations=355, l2_leaf_reg=5, learning_rate=0.12654888722780008, min_data_in_leaf=2, random_strength=10; total time=  17.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=61, depth=5, grow_policy=SymmetricTree, iterations=464, l2_leaf_reg=5, learning_rate=0.01500972515447788, min_data_in_leaf=1, random_strength=6; total time=  19.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=61, depth=5, grow_policy=SymmetricTree, iterations=464, l2_leaf_reg=5, learning_rate=0.01500972515447788, min_data_in_leaf=1, random_strength=6; total time=  19.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=61, depth=5, grow_policy=SymmetricTree, iterations=464, l2_leaf_reg=5, learning_rate=0.01500972515447788, min_data_in_leaf=1, random_strength=6; total time=  20.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=177, depth=10, grow_policy=SymmetricTree, iterations=366, l2_leaf_reg=5, learning_rate=0.1524198769954537, min_data_in_leaf=9, random_strength=6; total time=  48.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=177, depth=10, grow_policy=SymmetricTree, iterations=366, l2_leaf_reg=5, learning_rate=0.1524198769954537, min_data_in_leaf=9, random_strength=6; total time=  48.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=177, depth=10, grow_policy=SymmetricTree, iterations=366, l2_leaf_reg=5, learning_rate=0.1524198769954537, min_data_in_leaf=9, random_strength=6; total time=  48.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=58, depth=4, grow_policy=SymmetricTree, iterations=197, l2_leaf_reg=9, learning_rate=0.08881570544415639, min_data_in_leaf=1, random_strength=5; total time=   4.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=58, depth=4, grow_policy=SymmetricTree, iterations=197, l2_leaf_reg=9, learning_rate=0.08881570544415639, min_data_in_leaf=1, random_strength=5; total time=   4.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=58, depth=4, grow_policy=SymmetricTree, iterations=197, l2_leaf_reg=9, learning_rate=0.08881570544415639, min_data_in_leaf=1, random_strength=5; total time=   4.0s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=86, depth=9, grow_policy=Depthwise, iterations=296, l2_leaf_reg=5, learning_rate=0.19936099904404203, min_data_in_leaf=5, random_strength=7; total time=  18.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=86, depth=9, grow_policy=Depthwise, iterations=296, l2_leaf_reg=5, learning_rate=0.19936099904404203, min_data_in_leaf=5, random_strength=7; total time=  18.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=86, depth=9, grow_policy=Depthwise, iterations=296, l2_leaf_reg=5, learning_rate=0.19936099904404203, min_data_in_leaf=5, random_strength=7; total time=  18.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=84, depth=8, grow_policy=Depthwise, iterations=182, l2_leaf_reg=1, learning_rate=0.055806118142630055, min_data_in_leaf=9, random_strength=1; total time=  12.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=84, depth=8, grow_policy=Depthwise, iterations=182, l2_leaf_reg=1, learning_rate=0.055806118142630055, min_data_in_leaf=9, random_strength=1; total time=  12.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=84, depth=8, grow_policy=Depthwise, iterations=182, l2_leaf_reg=1, learning_rate=0.055806118142630055, min_data_in_leaf=9, random_strength=1; total time=  12.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=35, depth=9, grow_policy=SymmetricTree, iterations=468, l2_leaf_reg=8, learning_rate=0.1274443656870002, min_data_in_leaf=8, random_strength=7; total time=  47.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=35, depth=9, grow_policy=SymmetricTree, iterations=468, l2_leaf_reg=8, learning_rate=0.1274443656870002, min_data_in_leaf=8, random_strength=7; total time=  45.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=35, depth=9, grow_policy=SymmetricTree, iterations=468, l2_leaf_reg=8, learning_rate=0.1274443656870002, min_data_in_leaf=8, random_strength=7; total time=  44.9s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=193, depth=9, grow_policy=Depthwise, iterations=358, l2_leaf_reg=2, learning_rate=0.17191448506052262, min_data_in_leaf=6, random_strength=5; total time=  22.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=193, depth=9, grow_policy=Depthwise, iterations=358, l2_leaf_reg=2, learning_rate=0.17191448506052262, min_data_in_leaf=6, random_strength=5; total time=  22.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=193, depth=9, grow_policy=Depthwise, iterations=358, l2_leaf_reg=2, learning_rate=0.17191448506052262, min_data_in_leaf=6, random_strength=5; total time=  22.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=88, depth=4, grow_policy=Depthwise, iterations=354, l2_leaf_reg=7, learning_rate=0.15347607857798762, min_data_in_leaf=5, random_strength=2; total time=   8.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=88, depth=4, grow_policy=Depthwise, iterations=354, l2_leaf_reg=7, learning_rate=0.15347607857798762, min_data_in_leaf=5, random_strength=2; total time=   8.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=88, depth=4, grow_policy=Depthwise, iterations=354, l2_leaf_reg=7, learning_rate=0.15347607857798762, min_data_in_leaf=5, random_strength=2; total time=   8.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=134, depth=9, grow_policy=Depthwise, iterations=351, l2_leaf_reg=2, learning_rate=0.07661163617325342, min_data_in_leaf=2, random_strength=2; total time=  25.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=134, depth=9, grow_policy=Depthwise, iterations=351, l2_leaf_reg=2, learning_rate=0.07661163617325342, min_data_in_leaf=2, random_strength=2; total time=  25.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=134, depth=9, grow_policy=Depthwise, iterations=351, l2_leaf_reg=2, learning_rate=0.07661163617325342, min_data_in_leaf=2, random_strength=2; total time=  25.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=110, depth=6, grow_policy=SymmetricTree, iterations=407, l2_leaf_reg=9, learning_rate=0.10765800294036405, min_data_in_leaf=8, random_strength=7; total time=  20.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=110, depth=6, grow_policy=SymmetricTree, iterations=407, l2_leaf_reg=9, learning_rate=0.10765800294036405, min_data_in_leaf=8, random_strength=7; total time=  21.3s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=110, depth=6, grow_policy=SymmetricTree, iterations=407, l2_leaf_reg=9, learning_rate=0.10765800294036405, min_data_in_leaf=8, random_strength=7; total time=  21.2s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=82, depth=4, grow_policy=SymmetricTree, iterations=384, l2_leaf_reg=4, learning_rate=0.09727589350977275, min_data_in_leaf=1, random_strength=10; total time=  12.8s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=82, depth=4, grow_policy=SymmetricTree, iterations=384, l2_leaf_reg=4, learning_rate=0.09727589350977275, min_data_in_leaf=1, random_strength=10; total time=  12.7s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=82, depth=4, grow_policy=SymmetricTree, iterations=384, l2_leaf_reg=4, learning_rate=0.09727589350977275, min_data_in_leaf=1, random_strength=10; total time=  13.0s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=115, depth=8, grow_policy=Depthwise, iterations=361, l2_leaf_reg=5, learning_rate=0.0760085475628287, min_data_in_leaf=3, random_strength=9; total time=  20.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap_type=Bayesian, border_count=115, depth=8, grow_policy=Depthwise, iterations=361, l2_leaf_reg=5, learning_rate=0.0760085475628287, min_data_in_leaf=3, random_strength=9; total time=  20.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=115, depth=8, grow_policy=Depthwise, iterations=361, l2_leaf_reg=5, learning_rate=0.0760085475628287, min_data_in_leaf=3, random_strength=9; total time=  20.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=111, depth=10, grow_policy=SymmetricTree, iterations=473, l2_leaf_reg=8, learning_rate=0.044212781746366725, min_data_in_leaf=4, random_strength=8; total time=  56.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=111, depth=10, grow_policy=SymmetricTree, iterations=473, l2_leaf_reg=8, learning_rate=0.044212781746366725, min_data_in_leaf=4, random_strength=8; total time=  56.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=111, depth=10, grow_policy=SymmetricTree, iterations=473, l2_leaf_reg=8, learning_rate=0.044212781746366725, min_data_in_leaf=4, random_strength=8; total time=  56.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=127, depth=6, grow_policy=SymmetricTree, iterations=192, l2_leaf_reg=2, learning_rate=0.12436772515278244, min_data_in_leaf=3, random_strength=3; total time=   5.4s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=127, depth=6, grow_policy=SymmetricTree, iterations=192, l2_leaf_reg=2, learning_rate=0.12436772515278244, min_data_in_leaf=3, random_strength=3; total time=   5.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=127, depth=6, grow_policy=SymmetricTree, iterations=192, l2_leaf_reg=2, learning_rate=0.12436772515278244, min_data_in_leaf=3, random_strength=3; total time=   4.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=36, depth=5, grow_policy=Depthwise, iterations=269, l2_leaf_reg=6, learning_rate=0.026853481413840564, min_data_in_leaf=1, random_strength=5; total time=   9.8s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=36, depth=5, grow_policy=Depthwise, iterations=269, l2_leaf_reg=6, learning_rate=0.026853481413840564, min_data_in_leaf=1, random_strength=5; total time=   9.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=36, depth=5, grow_policy=Depthwise, iterations=269, l2_leaf_reg=6, learning_rate=0.026853481413840564, min_data_in_leaf=1, random_strength=5; total time=   9.5s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=43, depth=5, grow_policy=Depthwise, iterations=133, l2_leaf_reg=1, learning_rate=0.1056492814624228, min_data_in_leaf=9, random_strength=10; total time=   4.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=43, depth=5, grow_policy=Depthwise, iterations=133, l2_leaf_reg=1, learning_rate=0.1056492814624228, min_data_in_leaf=9, random_strength=10; total time=   4.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=43, depth=5, grow_policy=Depthwise, iterations=133, l2_leaf_reg=1, learning_rate=0.1056492814624228, min_data_in_leaf=9, random_strength=10; total time=   5.2s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=78, depth=4, grow_policy=Depthwise, iterations=338, l2_leaf_reg=8, learning_rate=0.17597993858028768, min_data_in_leaf=1, random_strength=10; total time=   9.6s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=78, depth=4, grow_policy=Depthwise, iterations=338, l2_leaf_reg=8, learning_rate=0.17597993858028768, min_data_in_leaf=1, random_strength=10; total time=   9.3s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=78, depth=4, grow_policy=Depthwise, iterations=338, l2_leaf_reg=8, learning_rate=0.17597993858028768, min_data_in_leaf=1, random_strength=10; total time=   9.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=32, depth=4, grow_policy=SymmetricTree, iterations=352, l2_leaf_reg=4, learning_rate=0.04977637143397496, min_data_in_leaf=8, random_strength=6; total time=  11.4s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=32, depth=4, grow_policy=SymmetricTree, iterations=352, l2_leaf_reg=4, learning_rate=0.04977637143397496, min_data_in_leaf=8, random_strength=6; total time=  11.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=32, depth=4, grow_policy=SymmetricTree, iterations=352, l2_leaf_reg=4, learning_rate=0.04977637143397496, min_data_in_leaf=8, random_strength=6; total time=  11.5s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=59, depth=10, grow_policy=Depthwise, iterations=315, l2_leaf_reg=2, learning_rate=0.15201947824541376, min_data_in_leaf=8, random_strength=3; total time=  23.1s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=59, depth=10, grow_policy=Depthwise, iterations=315, l2_leaf_reg=2, learning_rate=0.15201947824541376, min_data_in_leaf=8, random_strength=3; total time=  22.6s\n",
      "[CV] END bootstrap_type=Bernoulli, border_count=59, depth=10, grow_policy=Depthwise, iterations=315, l2_leaf_reg=2, learning_rate=0.15201947824541376, min_data_in_leaf=8, random_strength=3; total time=  22.7s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=34, depth=10, grow_policy=SymmetricTree, iterations=337, l2_leaf_reg=2, learning_rate=0.09500834969645638, min_data_in_leaf=3, random_strength=3; total time=  42.9s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=34, depth=10, grow_policy=SymmetricTree, iterations=337, l2_leaf_reg=2, learning_rate=0.09500834969645638, min_data_in_leaf=3, random_strength=3; total time=  42.1s\n",
      "[CV] END bootstrap_type=Bayesian, border_count=34, depth=10, grow_policy=SymmetricTree, iterations=337, l2_leaf_reg=2, learning_rate=0.09500834969645638, min_data_in_leaf=3, random_strength=3; total time=  42.5s\n",
      "Best parameters found:  {'bootstrap_type': 'Bayesian', 'border_count': 199, 'depth': 10, 'grow_policy': 'Depthwise', 'iterations': 459, 'l2_leaf_reg': 1, 'learning_rate': 0.13838112223746335, 'min_data_in_leaf': 9, 'random_strength': 9}\n",
      "Best Score: -1646.006495531565\n"
     ]
    }
   ],
   "source": [
    "# define the CatBoostRegressor model\n",
    "cat_model = CatBoostRegressor(cat_features=categorical_features, random_state=42, silent=True)\n",
    "\n",
    "# parameter grid\n",
    "param_distributions = {\n",
    "    'iterations': randint(100, 501),\n",
    "    'depth': randint(4, 11),\n",
    "    'learning_rate': uniform(0.01, 0.19),\n",
    "    'l2_leaf_reg': randint(1, 10),\n",
    "    'border_count': randint(32, 201),\n",
    "    'grow_policy': ['SymmetricTree', 'Depthwise'],\n",
    "    'random_strength': randint(1,11),\n",
    "    'min_data_in_leaf': randint(1,11),\n",
    "    'bootstrap_type': ['Bayesian', 'Bernoulli']\n",
    "}\n",
    "\n",
    "# set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=cat_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100, \n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(f\"Best Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4273.6258223\ttotal: 194ms\tremaining: 1m 28s\n",
      "1:\tlearn: 3906.5026901\ttotal: 374ms\tremaining: 1m 25s\n",
      "2:\tlearn: 3583.6490261\ttotal: 540ms\tremaining: 1m 22s\n",
      "3:\tlearn: 3310.8651469\ttotal: 729ms\tremaining: 1m 22s\n",
      "4:\tlearn: 3076.4786608\ttotal: 897ms\tremaining: 1m 21s\n",
      "5:\tlearn: 2886.0930084\ttotal: 1.08s\tremaining: 1m 21s\n",
      "6:\tlearn: 2729.4586690\ttotal: 1.24s\tremaining: 1m 19s\n",
      "7:\tlearn: 2587.6460156\ttotal: 1.41s\tremaining: 1m 19s\n",
      "8:\tlearn: 2467.7020861\ttotal: 1.59s\tremaining: 1m 19s\n",
      "9:\tlearn: 2383.2420937\ttotal: 1.76s\tremaining: 1m 19s\n",
      "10:\tlearn: 2297.8161571\ttotal: 1.94s\tremaining: 1m 18s\n",
      "11:\tlearn: 2222.0678538\ttotal: 2.11s\tremaining: 1m 18s\n",
      "12:\tlearn: 2162.3036891\ttotal: 2.27s\tremaining: 1m 18s\n",
      "13:\tlearn: 2115.8756305\ttotal: 2.45s\tremaining: 1m 17s\n",
      "14:\tlearn: 2074.0935408\ttotal: 2.61s\tremaining: 1m 17s\n",
      "15:\tlearn: 2041.2256283\ttotal: 2.77s\tremaining: 1m 16s\n",
      "16:\tlearn: 2013.5016318\ttotal: 2.92s\tremaining: 1m 15s\n",
      "17:\tlearn: 1990.3613995\ttotal: 3.08s\tremaining: 1m 15s\n",
      "18:\tlearn: 1967.8038786\ttotal: 3.26s\tremaining: 1m 15s\n",
      "19:\tlearn: 1951.1920468\ttotal: 3.39s\tremaining: 1m 14s\n",
      "20:\tlearn: 1933.0785292\ttotal: 3.57s\tremaining: 1m 14s\n",
      "21:\tlearn: 1920.8285644\ttotal: 3.73s\tremaining: 1m 14s\n",
      "22:\tlearn: 1906.3172254\ttotal: 3.89s\tremaining: 1m 13s\n",
      "23:\tlearn: 1895.1862936\ttotal: 4.05s\tremaining: 1m 13s\n",
      "24:\tlearn: 1885.7525187\ttotal: 4.22s\tremaining: 1m 13s\n",
      "25:\tlearn: 1877.8364089\ttotal: 4.36s\tremaining: 1m 12s\n",
      "26:\tlearn: 1869.4889161\ttotal: 4.55s\tremaining: 1m 12s\n",
      "27:\tlearn: 1863.0013893\ttotal: 4.71s\tremaining: 1m 12s\n",
      "28:\tlearn: 1853.2551098\ttotal: 4.87s\tremaining: 1m 12s\n",
      "29:\tlearn: 1845.9403333\ttotal: 5.03s\tremaining: 1m 11s\n",
      "30:\tlearn: 1838.8342240\ttotal: 5.22s\tremaining: 1m 12s\n",
      "31:\tlearn: 1832.2975130\ttotal: 5.37s\tremaining: 1m 11s\n",
      "32:\tlearn: 1826.4867145\ttotal: 5.51s\tremaining: 1m 11s\n",
      "33:\tlearn: 1822.0686585\ttotal: 5.67s\tremaining: 1m 10s\n",
      "34:\tlearn: 1819.0432137\ttotal: 5.82s\tremaining: 1m 10s\n",
      "35:\tlearn: 1815.0144566\ttotal: 5.97s\tremaining: 1m 10s\n",
      "36:\tlearn: 1811.5324042\ttotal: 6.11s\tremaining: 1m 9s\n",
      "37:\tlearn: 1806.4682683\ttotal: 6.27s\tremaining: 1m 9s\n",
      "38:\tlearn: 1804.9401513\ttotal: 6.42s\tremaining: 1m 9s\n",
      "39:\tlearn: 1801.9885897\ttotal: 6.59s\tremaining: 1m 9s\n",
      "40:\tlearn: 1799.3540659\ttotal: 6.73s\tremaining: 1m 8s\n",
      "41:\tlearn: 1797.5587859\ttotal: 6.88s\tremaining: 1m 8s\n",
      "42:\tlearn: 1795.8232812\ttotal: 7.04s\tremaining: 1m 8s\n",
      "43:\tlearn: 1794.0447210\ttotal: 7.21s\tremaining: 1m 7s\n",
      "44:\tlearn: 1790.2463150\ttotal: 7.37s\tremaining: 1m 7s\n",
      "45:\tlearn: 1787.5234948\ttotal: 7.52s\tremaining: 1m 7s\n",
      "46:\tlearn: 1785.1280074\ttotal: 7.67s\tremaining: 1m 7s\n",
      "47:\tlearn: 1781.5217145\ttotal: 7.81s\tremaining: 1m 6s\n",
      "48:\tlearn: 1780.3458327\ttotal: 7.96s\tremaining: 1m 6s\n",
      "49:\tlearn: 1778.6388254\ttotal: 8.11s\tremaining: 1m 6s\n",
      "50:\tlearn: 1777.3317237\ttotal: 8.26s\tremaining: 1m 6s\n",
      "51:\tlearn: 1775.7870799\ttotal: 8.39s\tremaining: 1m 5s\n",
      "52:\tlearn: 1773.9404404\ttotal: 8.54s\tremaining: 1m 5s\n",
      "53:\tlearn: 1772.7309861\ttotal: 8.7s\tremaining: 1m 5s\n",
      "54:\tlearn: 1771.2936841\ttotal: 8.85s\tremaining: 1m 5s\n",
      "55:\tlearn: 1769.5452016\ttotal: 8.99s\tremaining: 1m 4s\n",
      "56:\tlearn: 1768.7268636\ttotal: 9.14s\tremaining: 1m 4s\n",
      "57:\tlearn: 1765.7896778\ttotal: 9.31s\tremaining: 1m 4s\n",
      "58:\tlearn: 1764.4156435\ttotal: 9.46s\tremaining: 1m 4s\n",
      "59:\tlearn: 1762.9238935\ttotal: 9.62s\tremaining: 1m 3s\n",
      "60:\tlearn: 1761.5119826\ttotal: 9.78s\tremaining: 1m 3s\n",
      "61:\tlearn: 1759.2985973\ttotal: 9.94s\tremaining: 1m 3s\n",
      "62:\tlearn: 1756.5101421\ttotal: 10.1s\tremaining: 1m 3s\n",
      "63:\tlearn: 1754.8647573\ttotal: 10.2s\tremaining: 1m 3s\n",
      "64:\tlearn: 1753.7649663\ttotal: 10.4s\tremaining: 1m 2s\n",
      "65:\tlearn: 1752.5962099\ttotal: 10.5s\tremaining: 1m 2s\n",
      "66:\tlearn: 1751.1125979\ttotal: 10.7s\tremaining: 1m 2s\n",
      "67:\tlearn: 1749.8269522\ttotal: 10.8s\tremaining: 1m 2s\n",
      "68:\tlearn: 1749.0893610\ttotal: 11s\tremaining: 1m 2s\n",
      "69:\tlearn: 1748.1431516\ttotal: 11.1s\tremaining: 1m 1s\n",
      "70:\tlearn: 1746.2412614\ttotal: 11.3s\tremaining: 1m 1s\n",
      "71:\tlearn: 1745.4392940\ttotal: 11.4s\tremaining: 1m 1s\n",
      "72:\tlearn: 1744.7523972\ttotal: 11.6s\tremaining: 1m 1s\n",
      "73:\tlearn: 1743.0357093\ttotal: 11.7s\tremaining: 1m\n",
      "74:\tlearn: 1741.4130033\ttotal: 11.9s\tremaining: 1m\n",
      "75:\tlearn: 1740.5694973\ttotal: 12s\tremaining: 1m\n",
      "76:\tlearn: 1738.5911268\ttotal: 12.2s\tremaining: 1m\n",
      "77:\tlearn: 1737.0079289\ttotal: 12.3s\tremaining: 1m\n",
      "78:\tlearn: 1736.3350147\ttotal: 12.5s\tremaining: 59.9s\n",
      "79:\tlearn: 1735.2144955\ttotal: 12.6s\tremaining: 59.8s\n",
      "80:\tlearn: 1733.8198891\ttotal: 12.8s\tremaining: 59.6s\n",
      "81:\tlearn: 1732.4096725\ttotal: 12.9s\tremaining: 59.4s\n",
      "82:\tlearn: 1731.2283361\ttotal: 13.1s\tremaining: 59.2s\n",
      "83:\tlearn: 1729.2230346\ttotal: 13.2s\tremaining: 59.1s\n",
      "84:\tlearn: 1726.9366055\ttotal: 13.4s\tremaining: 58.9s\n",
      "85:\tlearn: 1724.5855738\ttotal: 13.5s\tremaining: 58.6s\n",
      "86:\tlearn: 1722.5575228\ttotal: 13.7s\tremaining: 58.4s\n",
      "87:\tlearn: 1719.5358705\ttotal: 13.8s\tremaining: 58.2s\n",
      "88:\tlearn: 1718.9464082\ttotal: 14s\tremaining: 58s\n",
      "89:\tlearn: 1715.5922347\ttotal: 14.1s\tremaining: 57.9s\n",
      "90:\tlearn: 1712.7159995\ttotal: 14.3s\tremaining: 57.7s\n",
      "91:\tlearn: 1710.6318170\ttotal: 14.4s\tremaining: 57.5s\n",
      "92:\tlearn: 1705.7412010\ttotal: 14.6s\tremaining: 57.4s\n",
      "93:\tlearn: 1703.5357403\ttotal: 14.7s\tremaining: 57.2s\n",
      "94:\tlearn: 1700.3587777\ttotal: 14.9s\tremaining: 57.1s\n",
      "95:\tlearn: 1696.4581188\ttotal: 15.1s\tremaining: 57s\n",
      "96:\tlearn: 1695.1060793\ttotal: 15.2s\tremaining: 56.7s\n",
      "97:\tlearn: 1691.7485976\ttotal: 15.3s\tremaining: 56.5s\n",
      "98:\tlearn: 1689.0783462\ttotal: 15.5s\tremaining: 56.4s\n",
      "99:\tlearn: 1686.5271727\ttotal: 15.7s\tremaining: 56.2s\n",
      "100:\tlearn: 1684.3250452\ttotal: 15.8s\tremaining: 55.9s\n",
      "101:\tlearn: 1679.2670083\ttotal: 16s\tremaining: 55.8s\n",
      "102:\tlearn: 1675.2568580\ttotal: 16.1s\tremaining: 55.7s\n",
      "103:\tlearn: 1670.9578866\ttotal: 16.3s\tremaining: 55.5s\n",
      "104:\tlearn: 1667.2898587\ttotal: 16.4s\tremaining: 55.4s\n",
      "105:\tlearn: 1664.1935952\ttotal: 16.6s\tremaining: 55.1s\n",
      "106:\tlearn: 1660.7092169\ttotal: 16.7s\tremaining: 54.9s\n",
      "107:\tlearn: 1657.1525108\ttotal: 16.9s\tremaining: 54.8s\n",
      "108:\tlearn: 1653.3159297\ttotal: 17s\tremaining: 54.6s\n",
      "109:\tlearn: 1647.1781459\ttotal: 17.2s\tremaining: 54.4s\n",
      "110:\tlearn: 1643.3839713\ttotal: 17.3s\tremaining: 54.2s\n",
      "111:\tlearn: 1637.6225988\ttotal: 17.5s\tremaining: 54.1s\n",
      "112:\tlearn: 1632.4233138\ttotal: 17.6s\tremaining: 54s\n",
      "113:\tlearn: 1629.1906282\ttotal: 17.8s\tremaining: 53.8s\n",
      "114:\tlearn: 1626.7052716\ttotal: 17.9s\tremaining: 53.6s\n",
      "115:\tlearn: 1625.6718378\ttotal: 18s\tremaining: 53.3s\n",
      "116:\tlearn: 1622.7041511\ttotal: 18.2s\tremaining: 53.1s\n",
      "117:\tlearn: 1616.8598282\ttotal: 18.3s\tremaining: 53s\n",
      "118:\tlearn: 1614.7580013\ttotal: 18.5s\tremaining: 52.8s\n",
      "119:\tlearn: 1612.7621932\ttotal: 18.6s\tremaining: 52.6s\n",
      "120:\tlearn: 1607.8093022\ttotal: 18.8s\tremaining: 52.5s\n",
      "121:\tlearn: 1607.5645545\ttotal: 18.9s\tremaining: 52.2s\n",
      "122:\tlearn: 1606.4543234\ttotal: 19s\tremaining: 52s\n",
      "123:\tlearn: 1604.3009407\ttotal: 19.2s\tremaining: 51.8s\n",
      "124:\tlearn: 1602.0755536\ttotal: 19.3s\tremaining: 51.6s\n",
      "125:\tlearn: 1599.4854013\ttotal: 19.4s\tremaining: 51.3s\n",
      "126:\tlearn: 1598.3204161\ttotal: 19.5s\tremaining: 51.1s\n",
      "127:\tlearn: 1596.0690568\ttotal: 19.7s\tremaining: 50.9s\n",
      "128:\tlearn: 1590.8327908\ttotal: 19.9s\tremaining: 50.8s\n",
      "129:\tlearn: 1587.7769996\ttotal: 20s\tremaining: 50.7s\n",
      "130:\tlearn: 1584.7546374\ttotal: 20.2s\tremaining: 50.5s\n",
      "131:\tlearn: 1583.0288999\ttotal: 20.3s\tremaining: 50.3s\n",
      "132:\tlearn: 1581.3499426\ttotal: 20.4s\tremaining: 50.1s\n",
      "133:\tlearn: 1579.7417028\ttotal: 20.6s\tremaining: 49.8s\n",
      "134:\tlearn: 1577.4290129\ttotal: 20.7s\tremaining: 49.6s\n",
      "135:\tlearn: 1576.1360644\ttotal: 20.8s\tremaining: 49.4s\n",
      "136:\tlearn: 1572.4073911\ttotal: 21s\tremaining: 49.3s\n",
      "137:\tlearn: 1569.9669461\ttotal: 21.1s\tremaining: 49.1s\n",
      "138:\tlearn: 1567.6744212\ttotal: 21.3s\tremaining: 49s\n",
      "139:\tlearn: 1566.3259874\ttotal: 21.4s\tremaining: 48.8s\n",
      "140:\tlearn: 1564.6872652\ttotal: 21.5s\tremaining: 48.6s\n",
      "141:\tlearn: 1562.1395124\ttotal: 21.7s\tremaining: 48.4s\n",
      "142:\tlearn: 1559.2874814\ttotal: 21.8s\tremaining: 48.2s\n",
      "143:\tlearn: 1555.8562625\ttotal: 22s\tremaining: 48.1s\n",
      "144:\tlearn: 1555.1220173\ttotal: 22.1s\tremaining: 47.8s\n",
      "145:\tlearn: 1550.2137723\ttotal: 22.2s\tremaining: 47.7s\n",
      "146:\tlearn: 1548.1823193\ttotal: 22.4s\tremaining: 47.5s\n",
      "147:\tlearn: 1544.4913425\ttotal: 22.6s\tremaining: 47.4s\n",
      "148:\tlearn: 1539.1632333\ttotal: 22.7s\tremaining: 47.3s\n",
      "149:\tlearn: 1536.8700982\ttotal: 22.9s\tremaining: 47.1s\n",
      "150:\tlearn: 1535.1236269\ttotal: 23s\tremaining: 47s\n",
      "151:\tlearn: 1534.3303009\ttotal: 23.1s\tremaining: 46.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152:\tlearn: 1533.4770909\ttotal: 23.3s\tremaining: 46.5s\n",
      "153:\tlearn: 1528.9541063\ttotal: 23.4s\tremaining: 46.4s\n",
      "154:\tlearn: 1527.2767995\ttotal: 23.6s\tremaining: 46.3s\n",
      "155:\tlearn: 1523.9393522\ttotal: 23.8s\tremaining: 46.2s\n",
      "156:\tlearn: 1522.3761714\ttotal: 23.9s\tremaining: 46s\n",
      "157:\tlearn: 1520.4819641\ttotal: 24.1s\tremaining: 45.8s\n",
      "158:\tlearn: 1517.7000803\ttotal: 24.2s\tremaining: 45.7s\n",
      "159:\tlearn: 1515.8606008\ttotal: 24.4s\tremaining: 45.5s\n",
      "160:\tlearn: 1515.2511072\ttotal: 24.5s\tremaining: 45.3s\n",
      "161:\tlearn: 1513.7895148\ttotal: 24.6s\tremaining: 45.1s\n",
      "162:\tlearn: 1511.2925401\ttotal: 24.7s\tremaining: 44.9s\n",
      "163:\tlearn: 1509.1342389\ttotal: 24.9s\tremaining: 44.7s\n",
      "164:\tlearn: 1506.2327623\ttotal: 25s\tremaining: 44.6s\n",
      "165:\tlearn: 1503.1851050\ttotal: 25.2s\tremaining: 44.4s\n",
      "166:\tlearn: 1499.4932762\ttotal: 25.3s\tremaining: 44.3s\n",
      "167:\tlearn: 1496.6595696\ttotal: 25.5s\tremaining: 44.2s\n",
      "168:\tlearn: 1493.0193242\ttotal: 25.7s\tremaining: 44.1s\n",
      "169:\tlearn: 1491.9673645\ttotal: 25.8s\tremaining: 43.9s\n",
      "170:\tlearn: 1490.3439984\ttotal: 25.9s\tremaining: 43.7s\n",
      "171:\tlearn: 1488.9688886\ttotal: 26.1s\tremaining: 43.5s\n",
      "172:\tlearn: 1486.9829076\ttotal: 26.3s\tremaining: 43.4s\n",
      "173:\tlearn: 1485.3102173\ttotal: 26.4s\tremaining: 43.2s\n",
      "174:\tlearn: 1483.0899533\ttotal: 26.6s\tremaining: 43.1s\n",
      "175:\tlearn: 1481.7905385\ttotal: 26.7s\tremaining: 42.9s\n",
      "176:\tlearn: 1479.3329526\ttotal: 26.9s\tremaining: 42.8s\n",
      "177:\tlearn: 1477.9925252\ttotal: 27s\tremaining: 42.6s\n",
      "178:\tlearn: 1475.1316853\ttotal: 27.2s\tremaining: 42.5s\n",
      "179:\tlearn: 1474.5885261\ttotal: 27.3s\tremaining: 42.3s\n",
      "180:\tlearn: 1472.6366406\ttotal: 27.4s\tremaining: 42.1s\n",
      "181:\tlearn: 1470.2578574\ttotal: 27.6s\tremaining: 42s\n",
      "182:\tlearn: 1469.5705801\ttotal: 27.7s\tremaining: 41.8s\n",
      "183:\tlearn: 1468.1095907\ttotal: 27.8s\tremaining: 41.6s\n",
      "184:\tlearn: 1467.4586684\ttotal: 28s\tremaining: 41.4s\n",
      "185:\tlearn: 1466.0834517\ttotal: 28.1s\tremaining: 41.2s\n",
      "186:\tlearn: 1464.9476787\ttotal: 28.2s\tremaining: 41s\n",
      "187:\tlearn: 1462.9723915\ttotal: 28.4s\tremaining: 40.9s\n",
      "188:\tlearn: 1460.5672591\ttotal: 28.5s\tremaining: 40.8s\n",
      "189:\tlearn: 1459.2561723\ttotal: 28.7s\tremaining: 40.6s\n",
      "190:\tlearn: 1458.1198740\ttotal: 28.8s\tremaining: 40.4s\n",
      "191:\tlearn: 1457.1382999\ttotal: 28.9s\tremaining: 40.2s\n",
      "192:\tlearn: 1456.3367271\ttotal: 29.1s\tremaining: 40.1s\n",
      "193:\tlearn: 1453.0165264\ttotal: 29.3s\tremaining: 40s\n",
      "194:\tlearn: 1451.7122990\ttotal: 29.4s\tremaining: 39.8s\n",
      "195:\tlearn: 1449.2011314\ttotal: 29.6s\tremaining: 39.7s\n",
      "196:\tlearn: 1448.0073689\ttotal: 29.7s\tremaining: 39.5s\n",
      "197:\tlearn: 1446.7079760\ttotal: 29.8s\tremaining: 39.3s\n",
      "198:\tlearn: 1444.7409305\ttotal: 30s\tremaining: 39.2s\n",
      "199:\tlearn: 1441.6527299\ttotal: 30.2s\tremaining: 39.1s\n",
      "200:\tlearn: 1440.8176479\ttotal: 30.3s\tremaining: 38.9s\n",
      "201:\tlearn: 1439.3413574\ttotal: 30.5s\tremaining: 38.7s\n",
      "202:\tlearn: 1438.1160499\ttotal: 30.6s\tremaining: 38.6s\n",
      "203:\tlearn: 1437.2913634\ttotal: 30.8s\tremaining: 38.4s\n",
      "204:\tlearn: 1435.2488764\ttotal: 30.9s\tremaining: 38.3s\n",
      "205:\tlearn: 1433.1822452\ttotal: 31.1s\tremaining: 38.2s\n",
      "206:\tlearn: 1432.2019846\ttotal: 31.2s\tremaining: 38s\n",
      "207:\tlearn: 1430.9479000\ttotal: 31.4s\tremaining: 37.9s\n",
      "208:\tlearn: 1430.2721191\ttotal: 31.5s\tremaining: 37.7s\n",
      "209:\tlearn: 1429.2999397\ttotal: 31.7s\tremaining: 37.5s\n",
      "210:\tlearn: 1426.6062416\ttotal: 31.8s\tremaining: 37.4s\n",
      "211:\tlearn: 1425.9191297\ttotal: 31.9s\tremaining: 37.2s\n",
      "212:\tlearn: 1424.3473735\ttotal: 32.1s\tremaining: 37.1s\n",
      "213:\tlearn: 1423.7946783\ttotal: 32.2s\tremaining: 36.9s\n",
      "214:\tlearn: 1422.9355598\ttotal: 32.4s\tremaining: 36.7s\n",
      "215:\tlearn: 1420.9688059\ttotal: 32.5s\tremaining: 36.6s\n",
      "216:\tlearn: 1419.4704215\ttotal: 32.7s\tremaining: 36.4s\n",
      "217:\tlearn: 1417.1687627\ttotal: 32.9s\tremaining: 36.4s\n",
      "218:\tlearn: 1415.0424216\ttotal: 33.1s\tremaining: 36.2s\n",
      "219:\tlearn: 1413.8149894\ttotal: 33.2s\tremaining: 36.1s\n",
      "220:\tlearn: 1412.4669348\ttotal: 33.3s\tremaining: 35.9s\n",
      "221:\tlearn: 1410.6551587\ttotal: 33.5s\tremaining: 35.8s\n",
      "222:\tlearn: 1409.9414340\ttotal: 33.6s\tremaining: 35.6s\n",
      "223:\tlearn: 1408.4314520\ttotal: 33.8s\tremaining: 35.4s\n",
      "224:\tlearn: 1407.5236751\ttotal: 33.9s\tremaining: 35.3s\n",
      "225:\tlearn: 1405.9957839\ttotal: 34.1s\tremaining: 35.1s\n",
      "226:\tlearn: 1404.0329527\ttotal: 34.2s\tremaining: 35s\n",
      "227:\tlearn: 1403.0156613\ttotal: 34.4s\tremaining: 34.8s\n",
      "228:\tlearn: 1401.6412382\ttotal: 34.5s\tremaining: 34.7s\n",
      "229:\tlearn: 1400.7430622\ttotal: 34.7s\tremaining: 34.5s\n",
      "230:\tlearn: 1399.5354415\ttotal: 34.8s\tremaining: 34.4s\n",
      "231:\tlearn: 1397.4549921\ttotal: 35s\tremaining: 34.2s\n",
      "232:\tlearn: 1396.4686263\ttotal: 35.1s\tremaining: 34.1s\n",
      "233:\tlearn: 1395.8010773\ttotal: 35.2s\tremaining: 33.9s\n",
      "234:\tlearn: 1393.4433896\ttotal: 35.4s\tremaining: 33.7s\n",
      "235:\tlearn: 1392.6335438\ttotal: 35.5s\tremaining: 33.6s\n",
      "236:\tlearn: 1390.8276579\ttotal: 35.7s\tremaining: 33.4s\n",
      "237:\tlearn: 1389.7530701\ttotal: 35.8s\tremaining: 33.3s\n",
      "238:\tlearn: 1388.6558615\ttotal: 36s\tremaining: 33.1s\n",
      "239:\tlearn: 1387.0153198\ttotal: 36.1s\tremaining: 32.9s\n",
      "240:\tlearn: 1385.5491012\ttotal: 36.3s\tremaining: 32.8s\n",
      "241:\tlearn: 1384.4940268\ttotal: 36.4s\tremaining: 32.7s\n",
      "242:\tlearn: 1383.5914065\ttotal: 36.6s\tremaining: 32.5s\n",
      "243:\tlearn: 1381.4486126\ttotal: 36.7s\tremaining: 32.4s\n",
      "244:\tlearn: 1379.7657002\ttotal: 36.9s\tremaining: 32.2s\n",
      "245:\tlearn: 1378.2560751\ttotal: 37s\tremaining: 32s\n",
      "246:\tlearn: 1377.1734722\ttotal: 37.2s\tremaining: 31.9s\n",
      "247:\tlearn: 1375.9743619\ttotal: 37.3s\tremaining: 31.7s\n",
      "248:\tlearn: 1374.3688212\ttotal: 37.5s\tremaining: 31.6s\n",
      "249:\tlearn: 1372.8766978\ttotal: 37.6s\tremaining: 31.5s\n",
      "250:\tlearn: 1370.7689909\ttotal: 37.8s\tremaining: 31.3s\n",
      "251:\tlearn: 1369.3666970\ttotal: 37.9s\tremaining: 31.2s\n",
      "252:\tlearn: 1367.8686109\ttotal: 38.1s\tremaining: 31s\n",
      "253:\tlearn: 1366.2954568\ttotal: 38.3s\tremaining: 30.9s\n",
      "254:\tlearn: 1364.3817235\ttotal: 38.4s\tremaining: 30.7s\n",
      "255:\tlearn: 1363.5662550\ttotal: 38.6s\tremaining: 30.6s\n",
      "256:\tlearn: 1361.0567709\ttotal: 38.8s\tremaining: 30.5s\n",
      "257:\tlearn: 1359.3275136\ttotal: 38.9s\tremaining: 30.3s\n",
      "258:\tlearn: 1358.0825808\ttotal: 39.1s\tremaining: 30.2s\n",
      "259:\tlearn: 1357.0133103\ttotal: 39.2s\tremaining: 30s\n",
      "260:\tlearn: 1355.6628186\ttotal: 39.4s\tremaining: 29.9s\n",
      "261:\tlearn: 1354.6868872\ttotal: 39.5s\tremaining: 29.7s\n",
      "262:\tlearn: 1353.0450841\ttotal: 39.7s\tremaining: 29.6s\n",
      "263:\tlearn: 1351.2510056\ttotal: 39.8s\tremaining: 29.4s\n",
      "264:\tlearn: 1349.9652591\ttotal: 40s\tremaining: 29.3s\n",
      "265:\tlearn: 1348.8759948\ttotal: 40.1s\tremaining: 29.1s\n",
      "266:\tlearn: 1348.0777807\ttotal: 40.3s\tremaining: 29s\n",
      "267:\tlearn: 1347.0018340\ttotal: 40.4s\tremaining: 28.8s\n",
      "268:\tlearn: 1346.3924007\ttotal: 40.6s\tremaining: 28.6s\n",
      "269:\tlearn: 1344.9034041\ttotal: 40.7s\tremaining: 28.5s\n",
      "270:\tlearn: 1344.1692075\ttotal: 40.9s\tremaining: 28.3s\n",
      "271:\tlearn: 1342.6967556\ttotal: 41s\tremaining: 28.2s\n",
      "272:\tlearn: 1341.2624983\ttotal: 41.2s\tremaining: 28s\n",
      "273:\tlearn: 1340.2522601\ttotal: 41.3s\tremaining: 27.9s\n",
      "274:\tlearn: 1338.8262680\ttotal: 41.5s\tremaining: 27.7s\n",
      "275:\tlearn: 1337.9575600\ttotal: 41.6s\tremaining: 27.6s\n",
      "276:\tlearn: 1337.4408431\ttotal: 41.7s\tremaining: 27.4s\n",
      "277:\tlearn: 1335.9026264\ttotal: 41.9s\tremaining: 27.3s\n",
      "278:\tlearn: 1335.0409968\ttotal: 42s\tremaining: 27.1s\n",
      "279:\tlearn: 1333.3837156\ttotal: 42.2s\tremaining: 27s\n",
      "280:\tlearn: 1333.0898402\ttotal: 42.3s\tremaining: 26.8s\n",
      "281:\tlearn: 1331.6863489\ttotal: 42.5s\tremaining: 26.7s\n",
      "282:\tlearn: 1330.1566768\ttotal: 42.6s\tremaining: 26.5s\n",
      "283:\tlearn: 1329.9741113\ttotal: 42.7s\tremaining: 26.3s\n",
      "284:\tlearn: 1329.0565737\ttotal: 42.9s\tremaining: 26.2s\n",
      "285:\tlearn: 1327.8789296\ttotal: 43s\tremaining: 26s\n",
      "286:\tlearn: 1326.2458927\ttotal: 43.2s\tremaining: 25.9s\n",
      "287:\tlearn: 1324.4486150\ttotal: 43.4s\tremaining: 25.8s\n",
      "288:\tlearn: 1323.0535470\ttotal: 43.5s\tremaining: 25.6s\n",
      "289:\tlearn: 1321.7810307\ttotal: 43.7s\tremaining: 25.5s\n",
      "290:\tlearn: 1320.5816608\ttotal: 43.9s\tremaining: 25.3s\n",
      "291:\tlearn: 1319.1740481\ttotal: 44s\tremaining: 25.2s\n",
      "292:\tlearn: 1316.8802462\ttotal: 44.2s\tremaining: 25s\n",
      "293:\tlearn: 1316.4224847\ttotal: 44.3s\tremaining: 24.9s\n",
      "294:\tlearn: 1315.1923541\ttotal: 44.5s\tremaining: 24.7s\n",
      "295:\tlearn: 1314.0979362\ttotal: 44.6s\tremaining: 24.6s\n",
      "296:\tlearn: 1312.9413249\ttotal: 44.9s\tremaining: 24.5s\n",
      "297:\tlearn: 1311.9857864\ttotal: 45s\tremaining: 24.3s\n",
      "298:\tlearn: 1311.0690234\ttotal: 45.2s\tremaining: 24.2s\n",
      "299:\tlearn: 1310.5431739\ttotal: 45.3s\tremaining: 24s\n",
      "300:\tlearn: 1308.6157839\ttotal: 45.5s\tremaining: 23.9s\n",
      "301:\tlearn: 1307.0773089\ttotal: 45.7s\tremaining: 23.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302:\tlearn: 1305.3802046\ttotal: 45.9s\tremaining: 23.6s\n",
      "303:\tlearn: 1303.6787071\ttotal: 46s\tremaining: 23.5s\n",
      "304:\tlearn: 1302.5464886\ttotal: 46.2s\tremaining: 23.3s\n",
      "305:\tlearn: 1301.1959931\ttotal: 46.4s\tremaining: 23.2s\n",
      "306:\tlearn: 1300.2909249\ttotal: 46.5s\tremaining: 23s\n",
      "307:\tlearn: 1298.8825664\ttotal: 46.7s\tremaining: 22.9s\n",
      "308:\tlearn: 1298.3879036\ttotal: 46.8s\tremaining: 22.7s\n",
      "309:\tlearn: 1296.7907247\ttotal: 47s\tremaining: 22.6s\n",
      "310:\tlearn: 1295.7532117\ttotal: 47.2s\tremaining: 22.5s\n",
      "311:\tlearn: 1294.4668019\ttotal: 47.4s\tremaining: 22.3s\n",
      "312:\tlearn: 1293.6833016\ttotal: 47.5s\tremaining: 22.2s\n",
      "313:\tlearn: 1292.9551490\ttotal: 47.7s\tremaining: 22s\n",
      "314:\tlearn: 1291.9736240\ttotal: 47.8s\tremaining: 21.9s\n",
      "315:\tlearn: 1290.5314975\ttotal: 48s\tremaining: 21.7s\n",
      "316:\tlearn: 1288.9318542\ttotal: 48.2s\tremaining: 21.6s\n",
      "317:\tlearn: 1287.6649741\ttotal: 48.4s\tremaining: 21.4s\n",
      "318:\tlearn: 1286.7306870\ttotal: 48.5s\tremaining: 21.3s\n",
      "319:\tlearn: 1285.0899838\ttotal: 48.7s\tremaining: 21.1s\n",
      "320:\tlearn: 1284.7096224\ttotal: 48.8s\tremaining: 21s\n",
      "321:\tlearn: 1283.4713908\ttotal: 49s\tremaining: 20.8s\n",
      "322:\tlearn: 1282.0537158\ttotal: 49.2s\tremaining: 20.7s\n",
      "323:\tlearn: 1281.3271303\ttotal: 49.3s\tremaining: 20.5s\n",
      "324:\tlearn: 1280.3674554\ttotal: 49.5s\tremaining: 20.4s\n",
      "325:\tlearn: 1279.7021437\ttotal: 49.6s\tremaining: 20.2s\n",
      "326:\tlearn: 1278.4939707\ttotal: 49.8s\tremaining: 20.1s\n",
      "327:\tlearn: 1277.0820706\ttotal: 49.9s\tremaining: 19.9s\n",
      "328:\tlearn: 1276.4421726\ttotal: 50.1s\tremaining: 19.8s\n",
      "329:\tlearn: 1275.5063153\ttotal: 50.2s\tremaining: 19.6s\n",
      "330:\tlearn: 1274.4697174\ttotal: 50.4s\tremaining: 19.5s\n",
      "331:\tlearn: 1273.6530270\ttotal: 50.5s\tremaining: 19.3s\n",
      "332:\tlearn: 1273.0901476\ttotal: 50.6s\tremaining: 19.2s\n",
      "333:\tlearn: 1272.2741340\ttotal: 50.8s\tremaining: 19s\n",
      "334:\tlearn: 1271.1926207\ttotal: 51s\tremaining: 18.9s\n",
      "335:\tlearn: 1270.0388078\ttotal: 51.1s\tremaining: 18.7s\n",
      "336:\tlearn: 1268.4254828\ttotal: 51.3s\tremaining: 18.6s\n",
      "337:\tlearn: 1267.0697856\ttotal: 51.5s\tremaining: 18.4s\n",
      "338:\tlearn: 1266.3680211\ttotal: 51.6s\tremaining: 18.3s\n",
      "339:\tlearn: 1265.6324824\ttotal: 51.8s\tremaining: 18.1s\n",
      "340:\tlearn: 1264.1381905\ttotal: 51.9s\tremaining: 18s\n",
      "341:\tlearn: 1262.8152037\ttotal: 52.1s\tremaining: 17.8s\n",
      "342:\tlearn: 1262.0151306\ttotal: 52.3s\tremaining: 17.7s\n",
      "343:\tlearn: 1260.6538003\ttotal: 52.4s\tremaining: 17.5s\n",
      "344:\tlearn: 1258.8185164\ttotal: 52.6s\tremaining: 17.4s\n",
      "345:\tlearn: 1258.1221479\ttotal: 52.8s\tremaining: 17.2s\n",
      "346:\tlearn: 1257.3398995\ttotal: 52.9s\tremaining: 17.1s\n",
      "347:\tlearn: 1255.5921261\ttotal: 53.1s\tremaining: 16.9s\n",
      "348:\tlearn: 1254.3905110\ttotal: 53.3s\tremaining: 16.8s\n",
      "349:\tlearn: 1253.6959219\ttotal: 53.4s\tremaining: 16.6s\n",
      "350:\tlearn: 1252.3770494\ttotal: 53.6s\tremaining: 16.5s\n",
      "351:\tlearn: 1251.8406254\ttotal: 53.7s\tremaining: 16.3s\n",
      "352:\tlearn: 1250.1616608\ttotal: 53.9s\tremaining: 16.2s\n",
      "353:\tlearn: 1248.5772548\ttotal: 54.1s\tremaining: 16s\n",
      "354:\tlearn: 1247.6868418\ttotal: 54.3s\tremaining: 15.9s\n",
      "355:\tlearn: 1246.1664182\ttotal: 54.4s\tremaining: 15.8s\n",
      "356:\tlearn: 1245.4108462\ttotal: 54.6s\tremaining: 15.6s\n",
      "357:\tlearn: 1244.5981375\ttotal: 54.7s\tremaining: 15.4s\n",
      "358:\tlearn: 1243.9256380\ttotal: 54.9s\tremaining: 15.3s\n",
      "359:\tlearn: 1243.0156627\ttotal: 55s\tremaining: 15.1s\n",
      "360:\tlearn: 1241.9765698\ttotal: 55.2s\tremaining: 15s\n",
      "361:\tlearn: 1241.6178017\ttotal: 55.3s\tremaining: 14.8s\n",
      "362:\tlearn: 1241.0532189\ttotal: 55.5s\tremaining: 14.7s\n",
      "363:\tlearn: 1240.5129534\ttotal: 55.6s\tremaining: 14.5s\n",
      "364:\tlearn: 1239.3689893\ttotal: 55.8s\tremaining: 14.4s\n",
      "365:\tlearn: 1238.7043378\ttotal: 55.9s\tremaining: 14.2s\n",
      "366:\tlearn: 1237.6997660\ttotal: 56.1s\tremaining: 14.1s\n",
      "367:\tlearn: 1236.9652848\ttotal: 56.2s\tremaining: 13.9s\n",
      "368:\tlearn: 1235.8481081\ttotal: 56.4s\tremaining: 13.8s\n",
      "369:\tlearn: 1234.5973447\ttotal: 56.6s\tremaining: 13.6s\n",
      "370:\tlearn: 1233.5345373\ttotal: 56.7s\tremaining: 13.5s\n",
      "371:\tlearn: 1232.9312067\ttotal: 56.9s\tremaining: 13.3s\n",
      "372:\tlearn: 1231.7180507\ttotal: 57s\tremaining: 13.2s\n",
      "373:\tlearn: 1230.6938401\ttotal: 57.2s\tremaining: 13s\n",
      "374:\tlearn: 1229.2961910\ttotal: 57.4s\tremaining: 12.8s\n",
      "375:\tlearn: 1228.6148243\ttotal: 57.5s\tremaining: 12.7s\n",
      "376:\tlearn: 1226.8244807\ttotal: 57.7s\tremaining: 12.6s\n",
      "377:\tlearn: 1225.5814456\ttotal: 57.9s\tremaining: 12.4s\n",
      "378:\tlearn: 1224.2173230\ttotal: 58.1s\tremaining: 12.3s\n",
      "379:\tlearn: 1223.1450907\ttotal: 58.2s\tremaining: 12.1s\n",
      "380:\tlearn: 1222.3141882\ttotal: 58.4s\tremaining: 12s\n",
      "381:\tlearn: 1221.1906104\ttotal: 58.6s\tremaining: 11.8s\n",
      "382:\tlearn: 1220.9967839\ttotal: 58.7s\tremaining: 11.6s\n",
      "383:\tlearn: 1220.1414458\ttotal: 58.8s\tremaining: 11.5s\n",
      "384:\tlearn: 1219.1292020\ttotal: 59s\tremaining: 11.3s\n",
      "385:\tlearn: 1218.3837435\ttotal: 59.2s\tremaining: 11.2s\n",
      "386:\tlearn: 1217.4455717\ttotal: 59.3s\tremaining: 11s\n",
      "387:\tlearn: 1216.0518789\ttotal: 59.5s\tremaining: 10.9s\n",
      "388:\tlearn: 1215.3550841\ttotal: 59.7s\tremaining: 10.7s\n",
      "389:\tlearn: 1214.2728067\ttotal: 59.9s\tremaining: 10.6s\n",
      "390:\tlearn: 1213.0158105\ttotal: 1m\tremaining: 10.4s\n",
      "391:\tlearn: 1212.3011810\ttotal: 1m\tremaining: 10.3s\n",
      "392:\tlearn: 1211.3054701\ttotal: 1m\tremaining: 10.1s\n",
      "393:\tlearn: 1210.6337509\ttotal: 1m\tremaining: 9.98s\n",
      "394:\tlearn: 1210.2615459\ttotal: 1m\tremaining: 9.83s\n",
      "395:\tlearn: 1209.6867628\ttotal: 1m\tremaining: 9.67s\n",
      "396:\tlearn: 1209.0114771\ttotal: 1m\tremaining: 9.52s\n",
      "397:\tlearn: 1207.7565192\ttotal: 1m 1s\tremaining: 9.37s\n",
      "398:\tlearn: 1206.7012217\ttotal: 1m 1s\tremaining: 9.21s\n",
      "399:\tlearn: 1205.2585812\ttotal: 1m 1s\tremaining: 9.06s\n",
      "400:\tlearn: 1203.7657226\ttotal: 1m 1s\tremaining: 8.92s\n",
      "401:\tlearn: 1203.1515330\ttotal: 1m 1s\tremaining: 8.77s\n",
      "402:\tlearn: 1201.7205408\ttotal: 1m 1s\tremaining: 8.61s\n",
      "403:\tlearn: 1200.3317688\ttotal: 1m 2s\tremaining: 8.46s\n",
      "404:\tlearn: 1199.7094132\ttotal: 1m 2s\tremaining: 8.31s\n",
      "405:\tlearn: 1198.9077805\ttotal: 1m 2s\tremaining: 8.16s\n",
      "406:\tlearn: 1197.9290879\ttotal: 1m 2s\tremaining: 8.01s\n",
      "407:\tlearn: 1196.6460356\ttotal: 1m 2s\tremaining: 7.85s\n",
      "408:\tlearn: 1195.9626148\ttotal: 1m 2s\tremaining: 7.7s\n",
      "409:\tlearn: 1194.6854443\ttotal: 1m 3s\tremaining: 7.55s\n",
      "410:\tlearn: 1193.5597773\ttotal: 1m 3s\tremaining: 7.4s\n",
      "411:\tlearn: 1192.4337505\ttotal: 1m 3s\tremaining: 7.24s\n",
      "412:\tlearn: 1191.0398254\ttotal: 1m 3s\tremaining: 7.09s\n",
      "413:\tlearn: 1189.8954897\ttotal: 1m 3s\tremaining: 6.94s\n",
      "414:\tlearn: 1189.1062328\ttotal: 1m 4s\tremaining: 6.79s\n",
      "415:\tlearn: 1188.5134765\ttotal: 1m 4s\tremaining: 6.63s\n",
      "416:\tlearn: 1188.0006398\ttotal: 1m 4s\tremaining: 6.48s\n",
      "417:\tlearn: 1187.4365518\ttotal: 1m 4s\tremaining: 6.32s\n",
      "418:\tlearn: 1185.5992491\ttotal: 1m 4s\tremaining: 6.17s\n",
      "419:\tlearn: 1184.9216128\ttotal: 1m 4s\tremaining: 6.01s\n",
      "420:\tlearn: 1184.4249291\ttotal: 1m 4s\tremaining: 5.86s\n",
      "421:\tlearn: 1183.8857350\ttotal: 1m 5s\tremaining: 5.7s\n",
      "422:\tlearn: 1183.7915279\ttotal: 1m 5s\tremaining: 5.54s\n",
      "423:\tlearn: 1182.7528965\ttotal: 1m 5s\tremaining: 5.39s\n",
      "424:\tlearn: 1182.1913583\ttotal: 1m 5s\tremaining: 5.23s\n",
      "425:\tlearn: 1181.4438217\ttotal: 1m 5s\tremaining: 5.08s\n",
      "426:\tlearn: 1180.3962525\ttotal: 1m 5s\tremaining: 4.93s\n",
      "427:\tlearn: 1180.2395429\ttotal: 1m 5s\tremaining: 4.77s\n",
      "428:\tlearn: 1179.4350004\ttotal: 1m 6s\tremaining: 4.62s\n",
      "429:\tlearn: 1179.0154042\ttotal: 1m 6s\tremaining: 4.46s\n",
      "430:\tlearn: 1178.5333614\ttotal: 1m 6s\tremaining: 4.31s\n",
      "431:\tlearn: 1177.6065107\ttotal: 1m 6s\tremaining: 4.16s\n",
      "432:\tlearn: 1176.6333141\ttotal: 1m 6s\tremaining: 4s\n",
      "433:\tlearn: 1175.6590854\ttotal: 1m 6s\tremaining: 3.85s\n",
      "434:\tlearn: 1174.8198443\ttotal: 1m 7s\tremaining: 3.7s\n",
      "435:\tlearn: 1173.9126722\ttotal: 1m 7s\tremaining: 3.54s\n",
      "436:\tlearn: 1173.3425180\ttotal: 1m 7s\tremaining: 3.39s\n",
      "437:\tlearn: 1172.5496692\ttotal: 1m 7s\tremaining: 3.24s\n",
      "438:\tlearn: 1171.7877161\ttotal: 1m 7s\tremaining: 3.08s\n",
      "439:\tlearn: 1171.1300550\ttotal: 1m 7s\tremaining: 2.93s\n",
      "440:\tlearn: 1170.1672631\ttotal: 1m 8s\tremaining: 2.77s\n",
      "441:\tlearn: 1169.1383426\ttotal: 1m 8s\tremaining: 2.62s\n",
      "442:\tlearn: 1168.0139896\ttotal: 1m 8s\tremaining: 2.47s\n",
      "443:\tlearn: 1167.5747570\ttotal: 1m 8s\tremaining: 2.31s\n",
      "444:\tlearn: 1166.4635500\ttotal: 1m 8s\tremaining: 2.16s\n",
      "445:\tlearn: 1165.5408714\ttotal: 1m 8s\tremaining: 2.01s\n",
      "446:\tlearn: 1164.4729747\ttotal: 1m 9s\tremaining: 1.85s\n",
      "447:\tlearn: 1163.9231263\ttotal: 1m 9s\tremaining: 1.7s\n",
      "448:\tlearn: 1163.7518928\ttotal: 1m 9s\tremaining: 1.54s\n",
      "449:\tlearn: 1162.9966681\ttotal: 1m 9s\tremaining: 1.39s\n",
      "450:\tlearn: 1162.4741074\ttotal: 1m 9s\tremaining: 1.24s\n",
      "451:\tlearn: 1160.9841031\ttotal: 1m 9s\tremaining: 1.08s\n",
      "452:\tlearn: 1160.0075584\ttotal: 1m 9s\tremaining: 927ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453:\tlearn: 1159.0736227\ttotal: 1m 10s\tremaining: 773ms\n",
      "454:\tlearn: 1157.6485770\ttotal: 1m 10s\tremaining: 618ms\n",
      "455:\tlearn: 1156.7795041\ttotal: 1m 10s\tremaining: 464ms\n",
      "456:\tlearn: 1155.7134381\ttotal: 1m 10s\tremaining: 309ms\n",
      "457:\tlearn: 1154.6775781\ttotal: 1m 10s\tremaining: 155ms\n",
      "458:\tlearn: 1154.1064340\ttotal: 1m 11s\tremaining: 0us\n",
      "0:\tlearn: 4279.7298823\ttotal: 198ms\tremaining: 1m 30s\n",
      "1:\tlearn: 3889.5196658\ttotal: 374ms\tremaining: 1m 25s\n",
      "2:\tlearn: 3571.1897302\ttotal: 550ms\tremaining: 1m 23s\n",
      "3:\tlearn: 3285.4808644\ttotal: 728ms\tremaining: 1m 22s\n",
      "4:\tlearn: 3051.5058609\ttotal: 884ms\tremaining: 1m 20s\n",
      "5:\tlearn: 2862.7609535\ttotal: 1.06s\tremaining: 1m 19s\n",
      "6:\tlearn: 2719.3283994\ttotal: 1.2s\tremaining: 1m 17s\n",
      "7:\tlearn: 2579.1852142\ttotal: 1.36s\tremaining: 1m 16s\n",
      "8:\tlearn: 2460.6492513\ttotal: 1.54s\tremaining: 1m 16s\n",
      "9:\tlearn: 2363.3438422\ttotal: 1.71s\tremaining: 1m 16s\n",
      "10:\tlearn: 2283.7664003\ttotal: 1.88s\tremaining: 1m 16s\n",
      "11:\tlearn: 2217.2705417\ttotal: 2.06s\tremaining: 1m 16s\n",
      "12:\tlearn: 2165.7867241\ttotal: 2.22s\tremaining: 1m 16s\n",
      "13:\tlearn: 2121.2231346\ttotal: 2.38s\tremaining: 1m 15s\n",
      "14:\tlearn: 2081.2322988\ttotal: 2.56s\tremaining: 1m 15s\n",
      "15:\tlearn: 2044.3861868\ttotal: 2.73s\tremaining: 1m 15s\n",
      "16:\tlearn: 2013.2636561\ttotal: 2.9s\tremaining: 1m 15s\n",
      "17:\tlearn: 1991.1417707\ttotal: 3.08s\tremaining: 1m 15s\n",
      "18:\tlearn: 1966.8912039\ttotal: 3.25s\tremaining: 1m 15s\n",
      "19:\tlearn: 1949.1322676\ttotal: 3.43s\tremaining: 1m 15s\n",
      "20:\tlearn: 1935.0789330\ttotal: 3.59s\tremaining: 1m 14s\n",
      "21:\tlearn: 1922.5970095\ttotal: 3.76s\tremaining: 1m 14s\n",
      "22:\tlearn: 1909.9979229\ttotal: 3.91s\tremaining: 1m 14s\n",
      "23:\tlearn: 1898.6024079\ttotal: 4.07s\tremaining: 1m 13s\n",
      "24:\tlearn: 1885.4590227\ttotal: 4.23s\tremaining: 1m 13s\n",
      "25:\tlearn: 1877.2088324\ttotal: 4.4s\tremaining: 1m 13s\n",
      "26:\tlearn: 1870.2157749\ttotal: 4.57s\tremaining: 1m 13s\n",
      "27:\tlearn: 1863.9890032\ttotal: 4.71s\tremaining: 1m 12s\n",
      "28:\tlearn: 1854.7782315\ttotal: 4.89s\tremaining: 1m 12s\n",
      "29:\tlearn: 1848.1489405\ttotal: 5.04s\tremaining: 1m 12s\n",
      "30:\tlearn: 1841.4489013\ttotal: 5.21s\tremaining: 1m 12s\n",
      "31:\tlearn: 1835.0249773\ttotal: 5.37s\tremaining: 1m 11s\n",
      "32:\tlearn: 1830.8903609\ttotal: 5.49s\tremaining: 1m 10s\n",
      "33:\tlearn: 1825.5305569\ttotal: 5.66s\tremaining: 1m 10s\n",
      "34:\tlearn: 1820.5815867\ttotal: 5.81s\tremaining: 1m 10s\n",
      "35:\tlearn: 1814.7635881\ttotal: 5.97s\tremaining: 1m 10s\n",
      "36:\tlearn: 1811.4448344\ttotal: 6.13s\tremaining: 1m 9s\n",
      "37:\tlearn: 1807.8557958\ttotal: 6.29s\tremaining: 1m 9s\n",
      "38:\tlearn: 1803.3642019\ttotal: 6.45s\tremaining: 1m 9s\n",
      "39:\tlearn: 1799.4409524\ttotal: 6.61s\tremaining: 1m 9s\n",
      "40:\tlearn: 1795.7685778\ttotal: 6.77s\tremaining: 1m 9s\n",
      "41:\tlearn: 1793.0045290\ttotal: 6.91s\tremaining: 1m 8s\n",
      "42:\tlearn: 1789.0840488\ttotal: 7.08s\tremaining: 1m 8s\n",
      "43:\tlearn: 1784.8987362\ttotal: 7.24s\tremaining: 1m 8s\n",
      "44:\tlearn: 1781.9608731\ttotal: 7.4s\tremaining: 1m 8s\n",
      "45:\tlearn: 1779.1558308\ttotal: 7.55s\tremaining: 1m 7s\n",
      "46:\tlearn: 1776.8550260\ttotal: 7.71s\tremaining: 1m 7s\n",
      "47:\tlearn: 1774.9399330\ttotal: 7.84s\tremaining: 1m 7s\n",
      "48:\tlearn: 1772.7393462\ttotal: 8s\tremaining: 1m 6s\n",
      "49:\tlearn: 1770.9081260\ttotal: 8.16s\tremaining: 1m 6s\n",
      "50:\tlearn: 1768.9682855\ttotal: 8.31s\tremaining: 1m 6s\n",
      "51:\tlearn: 1767.2844129\ttotal: 8.45s\tremaining: 1m 6s\n",
      "52:\tlearn: 1764.5295202\ttotal: 8.6s\tremaining: 1m 5s\n",
      "53:\tlearn: 1762.6623983\ttotal: 8.76s\tremaining: 1m 5s\n",
      "54:\tlearn: 1760.4455358\ttotal: 8.91s\tremaining: 1m 5s\n",
      "55:\tlearn: 1758.8640761\ttotal: 9.06s\tremaining: 1m 5s\n",
      "56:\tlearn: 1757.4940851\ttotal: 9.19s\tremaining: 1m 4s\n",
      "57:\tlearn: 1755.7682488\ttotal: 9.34s\tremaining: 1m 4s\n",
      "58:\tlearn: 1754.5343811\ttotal: 9.49s\tremaining: 1m 4s\n",
      "59:\tlearn: 1753.6502303\ttotal: 9.62s\tremaining: 1m 3s\n",
      "60:\tlearn: 1752.2778665\ttotal: 9.78s\tremaining: 1m 3s\n",
      "61:\tlearn: 1750.9865654\ttotal: 9.93s\tremaining: 1m 3s\n",
      "62:\tlearn: 1749.2491181\ttotal: 10.1s\tremaining: 1m 3s\n",
      "63:\tlearn: 1747.9888635\ttotal: 10.2s\tremaining: 1m 3s\n",
      "64:\tlearn: 1747.2855310\ttotal: 10.4s\tremaining: 1m 2s\n",
      "65:\tlearn: 1745.2964882\ttotal: 10.5s\tremaining: 1m 2s\n",
      "66:\tlearn: 1743.7119533\ttotal: 10.7s\tremaining: 1m 2s\n",
      "67:\tlearn: 1743.0564419\ttotal: 10.8s\tremaining: 1m 2s\n",
      "68:\tlearn: 1741.5524503\ttotal: 11s\tremaining: 1m 2s\n",
      "69:\tlearn: 1740.8468533\ttotal: 11.1s\tremaining: 1m 1s\n",
      "70:\tlearn: 1739.9244516\ttotal: 11.3s\tremaining: 1m 1s\n",
      "71:\tlearn: 1738.1653970\ttotal: 11.4s\tremaining: 1m 1s\n",
      "72:\tlearn: 1737.0309813\ttotal: 11.6s\tremaining: 1m 1s\n",
      "73:\tlearn: 1735.7198896\ttotal: 11.7s\tremaining: 1m\n",
      "74:\tlearn: 1734.3204014\ttotal: 11.9s\tremaining: 1m\n",
      "75:\tlearn: 1732.9608523\ttotal: 12s\tremaining: 1m\n",
      "76:\tlearn: 1731.3521820\ttotal: 12.2s\tremaining: 1m\n",
      "77:\tlearn: 1729.1564234\ttotal: 12.3s\tremaining: 1m\n",
      "78:\tlearn: 1728.6329544\ttotal: 12.5s\tremaining: 59.9s\n",
      "79:\tlearn: 1727.5593326\ttotal: 12.6s\tremaining: 59.7s\n",
      "80:\tlearn: 1724.6098779\ttotal: 12.8s\tremaining: 59.6s\n",
      "81:\tlearn: 1723.0424765\ttotal: 12.9s\tremaining: 59.5s\n",
      "82:\tlearn: 1722.0399386\ttotal: 13.1s\tremaining: 59.3s\n",
      "83:\tlearn: 1721.2588598\ttotal: 13.2s\tremaining: 59s\n",
      "84:\tlearn: 1720.5003938\ttotal: 13.4s\tremaining: 58.8s\n",
      "85:\tlearn: 1718.7916987\ttotal: 13.5s\tremaining: 58.6s\n",
      "86:\tlearn: 1715.8439602\ttotal: 13.7s\tremaining: 58.5s\n",
      "87:\tlearn: 1713.1081350\ttotal: 13.8s\tremaining: 58.3s\n",
      "88:\tlearn: 1712.5251449\ttotal: 13.9s\tremaining: 58s\n",
      "89:\tlearn: 1710.3301776\ttotal: 14.1s\tremaining: 57.7s\n",
      "90:\tlearn: 1706.3627695\ttotal: 14.2s\tremaining: 57.5s\n",
      "91:\tlearn: 1703.0395037\ttotal: 14.4s\tremaining: 57.4s\n",
      "92:\tlearn: 1699.7848889\ttotal: 14.5s\tremaining: 57.2s\n",
      "93:\tlearn: 1697.1890016\ttotal: 14.7s\tremaining: 57.1s\n",
      "94:\tlearn: 1693.8316149\ttotal: 14.9s\tremaining: 56.9s\n",
      "95:\tlearn: 1690.1757737\ttotal: 15s\tremaining: 56.8s\n",
      "96:\tlearn: 1685.2845021\ttotal: 15.2s\tremaining: 56.8s\n",
      "97:\tlearn: 1680.8636158\ttotal: 15.4s\tremaining: 56.9s\n",
      "98:\tlearn: 1678.3842288\ttotal: 15.7s\tremaining: 56.9s\n",
      "99:\tlearn: 1674.7468519\ttotal: 15.8s\tremaining: 56.8s\n",
      "100:\tlearn: 1670.8073173\ttotal: 16s\tremaining: 56.7s\n",
      "101:\tlearn: 1666.0263104\ttotal: 16.2s\tremaining: 56.6s\n",
      "102:\tlearn: 1662.4305269\ttotal: 16.3s\tremaining: 56.4s\n",
      "103:\tlearn: 1659.2068992\ttotal: 16.5s\tremaining: 56.2s\n",
      "104:\tlearn: 1655.6688954\ttotal: 16.6s\tremaining: 56s\n",
      "105:\tlearn: 1654.0505122\ttotal: 16.7s\tremaining: 55.7s\n",
      "106:\tlearn: 1648.8671243\ttotal: 16.9s\tremaining: 55.7s\n",
      "107:\tlearn: 1646.7043179\ttotal: 17s\tremaining: 55.3s\n",
      "108:\tlearn: 1641.6387200\ttotal: 17.2s\tremaining: 55.2s\n",
      "109:\tlearn: 1638.4847822\ttotal: 17.3s\tremaining: 54.9s\n",
      "110:\tlearn: 1634.5756712\ttotal: 17.5s\tremaining: 54.7s\n",
      "111:\tlearn: 1628.2455185\ttotal: 17.6s\tremaining: 54.6s\n",
      "112:\tlearn: 1625.6932471\ttotal: 17.8s\tremaining: 54.3s\n",
      "113:\tlearn: 1623.3291404\ttotal: 17.9s\tremaining: 54.1s\n",
      "114:\tlearn: 1620.8338664\ttotal: 18s\tremaining: 53.9s\n",
      "115:\tlearn: 1615.6104547\ttotal: 18.2s\tremaining: 53.8s\n",
      "116:\tlearn: 1614.6979169\ttotal: 18.2s\tremaining: 53.3s\n",
      "117:\tlearn: 1611.9511166\ttotal: 18.4s\tremaining: 53.1s\n",
      "118:\tlearn: 1608.6417147\ttotal: 18.5s\tremaining: 52.8s\n",
      "119:\tlearn: 1606.3441207\ttotal: 18.6s\tremaining: 52.6s\n",
      "120:\tlearn: 1604.9534804\ttotal: 18.8s\tremaining: 52.4s\n",
      "121:\tlearn: 1603.3745376\ttotal: 18.9s\tremaining: 52.2s\n",
      "122:\tlearn: 1600.7797741\ttotal: 19s\tremaining: 52s\n",
      "123:\tlearn: 1598.5691800\ttotal: 19.2s\tremaining: 51.8s\n",
      "124:\tlearn: 1595.9448478\ttotal: 19.3s\tremaining: 51.6s\n",
      "125:\tlearn: 1593.5021756\ttotal: 19.5s\tremaining: 51.4s\n",
      "126:\tlearn: 1591.9546382\ttotal: 19.6s\tremaining: 51.2s\n",
      "127:\tlearn: 1588.4367690\ttotal: 19.7s\tremaining: 51s\n",
      "128:\tlearn: 1586.5496216\ttotal: 19.9s\tremaining: 50.8s\n",
      "129:\tlearn: 1585.2983434\ttotal: 20s\tremaining: 50.6s\n",
      "130:\tlearn: 1582.3023452\ttotal: 20.1s\tremaining: 50.4s\n",
      "131:\tlearn: 1580.0539035\ttotal: 20.3s\tremaining: 50.2s\n",
      "132:\tlearn: 1575.7944348\ttotal: 20.4s\tremaining: 50.1s\n",
      "133:\tlearn: 1571.4872682\ttotal: 20.6s\tremaining: 49.9s\n",
      "134:\tlearn: 1569.6082745\ttotal: 20.7s\tremaining: 49.7s\n",
      "135:\tlearn: 1565.2930028\ttotal: 20.9s\tremaining: 49.6s\n",
      "136:\tlearn: 1564.0188186\ttotal: 21s\tremaining: 49.5s\n",
      "137:\tlearn: 1561.3801755\ttotal: 21.2s\tremaining: 49.3s\n",
      "138:\tlearn: 1559.3679994\ttotal: 21.3s\tremaining: 49.1s\n",
      "139:\tlearn: 1556.8514934\ttotal: 21.4s\tremaining: 48.9s\n",
      "140:\tlearn: 1555.0670790\ttotal: 21.6s\tremaining: 48.6s\n",
      "141:\tlearn: 1552.5526752\ttotal: 21.7s\tremaining: 48.5s\n",
      "142:\tlearn: 1551.2897273\ttotal: 21.8s\tremaining: 48.2s\n",
      "143:\tlearn: 1547.4536938\ttotal: 22s\tremaining: 48s\n",
      "144:\tlearn: 1545.2951399\ttotal: 22.1s\tremaining: 47.8s\n",
      "145:\tlearn: 1542.5326704\ttotal: 22.2s\tremaining: 47.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146:\tlearn: 1540.6020477\ttotal: 22.4s\tremaining: 47.5s\n",
      "147:\tlearn: 1539.1167045\ttotal: 22.5s\tremaining: 47.3s\n",
      "148:\tlearn: 1535.3278304\ttotal: 22.6s\tremaining: 47.1s\n",
      "149:\tlearn: 1534.2971090\ttotal: 22.7s\tremaining: 46.8s\n",
      "150:\tlearn: 1530.9226112\ttotal: 22.9s\tremaining: 46.7s\n",
      "151:\tlearn: 1527.5574950\ttotal: 23.1s\tremaining: 46.6s\n",
      "152:\tlearn: 1524.0732576\ttotal: 23.2s\tremaining: 46.5s\n",
      "153:\tlearn: 1522.3842862\ttotal: 23.4s\tremaining: 46.3s\n",
      "154:\tlearn: 1521.6115064\ttotal: 23.5s\tremaining: 46s\n",
      "155:\tlearn: 1520.0258580\ttotal: 23.6s\tremaining: 45.8s\n",
      "156:\tlearn: 1519.2366770\ttotal: 23.7s\tremaining: 45.7s\n",
      "157:\tlearn: 1516.7259767\ttotal: 23.9s\tremaining: 45.5s\n",
      "158:\tlearn: 1515.3585732\ttotal: 24s\tremaining: 45.4s\n",
      "159:\tlearn: 1513.8348989\ttotal: 24.2s\tremaining: 45.1s\n",
      "160:\tlearn: 1510.9749651\ttotal: 24.3s\tremaining: 45s\n",
      "161:\tlearn: 1509.5490282\ttotal: 24.5s\tremaining: 44.8s\n",
      "162:\tlearn: 1507.6875048\ttotal: 24.6s\tremaining: 44.7s\n",
      "163:\tlearn: 1506.1063384\ttotal: 24.7s\tremaining: 44.5s\n",
      "164:\tlearn: 1504.0215954\ttotal: 24.9s\tremaining: 44.3s\n",
      "165:\tlearn: 1500.7159727\ttotal: 25s\tremaining: 44.2s\n",
      "166:\tlearn: 1499.6514278\ttotal: 25.2s\tremaining: 44s\n",
      "167:\tlearn: 1497.0047127\ttotal: 25.3s\tremaining: 43.9s\n",
      "168:\tlearn: 1496.2894171\ttotal: 25.4s\tremaining: 43.7s\n",
      "169:\tlearn: 1494.1234048\ttotal: 25.6s\tremaining: 43.5s\n",
      "170:\tlearn: 1491.9800272\ttotal: 25.7s\tremaining: 43.4s\n",
      "171:\tlearn: 1490.3202447\ttotal: 25.9s\tremaining: 43.2s\n",
      "172:\tlearn: 1489.1572543\ttotal: 26s\tremaining: 43s\n",
      "173:\tlearn: 1487.1655896\ttotal: 26.2s\tremaining: 42.9s\n",
      "174:\tlearn: 1485.9196636\ttotal: 26.3s\tremaining: 42.7s\n",
      "175:\tlearn: 1483.4470392\ttotal: 26.5s\tremaining: 42.5s\n",
      "176:\tlearn: 1481.3787743\ttotal: 26.6s\tremaining: 42.4s\n",
      "177:\tlearn: 1478.2167275\ttotal: 26.8s\tremaining: 42.2s\n",
      "178:\tlearn: 1476.9793470\ttotal: 26.9s\tremaining: 42.1s\n",
      "179:\tlearn: 1474.1085196\ttotal: 27.1s\tremaining: 42s\n",
      "180:\tlearn: 1472.3634750\ttotal: 27.2s\tremaining: 41.8s\n",
      "181:\tlearn: 1470.4842818\ttotal: 27.4s\tremaining: 41.6s\n",
      "182:\tlearn: 1469.4255414\ttotal: 27.5s\tremaining: 41.5s\n",
      "183:\tlearn: 1467.8085489\ttotal: 27.6s\tremaining: 41.3s\n",
      "184:\tlearn: 1466.5736687\ttotal: 27.7s\tremaining: 41.1s\n",
      "185:\tlearn: 1465.1220968\ttotal: 27.9s\tremaining: 41s\n",
      "186:\tlearn: 1463.5140727\ttotal: 28.1s\tremaining: 40.8s\n",
      "187:\tlearn: 1460.5746145\ttotal: 28.2s\tremaining: 40.7s\n",
      "188:\tlearn: 1458.5720095\ttotal: 28.4s\tremaining: 40.5s\n",
      "189:\tlearn: 1456.8658338\ttotal: 28.5s\tremaining: 40.3s\n",
      "190:\tlearn: 1455.2306317\ttotal: 28.7s\tremaining: 40.2s\n",
      "191:\tlearn: 1454.7487478\ttotal: 28.8s\tremaining: 40s\n",
      "192:\tlearn: 1452.0952282\ttotal: 28.9s\tremaining: 39.9s\n",
      "193:\tlearn: 1450.1967340\ttotal: 29.1s\tremaining: 39.7s\n",
      "194:\tlearn: 1448.5414013\ttotal: 29.2s\tremaining: 39.6s\n",
      "195:\tlearn: 1445.8633865\ttotal: 29.4s\tremaining: 39.4s\n",
      "196:\tlearn: 1444.2771291\ttotal: 29.6s\tremaining: 39.3s\n",
      "197:\tlearn: 1442.0276648\ttotal: 29.7s\tremaining: 39.1s\n",
      "198:\tlearn: 1440.7428121\ttotal: 29.8s\tremaining: 39s\n",
      "199:\tlearn: 1439.3189762\ttotal: 30s\tremaining: 38.8s\n",
      "200:\tlearn: 1437.9993853\ttotal: 30.1s\tremaining: 38.6s\n",
      "201:\tlearn: 1435.7465628\ttotal: 30.2s\tremaining: 38.5s\n",
      "202:\tlearn: 1433.3664313\ttotal: 30.4s\tremaining: 38.3s\n",
      "203:\tlearn: 1431.7501593\ttotal: 30.5s\tremaining: 38.2s\n",
      "204:\tlearn: 1430.1657408\ttotal: 30.7s\tremaining: 38s\n",
      "205:\tlearn: 1429.4060539\ttotal: 30.8s\tremaining: 37.9s\n",
      "206:\tlearn: 1427.5783031\ttotal: 31s\tremaining: 37.7s\n",
      "207:\tlearn: 1425.8555765\ttotal: 31.1s\tremaining: 37.6s\n",
      "208:\tlearn: 1424.9473846\ttotal: 31.3s\tremaining: 37.4s\n",
      "209:\tlearn: 1422.9555238\ttotal: 31.4s\tremaining: 37.3s\n",
      "210:\tlearn: 1421.0091753\ttotal: 31.6s\tremaining: 37.1s\n",
      "211:\tlearn: 1419.2982313\ttotal: 31.7s\tremaining: 37s\n",
      "212:\tlearn: 1417.7030843\ttotal: 31.9s\tremaining: 36.8s\n",
      "213:\tlearn: 1416.5738118\ttotal: 32s\tremaining: 36.7s\n",
      "214:\tlearn: 1414.7043722\ttotal: 32.2s\tremaining: 36.5s\n",
      "215:\tlearn: 1413.2238559\ttotal: 32.3s\tremaining: 36.4s\n",
      "216:\tlearn: 1412.1728895\ttotal: 32.5s\tremaining: 36.2s\n",
      "217:\tlearn: 1410.9074052\ttotal: 32.6s\tremaining: 36.1s\n",
      "218:\tlearn: 1409.8937131\ttotal: 32.7s\tremaining: 35.9s\n",
      "219:\tlearn: 1409.3726646\ttotal: 32.9s\tremaining: 35.7s\n",
      "220:\tlearn: 1407.9624061\ttotal: 33s\tremaining: 35.6s\n",
      "221:\tlearn: 1406.1443476\ttotal: 33.2s\tremaining: 35.4s\n",
      "222:\tlearn: 1405.2577283\ttotal: 33.3s\tremaining: 35.3s\n",
      "223:\tlearn: 1404.4020563\ttotal: 33.5s\tremaining: 35.1s\n",
      "224:\tlearn: 1403.3802848\ttotal: 33.6s\tremaining: 35s\n",
      "225:\tlearn: 1401.9102467\ttotal: 33.8s\tremaining: 34.8s\n",
      "226:\tlearn: 1399.9750250\ttotal: 33.9s\tremaining: 34.7s\n",
      "227:\tlearn: 1398.4785221\ttotal: 34.1s\tremaining: 34.5s\n",
      "228:\tlearn: 1398.1356172\ttotal: 34.2s\tremaining: 34.4s\n",
      "229:\tlearn: 1397.3495905\ttotal: 34.4s\tremaining: 34.2s\n",
      "230:\tlearn: 1394.8813604\ttotal: 34.5s\tremaining: 34.1s\n",
      "231:\tlearn: 1392.2188718\ttotal: 34.7s\tremaining: 34s\n",
      "232:\tlearn: 1391.0722201\ttotal: 34.9s\tremaining: 33.8s\n",
      "233:\tlearn: 1389.6229951\ttotal: 35s\tremaining: 33.7s\n",
      "234:\tlearn: 1388.4984366\ttotal: 35.2s\tremaining: 33.5s\n",
      "235:\tlearn: 1386.7739574\ttotal: 35.3s\tremaining: 33.4s\n",
      "236:\tlearn: 1385.6567231\ttotal: 35.5s\tremaining: 33.2s\n",
      "237:\tlearn: 1384.4049306\ttotal: 35.6s\tremaining: 33.1s\n",
      "238:\tlearn: 1383.5132270\ttotal: 35.8s\tremaining: 32.9s\n",
      "239:\tlearn: 1381.8965244\ttotal: 35.9s\tremaining: 32.8s\n",
      "240:\tlearn: 1381.3975425\ttotal: 36s\tremaining: 32.6s\n",
      "241:\tlearn: 1380.2931776\ttotal: 36.2s\tremaining: 32.4s\n",
      "242:\tlearn: 1378.5270037\ttotal: 36.3s\tremaining: 32.3s\n",
      "243:\tlearn: 1376.9825320\ttotal: 36.5s\tremaining: 32.1s\n",
      "244:\tlearn: 1375.4799201\ttotal: 36.6s\tremaining: 32s\n",
      "245:\tlearn: 1373.6689045\ttotal: 36.8s\tremaining: 31.8s\n",
      "246:\tlearn: 1372.4603614\ttotal: 36.9s\tremaining: 31.7s\n",
      "247:\tlearn: 1371.1932096\ttotal: 37.1s\tremaining: 31.6s\n",
      "248:\tlearn: 1369.3414019\ttotal: 37.3s\tremaining: 31.4s\n",
      "249:\tlearn: 1367.4084500\ttotal: 37.4s\tremaining: 31.3s\n",
      "250:\tlearn: 1367.1100274\ttotal: 37.5s\tremaining: 31.1s\n",
      "251:\tlearn: 1366.2143368\ttotal: 37.7s\tremaining: 30.9s\n",
      "252:\tlearn: 1364.2038685\ttotal: 37.8s\tremaining: 30.8s\n",
      "253:\tlearn: 1363.0710734\ttotal: 38s\tremaining: 30.7s\n",
      "254:\tlearn: 1361.8578415\ttotal: 38.1s\tremaining: 30.5s\n",
      "255:\tlearn: 1360.8096486\ttotal: 38.3s\tremaining: 30.3s\n",
      "256:\tlearn: 1358.7402906\ttotal: 38.5s\tremaining: 30.2s\n",
      "257:\tlearn: 1357.0036505\ttotal: 38.6s\tremaining: 30.1s\n",
      "258:\tlearn: 1355.2626453\ttotal: 38.8s\tremaining: 29.9s\n",
      "259:\tlearn: 1353.9369456\ttotal: 38.9s\tremaining: 29.8s\n",
      "260:\tlearn: 1352.3847404\ttotal: 39.1s\tremaining: 29.7s\n",
      "261:\tlearn: 1351.8667739\ttotal: 39.2s\tremaining: 29.5s\n",
      "262:\tlearn: 1349.9454626\ttotal: 39.4s\tremaining: 29.3s\n",
      "263:\tlearn: 1347.3069770\ttotal: 39.5s\tremaining: 29.2s\n",
      "264:\tlearn: 1345.6719142\ttotal: 39.7s\tremaining: 29.1s\n",
      "265:\tlearn: 1344.2717184\ttotal: 39.8s\tremaining: 28.9s\n",
      "266:\tlearn: 1343.3222515\ttotal: 40s\tremaining: 28.8s\n",
      "267:\tlearn: 1342.5335134\ttotal: 40.1s\tremaining: 28.6s\n",
      "268:\tlearn: 1341.8581592\ttotal: 40.3s\tremaining: 28.4s\n",
      "269:\tlearn: 1340.9420342\ttotal: 40.4s\tremaining: 28.3s\n",
      "270:\tlearn: 1339.7304430\ttotal: 40.5s\tremaining: 28.1s\n",
      "271:\tlearn: 1338.5702232\ttotal: 40.7s\tremaining: 28s\n",
      "272:\tlearn: 1337.4414432\ttotal: 40.9s\tremaining: 27.8s\n",
      "273:\tlearn: 1336.4744418\ttotal: 41s\tremaining: 27.7s\n",
      "274:\tlearn: 1334.8655172\ttotal: 41.2s\tremaining: 27.5s\n",
      "275:\tlearn: 1332.6391324\ttotal: 41.3s\tremaining: 27.4s\n",
      "276:\tlearn: 1331.6770894\ttotal: 41.5s\tremaining: 27.3s\n",
      "277:\tlearn: 1330.2077853\ttotal: 41.6s\tremaining: 27.1s\n",
      "278:\tlearn: 1329.4576522\ttotal: 41.8s\tremaining: 26.9s\n",
      "279:\tlearn: 1327.8141482\ttotal: 41.9s\tremaining: 26.8s\n",
      "280:\tlearn: 1326.6020607\ttotal: 42.1s\tremaining: 26.7s\n",
      "281:\tlearn: 1325.0010085\ttotal: 42.3s\tremaining: 26.5s\n",
      "282:\tlearn: 1323.4995340\ttotal: 42.4s\tremaining: 26.4s\n",
      "283:\tlearn: 1322.5297383\ttotal: 42.6s\tremaining: 26.2s\n",
      "284:\tlearn: 1321.5072488\ttotal: 42.7s\tremaining: 26.1s\n",
      "285:\tlearn: 1320.0966126\ttotal: 42.9s\tremaining: 25.9s\n",
      "286:\tlearn: 1319.0397631\ttotal: 43.1s\tremaining: 25.8s\n",
      "287:\tlearn: 1317.9278239\ttotal: 43.2s\tremaining: 25.7s\n",
      "288:\tlearn: 1316.9711219\ttotal: 43.3s\tremaining: 25.5s\n",
      "289:\tlearn: 1315.4982892\ttotal: 43.5s\tremaining: 25.4s\n",
      "290:\tlearn: 1313.9995716\ttotal: 43.7s\tremaining: 25.2s\n",
      "291:\tlearn: 1311.9110036\ttotal: 43.9s\tremaining: 25.1s\n",
      "292:\tlearn: 1311.0676528\ttotal: 44s\tremaining: 24.9s\n",
      "293:\tlearn: 1309.3996369\ttotal: 44.2s\tremaining: 24.8s\n",
      "294:\tlearn: 1307.9751334\ttotal: 44.3s\tremaining: 24.6s\n",
      "295:\tlearn: 1307.1207109\ttotal: 44.5s\tremaining: 24.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296:\tlearn: 1306.0398772\ttotal: 44.6s\tremaining: 24.3s\n",
      "297:\tlearn: 1304.9851818\ttotal: 44.8s\tremaining: 24.2s\n",
      "298:\tlearn: 1304.2974563\ttotal: 44.9s\tremaining: 24s\n",
      "299:\tlearn: 1302.8930576\ttotal: 45s\tremaining: 23.9s\n",
      "300:\tlearn: 1302.0807600\ttotal: 45.2s\tremaining: 23.7s\n",
      "301:\tlearn: 1301.1756110\ttotal: 45.3s\tremaining: 23.6s\n",
      "302:\tlearn: 1300.0020819\ttotal: 45.5s\tremaining: 23.4s\n",
      "303:\tlearn: 1298.6418784\ttotal: 45.6s\tremaining: 23.3s\n",
      "304:\tlearn: 1297.6412692\ttotal: 45.8s\tremaining: 23.1s\n",
      "305:\tlearn: 1296.8751284\ttotal: 45.9s\tremaining: 23s\n",
      "306:\tlearn: 1296.0030977\ttotal: 46.1s\tremaining: 22.8s\n",
      "307:\tlearn: 1294.6523277\ttotal: 46.2s\tremaining: 22.7s\n",
      "308:\tlearn: 1293.1597035\ttotal: 46.4s\tremaining: 22.5s\n",
      "309:\tlearn: 1291.6331775\ttotal: 46.5s\tremaining: 22.4s\n",
      "310:\tlearn: 1290.4432830\ttotal: 46.7s\tremaining: 22.2s\n",
      "311:\tlearn: 1289.9603465\ttotal: 46.8s\tremaining: 22.1s\n",
      "312:\tlearn: 1288.5225335\ttotal: 47s\tremaining: 21.9s\n",
      "313:\tlearn: 1287.8067615\ttotal: 47.1s\tremaining: 21.8s\n",
      "314:\tlearn: 1287.0292203\ttotal: 47.3s\tremaining: 21.6s\n",
      "315:\tlearn: 1285.5314540\ttotal: 47.5s\tremaining: 21.5s\n",
      "316:\tlearn: 1284.1617098\ttotal: 47.6s\tremaining: 21.3s\n",
      "317:\tlearn: 1282.9085392\ttotal: 47.8s\tremaining: 21.2s\n",
      "318:\tlearn: 1281.5469692\ttotal: 48s\tremaining: 21.1s\n",
      "319:\tlearn: 1280.1283143\ttotal: 48.1s\tremaining: 20.9s\n",
      "320:\tlearn: 1278.7671935\ttotal: 48.3s\tremaining: 20.8s\n",
      "321:\tlearn: 1278.1173031\ttotal: 48.4s\tremaining: 20.6s\n",
      "322:\tlearn: 1276.2098512\ttotal: 48.6s\tremaining: 20.5s\n",
      "323:\tlearn: 1275.1372391\ttotal: 48.8s\tremaining: 20.3s\n",
      "324:\tlearn: 1274.1063971\ttotal: 48.9s\tremaining: 20.2s\n",
      "325:\tlearn: 1273.2001805\ttotal: 49.1s\tremaining: 20s\n",
      "326:\tlearn: 1271.8412323\ttotal: 49.3s\tremaining: 19.9s\n",
      "327:\tlearn: 1271.1859952\ttotal: 49.4s\tremaining: 19.7s\n",
      "328:\tlearn: 1270.5020791\ttotal: 49.5s\tremaining: 19.6s\n",
      "329:\tlearn: 1268.5339465\ttotal: 49.7s\tremaining: 19.4s\n",
      "330:\tlearn: 1267.1365920\ttotal: 49.8s\tremaining: 19.3s\n",
      "331:\tlearn: 1266.6027048\ttotal: 50s\tremaining: 19.1s\n",
      "332:\tlearn: 1266.0380643\ttotal: 50.1s\tremaining: 19s\n",
      "333:\tlearn: 1265.2768295\ttotal: 50.2s\tremaining: 18.8s\n",
      "334:\tlearn: 1264.2826255\ttotal: 50.4s\tremaining: 18.6s\n",
      "335:\tlearn: 1263.4964408\ttotal: 50.5s\tremaining: 18.5s\n",
      "336:\tlearn: 1262.5701600\ttotal: 50.7s\tremaining: 18.3s\n",
      "337:\tlearn: 1261.6434434\ttotal: 50.8s\tremaining: 18.2s\n",
      "338:\tlearn: 1260.7986929\ttotal: 51s\tremaining: 18s\n",
      "339:\tlearn: 1260.5634534\ttotal: 51.1s\tremaining: 17.9s\n",
      "340:\tlearn: 1260.0215065\ttotal: 51.2s\tremaining: 17.7s\n",
      "341:\tlearn: 1259.2462667\ttotal: 51.4s\tremaining: 17.6s\n",
      "342:\tlearn: 1258.2670094\ttotal: 51.6s\tremaining: 17.4s\n",
      "343:\tlearn: 1256.6553638\ttotal: 51.7s\tremaining: 17.3s\n",
      "344:\tlearn: 1255.6188825\ttotal: 51.9s\tremaining: 17.2s\n",
      "345:\tlearn: 1254.9705231\ttotal: 52s\tremaining: 17s\n",
      "346:\tlearn: 1254.0923040\ttotal: 52.2s\tremaining: 16.8s\n",
      "347:\tlearn: 1252.8393544\ttotal: 52.3s\tremaining: 16.7s\n",
      "348:\tlearn: 1251.7366832\ttotal: 52.5s\tremaining: 16.6s\n",
      "349:\tlearn: 1250.6207166\ttotal: 52.7s\tremaining: 16.4s\n",
      "350:\tlearn: 1249.7330782\ttotal: 52.8s\tremaining: 16.3s\n",
      "351:\tlearn: 1248.5446100\ttotal: 53s\tremaining: 16.1s\n",
      "352:\tlearn: 1247.7873439\ttotal: 53.2s\tremaining: 16s\n",
      "353:\tlearn: 1246.9557625\ttotal: 53.3s\tremaining: 15.8s\n",
      "354:\tlearn: 1246.0363047\ttotal: 53.5s\tremaining: 15.7s\n",
      "355:\tlearn: 1245.2155439\ttotal: 53.6s\tremaining: 15.5s\n",
      "356:\tlearn: 1243.5531145\ttotal: 53.8s\tremaining: 15.4s\n",
      "357:\tlearn: 1242.8744451\ttotal: 53.9s\tremaining: 15.2s\n",
      "358:\tlearn: 1241.3808969\ttotal: 54.1s\tremaining: 15.1s\n",
      "359:\tlearn: 1240.4974337\ttotal: 54.2s\tremaining: 14.9s\n",
      "360:\tlearn: 1239.5142162\ttotal: 54.4s\tremaining: 14.8s\n",
      "361:\tlearn: 1238.2366052\ttotal: 54.6s\tremaining: 14.6s\n",
      "362:\tlearn: 1237.4614819\ttotal: 54.7s\tremaining: 14.5s\n",
      "363:\tlearn: 1236.7302653\ttotal: 54.9s\tremaining: 14.3s\n",
      "364:\tlearn: 1235.8663901\ttotal: 55.1s\tremaining: 14.2s\n",
      "365:\tlearn: 1235.5535791\ttotal: 55.2s\tremaining: 14s\n",
      "366:\tlearn: 1234.3596139\ttotal: 55.3s\tremaining: 13.9s\n",
      "367:\tlearn: 1233.6652860\ttotal: 55.5s\tremaining: 13.7s\n",
      "368:\tlearn: 1232.8166785\ttotal: 55.7s\tremaining: 13.6s\n",
      "369:\tlearn: 1231.5971905\ttotal: 55.9s\tremaining: 13.4s\n",
      "370:\tlearn: 1230.3852818\ttotal: 56s\tremaining: 13.3s\n",
      "371:\tlearn: 1229.6000147\ttotal: 56.2s\tremaining: 13.1s\n",
      "372:\tlearn: 1229.3253045\ttotal: 56.3s\tremaining: 13s\n",
      "373:\tlearn: 1228.3180051\ttotal: 56.4s\tremaining: 12.8s\n",
      "374:\tlearn: 1227.4240362\ttotal: 56.6s\tremaining: 12.7s\n",
      "375:\tlearn: 1226.6665677\ttotal: 56.8s\tremaining: 12.5s\n",
      "376:\tlearn: 1225.2280605\ttotal: 56.9s\tremaining: 12.4s\n",
      "377:\tlearn: 1224.0367592\ttotal: 57.1s\tremaining: 12.2s\n",
      "378:\tlearn: 1222.9262318\ttotal: 57.3s\tremaining: 12.1s\n",
      "379:\tlearn: 1222.3428733\ttotal: 57.4s\tremaining: 11.9s\n",
      "380:\tlearn: 1221.7630444\ttotal: 57.6s\tremaining: 11.8s\n",
      "381:\tlearn: 1221.0724011\ttotal: 57.7s\tremaining: 11.6s\n",
      "382:\tlearn: 1220.5877565\ttotal: 57.8s\tremaining: 11.5s\n",
      "383:\tlearn: 1219.8947919\ttotal: 58s\tremaining: 11.3s\n",
      "384:\tlearn: 1218.7715195\ttotal: 58.2s\tremaining: 11.2s\n",
      "385:\tlearn: 1218.3240190\ttotal: 58.3s\tremaining: 11s\n",
      "386:\tlearn: 1217.4912082\ttotal: 58.4s\tremaining: 10.9s\n",
      "387:\tlearn: 1217.0649772\ttotal: 58.6s\tremaining: 10.7s\n",
      "388:\tlearn: 1216.2647271\ttotal: 58.7s\tremaining: 10.6s\n",
      "389:\tlearn: 1215.1814537\ttotal: 58.9s\tremaining: 10.4s\n",
      "390:\tlearn: 1214.5399522\ttotal: 59s\tremaining: 10.3s\n",
      "391:\tlearn: 1213.9844719\ttotal: 59.1s\tremaining: 10.1s\n",
      "392:\tlearn: 1213.5947539\ttotal: 59.3s\tremaining: 9.96s\n",
      "393:\tlearn: 1212.7469705\ttotal: 59.4s\tremaining: 9.81s\n",
      "394:\tlearn: 1211.6548676\ttotal: 59.6s\tremaining: 9.66s\n",
      "395:\tlearn: 1210.2436503\ttotal: 59.8s\tremaining: 9.52s\n",
      "396:\tlearn: 1209.7201683\ttotal: 60s\tremaining: 9.36s\n",
      "397:\tlearn: 1208.8928075\ttotal: 1m\tremaining: 9.21s\n",
      "398:\tlearn: 1208.1571840\ttotal: 1m\tremaining: 9.06s\n",
      "399:\tlearn: 1207.1817334\ttotal: 1m\tremaining: 8.91s\n",
      "400:\tlearn: 1206.2487836\ttotal: 1m\tremaining: 8.76s\n",
      "401:\tlearn: 1205.3673635\ttotal: 1m\tremaining: 8.62s\n",
      "402:\tlearn: 1203.9896726\ttotal: 1m\tremaining: 8.47s\n",
      "403:\tlearn: 1203.2293163\ttotal: 1m 1s\tremaining: 8.32s\n",
      "404:\tlearn: 1202.5841042\ttotal: 1m 1s\tremaining: 8.17s\n",
      "405:\tlearn: 1202.2862913\ttotal: 1m 1s\tremaining: 8.01s\n",
      "406:\tlearn: 1201.2628990\ttotal: 1m 1s\tremaining: 7.86s\n",
      "407:\tlearn: 1200.1546477\ttotal: 1m 1s\tremaining: 7.71s\n",
      "408:\tlearn: 1199.2053604\ttotal: 1m 1s\tremaining: 7.57s\n",
      "409:\tlearn: 1198.2934800\ttotal: 1m 2s\tremaining: 7.42s\n",
      "410:\tlearn: 1197.4975641\ttotal: 1m 2s\tremaining: 7.26s\n",
      "411:\tlearn: 1196.7230667\ttotal: 1m 2s\tremaining: 7.12s\n",
      "412:\tlearn: 1195.3052281\ttotal: 1m 2s\tremaining: 6.97s\n",
      "413:\tlearn: 1194.1157682\ttotal: 1m 2s\tremaining: 6.82s\n",
      "414:\tlearn: 1193.0631920\ttotal: 1m 2s\tremaining: 6.67s\n",
      "415:\tlearn: 1192.1402801\ttotal: 1m 3s\tremaining: 6.52s\n",
      "416:\tlearn: 1191.3657696\ttotal: 1m 3s\tremaining: 6.37s\n",
      "417:\tlearn: 1190.8387305\ttotal: 1m 3s\tremaining: 6.22s\n",
      "418:\tlearn: 1189.9251836\ttotal: 1m 3s\tremaining: 6.07s\n",
      "419:\tlearn: 1188.9413836\ttotal: 1m 3s\tremaining: 5.92s\n",
      "420:\tlearn: 1188.5736648\ttotal: 1m 3s\tremaining: 5.76s\n",
      "421:\tlearn: 1187.2814087\ttotal: 1m 4s\tremaining: 5.62s\n",
      "422:\tlearn: 1186.3794779\ttotal: 1m 4s\tremaining: 5.46s\n",
      "423:\tlearn: 1185.5202910\ttotal: 1m 4s\tremaining: 5.31s\n",
      "424:\tlearn: 1184.8364529\ttotal: 1m 4s\tremaining: 5.16s\n",
      "425:\tlearn: 1184.5756477\ttotal: 1m 4s\tremaining: 5.01s\n",
      "426:\tlearn: 1183.3970071\ttotal: 1m 4s\tremaining: 4.86s\n",
      "427:\tlearn: 1182.4425821\ttotal: 1m 5s\tremaining: 4.71s\n",
      "428:\tlearn: 1181.7663978\ttotal: 1m 5s\tremaining: 4.56s\n",
      "429:\tlearn: 1180.4312320\ttotal: 1m 5s\tremaining: 4.41s\n",
      "430:\tlearn: 1179.5160780\ttotal: 1m 5s\tremaining: 4.26s\n",
      "431:\tlearn: 1178.7898616\ttotal: 1m 5s\tremaining: 4.1s\n",
      "432:\tlearn: 1178.1919051\ttotal: 1m 5s\tremaining: 3.95s\n",
      "433:\tlearn: 1177.4203732\ttotal: 1m 5s\tremaining: 3.8s\n",
      "434:\tlearn: 1176.0111408\ttotal: 1m 6s\tremaining: 3.65s\n",
      "435:\tlearn: 1175.6705354\ttotal: 1m 6s\tremaining: 3.5s\n",
      "436:\tlearn: 1174.5042584\ttotal: 1m 6s\tremaining: 3.35s\n",
      "437:\tlearn: 1173.5050005\ttotal: 1m 6s\tremaining: 3.19s\n",
      "438:\tlearn: 1172.7289791\ttotal: 1m 6s\tremaining: 3.04s\n",
      "439:\tlearn: 1171.6691443\ttotal: 1m 6s\tremaining: 2.89s\n",
      "440:\tlearn: 1171.2376460\ttotal: 1m 7s\tremaining: 2.74s\n",
      "441:\tlearn: 1170.8511252\ttotal: 1m 7s\tremaining: 2.59s\n",
      "442:\tlearn: 1170.0170010\ttotal: 1m 7s\tremaining: 2.44s\n",
      "443:\tlearn: 1168.6019091\ttotal: 1m 7s\tremaining: 2.29s\n",
      "444:\tlearn: 1167.8774193\ttotal: 1m 7s\tremaining: 2.13s\n",
      "445:\tlearn: 1166.9938844\ttotal: 1m 7s\tremaining: 1.98s\n",
      "446:\tlearn: 1166.0445264\ttotal: 1m 8s\tremaining: 1.83s\n",
      "447:\tlearn: 1165.4583073\ttotal: 1m 8s\tremaining: 1.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448:\tlearn: 1164.7762140\ttotal: 1m 8s\tremaining: 1.52s\n",
      "449:\tlearn: 1163.8493556\ttotal: 1m 8s\tremaining: 1.37s\n",
      "450:\tlearn: 1162.7073743\ttotal: 1m 8s\tremaining: 1.22s\n",
      "451:\tlearn: 1161.3686055\ttotal: 1m 8s\tremaining: 1.07s\n",
      "452:\tlearn: 1160.3031116\ttotal: 1m 9s\tremaining: 915ms\n",
      "453:\tlearn: 1159.3623437\ttotal: 1m 9s\tremaining: 763ms\n",
      "454:\tlearn: 1158.6436340\ttotal: 1m 9s\tremaining: 611ms\n",
      "455:\tlearn: 1157.5858498\ttotal: 1m 9s\tremaining: 458ms\n",
      "456:\tlearn: 1157.0486050\ttotal: 1m 9s\tremaining: 305ms\n",
      "457:\tlearn: 1156.4576398\ttotal: 1m 9s\tremaining: 153ms\n",
      "458:\tlearn: 1155.5303998\ttotal: 1m 10s\tremaining: 0us\n",
      "0:\tlearn: 4265.7383907\ttotal: 188ms\tremaining: 1m 26s\n",
      "1:\tlearn: 3902.3754782\ttotal: 362ms\tremaining: 1m 22s\n",
      "2:\tlearn: 3590.1081262\ttotal: 526ms\tremaining: 1m 19s\n",
      "3:\tlearn: 3319.2088082\ttotal: 700ms\tremaining: 1m 19s\n",
      "4:\tlearn: 3078.5608503\ttotal: 870ms\tremaining: 1m 18s\n",
      "5:\tlearn: 2900.2681012\ttotal: 1.02s\tremaining: 1m 17s\n",
      "6:\tlearn: 2746.4103873\ttotal: 1.2s\tremaining: 1m 17s\n",
      "7:\tlearn: 2603.9868864\ttotal: 1.36s\tremaining: 1m 16s\n",
      "8:\tlearn: 2482.5834299\ttotal: 1.54s\tremaining: 1m 17s\n",
      "9:\tlearn: 2377.5226439\ttotal: 1.72s\tremaining: 1m 17s\n",
      "10:\tlearn: 2293.1755366\ttotal: 1.89s\tremaining: 1m 16s\n",
      "11:\tlearn: 2225.5012481\ttotal: 2.05s\tremaining: 1m 16s\n",
      "12:\tlearn: 2176.3887218\ttotal: 2.23s\tremaining: 1m 16s\n",
      "13:\tlearn: 2119.5074488\ttotal: 2.41s\tremaining: 1m 16s\n",
      "14:\tlearn: 2077.4461576\ttotal: 2.58s\tremaining: 1m 16s\n",
      "15:\tlearn: 2042.2426206\ttotal: 2.75s\tremaining: 1m 16s\n",
      "16:\tlearn: 2016.2744448\ttotal: 2.92s\tremaining: 1m 16s\n",
      "17:\tlearn: 1990.0577719\ttotal: 3.09s\tremaining: 1m 15s\n",
      "18:\tlearn: 1967.0740633\ttotal: 3.27s\tremaining: 1m 15s\n",
      "19:\tlearn: 1950.6540053\ttotal: 3.4s\tremaining: 1m 14s\n",
      "20:\tlearn: 1933.0505334\ttotal: 3.55s\tremaining: 1m 14s\n",
      "21:\tlearn: 1916.4204434\ttotal: 3.71s\tremaining: 1m 13s\n",
      "22:\tlearn: 1902.0031955\ttotal: 3.88s\tremaining: 1m 13s\n",
      "23:\tlearn: 1890.1030886\ttotal: 4.04s\tremaining: 1m 13s\n",
      "24:\tlearn: 1881.7794185\ttotal: 4.21s\tremaining: 1m 13s\n",
      "25:\tlearn: 1873.7452023\ttotal: 4.38s\tremaining: 1m 13s\n",
      "26:\tlearn: 1864.6255185\ttotal: 4.56s\tremaining: 1m 12s\n",
      "27:\tlearn: 1856.5274923\ttotal: 4.71s\tremaining: 1m 12s\n",
      "28:\tlearn: 1851.0724751\ttotal: 4.86s\tremaining: 1m 12s\n",
      "29:\tlearn: 1844.1879923\ttotal: 5.03s\tremaining: 1m 11s\n",
      "30:\tlearn: 1839.0527600\ttotal: 5.19s\tremaining: 1m 11s\n",
      "31:\tlearn: 1834.7451622\ttotal: 5.33s\tremaining: 1m 11s\n",
      "32:\tlearn: 1828.7326656\ttotal: 5.5s\tremaining: 1m 10s\n",
      "33:\tlearn: 1824.3017889\ttotal: 5.66s\tremaining: 1m 10s\n",
      "34:\tlearn: 1821.2575188\ttotal: 5.81s\tremaining: 1m 10s\n",
      "35:\tlearn: 1817.3129614\ttotal: 5.96s\tremaining: 1m 10s\n",
      "36:\tlearn: 1813.7491616\ttotal: 6.12s\tremaining: 1m 9s\n",
      "37:\tlearn: 1811.1058237\ttotal: 6.28s\tremaining: 1m 9s\n",
      "38:\tlearn: 1807.9225804\ttotal: 6.43s\tremaining: 1m 9s\n",
      "39:\tlearn: 1806.1851681\ttotal: 6.58s\tremaining: 1m 8s\n",
      "40:\tlearn: 1802.5764326\ttotal: 6.73s\tremaining: 1m 8s\n",
      "41:\tlearn: 1799.4066279\ttotal: 6.89s\tremaining: 1m 8s\n",
      "42:\tlearn: 1797.1005464\ttotal: 7.02s\tremaining: 1m 7s\n",
      "43:\tlearn: 1794.3090846\ttotal: 7.18s\tremaining: 1m 7s\n",
      "44:\tlearn: 1790.1060752\ttotal: 7.34s\tremaining: 1m 7s\n",
      "45:\tlearn: 1788.4541153\ttotal: 7.49s\tremaining: 1m 7s\n",
      "46:\tlearn: 1787.3927292\ttotal: 7.64s\tremaining: 1m 6s\n",
      "47:\tlearn: 1786.6965816\ttotal: 7.78s\tremaining: 1m 6s\n",
      "48:\tlearn: 1784.3457134\ttotal: 7.93s\tremaining: 1m 6s\n",
      "49:\tlearn: 1782.1913077\ttotal: 8.1s\tremaining: 1m 6s\n",
      "50:\tlearn: 1778.3093043\ttotal: 8.26s\tremaining: 1m 6s\n",
      "51:\tlearn: 1774.7958015\ttotal: 8.42s\tremaining: 1m 5s\n",
      "52:\tlearn: 1773.1421349\ttotal: 8.57s\tremaining: 1m 5s\n",
      "53:\tlearn: 1771.6700340\ttotal: 8.7s\tremaining: 1m 5s\n",
      "54:\tlearn: 1769.4289118\ttotal: 8.86s\tremaining: 1m 5s\n",
      "55:\tlearn: 1768.0343368\ttotal: 9.01s\tremaining: 1m 4s\n",
      "56:\tlearn: 1766.0177579\ttotal: 9.16s\tremaining: 1m 4s\n",
      "57:\tlearn: 1763.3024198\ttotal: 9.3s\tremaining: 1m 4s\n",
      "58:\tlearn: 1762.7881829\ttotal: 9.42s\tremaining: 1m 3s\n",
      "59:\tlearn: 1760.6057286\ttotal: 9.55s\tremaining: 1m 3s\n",
      "60:\tlearn: 1758.7510716\ttotal: 9.71s\tremaining: 1m 3s\n",
      "61:\tlearn: 1757.3017771\ttotal: 9.87s\tremaining: 1m 3s\n",
      "62:\tlearn: 1755.3285579\ttotal: 10s\tremaining: 1m 3s\n",
      "63:\tlearn: 1754.0081376\ttotal: 10.2s\tremaining: 1m 2s\n",
      "64:\tlearn: 1752.5741067\ttotal: 10.3s\tremaining: 1m 2s\n",
      "65:\tlearn: 1751.1973519\ttotal: 10.5s\tremaining: 1m 2s\n",
      "66:\tlearn: 1749.6602375\ttotal: 10.6s\tremaining: 1m 2s\n",
      "67:\tlearn: 1747.9174789\ttotal: 10.8s\tremaining: 1m 2s\n",
      "68:\tlearn: 1746.2785372\ttotal: 11s\tremaining: 1m 1s\n",
      "69:\tlearn: 1745.0738316\ttotal: 11.1s\tremaining: 1m 1s\n",
      "70:\tlearn: 1743.8393537\ttotal: 11.3s\tremaining: 1m 1s\n",
      "71:\tlearn: 1743.3039455\ttotal: 11.4s\tremaining: 1m 1s\n",
      "72:\tlearn: 1741.4391559\ttotal: 11.6s\tremaining: 1m 1s\n",
      "73:\tlearn: 1739.8370940\ttotal: 11.7s\tremaining: 1m\n",
      "74:\tlearn: 1737.5759084\ttotal: 11.9s\tremaining: 1m\n",
      "75:\tlearn: 1735.2246606\ttotal: 12s\tremaining: 1m\n",
      "76:\tlearn: 1733.3427221\ttotal: 12.2s\tremaining: 1m\n",
      "77:\tlearn: 1731.8009227\ttotal: 12.3s\tremaining: 1m\n",
      "78:\tlearn: 1729.2140377\ttotal: 12.5s\tremaining: 1m\n",
      "79:\tlearn: 1727.4917983\ttotal: 12.7s\tremaining: 60s\n",
      "80:\tlearn: 1726.5304928\ttotal: 12.8s\tremaining: 59.7s\n",
      "81:\tlearn: 1725.6283612\ttotal: 12.9s\tremaining: 59.5s\n",
      "82:\tlearn: 1724.5377314\ttotal: 13.1s\tremaining: 59.3s\n",
      "83:\tlearn: 1723.4861189\ttotal: 13.2s\tremaining: 59.1s\n",
      "84:\tlearn: 1721.5848377\ttotal: 13.4s\tremaining: 58.8s\n",
      "85:\tlearn: 1720.2683328\ttotal: 13.5s\tremaining: 58.5s\n",
      "86:\tlearn: 1719.6346001\ttotal: 13.6s\tremaining: 58.3s\n",
      "87:\tlearn: 1718.8441550\ttotal: 13.8s\tremaining: 58s\n",
      "88:\tlearn: 1717.0172381\ttotal: 13.9s\tremaining: 57.9s\n",
      "89:\tlearn: 1715.8117428\ttotal: 14s\tremaining: 57.6s\n",
      "90:\tlearn: 1714.3050788\ttotal: 14.2s\tremaining: 57.4s\n",
      "91:\tlearn: 1711.6374805\ttotal: 14.3s\tremaining: 57.2s\n",
      "92:\tlearn: 1708.4807211\ttotal: 14.5s\tremaining: 57s\n",
      "93:\tlearn: 1705.5941786\ttotal: 14.6s\tremaining: 56.8s\n",
      "94:\tlearn: 1701.7861552\ttotal: 14.8s\tremaining: 56.8s\n",
      "95:\tlearn: 1697.2204845\ttotal: 15s\tremaining: 56.6s\n",
      "96:\tlearn: 1692.8215094\ttotal: 15.1s\tremaining: 56.4s\n",
      "97:\tlearn: 1689.2358734\ttotal: 15.3s\tremaining: 56.3s\n",
      "98:\tlearn: 1684.9871047\ttotal: 15.5s\tremaining: 56.2s\n",
      "99:\tlearn: 1680.2497090\ttotal: 15.6s\tremaining: 56.1s\n",
      "100:\tlearn: 1675.8891836\ttotal: 15.8s\tremaining: 56s\n",
      "101:\tlearn: 1672.3818686\ttotal: 15.9s\tremaining: 55.7s\n",
      "102:\tlearn: 1670.5783592\ttotal: 16.1s\tremaining: 55.6s\n",
      "103:\tlearn: 1666.5853704\ttotal: 16.2s\tremaining: 55.4s\n",
      "104:\tlearn: 1664.8626111\ttotal: 16.4s\tremaining: 55.1s\n",
      "105:\tlearn: 1662.2415181\ttotal: 16.5s\tremaining: 54.9s\n",
      "106:\tlearn: 1659.5665497\ttotal: 16.6s\tremaining: 54.6s\n",
      "107:\tlearn: 1652.9867002\ttotal: 16.8s\tremaining: 54.4s\n",
      "108:\tlearn: 1650.3206289\ttotal: 16.9s\tremaining: 54.2s\n",
      "109:\tlearn: 1647.5515613\ttotal: 17s\tremaining: 54s\n",
      "110:\tlearn: 1644.6993120\ttotal: 17.2s\tremaining: 53.8s\n",
      "111:\tlearn: 1640.6191037\ttotal: 17.3s\tremaining: 53.6s\n",
      "112:\tlearn: 1637.7695218\ttotal: 17.4s\tremaining: 53.4s\n",
      "113:\tlearn: 1630.7092591\ttotal: 17.6s\tremaining: 53.3s\n",
      "114:\tlearn: 1629.2275701\ttotal: 17.7s\tremaining: 53.1s\n",
      "115:\tlearn: 1626.4571807\ttotal: 17.9s\tremaining: 52.8s\n",
      "116:\tlearn: 1623.9708286\ttotal: 18s\tremaining: 52.6s\n",
      "117:\tlearn: 1621.1773039\ttotal: 18.2s\tremaining: 52.5s\n",
      "118:\tlearn: 1617.0014952\ttotal: 18.3s\tremaining: 52.3s\n",
      "119:\tlearn: 1615.7139140\ttotal: 18.4s\tremaining: 52.1s\n",
      "120:\tlearn: 1613.8819398\ttotal: 18.5s\tremaining: 51.8s\n",
      "121:\tlearn: 1610.1342553\ttotal: 18.7s\tremaining: 51.6s\n",
      "122:\tlearn: 1608.2140429\ttotal: 18.8s\tremaining: 51.4s\n",
      "123:\tlearn: 1603.1115957\ttotal: 19s\tremaining: 51.3s\n",
      "124:\tlearn: 1600.4676182\ttotal: 19.1s\tremaining: 51.1s\n",
      "125:\tlearn: 1596.0784027\ttotal: 19.3s\tremaining: 50.9s\n",
      "126:\tlearn: 1593.9513277\ttotal: 19.4s\tremaining: 50.7s\n",
      "127:\tlearn: 1589.1241970\ttotal: 19.6s\tremaining: 50.6s\n",
      "128:\tlearn: 1587.7460181\ttotal: 19.7s\tremaining: 50.3s\n",
      "129:\tlearn: 1584.2435945\ttotal: 19.8s\tremaining: 50.1s\n",
      "130:\tlearn: 1581.7220946\ttotal: 19.9s\tremaining: 49.9s\n",
      "131:\tlearn: 1579.5423339\ttotal: 20.1s\tremaining: 49.7s\n",
      "132:\tlearn: 1577.6452167\ttotal: 20.2s\tremaining: 49.5s\n",
      "133:\tlearn: 1575.0687619\ttotal: 20.3s\tremaining: 49.3s\n",
      "134:\tlearn: 1574.0630952\ttotal: 20.5s\tremaining: 49.1s\n",
      "135:\tlearn: 1572.9867740\ttotal: 20.6s\tremaining: 49s\n",
      "136:\tlearn: 1570.4809091\ttotal: 20.8s\tremaining: 48.8s\n",
      "137:\tlearn: 1565.7637136\ttotal: 20.9s\tremaining: 48.6s\n",
      "138:\tlearn: 1564.8349985\ttotal: 21s\tremaining: 48.4s\n",
      "139:\tlearn: 1561.4027840\ttotal: 21.2s\tremaining: 48.3s\n",
      "140:\tlearn: 1558.2107740\ttotal: 21.3s\tremaining: 48.1s\n",
      "141:\tlearn: 1556.1171441\ttotal: 21.5s\tremaining: 47.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142:\tlearn: 1552.3538736\ttotal: 21.6s\tremaining: 47.8s\n",
      "143:\tlearn: 1549.8433960\ttotal: 21.8s\tremaining: 47.6s\n",
      "144:\tlearn: 1546.9782682\ttotal: 21.9s\tremaining: 47.5s\n",
      "145:\tlearn: 1545.7265538\ttotal: 22.1s\tremaining: 47.3s\n",
      "146:\tlearn: 1543.6555147\ttotal: 22.2s\tremaining: 47.2s\n",
      "147:\tlearn: 1541.5608116\ttotal: 22.4s\tremaining: 47s\n",
      "148:\tlearn: 1539.9281826\ttotal: 22.5s\tremaining: 46.8s\n",
      "149:\tlearn: 1536.6299188\ttotal: 22.7s\tremaining: 46.7s\n",
      "150:\tlearn: 1533.2880810\ttotal: 22.8s\tremaining: 46.6s\n",
      "151:\tlearn: 1531.8839046\ttotal: 23s\tremaining: 46.4s\n",
      "152:\tlearn: 1530.0083893\ttotal: 23.1s\tremaining: 46.2s\n",
      "153:\tlearn: 1526.7716505\ttotal: 23.3s\tremaining: 46.1s\n",
      "154:\tlearn: 1524.1686563\ttotal: 23.4s\tremaining: 45.9s\n",
      "155:\tlearn: 1523.4568676\ttotal: 23.5s\tremaining: 45.7s\n",
      "156:\tlearn: 1521.4755964\ttotal: 23.7s\tremaining: 45.6s\n",
      "157:\tlearn: 1520.3530781\ttotal: 23.8s\tremaining: 45.4s\n",
      "158:\tlearn: 1519.4182640\ttotal: 23.9s\tremaining: 45.2s\n",
      "159:\tlearn: 1516.6894044\ttotal: 24.1s\tremaining: 45s\n",
      "160:\tlearn: 1515.1842106\ttotal: 24.2s\tremaining: 44.8s\n",
      "161:\tlearn: 1514.0476370\ttotal: 24.4s\tremaining: 44.7s\n",
      "162:\tlearn: 1511.8725527\ttotal: 24.5s\tremaining: 44.6s\n",
      "163:\tlearn: 1509.3168449\ttotal: 24.7s\tremaining: 44.4s\n",
      "164:\tlearn: 1508.7448932\ttotal: 24.8s\tremaining: 44.2s\n",
      "165:\tlearn: 1507.0577021\ttotal: 24.9s\tremaining: 44s\n",
      "166:\tlearn: 1504.7339324\ttotal: 25.1s\tremaining: 43.9s\n",
      "167:\tlearn: 1503.6388674\ttotal: 25.2s\tremaining: 43.7s\n",
      "168:\tlearn: 1501.4851915\ttotal: 25.4s\tremaining: 43.6s\n",
      "169:\tlearn: 1498.5933925\ttotal: 25.6s\tremaining: 43.5s\n",
      "170:\tlearn: 1495.9634645\ttotal: 25.7s\tremaining: 43.3s\n",
      "171:\tlearn: 1494.6092823\ttotal: 25.9s\tremaining: 43.1s\n",
      "172:\tlearn: 1491.9470770\ttotal: 26s\tremaining: 43s\n",
      "173:\tlearn: 1488.9296418\ttotal: 26.2s\tremaining: 42.9s\n",
      "174:\tlearn: 1485.6658079\ttotal: 26.3s\tremaining: 42.8s\n",
      "175:\tlearn: 1483.4871836\ttotal: 26.5s\tremaining: 42.6s\n",
      "176:\tlearn: 1482.2217247\ttotal: 26.7s\tremaining: 42.5s\n",
      "177:\tlearn: 1480.6399850\ttotal: 26.8s\tremaining: 42.3s\n",
      "178:\tlearn: 1479.5050188\ttotal: 26.9s\tremaining: 42.1s\n",
      "179:\tlearn: 1477.1422343\ttotal: 27.1s\tremaining: 41.9s\n",
      "180:\tlearn: 1475.1323059\ttotal: 27.2s\tremaining: 41.8s\n",
      "181:\tlearn: 1473.3256911\ttotal: 27.3s\tremaining: 41.6s\n",
      "182:\tlearn: 1471.2532657\ttotal: 27.5s\tremaining: 41.5s\n",
      "183:\tlearn: 1469.5915626\ttotal: 27.6s\tremaining: 41.3s\n",
      "184:\tlearn: 1467.4401005\ttotal: 27.8s\tremaining: 41.1s\n",
      "185:\tlearn: 1465.4574653\ttotal: 27.9s\tremaining: 41s\n",
      "186:\tlearn: 1463.3635152\ttotal: 28.1s\tremaining: 40.9s\n",
      "187:\tlearn: 1462.0876338\ttotal: 28.2s\tremaining: 40.6s\n",
      "188:\tlearn: 1459.4379471\ttotal: 28.3s\tremaining: 40.5s\n",
      "189:\tlearn: 1458.0633346\ttotal: 28.5s\tremaining: 40.3s\n",
      "190:\tlearn: 1455.7410747\ttotal: 28.6s\tremaining: 40.2s\n",
      "191:\tlearn: 1453.6166692\ttotal: 28.8s\tremaining: 40s\n",
      "192:\tlearn: 1451.5402330\ttotal: 28.9s\tremaining: 39.9s\n",
      "193:\tlearn: 1449.4780452\ttotal: 29.1s\tremaining: 39.7s\n",
      "194:\tlearn: 1447.5774064\ttotal: 29.2s\tremaining: 39.6s\n",
      "195:\tlearn: 1445.4245460\ttotal: 29.4s\tremaining: 39.4s\n",
      "196:\tlearn: 1444.1385487\ttotal: 29.5s\tremaining: 39.3s\n",
      "197:\tlearn: 1443.4564878\ttotal: 29.7s\tremaining: 39.1s\n",
      "198:\tlearn: 1442.2380994\ttotal: 29.8s\tremaining: 38.9s\n",
      "199:\tlearn: 1439.7033075\ttotal: 30s\tremaining: 38.8s\n",
      "200:\tlearn: 1438.7886490\ttotal: 30.1s\tremaining: 38.6s\n",
      "201:\tlearn: 1438.0911572\ttotal: 30.2s\tremaining: 38.4s\n",
      "202:\tlearn: 1436.2356590\ttotal: 30.4s\tremaining: 38.3s\n",
      "203:\tlearn: 1434.6753201\ttotal: 30.5s\tremaining: 38.1s\n",
      "204:\tlearn: 1433.1242429\ttotal: 30.7s\tremaining: 38s\n",
      "205:\tlearn: 1432.3022471\ttotal: 30.8s\tremaining: 37.8s\n",
      "206:\tlearn: 1431.2820299\ttotal: 30.9s\tremaining: 37.7s\n",
      "207:\tlearn: 1429.1324328\ttotal: 31.1s\tremaining: 37.5s\n",
      "208:\tlearn: 1427.5289839\ttotal: 31.2s\tremaining: 37.4s\n",
      "209:\tlearn: 1425.9788188\ttotal: 31.4s\tremaining: 37.2s\n",
      "210:\tlearn: 1424.4359841\ttotal: 31.5s\tremaining: 37.1s\n",
      "211:\tlearn: 1422.7339339\ttotal: 31.7s\tremaining: 36.9s\n",
      "212:\tlearn: 1420.4638211\ttotal: 31.9s\tremaining: 36.8s\n",
      "213:\tlearn: 1419.0398566\ttotal: 32s\tremaining: 36.6s\n",
      "214:\tlearn: 1418.0011809\ttotal: 32.2s\tremaining: 36.5s\n",
      "215:\tlearn: 1416.7277341\ttotal: 32.3s\tremaining: 36.3s\n",
      "216:\tlearn: 1414.1656507\ttotal: 32.5s\tremaining: 36.2s\n",
      "217:\tlearn: 1413.0000341\ttotal: 32.6s\tremaining: 36s\n",
      "218:\tlearn: 1412.1688043\ttotal: 32.7s\tremaining: 35.9s\n",
      "219:\tlearn: 1410.7140889\ttotal: 32.9s\tremaining: 35.7s\n",
      "220:\tlearn: 1408.5200649\ttotal: 33.1s\tremaining: 35.6s\n",
      "221:\tlearn: 1407.5320947\ttotal: 33.2s\tremaining: 35.5s\n",
      "222:\tlearn: 1406.7619998\ttotal: 33.3s\tremaining: 35.3s\n",
      "223:\tlearn: 1404.7960903\ttotal: 33.5s\tremaining: 35.1s\n",
      "224:\tlearn: 1402.9703722\ttotal: 33.7s\tremaining: 35s\n",
      "225:\tlearn: 1401.9098828\ttotal: 33.8s\tremaining: 34.8s\n",
      "226:\tlearn: 1400.7433008\ttotal: 33.9s\tremaining: 34.7s\n",
      "227:\tlearn: 1399.7528297\ttotal: 34.1s\tremaining: 34.5s\n",
      "228:\tlearn: 1399.0166127\ttotal: 34.2s\tremaining: 34.3s\n",
      "229:\tlearn: 1397.5228294\ttotal: 34.4s\tremaining: 34.2s\n",
      "230:\tlearn: 1396.6492532\ttotal: 34.5s\tremaining: 34s\n",
      "231:\tlearn: 1395.6436027\ttotal: 34.6s\tremaining: 33.9s\n",
      "232:\tlearn: 1393.7819001\ttotal: 34.8s\tremaining: 33.7s\n",
      "233:\tlearn: 1392.6226185\ttotal: 34.9s\tremaining: 33.6s\n",
      "234:\tlearn: 1391.5006679\ttotal: 35.1s\tremaining: 33.4s\n",
      "235:\tlearn: 1390.2444302\ttotal: 35.2s\tremaining: 33.3s\n",
      "236:\tlearn: 1388.6553685\ttotal: 35.4s\tremaining: 33.1s\n",
      "237:\tlearn: 1386.6877488\ttotal: 35.5s\tremaining: 33s\n",
      "238:\tlearn: 1385.3910930\ttotal: 35.7s\tremaining: 32.9s\n",
      "239:\tlearn: 1384.4511644\ttotal: 35.9s\tremaining: 32.7s\n",
      "240:\tlearn: 1383.2866746\ttotal: 36s\tremaining: 32.6s\n",
      "241:\tlearn: 1381.7095304\ttotal: 36.2s\tremaining: 32.4s\n",
      "242:\tlearn: 1379.9725902\ttotal: 36.4s\tremaining: 32.3s\n",
      "243:\tlearn: 1378.7384732\ttotal: 36.5s\tremaining: 32.2s\n",
      "244:\tlearn: 1376.9537137\ttotal: 36.7s\tremaining: 32s\n",
      "245:\tlearn: 1375.6465273\ttotal: 36.8s\tremaining: 31.9s\n",
      "246:\tlearn: 1373.9650611\ttotal: 37s\tremaining: 31.8s\n",
      "247:\tlearn: 1372.9277890\ttotal: 37.2s\tremaining: 31.6s\n",
      "248:\tlearn: 1372.2148520\ttotal: 37.3s\tremaining: 31.5s\n",
      "249:\tlearn: 1370.9711693\ttotal: 37.5s\tremaining: 31.3s\n",
      "250:\tlearn: 1369.3161710\ttotal: 37.6s\tremaining: 31.2s\n",
      "251:\tlearn: 1366.5338314\ttotal: 37.8s\tremaining: 31.1s\n",
      "252:\tlearn: 1365.8315738\ttotal: 38s\tremaining: 30.9s\n",
      "253:\tlearn: 1364.0997739\ttotal: 38.1s\tremaining: 30.8s\n",
      "254:\tlearn: 1363.7417234\ttotal: 38.3s\tremaining: 30.6s\n",
      "255:\tlearn: 1362.3890529\ttotal: 38.4s\tremaining: 30.5s\n",
      "256:\tlearn: 1361.8488346\ttotal: 38.5s\tremaining: 30.3s\n",
      "257:\tlearn: 1359.8804025\ttotal: 38.7s\tremaining: 30.2s\n",
      "258:\tlearn: 1357.5281642\ttotal: 38.9s\tremaining: 30.1s\n",
      "259:\tlearn: 1355.9775618\ttotal: 39.1s\tremaining: 29.9s\n",
      "260:\tlearn: 1354.5279323\ttotal: 39.2s\tremaining: 29.8s\n",
      "261:\tlearn: 1352.9640816\ttotal: 39.4s\tremaining: 29.6s\n",
      "262:\tlearn: 1351.5033247\ttotal: 39.6s\tremaining: 29.5s\n",
      "263:\tlearn: 1350.3260555\ttotal: 39.7s\tremaining: 29.4s\n",
      "264:\tlearn: 1349.2830388\ttotal: 39.9s\tremaining: 29.2s\n",
      "265:\tlearn: 1347.9570679\ttotal: 40.1s\tremaining: 29.1s\n",
      "266:\tlearn: 1346.0848229\ttotal: 40.3s\tremaining: 29s\n",
      "267:\tlearn: 1345.2234715\ttotal: 40.4s\tremaining: 28.8s\n",
      "268:\tlearn: 1344.2632245\ttotal: 40.6s\tremaining: 28.7s\n",
      "269:\tlearn: 1343.2255558\ttotal: 40.7s\tremaining: 28.5s\n",
      "270:\tlearn: 1341.9156205\ttotal: 40.9s\tremaining: 28.4s\n",
      "271:\tlearn: 1339.9902702\ttotal: 41.1s\tremaining: 28.2s\n",
      "272:\tlearn: 1338.7128617\ttotal: 41.2s\tremaining: 28.1s\n",
      "273:\tlearn: 1337.8587257\ttotal: 41.4s\tremaining: 27.9s\n",
      "274:\tlearn: 1336.3062148\ttotal: 41.5s\tremaining: 27.8s\n",
      "275:\tlearn: 1335.3929583\ttotal: 41.7s\tremaining: 27.7s\n",
      "276:\tlearn: 1334.0205664\ttotal: 41.9s\tremaining: 27.5s\n",
      "277:\tlearn: 1332.7235007\ttotal: 42s\tremaining: 27.4s\n",
      "278:\tlearn: 1331.3826930\ttotal: 42.3s\tremaining: 27.3s\n",
      "279:\tlearn: 1330.0767077\ttotal: 42.4s\tremaining: 27.1s\n",
      "280:\tlearn: 1328.6080987\ttotal: 42.6s\tremaining: 27s\n",
      "281:\tlearn: 1326.9041680\ttotal: 42.8s\tremaining: 26.9s\n",
      "282:\tlearn: 1325.6709969\ttotal: 43s\tremaining: 26.7s\n",
      "283:\tlearn: 1325.3368905\ttotal: 43.1s\tremaining: 26.6s\n",
      "284:\tlearn: 1323.2739952\ttotal: 43.3s\tremaining: 26.5s\n",
      "285:\tlearn: 1322.0939524\ttotal: 43.5s\tremaining: 26.3s\n",
      "286:\tlearn: 1321.0035757\ttotal: 43.7s\tremaining: 26.2s\n",
      "287:\tlearn: 1320.1090855\ttotal: 43.8s\tremaining: 26s\n",
      "288:\tlearn: 1318.8635873\ttotal: 44s\tremaining: 25.9s\n",
      "289:\tlearn: 1318.1524893\ttotal: 44.1s\tremaining: 25.7s\n",
      "290:\tlearn: 1316.3077749\ttotal: 44.3s\tremaining: 25.6s\n",
      "291:\tlearn: 1315.2652845\ttotal: 44.5s\tremaining: 25.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292:\tlearn: 1314.2500346\ttotal: 44.7s\tremaining: 25.3s\n",
      "293:\tlearn: 1313.2970920\ttotal: 44.8s\tremaining: 25.2s\n",
      "294:\tlearn: 1311.8583334\ttotal: 45s\tremaining: 25s\n",
      "295:\tlearn: 1309.6905900\ttotal: 45.2s\tremaining: 24.9s\n",
      "296:\tlearn: 1308.3274212\ttotal: 45.4s\tremaining: 24.8s\n",
      "297:\tlearn: 1307.6688481\ttotal: 45.5s\tremaining: 24.6s\n",
      "298:\tlearn: 1306.2174543\ttotal: 45.7s\tremaining: 24.5s\n",
      "299:\tlearn: 1305.0115821\ttotal: 45.9s\tremaining: 24.3s\n",
      "300:\tlearn: 1304.3135315\ttotal: 46.1s\tremaining: 24.2s\n",
      "301:\tlearn: 1302.0141099\ttotal: 46.3s\tremaining: 24.1s\n",
      "302:\tlearn: 1301.0636759\ttotal: 46.4s\tremaining: 23.9s\n",
      "303:\tlearn: 1299.3230440\ttotal: 46.6s\tremaining: 23.8s\n",
      "304:\tlearn: 1298.1116982\ttotal: 46.8s\tremaining: 23.6s\n",
      "305:\tlearn: 1296.9002461\ttotal: 47s\tremaining: 23.5s\n",
      "306:\tlearn: 1295.4881015\ttotal: 47.1s\tremaining: 23.3s\n",
      "307:\tlearn: 1295.1383964\ttotal: 47.3s\tremaining: 23.2s\n",
      "308:\tlearn: 1294.4162916\ttotal: 47.4s\tremaining: 23s\n",
      "309:\tlearn: 1293.2551301\ttotal: 47.6s\tremaining: 22.9s\n",
      "310:\tlearn: 1291.8342482\ttotal: 47.8s\tremaining: 22.7s\n",
      "311:\tlearn: 1290.5209892\ttotal: 47.9s\tremaining: 22.6s\n",
      "312:\tlearn: 1289.6712627\ttotal: 48.1s\tremaining: 22.4s\n",
      "313:\tlearn: 1288.6736744\ttotal: 48.3s\tremaining: 22.3s\n",
      "314:\tlearn: 1288.2355849\ttotal: 48.4s\tremaining: 22.1s\n",
      "315:\tlearn: 1287.6929953\ttotal: 48.5s\tremaining: 22s\n",
      "316:\tlearn: 1286.8306432\ttotal: 48.7s\tremaining: 21.8s\n",
      "317:\tlearn: 1286.1284258\ttotal: 48.8s\tremaining: 21.6s\n",
      "318:\tlearn: 1284.9124471\ttotal: 49s\tremaining: 21.5s\n",
      "319:\tlearn: 1283.5061014\ttotal: 49.2s\tremaining: 21.4s\n",
      "320:\tlearn: 1282.5394585\ttotal: 49.3s\tremaining: 21.2s\n",
      "321:\tlearn: 1281.2762816\ttotal: 49.5s\tremaining: 21.1s\n",
      "322:\tlearn: 1280.6014300\ttotal: 49.7s\tremaining: 20.9s\n",
      "323:\tlearn: 1279.9213442\ttotal: 49.8s\tremaining: 20.8s\n",
      "324:\tlearn: 1279.1533836\ttotal: 49.9s\tremaining: 20.6s\n",
      "325:\tlearn: 1278.0169307\ttotal: 50.1s\tremaining: 20.4s\n",
      "326:\tlearn: 1277.1602445\ttotal: 50.3s\tremaining: 20.3s\n",
      "327:\tlearn: 1275.3250044\ttotal: 50.5s\tremaining: 20.2s\n",
      "328:\tlearn: 1273.8180871\ttotal: 50.7s\tremaining: 20s\n",
      "329:\tlearn: 1272.5815132\ttotal: 50.8s\tremaining: 19.9s\n",
      "330:\tlearn: 1271.7377135\ttotal: 51s\tremaining: 19.7s\n",
      "331:\tlearn: 1270.2045019\ttotal: 51.2s\tremaining: 19.6s\n",
      "332:\tlearn: 1268.9317612\ttotal: 51.3s\tremaining: 19.4s\n",
      "333:\tlearn: 1267.7049590\ttotal: 51.5s\tremaining: 19.3s\n",
      "334:\tlearn: 1266.4634555\ttotal: 51.7s\tremaining: 19.1s\n",
      "335:\tlearn: 1265.0487961\ttotal: 51.9s\tremaining: 19s\n",
      "336:\tlearn: 1264.1837263\ttotal: 52.1s\tremaining: 18.8s\n",
      "337:\tlearn: 1263.5920166\ttotal: 52.2s\tremaining: 18.7s\n",
      "338:\tlearn: 1262.6026962\ttotal: 52.4s\tremaining: 18.5s\n",
      "339:\tlearn: 1261.4627770\ttotal: 52.6s\tremaining: 18.4s\n",
      "340:\tlearn: 1260.2075129\ttotal: 52.7s\tremaining: 18.2s\n",
      "341:\tlearn: 1258.8798124\ttotal: 52.9s\tremaining: 18.1s\n",
      "342:\tlearn: 1257.4749591\ttotal: 53.1s\tremaining: 18s\n",
      "343:\tlearn: 1256.3561825\ttotal: 53.3s\tremaining: 17.8s\n",
      "344:\tlearn: 1255.4047182\ttotal: 53.4s\tremaining: 17.7s\n",
      "345:\tlearn: 1254.5286808\ttotal: 53.6s\tremaining: 17.5s\n",
      "346:\tlearn: 1253.6589508\ttotal: 53.7s\tremaining: 17.3s\n",
      "347:\tlearn: 1252.1993621\ttotal: 53.9s\tremaining: 17.2s\n",
      "348:\tlearn: 1251.4416258\ttotal: 54.1s\tremaining: 17.1s\n",
      "349:\tlearn: 1251.0232372\ttotal: 54.3s\tremaining: 16.9s\n",
      "350:\tlearn: 1249.6465852\ttotal: 54.5s\tremaining: 16.8s\n",
      "351:\tlearn: 1248.5789414\ttotal: 54.7s\tremaining: 16.6s\n",
      "352:\tlearn: 1247.6886641\ttotal: 54.9s\tremaining: 16.5s\n",
      "353:\tlearn: 1246.6632010\ttotal: 55.1s\tremaining: 16.3s\n",
      "354:\tlearn: 1245.7092616\ttotal: 55.3s\tremaining: 16.2s\n",
      "355:\tlearn: 1244.9935600\ttotal: 55.4s\tremaining: 16s\n",
      "356:\tlearn: 1243.6691960\ttotal: 55.6s\tremaining: 15.9s\n",
      "357:\tlearn: 1242.9485461\ttotal: 55.8s\tremaining: 15.7s\n",
      "358:\tlearn: 1241.9001640\ttotal: 56s\tremaining: 15.6s\n",
      "359:\tlearn: 1240.9748158\ttotal: 56.1s\tremaining: 15.4s\n",
      "360:\tlearn: 1240.6406283\ttotal: 56.3s\tremaining: 15.3s\n",
      "361:\tlearn: 1239.3028921\ttotal: 56.5s\tremaining: 15.1s\n",
      "362:\tlearn: 1237.9169384\ttotal: 56.6s\tremaining: 15s\n",
      "363:\tlearn: 1237.0964640\ttotal: 56.8s\tremaining: 14.8s\n",
      "364:\tlearn: 1236.0334151\ttotal: 57s\tremaining: 14.7s\n",
      "365:\tlearn: 1234.7205390\ttotal: 57.2s\tremaining: 14.5s\n",
      "366:\tlearn: 1233.8157412\ttotal: 57.3s\tremaining: 14.4s\n",
      "367:\tlearn: 1232.5167092\ttotal: 57.5s\tremaining: 14.2s\n",
      "368:\tlearn: 1230.8062728\ttotal: 57.7s\tremaining: 14.1s\n",
      "369:\tlearn: 1230.0098028\ttotal: 57.9s\tremaining: 13.9s\n",
      "370:\tlearn: 1229.1758937\ttotal: 58s\tremaining: 13.8s\n",
      "371:\tlearn: 1228.8531933\ttotal: 58.1s\tremaining: 13.6s\n",
      "372:\tlearn: 1227.8305879\ttotal: 58.3s\tremaining: 13.4s\n",
      "373:\tlearn: 1226.5089488\ttotal: 58.5s\tremaining: 13.3s\n",
      "374:\tlearn: 1225.9514416\ttotal: 58.6s\tremaining: 13.1s\n",
      "375:\tlearn: 1224.9596924\ttotal: 58.8s\tremaining: 13s\n",
      "376:\tlearn: 1223.8171313\ttotal: 59s\tremaining: 12.8s\n",
      "377:\tlearn: 1222.5638846\ttotal: 59.2s\tremaining: 12.7s\n",
      "378:\tlearn: 1221.4956959\ttotal: 59.3s\tremaining: 12.5s\n",
      "379:\tlearn: 1220.3389782\ttotal: 59.5s\tremaining: 12.4s\n",
      "380:\tlearn: 1219.6105537\ttotal: 59.7s\tremaining: 12.2s\n",
      "381:\tlearn: 1218.6753633\ttotal: 59.9s\tremaining: 12.1s\n",
      "382:\tlearn: 1218.0188795\ttotal: 1m\tremaining: 11.9s\n",
      "383:\tlearn: 1216.9463921\ttotal: 1m\tremaining: 11.8s\n",
      "384:\tlearn: 1216.0522858\ttotal: 1m\tremaining: 11.6s\n",
      "385:\tlearn: 1215.7033568\ttotal: 1m\tremaining: 11.4s\n",
      "386:\tlearn: 1215.0916566\ttotal: 1m\tremaining: 11.3s\n",
      "387:\tlearn: 1213.9687568\ttotal: 1m\tremaining: 11.1s\n",
      "388:\tlearn: 1212.9059799\ttotal: 1m 1s\tremaining: 11s\n",
      "389:\tlearn: 1211.6031944\ttotal: 1m 1s\tremaining: 10.8s\n",
      "390:\tlearn: 1210.2463832\ttotal: 1m 1s\tremaining: 10.7s\n",
      "391:\tlearn: 1209.5944207\ttotal: 1m 1s\tremaining: 10.5s\n",
      "392:\tlearn: 1208.3383490\ttotal: 1m 1s\tremaining: 10.4s\n",
      "393:\tlearn: 1207.6703976\ttotal: 1m 1s\tremaining: 10.2s\n",
      "394:\tlearn: 1206.9869610\ttotal: 1m 2s\tremaining: 10.1s\n",
      "395:\tlearn: 1205.9951376\ttotal: 1m 2s\tremaining: 9.9s\n",
      "396:\tlearn: 1204.9984718\ttotal: 1m 2s\tremaining: 9.74s\n",
      "397:\tlearn: 1204.1405015\ttotal: 1m 2s\tremaining: 9.59s\n",
      "398:\tlearn: 1203.1720709\ttotal: 1m 2s\tremaining: 9.43s\n",
      "399:\tlearn: 1202.1383881\ttotal: 1m 2s\tremaining: 9.28s\n",
      "400:\tlearn: 1201.9388720\ttotal: 1m 3s\tremaining: 9.12s\n",
      "401:\tlearn: 1201.1742673\ttotal: 1m 3s\tremaining: 8.96s\n",
      "402:\tlearn: 1200.0952457\ttotal: 1m 3s\tremaining: 8.81s\n",
      "403:\tlearn: 1199.0728214\ttotal: 1m 3s\tremaining: 8.66s\n",
      "404:\tlearn: 1198.5051998\ttotal: 1m 3s\tremaining: 8.5s\n",
      "405:\tlearn: 1197.9009252\ttotal: 1m 3s\tremaining: 8.35s\n",
      "406:\tlearn: 1197.6497452\ttotal: 1m 4s\tremaining: 8.2s\n",
      "407:\tlearn: 1196.4782414\ttotal: 1m 4s\tremaining: 8.06s\n",
      "408:\tlearn: 1195.1839800\ttotal: 1m 4s\tremaining: 7.91s\n",
      "409:\tlearn: 1193.7428788\ttotal: 1m 4s\tremaining: 7.75s\n",
      "410:\tlearn: 1192.1915237\ttotal: 1m 5s\tremaining: 7.6s\n",
      "411:\tlearn: 1191.0580326\ttotal: 1m 5s\tremaining: 7.44s\n",
      "412:\tlearn: 1190.2456716\ttotal: 1m 5s\tremaining: 7.28s\n",
      "413:\tlearn: 1189.3904988\ttotal: 1m 5s\tremaining: 7.13s\n",
      "414:\tlearn: 1188.7632799\ttotal: 1m 5s\tremaining: 6.97s\n",
      "415:\tlearn: 1187.8687683\ttotal: 1m 5s\tremaining: 6.81s\n",
      "416:\tlearn: 1187.0294900\ttotal: 1m 6s\tremaining: 6.66s\n",
      "417:\tlearn: 1186.5662353\ttotal: 1m 6s\tremaining: 6.5s\n",
      "418:\tlearn: 1185.9622295\ttotal: 1m 6s\tremaining: 6.34s\n",
      "419:\tlearn: 1185.1267442\ttotal: 1m 6s\tremaining: 6.18s\n",
      "420:\tlearn: 1184.1480764\ttotal: 1m 6s\tremaining: 6.03s\n",
      "421:\tlearn: 1183.0782632\ttotal: 1m 6s\tremaining: 5.87s\n",
      "422:\tlearn: 1182.0404227\ttotal: 1m 7s\tremaining: 5.71s\n",
      "423:\tlearn: 1180.7842317\ttotal: 1m 7s\tremaining: 5.56s\n",
      "424:\tlearn: 1179.1585985\ttotal: 1m 7s\tremaining: 5.4s\n",
      "425:\tlearn: 1178.1567170\ttotal: 1m 7s\tremaining: 5.25s\n",
      "426:\tlearn: 1177.5187519\ttotal: 1m 7s\tremaining: 5.09s\n",
      "427:\tlearn: 1176.5816480\ttotal: 1m 8s\tremaining: 4.93s\n",
      "428:\tlearn: 1175.4859050\ttotal: 1m 8s\tremaining: 4.77s\n",
      "429:\tlearn: 1174.6849219\ttotal: 1m 8s\tremaining: 4.61s\n",
      "430:\tlearn: 1173.7440158\ttotal: 1m 8s\tremaining: 4.46s\n",
      "431:\tlearn: 1173.0792598\ttotal: 1m 8s\tremaining: 4.3s\n",
      "432:\tlearn: 1172.4702557\ttotal: 1m 8s\tremaining: 4.14s\n",
      "433:\tlearn: 1171.2115558\ttotal: 1m 9s\tremaining: 3.98s\n",
      "434:\tlearn: 1170.1978445\ttotal: 1m 9s\tremaining: 3.82s\n",
      "435:\tlearn: 1169.2586647\ttotal: 1m 9s\tremaining: 3.67s\n",
      "436:\tlearn: 1168.5871609\ttotal: 1m 9s\tremaining: 3.51s\n",
      "437:\tlearn: 1167.9257219\ttotal: 1m 9s\tremaining: 3.35s\n",
      "438:\tlearn: 1167.1105250\ttotal: 1m 9s\tremaining: 3.19s\n",
      "439:\tlearn: 1166.4148530\ttotal: 1m 10s\tremaining: 3.03s\n",
      "440:\tlearn: 1165.6359331\ttotal: 1m 10s\tremaining: 2.87s\n",
      "441:\tlearn: 1164.3154272\ttotal: 1m 10s\tremaining: 2.71s\n",
      "442:\tlearn: 1163.9294035\ttotal: 1m 10s\tremaining: 2.55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443:\tlearn: 1162.8049322\ttotal: 1m 10s\tremaining: 2.39s\n",
      "444:\tlearn: 1162.3425114\ttotal: 1m 11s\tremaining: 2.23s\n",
      "445:\tlearn: 1161.8294568\ttotal: 1m 11s\tremaining: 2.07s\n",
      "446:\tlearn: 1160.9651093\ttotal: 1m 11s\tremaining: 1.92s\n",
      "447:\tlearn: 1160.0255485\ttotal: 1m 11s\tremaining: 1.76s\n",
      "448:\tlearn: 1159.0006221\ttotal: 1m 11s\tremaining: 1.6s\n",
      "449:\tlearn: 1158.1795487\ttotal: 1m 11s\tremaining: 1.44s\n",
      "450:\tlearn: 1157.7271940\ttotal: 1m 12s\tremaining: 1.28s\n",
      "451:\tlearn: 1156.4340939\ttotal: 1m 12s\tremaining: 1.12s\n",
      "452:\tlearn: 1155.6335092\ttotal: 1m 12s\tremaining: 959ms\n",
      "453:\tlearn: 1155.2305523\ttotal: 1m 12s\tremaining: 799ms\n",
      "454:\tlearn: 1154.1658326\ttotal: 1m 12s\tremaining: 640ms\n",
      "455:\tlearn: 1153.4542929\ttotal: 1m 12s\tremaining: 480ms\n",
      "456:\tlearn: 1152.6872046\ttotal: 1m 13s\tremaining: 320ms\n",
      "457:\tlearn: 1152.3003835\ttotal: 1m 13s\tremaining: 160ms\n",
      "458:\tlearn: 1151.6596956\ttotal: 1m 13s\tremaining: 0us\n",
      "0:\tlearn: 4270.3406001\ttotal: 194ms\tremaining: 1m 28s\n",
      "1:\tlearn: 3891.0567976\ttotal: 379ms\tremaining: 1m 26s\n",
      "2:\tlearn: 3581.9627742\ttotal: 576ms\tremaining: 1m 27s\n",
      "3:\tlearn: 3307.6301985\ttotal: 740ms\tremaining: 1m 24s\n",
      "4:\tlearn: 3078.9219589\ttotal: 932ms\tremaining: 1m 24s\n",
      "5:\tlearn: 2890.7472840\ttotal: 1.12s\tremaining: 1m 24s\n",
      "6:\tlearn: 2719.9976141\ttotal: 1.33s\tremaining: 1m 25s\n",
      "7:\tlearn: 2595.5416627\ttotal: 1.5s\tremaining: 1m 24s\n",
      "8:\tlearn: 2470.3035410\ttotal: 1.69s\tremaining: 1m 24s\n",
      "9:\tlearn: 2378.6397377\ttotal: 1.87s\tremaining: 1m 23s\n",
      "10:\tlearn: 2293.9937147\ttotal: 2.05s\tremaining: 1m 23s\n",
      "11:\tlearn: 2224.3954921\ttotal: 2.24s\tremaining: 1m 23s\n",
      "12:\tlearn: 2165.3287658\ttotal: 2.41s\tremaining: 1m 22s\n",
      "13:\tlearn: 2114.8430779\ttotal: 2.58s\tremaining: 1m 22s\n",
      "14:\tlearn: 2072.7580615\ttotal: 2.76s\tremaining: 1m 21s\n",
      "15:\tlearn: 2037.0750934\ttotal: 2.94s\tremaining: 1m 21s\n",
      "16:\tlearn: 2004.4105644\ttotal: 3.12s\tremaining: 1m 21s\n",
      "17:\tlearn: 1981.1786170\ttotal: 3.29s\tremaining: 1m 20s\n",
      "18:\tlearn: 1962.2436675\ttotal: 3.45s\tremaining: 1m 19s\n",
      "19:\tlearn: 1944.7528349\ttotal: 3.63s\tremaining: 1m 19s\n",
      "20:\tlearn: 1929.6212899\ttotal: 3.81s\tremaining: 1m 19s\n",
      "21:\tlearn: 1917.0040036\ttotal: 3.96s\tremaining: 1m 18s\n",
      "22:\tlearn: 1904.3474633\ttotal: 4.13s\tremaining: 1m 18s\n",
      "23:\tlearn: 1895.1520210\ttotal: 4.28s\tremaining: 1m 17s\n",
      "24:\tlearn: 1883.8872026\ttotal: 4.45s\tremaining: 1m 17s\n",
      "25:\tlearn: 1877.1309907\ttotal: 4.6s\tremaining: 1m 16s\n",
      "26:\tlearn: 1868.3681118\ttotal: 4.78s\tremaining: 1m 16s\n",
      "27:\tlearn: 1860.4607197\ttotal: 4.93s\tremaining: 1m 15s\n",
      "28:\tlearn: 1851.8966101\ttotal: 5.12s\tremaining: 1m 15s\n",
      "29:\tlearn: 1845.9540478\ttotal: 5.28s\tremaining: 1m 15s\n",
      "30:\tlearn: 1838.3231532\ttotal: 5.44s\tremaining: 1m 15s\n",
      "31:\tlearn: 1832.7565635\ttotal: 5.6s\tremaining: 1m 14s\n",
      "32:\tlearn: 1830.6022095\ttotal: 5.76s\tremaining: 1m 14s\n",
      "33:\tlearn: 1824.2926706\ttotal: 5.91s\tremaining: 1m 13s\n",
      "34:\tlearn: 1820.9961162\ttotal: 6.06s\tremaining: 1m 13s\n",
      "35:\tlearn: 1816.0703396\ttotal: 6.23s\tremaining: 1m 13s\n",
      "36:\tlearn: 1812.1076358\ttotal: 6.4s\tremaining: 1m 12s\n",
      "37:\tlearn: 1809.2695541\ttotal: 6.55s\tremaining: 1m 12s\n",
      "38:\tlearn: 1807.2866346\ttotal: 6.71s\tremaining: 1m 12s\n",
      "39:\tlearn: 1804.7110385\ttotal: 6.87s\tremaining: 1m 11s\n",
      "40:\tlearn: 1801.8526817\ttotal: 7.03s\tremaining: 1m 11s\n",
      "41:\tlearn: 1799.2575013\ttotal: 7.18s\tremaining: 1m 11s\n",
      "42:\tlearn: 1798.2041215\ttotal: 7.33s\tremaining: 1m 10s\n",
      "43:\tlearn: 1794.6719338\ttotal: 7.48s\tremaining: 1m 10s\n",
      "44:\tlearn: 1790.8797796\ttotal: 7.66s\tremaining: 1m 10s\n",
      "45:\tlearn: 1786.9680431\ttotal: 7.83s\tremaining: 1m 10s\n",
      "46:\tlearn: 1784.1745576\ttotal: 8.02s\tremaining: 1m 10s\n",
      "47:\tlearn: 1782.5874578\ttotal: 8.15s\tremaining: 1m 9s\n",
      "48:\tlearn: 1780.4432560\ttotal: 8.3s\tremaining: 1m 9s\n",
      "49:\tlearn: 1778.6864726\ttotal: 8.46s\tremaining: 1m 9s\n",
      "50:\tlearn: 1777.2619314\ttotal: 8.63s\tremaining: 1m 9s\n",
      "51:\tlearn: 1774.9937074\ttotal: 8.79s\tremaining: 1m 8s\n",
      "52:\tlearn: 1772.5709248\ttotal: 8.97s\tremaining: 1m 8s\n",
      "53:\tlearn: 1768.4493622\ttotal: 9.13s\tremaining: 1m 8s\n",
      "54:\tlearn: 1766.9401942\ttotal: 9.3s\tremaining: 1m 8s\n",
      "55:\tlearn: 1764.3757125\ttotal: 9.46s\tremaining: 1m 8s\n",
      "56:\tlearn: 1762.8699341\ttotal: 9.6s\tremaining: 1m 7s\n",
      "57:\tlearn: 1761.6795733\ttotal: 9.74s\tremaining: 1m 7s\n",
      "58:\tlearn: 1759.9355714\ttotal: 9.91s\tremaining: 1m 7s\n",
      "59:\tlearn: 1757.7603386\ttotal: 10.1s\tremaining: 1m 7s\n",
      "60:\tlearn: 1755.1952378\ttotal: 10.3s\tremaining: 1m 6s\n",
      "61:\tlearn: 1754.1696406\ttotal: 10.4s\tremaining: 1m 6s\n",
      "62:\tlearn: 1752.6766115\ttotal: 10.6s\tremaining: 1m 6s\n",
      "63:\tlearn: 1751.9490282\ttotal: 10.7s\tremaining: 1m 6s\n",
      "64:\tlearn: 1750.2785058\ttotal: 10.9s\tremaining: 1m 5s\n",
      "65:\tlearn: 1749.4678624\ttotal: 11s\tremaining: 1m 5s\n",
      "66:\tlearn: 1748.2496393\ttotal: 11.2s\tremaining: 1m 5s\n",
      "67:\tlearn: 1744.6829871\ttotal: 11.4s\tremaining: 1m 5s\n",
      "68:\tlearn: 1743.4574626\ttotal: 11.5s\tremaining: 1m 5s\n",
      "69:\tlearn: 1741.6908229\ttotal: 11.7s\tremaining: 1m 4s\n",
      "70:\tlearn: 1740.3017369\ttotal: 11.9s\tremaining: 1m 4s\n",
      "71:\tlearn: 1739.2479784\ttotal: 12s\tremaining: 1m 4s\n",
      "72:\tlearn: 1738.7717585\ttotal: 12.2s\tremaining: 1m 4s\n",
      "73:\tlearn: 1737.4825168\ttotal: 12.3s\tremaining: 1m 4s\n",
      "74:\tlearn: 1736.2844570\ttotal: 12.5s\tremaining: 1m 3s\n",
      "75:\tlearn: 1734.9781321\ttotal: 12.6s\tremaining: 1m 3s\n",
      "76:\tlearn: 1734.4619087\ttotal: 12.8s\tremaining: 1m 3s\n",
      "77:\tlearn: 1732.5387830\ttotal: 12.9s\tremaining: 1m 3s\n",
      "78:\tlearn: 1730.3784197\ttotal: 13.1s\tremaining: 1m 2s\n",
      "79:\tlearn: 1728.7197040\ttotal: 13.3s\tremaining: 1m 2s\n",
      "80:\tlearn: 1727.4008597\ttotal: 13.4s\tremaining: 1m 2s\n",
      "81:\tlearn: 1727.1150629\ttotal: 13.5s\tremaining: 1m 2s\n",
      "82:\tlearn: 1725.8775366\ttotal: 13.7s\tremaining: 1m 2s\n",
      "83:\tlearn: 1724.7176310\ttotal: 13.9s\tremaining: 1m 1s\n",
      "84:\tlearn: 1723.0604475\ttotal: 14s\tremaining: 1m 1s\n",
      "85:\tlearn: 1721.8707342\ttotal: 14.2s\tremaining: 1m 1s\n",
      "86:\tlearn: 1718.9627367\ttotal: 14.3s\tremaining: 1m 1s\n",
      "87:\tlearn: 1717.0457848\ttotal: 14.5s\tremaining: 1m 1s\n",
      "88:\tlearn: 1714.3763422\ttotal: 14.7s\tremaining: 1m\n",
      "89:\tlearn: 1710.9894900\ttotal: 14.8s\tremaining: 1m\n",
      "90:\tlearn: 1708.5028153\ttotal: 15s\tremaining: 1m\n",
      "91:\tlearn: 1707.2463396\ttotal: 15.1s\tremaining: 1m\n",
      "92:\tlearn: 1703.3606547\ttotal: 15.3s\tremaining: 1m\n",
      "93:\tlearn: 1701.7419067\ttotal: 15.4s\tremaining: 59.9s\n",
      "94:\tlearn: 1698.2644385\ttotal: 15.6s\tremaining: 59.7s\n",
      "95:\tlearn: 1696.0990015\ttotal: 15.7s\tremaining: 59.4s\n",
      "96:\tlearn: 1694.9412980\ttotal: 15.9s\tremaining: 59.2s\n",
      "97:\tlearn: 1691.7306317\ttotal: 16s\tremaining: 59s\n",
      "98:\tlearn: 1685.5195456\ttotal: 16.2s\tremaining: 58.9s\n",
      "99:\tlearn: 1682.7914205\ttotal: 16.3s\tremaining: 58.6s\n",
      "100:\tlearn: 1678.4697859\ttotal: 16.5s\tremaining: 58.5s\n",
      "101:\tlearn: 1673.7660802\ttotal: 16.7s\tremaining: 58.4s\n",
      "102:\tlearn: 1671.1580547\ttotal: 16.8s\tremaining: 58.2s\n",
      "103:\tlearn: 1669.3076148\ttotal: 17s\tremaining: 58s\n",
      "104:\tlearn: 1664.5146877\ttotal: 17.2s\tremaining: 57.9s\n",
      "105:\tlearn: 1661.1427432\ttotal: 17.3s\tremaining: 57.7s\n",
      "106:\tlearn: 1659.9377159\ttotal: 17.5s\tremaining: 57.4s\n",
      "107:\tlearn: 1655.2902696\ttotal: 17.6s\tremaining: 57.3s\n",
      "108:\tlearn: 1652.0144037\ttotal: 17.8s\tremaining: 57s\n",
      "109:\tlearn: 1649.3513487\ttotal: 17.9s\tremaining: 56.8s\n",
      "110:\tlearn: 1645.2174507\ttotal: 18.1s\tremaining: 56.6s\n",
      "111:\tlearn: 1642.2492672\ttotal: 18.2s\tremaining: 56.4s\n",
      "112:\tlearn: 1639.5829545\ttotal: 18.4s\tremaining: 56.3s\n",
      "113:\tlearn: 1634.9818523\ttotal: 18.6s\tremaining: 56.2s\n",
      "114:\tlearn: 1627.6136707\ttotal: 18.7s\tremaining: 56.1s\n",
      "115:\tlearn: 1624.0856670\ttotal: 18.9s\tremaining: 55.8s\n",
      "116:\tlearn: 1623.0515482\ttotal: 19s\tremaining: 55.6s\n",
      "117:\tlearn: 1619.6475927\ttotal: 19.2s\tremaining: 55.4s\n",
      "118:\tlearn: 1617.6549913\ttotal: 19.3s\tremaining: 55.1s\n",
      "119:\tlearn: 1614.3702049\ttotal: 19.5s\tremaining: 55s\n",
      "120:\tlearn: 1612.3199858\ttotal: 19.6s\tremaining: 54.8s\n",
      "121:\tlearn: 1609.3624942\ttotal: 19.8s\tremaining: 54.6s\n",
      "122:\tlearn: 1606.1897276\ttotal: 19.9s\tremaining: 54.4s\n",
      "123:\tlearn: 1602.9999752\ttotal: 20.1s\tremaining: 54.3s\n",
      "124:\tlearn: 1601.3714492\ttotal: 20.2s\tremaining: 54s\n",
      "125:\tlearn: 1598.8156204\ttotal: 20.4s\tremaining: 53.8s\n",
      "126:\tlearn: 1595.8871683\ttotal: 20.5s\tremaining: 53.7s\n",
      "127:\tlearn: 1594.1174669\ttotal: 20.7s\tremaining: 53.5s\n",
      "128:\tlearn: 1591.1478636\ttotal: 20.8s\tremaining: 53.3s\n",
      "129:\tlearn: 1587.6369848\ttotal: 21s\tremaining: 53.1s\n",
      "130:\tlearn: 1582.5977691\ttotal: 21.2s\tremaining: 53s\n",
      "131:\tlearn: 1580.8103414\ttotal: 21.3s\tremaining: 52.8s\n",
      "132:\tlearn: 1577.2820959\ttotal: 21.5s\tremaining: 52.6s\n",
      "133:\tlearn: 1573.8716717\ttotal: 21.6s\tremaining: 52.5s\n",
      "134:\tlearn: 1571.3697237\ttotal: 21.8s\tremaining: 52.3s\n",
      "135:\tlearn: 1568.4934087\ttotal: 21.9s\tremaining: 52.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136:\tlearn: 1567.7960731\ttotal: 22.1s\tremaining: 51.9s\n",
      "137:\tlearn: 1564.8144482\ttotal: 22.2s\tremaining: 51.7s\n",
      "138:\tlearn: 1562.9274803\ttotal: 22.4s\tremaining: 51.5s\n",
      "139:\tlearn: 1558.0444366\ttotal: 22.6s\tremaining: 51.4s\n",
      "140:\tlearn: 1554.8383040\ttotal: 22.7s\tremaining: 51.3s\n",
      "141:\tlearn: 1553.8712887\ttotal: 22.9s\tremaining: 51s\n",
      "142:\tlearn: 1551.0876391\ttotal: 23s\tremaining: 50.8s\n",
      "143:\tlearn: 1550.1479182\ttotal: 23.1s\tremaining: 50.6s\n",
      "144:\tlearn: 1548.7828483\ttotal: 23.3s\tremaining: 50.4s\n",
      "145:\tlearn: 1544.3498978\ttotal: 23.4s\tremaining: 50.3s\n",
      "146:\tlearn: 1542.8533992\ttotal: 23.6s\tremaining: 50s\n",
      "147:\tlearn: 1542.1985630\ttotal: 23.7s\tremaining: 49.8s\n",
      "148:\tlearn: 1540.5017996\ttotal: 23.8s\tremaining: 49.6s\n",
      "149:\tlearn: 1536.9459715\ttotal: 24s\tremaining: 49.4s\n",
      "150:\tlearn: 1534.7661854\ttotal: 24.1s\tremaining: 49.2s\n",
      "151:\tlearn: 1532.8621729\ttotal: 24.3s\tremaining: 49.1s\n",
      "152:\tlearn: 1531.1347213\ttotal: 24.4s\tremaining: 48.9s\n",
      "153:\tlearn: 1529.6552211\ttotal: 24.6s\tremaining: 48.7s\n",
      "154:\tlearn: 1526.7712848\ttotal: 24.7s\tremaining: 48.5s\n",
      "155:\tlearn: 1524.5428085\ttotal: 24.9s\tremaining: 48.3s\n",
      "156:\tlearn: 1522.6931072\ttotal: 25s\tremaining: 48.1s\n",
      "157:\tlearn: 1520.9810482\ttotal: 25.2s\tremaining: 48s\n",
      "158:\tlearn: 1517.5353747\ttotal: 25.4s\tremaining: 47.8s\n",
      "159:\tlearn: 1516.9982093\ttotal: 25.5s\tremaining: 47.6s\n",
      "160:\tlearn: 1515.5124555\ttotal: 25.6s\tremaining: 47.4s\n",
      "161:\tlearn: 1514.9078031\ttotal: 25.8s\tremaining: 47.2s\n",
      "162:\tlearn: 1511.6955121\ttotal: 25.9s\tremaining: 47.1s\n",
      "163:\tlearn: 1510.3647150\ttotal: 26.1s\tremaining: 46.9s\n",
      "164:\tlearn: 1509.4211797\ttotal: 26.2s\tremaining: 46.7s\n",
      "165:\tlearn: 1506.7911777\ttotal: 26.4s\tremaining: 46.6s\n",
      "166:\tlearn: 1505.3001830\ttotal: 26.5s\tremaining: 46.4s\n",
      "167:\tlearn: 1503.0305331\ttotal: 26.7s\tremaining: 46.3s\n",
      "168:\tlearn: 1501.0709627\ttotal: 26.9s\tremaining: 46.1s\n",
      "169:\tlearn: 1498.9184269\ttotal: 27s\tremaining: 45.9s\n",
      "170:\tlearn: 1498.1124482\ttotal: 27.1s\tremaining: 45.7s\n",
      "171:\tlearn: 1497.3657331\ttotal: 27.3s\tremaining: 45.5s\n",
      "172:\tlearn: 1495.3570498\ttotal: 27.4s\tremaining: 45.3s\n",
      "173:\tlearn: 1493.3655164\ttotal: 27.6s\tremaining: 45.1s\n",
      "174:\tlearn: 1491.8955245\ttotal: 27.7s\tremaining: 45s\n",
      "175:\tlearn: 1490.4803250\ttotal: 27.9s\tremaining: 44.8s\n",
      "176:\tlearn: 1488.6230935\ttotal: 28s\tremaining: 44.7s\n",
      "177:\tlearn: 1487.5855937\ttotal: 28.2s\tremaining: 44.5s\n",
      "178:\tlearn: 1485.3825638\ttotal: 28.3s\tremaining: 44.3s\n",
      "179:\tlearn: 1484.1878186\ttotal: 28.4s\tremaining: 44.1s\n",
      "180:\tlearn: 1482.9328043\ttotal: 28.6s\tremaining: 43.9s\n",
      "181:\tlearn: 1481.2997133\ttotal: 28.7s\tremaining: 43.7s\n",
      "182:\tlearn: 1480.3360266\ttotal: 28.9s\tremaining: 43.6s\n",
      "183:\tlearn: 1479.8440314\ttotal: 29s\tremaining: 43.3s\n",
      "184:\tlearn: 1478.3698786\ttotal: 29.1s\tremaining: 43.1s\n",
      "185:\tlearn: 1476.2878514\ttotal: 29.3s\tremaining: 42.9s\n",
      "186:\tlearn: 1473.7559634\ttotal: 29.4s\tremaining: 42.8s\n",
      "187:\tlearn: 1472.0870726\ttotal: 29.6s\tremaining: 42.7s\n",
      "188:\tlearn: 1469.4502823\ttotal: 29.8s\tremaining: 42.5s\n",
      "189:\tlearn: 1468.5456259\ttotal: 29.9s\tremaining: 42.3s\n",
      "190:\tlearn: 1466.9102780\ttotal: 30.1s\tremaining: 42.2s\n",
      "191:\tlearn: 1463.4195665\ttotal: 30.3s\tremaining: 42.1s\n",
      "192:\tlearn: 1461.9313756\ttotal: 30.4s\tremaining: 41.9s\n",
      "193:\tlearn: 1458.8965221\ttotal: 30.6s\tremaining: 41.8s\n",
      "194:\tlearn: 1457.5689386\ttotal: 30.7s\tremaining: 41.6s\n",
      "195:\tlearn: 1455.0124831\ttotal: 30.9s\tremaining: 41.4s\n",
      "196:\tlearn: 1453.3742600\ttotal: 31s\tremaining: 41.3s\n",
      "197:\tlearn: 1452.2215888\ttotal: 31.2s\tremaining: 41.1s\n",
      "198:\tlearn: 1450.3143560\ttotal: 31.4s\tremaining: 41s\n",
      "199:\tlearn: 1449.5012856\ttotal: 31.5s\tremaining: 40.8s\n",
      "200:\tlearn: 1448.1926827\ttotal: 31.7s\tremaining: 40.6s\n",
      "201:\tlearn: 1446.0568375\ttotal: 31.9s\tremaining: 40.5s\n",
      "202:\tlearn: 1443.3560725\ttotal: 32s\tremaining: 40.4s\n",
      "203:\tlearn: 1440.6339479\ttotal: 32.2s\tremaining: 40.3s\n",
      "204:\tlearn: 1439.7589759\ttotal: 32.3s\tremaining: 40.1s\n",
      "205:\tlearn: 1438.9150131\ttotal: 32.5s\tremaining: 39.9s\n",
      "206:\tlearn: 1437.4065090\ttotal: 32.6s\tremaining: 39.7s\n",
      "207:\tlearn: 1436.1172668\ttotal: 32.8s\tremaining: 39.6s\n",
      "208:\tlearn: 1434.9010748\ttotal: 33s\tremaining: 39.4s\n",
      "209:\tlearn: 1432.6074530\ttotal: 33.1s\tremaining: 39.3s\n",
      "210:\tlearn: 1431.6481953\ttotal: 33.3s\tremaining: 39.1s\n",
      "211:\tlearn: 1429.9702254\ttotal: 33.5s\tremaining: 39s\n",
      "212:\tlearn: 1428.6995816\ttotal: 33.6s\tremaining: 38.8s\n",
      "213:\tlearn: 1427.0247603\ttotal: 33.8s\tremaining: 38.7s\n",
      "214:\tlearn: 1424.8657496\ttotal: 34s\tremaining: 38.6s\n",
      "215:\tlearn: 1423.5163789\ttotal: 34.1s\tremaining: 38.4s\n",
      "216:\tlearn: 1420.1941225\ttotal: 34.3s\tremaining: 38.3s\n",
      "217:\tlearn: 1418.2806955\ttotal: 34.5s\tremaining: 38.1s\n",
      "218:\tlearn: 1416.1155093\ttotal: 34.7s\tremaining: 38s\n",
      "219:\tlearn: 1414.2163363\ttotal: 34.8s\tremaining: 37.8s\n",
      "220:\tlearn: 1412.0493493\ttotal: 35s\tremaining: 37.7s\n",
      "221:\tlearn: 1409.4799049\ttotal: 35.1s\tremaining: 37.5s\n",
      "222:\tlearn: 1408.3110342\ttotal: 35.3s\tremaining: 37.3s\n",
      "223:\tlearn: 1407.1760176\ttotal: 35.4s\tremaining: 37.2s\n",
      "224:\tlearn: 1405.4196892\ttotal: 35.6s\tremaining: 37s\n",
      "225:\tlearn: 1404.3563657\ttotal: 35.7s\tremaining: 36.8s\n",
      "226:\tlearn: 1403.2878992\ttotal: 35.9s\tremaining: 36.7s\n",
      "227:\tlearn: 1402.4901297\ttotal: 36s\tremaining: 36.5s\n",
      "228:\tlearn: 1401.2295002\ttotal: 36.2s\tremaining: 36.3s\n",
      "229:\tlearn: 1400.7054158\ttotal: 36.3s\tremaining: 36.2s\n",
      "230:\tlearn: 1399.9670306\ttotal: 36.5s\tremaining: 36s\n",
      "231:\tlearn: 1398.0388691\ttotal: 36.6s\tremaining: 35.9s\n",
      "232:\tlearn: 1397.5340090\ttotal: 36.8s\tremaining: 35.7s\n",
      "233:\tlearn: 1396.1018151\ttotal: 36.9s\tremaining: 35.5s\n",
      "234:\tlearn: 1394.8069721\ttotal: 37.1s\tremaining: 35.4s\n",
      "235:\tlearn: 1393.2118473\ttotal: 37.3s\tremaining: 35.2s\n",
      "236:\tlearn: 1391.7142877\ttotal: 37.4s\tremaining: 35.1s\n",
      "237:\tlearn: 1390.8609156\ttotal: 37.6s\tremaining: 34.9s\n",
      "238:\tlearn: 1390.2457347\ttotal: 37.7s\tremaining: 34.7s\n",
      "239:\tlearn: 1388.8841596\ttotal: 37.9s\tremaining: 34.5s\n",
      "240:\tlearn: 1387.6807946\ttotal: 38s\tremaining: 34.4s\n",
      "241:\tlearn: 1385.8942116\ttotal: 38.2s\tremaining: 34.2s\n",
      "242:\tlearn: 1384.8486295\ttotal: 38.3s\tremaining: 34.1s\n",
      "243:\tlearn: 1383.2608502\ttotal: 38.5s\tremaining: 33.9s\n",
      "244:\tlearn: 1381.7121159\ttotal: 38.7s\tremaining: 33.8s\n",
      "245:\tlearn: 1380.2319441\ttotal: 38.8s\tremaining: 33.6s\n",
      "246:\tlearn: 1378.4130313\ttotal: 39s\tremaining: 33.5s\n",
      "247:\tlearn: 1376.0293827\ttotal: 39.2s\tremaining: 33.3s\n",
      "248:\tlearn: 1374.5778642\ttotal: 39.4s\tremaining: 33.2s\n",
      "249:\tlearn: 1372.9502734\ttotal: 39.5s\tremaining: 33s\n",
      "250:\tlearn: 1371.4217330\ttotal: 39.7s\tremaining: 32.9s\n",
      "251:\tlearn: 1369.7707646\ttotal: 39.9s\tremaining: 32.8s\n",
      "252:\tlearn: 1369.0287122\ttotal: 40s\tremaining: 32.6s\n",
      "253:\tlearn: 1366.6873044\ttotal: 40.2s\tremaining: 32.5s\n",
      "254:\tlearn: 1365.4379912\ttotal: 40.4s\tremaining: 32.3s\n",
      "255:\tlearn: 1364.4150697\ttotal: 40.5s\tremaining: 32.1s\n",
      "256:\tlearn: 1363.3058248\ttotal: 40.7s\tremaining: 32s\n",
      "257:\tlearn: 1362.5115732\ttotal: 40.9s\tremaining: 31.8s\n",
      "258:\tlearn: 1360.8952983\ttotal: 41s\tremaining: 31.7s\n",
      "259:\tlearn: 1359.5193597\ttotal: 41.2s\tremaining: 31.5s\n",
      "260:\tlearn: 1358.3135838\ttotal: 41.4s\tremaining: 31.4s\n",
      "261:\tlearn: 1357.2698729\ttotal: 41.6s\tremaining: 31.3s\n",
      "262:\tlearn: 1356.4771871\ttotal: 41.7s\tremaining: 31.1s\n",
      "263:\tlearn: 1354.7525948\ttotal: 41.9s\tremaining: 30.9s\n",
      "264:\tlearn: 1353.5548960\ttotal: 42s\tremaining: 30.8s\n",
      "265:\tlearn: 1352.2533307\ttotal: 42.2s\tremaining: 30.6s\n",
      "266:\tlearn: 1351.0721468\ttotal: 42.4s\tremaining: 30.5s\n",
      "267:\tlearn: 1350.2090175\ttotal: 42.5s\tremaining: 30.3s\n",
      "268:\tlearn: 1349.4875013\ttotal: 42.7s\tremaining: 30.1s\n",
      "269:\tlearn: 1348.7813703\ttotal: 42.8s\tremaining: 30s\n",
      "270:\tlearn: 1346.2961149\ttotal: 43s\tremaining: 29.8s\n",
      "271:\tlearn: 1345.3545643\ttotal: 43.2s\tremaining: 29.7s\n",
      "272:\tlearn: 1344.6859606\ttotal: 43.3s\tremaining: 29.5s\n",
      "273:\tlearn: 1344.0797681\ttotal: 43.5s\tremaining: 29.3s\n",
      "274:\tlearn: 1342.3281782\ttotal: 43.6s\tremaining: 29.2s\n",
      "275:\tlearn: 1340.9841432\ttotal: 43.8s\tremaining: 29.1s\n",
      "276:\tlearn: 1339.3839609\ttotal: 44s\tremaining: 28.9s\n",
      "277:\tlearn: 1337.9607130\ttotal: 44.2s\tremaining: 28.7s\n",
      "278:\tlearn: 1336.7003960\ttotal: 44.3s\tremaining: 28.6s\n",
      "279:\tlearn: 1334.9293388\ttotal: 44.5s\tremaining: 28.5s\n",
      "280:\tlearn: 1333.6143001\ttotal: 44.7s\tremaining: 28.3s\n",
      "281:\tlearn: 1332.4986049\ttotal: 44.9s\tremaining: 28.2s\n",
      "282:\tlearn: 1331.7230849\ttotal: 45s\tremaining: 28s\n",
      "283:\tlearn: 1330.5365527\ttotal: 45.1s\tremaining: 27.8s\n",
      "284:\tlearn: 1329.3901126\ttotal: 45.3s\tremaining: 27.7s\n",
      "285:\tlearn: 1327.8162951\ttotal: 45.5s\tremaining: 27.5s\n",
      "286:\tlearn: 1326.5330977\ttotal: 45.6s\tremaining: 27.4s\n",
      "287:\tlearn: 1325.4146978\ttotal: 45.8s\tremaining: 27.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288:\tlearn: 1323.9777494\ttotal: 46s\tremaining: 27s\n",
      "289:\tlearn: 1321.9296786\ttotal: 46.2s\tremaining: 26.9s\n",
      "290:\tlearn: 1320.5085803\ttotal: 46.3s\tremaining: 26.7s\n",
      "291:\tlearn: 1319.9439619\ttotal: 46.5s\tremaining: 26.6s\n",
      "292:\tlearn: 1318.3604231\ttotal: 46.7s\tremaining: 26.4s\n",
      "293:\tlearn: 1316.7661816\ttotal: 46.8s\tremaining: 26.3s\n",
      "294:\tlearn: 1315.9064295\ttotal: 47s\tremaining: 26.1s\n",
      "295:\tlearn: 1314.7839210\ttotal: 47.1s\tremaining: 26s\n",
      "296:\tlearn: 1312.9841229\ttotal: 47.3s\tremaining: 25.8s\n",
      "297:\tlearn: 1311.4923055\ttotal: 47.5s\tremaining: 25.7s\n",
      "298:\tlearn: 1310.6048480\ttotal: 47.6s\tremaining: 25.5s\n",
      "299:\tlearn: 1309.0443847\ttotal: 47.8s\tremaining: 25.3s\n",
      "300:\tlearn: 1307.5290272\ttotal: 48s\tremaining: 25.2s\n",
      "301:\tlearn: 1306.2088398\ttotal: 48.2s\tremaining: 25s\n",
      "302:\tlearn: 1305.2764977\ttotal: 48.3s\tremaining: 24.9s\n",
      "303:\tlearn: 1304.4027778\ttotal: 48.5s\tremaining: 24.7s\n",
      "304:\tlearn: 1303.1909939\ttotal: 48.7s\tremaining: 24.6s\n",
      "305:\tlearn: 1302.1260275\ttotal: 48.8s\tremaining: 24.4s\n",
      "306:\tlearn: 1301.5739608\ttotal: 49s\tremaining: 24.3s\n",
      "307:\tlearn: 1300.5228163\ttotal: 49.2s\tremaining: 24.1s\n",
      "308:\tlearn: 1299.5705725\ttotal: 49.4s\tremaining: 24s\n",
      "309:\tlearn: 1298.5192445\ttotal: 49.5s\tremaining: 23.8s\n",
      "310:\tlearn: 1296.9113445\ttotal: 49.7s\tremaining: 23.7s\n",
      "311:\tlearn: 1295.6852959\ttotal: 49.9s\tremaining: 23.5s\n",
      "312:\tlearn: 1294.8397074\ttotal: 50s\tremaining: 23.3s\n",
      "313:\tlearn: 1293.8107633\ttotal: 50.2s\tremaining: 23.2s\n",
      "314:\tlearn: 1291.9325449\ttotal: 50.4s\tremaining: 23s\n",
      "315:\tlearn: 1290.4126364\ttotal: 50.6s\tremaining: 22.9s\n",
      "316:\tlearn: 1289.6934583\ttotal: 50.7s\tremaining: 22.7s\n",
      "317:\tlearn: 1288.6655296\ttotal: 50.9s\tremaining: 22.6s\n",
      "318:\tlearn: 1288.1919536\ttotal: 51s\tremaining: 22.4s\n",
      "319:\tlearn: 1286.7014181\ttotal: 51.2s\tremaining: 22.3s\n",
      "320:\tlearn: 1285.4759821\ttotal: 51.4s\tremaining: 22.1s\n",
      "321:\tlearn: 1284.5770263\ttotal: 51.6s\tremaining: 21.9s\n",
      "322:\tlearn: 1284.1884141\ttotal: 51.7s\tremaining: 21.8s\n",
      "323:\tlearn: 1282.8910222\ttotal: 51.9s\tremaining: 21.6s\n",
      "324:\tlearn: 1282.3366242\ttotal: 52.1s\tremaining: 21.5s\n",
      "325:\tlearn: 1281.2018228\ttotal: 52.2s\tremaining: 21.3s\n",
      "326:\tlearn: 1280.4351901\ttotal: 52.4s\tremaining: 21.2s\n",
      "327:\tlearn: 1279.9095474\ttotal: 52.6s\tremaining: 21s\n",
      "328:\tlearn: 1278.6735925\ttotal: 52.7s\tremaining: 20.8s\n",
      "329:\tlearn: 1276.9403702\ttotal: 52.9s\tremaining: 20.7s\n",
      "330:\tlearn: 1275.7397783\ttotal: 53.1s\tremaining: 20.5s\n",
      "331:\tlearn: 1274.9155062\ttotal: 53.3s\tremaining: 20.4s\n",
      "332:\tlearn: 1273.8794294\ttotal: 53.5s\tremaining: 20.2s\n",
      "333:\tlearn: 1272.7705196\ttotal: 53.6s\tremaining: 20.1s\n",
      "334:\tlearn: 1272.1151669\ttotal: 53.8s\tremaining: 19.9s\n",
      "335:\tlearn: 1271.5975212\ttotal: 54s\tremaining: 19.8s\n",
      "336:\tlearn: 1270.5805560\ttotal: 54.1s\tremaining: 19.6s\n",
      "337:\tlearn: 1269.6661328\ttotal: 54.3s\tremaining: 19.4s\n",
      "338:\tlearn: 1267.6148035\ttotal: 54.5s\tremaining: 19.3s\n",
      "339:\tlearn: 1266.9245809\ttotal: 54.7s\tremaining: 19.1s\n",
      "340:\tlearn: 1265.5552318\ttotal: 54.8s\tremaining: 19s\n",
      "341:\tlearn: 1264.9839531\ttotal: 55s\tremaining: 18.8s\n",
      "342:\tlearn: 1264.2351365\ttotal: 55.1s\tremaining: 18.6s\n",
      "343:\tlearn: 1262.9398988\ttotal: 55.3s\tremaining: 18.5s\n",
      "344:\tlearn: 1261.1451051\ttotal: 55.5s\tremaining: 18.3s\n",
      "345:\tlearn: 1259.3946292\ttotal: 55.7s\tremaining: 18.2s\n",
      "346:\tlearn: 1258.7702267\ttotal: 55.9s\tremaining: 18s\n",
      "347:\tlearn: 1258.0384611\ttotal: 56.1s\tremaining: 17.9s\n",
      "348:\tlearn: 1256.5061192\ttotal: 56.3s\tremaining: 17.7s\n",
      "349:\tlearn: 1255.1369440\ttotal: 56.4s\tremaining: 17.6s\n",
      "350:\tlearn: 1253.8424366\ttotal: 56.6s\tremaining: 17.4s\n",
      "351:\tlearn: 1252.6199031\ttotal: 56.8s\tremaining: 17.3s\n",
      "352:\tlearn: 1251.8712229\ttotal: 57s\tremaining: 17.1s\n",
      "353:\tlearn: 1251.3318152\ttotal: 57.1s\tremaining: 16.9s\n",
      "354:\tlearn: 1249.9468055\ttotal: 57.3s\tremaining: 16.8s\n",
      "355:\tlearn: 1248.6082716\ttotal: 57.5s\tremaining: 16.6s\n",
      "356:\tlearn: 1247.7015116\ttotal: 57.7s\tremaining: 16.5s\n",
      "357:\tlearn: 1246.4165941\ttotal: 57.8s\tremaining: 16.3s\n",
      "358:\tlearn: 1245.2242307\ttotal: 58s\tremaining: 16.2s\n",
      "359:\tlearn: 1244.2444978\ttotal: 58.2s\tremaining: 16s\n",
      "360:\tlearn: 1243.4952315\ttotal: 58.3s\tremaining: 15.8s\n",
      "361:\tlearn: 1243.0214222\ttotal: 58.5s\tremaining: 15.7s\n",
      "362:\tlearn: 1242.5048856\ttotal: 58.6s\tremaining: 15.5s\n",
      "363:\tlearn: 1241.6426287\ttotal: 58.8s\tremaining: 15.4s\n",
      "364:\tlearn: 1240.3564916\ttotal: 59s\tremaining: 15.2s\n",
      "365:\tlearn: 1239.0366270\ttotal: 59.2s\tremaining: 15s\n",
      "366:\tlearn: 1238.0599101\ttotal: 59.4s\tremaining: 14.9s\n",
      "367:\tlearn: 1236.7622163\ttotal: 59.5s\tremaining: 14.7s\n",
      "368:\tlearn: 1236.5765066\ttotal: 59.7s\tremaining: 14.6s\n",
      "369:\tlearn: 1235.2517354\ttotal: 59.8s\tremaining: 14.4s\n",
      "370:\tlearn: 1234.5047439\ttotal: 60s\tremaining: 14.2s\n",
      "371:\tlearn: 1233.9137172\ttotal: 1m\tremaining: 14.1s\n",
      "372:\tlearn: 1232.8397904\ttotal: 1m\tremaining: 13.9s\n",
      "373:\tlearn: 1231.2280664\ttotal: 1m\tremaining: 13.8s\n",
      "374:\tlearn: 1230.2419113\ttotal: 1m\tremaining: 13.6s\n",
      "375:\tlearn: 1229.1324615\ttotal: 1m\tremaining: 13.4s\n",
      "376:\tlearn: 1227.9311075\ttotal: 1m 1s\tremaining: 13.3s\n",
      "377:\tlearn: 1226.6030288\ttotal: 1m 1s\tremaining: 13.1s\n",
      "378:\tlearn: 1225.9917453\ttotal: 1m 1s\tremaining: 13s\n",
      "379:\tlearn: 1224.6817458\ttotal: 1m 1s\tremaining: 12.8s\n",
      "380:\tlearn: 1224.0042711\ttotal: 1m 1s\tremaining: 12.6s\n",
      "381:\tlearn: 1223.3954334\ttotal: 1m 1s\tremaining: 12.5s\n",
      "382:\tlearn: 1222.1687929\ttotal: 1m 2s\tremaining: 12.3s\n",
      "383:\tlearn: 1220.9597429\ttotal: 1m 2s\tremaining: 12.2s\n",
      "384:\tlearn: 1220.2522850\ttotal: 1m 2s\tremaining: 12s\n",
      "385:\tlearn: 1219.2373711\ttotal: 1m 2s\tremaining: 11.8s\n",
      "386:\tlearn: 1218.5913610\ttotal: 1m 2s\tremaining: 11.7s\n",
      "387:\tlearn: 1217.7231498\ttotal: 1m 2s\tremaining: 11.5s\n",
      "388:\tlearn: 1216.6299222\ttotal: 1m 3s\tremaining: 11.4s\n",
      "389:\tlearn: 1215.3651010\ttotal: 1m 3s\tremaining: 11.2s\n",
      "390:\tlearn: 1213.7822098\ttotal: 1m 3s\tremaining: 11s\n",
      "391:\tlearn: 1212.6829737\ttotal: 1m 3s\tremaining: 10.9s\n",
      "392:\tlearn: 1211.5987004\ttotal: 1m 3s\tremaining: 10.7s\n",
      "393:\tlearn: 1210.9804078\ttotal: 1m 4s\tremaining: 10.6s\n",
      "394:\tlearn: 1210.0877768\ttotal: 1m 4s\tremaining: 10.4s\n",
      "395:\tlearn: 1209.0864378\ttotal: 1m 4s\tremaining: 10.2s\n",
      "396:\tlearn: 1208.1423231\ttotal: 1m 4s\tremaining: 10.1s\n",
      "397:\tlearn: 1207.3044718\ttotal: 1m 4s\tremaining: 9.92s\n",
      "398:\tlearn: 1205.9679297\ttotal: 1m 4s\tremaining: 9.76s\n",
      "399:\tlearn: 1204.9368151\ttotal: 1m 5s\tremaining: 9.6s\n",
      "400:\tlearn: 1204.2719570\ttotal: 1m 5s\tremaining: 9.44s\n",
      "401:\tlearn: 1202.9857484\ttotal: 1m 5s\tremaining: 9.27s\n",
      "402:\tlearn: 1201.9282366\ttotal: 1m 5s\tremaining: 9.11s\n",
      "403:\tlearn: 1200.4668163\ttotal: 1m 5s\tremaining: 8.96s\n",
      "404:\tlearn: 1199.5634884\ttotal: 1m 5s\tremaining: 8.79s\n",
      "405:\tlearn: 1198.9218476\ttotal: 1m 6s\tremaining: 8.63s\n",
      "406:\tlearn: 1198.0133502\ttotal: 1m 6s\tremaining: 8.47s\n",
      "407:\tlearn: 1197.0819185\ttotal: 1m 6s\tremaining: 8.31s\n",
      "408:\tlearn: 1196.1757181\ttotal: 1m 6s\tremaining: 8.15s\n",
      "409:\tlearn: 1195.4308598\ttotal: 1m 6s\tremaining: 7.99s\n",
      "410:\tlearn: 1194.6050407\ttotal: 1m 7s\tremaining: 7.82s\n",
      "411:\tlearn: 1193.9378612\ttotal: 1m 7s\tremaining: 7.66s\n",
      "412:\tlearn: 1191.8503973\ttotal: 1m 7s\tremaining: 7.5s\n",
      "413:\tlearn: 1190.9099589\ttotal: 1m 7s\tremaining: 7.34s\n",
      "414:\tlearn: 1189.8378757\ttotal: 1m 7s\tremaining: 7.18s\n",
      "415:\tlearn: 1189.3455397\ttotal: 1m 7s\tremaining: 7.02s\n",
      "416:\tlearn: 1187.7933377\ttotal: 1m 8s\tremaining: 6.86s\n",
      "417:\tlearn: 1186.5471754\ttotal: 1m 8s\tremaining: 6.7s\n",
      "418:\tlearn: 1185.8555901\ttotal: 1m 8s\tremaining: 6.54s\n",
      "419:\tlearn: 1184.8850744\ttotal: 1m 8s\tremaining: 6.37s\n",
      "420:\tlearn: 1183.8414965\ttotal: 1m 8s\tremaining: 6.21s\n",
      "421:\tlearn: 1183.3515337\ttotal: 1m 8s\tremaining: 6.05s\n",
      "422:\tlearn: 1182.7651618\ttotal: 1m 9s\tremaining: 5.88s\n",
      "423:\tlearn: 1182.2594825\ttotal: 1m 9s\tremaining: 5.72s\n",
      "424:\tlearn: 1181.4624104\ttotal: 1m 9s\tremaining: 5.56s\n",
      "425:\tlearn: 1180.8317494\ttotal: 1m 9s\tremaining: 5.4s\n",
      "426:\tlearn: 1179.8038011\ttotal: 1m 9s\tremaining: 5.23s\n",
      "427:\tlearn: 1179.2318492\ttotal: 1m 10s\tremaining: 5.07s\n",
      "428:\tlearn: 1178.1040730\ttotal: 1m 10s\tremaining: 4.91s\n",
      "429:\tlearn: 1177.5143086\ttotal: 1m 10s\tremaining: 4.74s\n",
      "430:\tlearn: 1176.2917148\ttotal: 1m 10s\tremaining: 4.58s\n",
      "431:\tlearn: 1175.4815917\ttotal: 1m 10s\tremaining: 4.42s\n",
      "432:\tlearn: 1174.3709371\ttotal: 1m 10s\tremaining: 4.25s\n",
      "433:\tlearn: 1173.4820189\ttotal: 1m 11s\tremaining: 4.09s\n",
      "434:\tlearn: 1172.7408453\ttotal: 1m 11s\tremaining: 3.93s\n",
      "435:\tlearn: 1172.2885519\ttotal: 1m 11s\tremaining: 3.76s\n",
      "436:\tlearn: 1171.1088671\ttotal: 1m 11s\tremaining: 3.6s\n",
      "437:\tlearn: 1170.4833868\ttotal: 1m 11s\tremaining: 3.44s\n",
      "438:\tlearn: 1169.8521557\ttotal: 1m 11s\tremaining: 3.27s\n",
      "439:\tlearn: 1168.9311893\ttotal: 1m 12s\tremaining: 3.11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440:\tlearn: 1168.2414925\ttotal: 1m 12s\tremaining: 2.95s\n",
      "441:\tlearn: 1167.3666798\ttotal: 1m 12s\tremaining: 2.79s\n",
      "442:\tlearn: 1166.6937480\ttotal: 1m 12s\tremaining: 2.62s\n",
      "443:\tlearn: 1166.1399470\ttotal: 1m 12s\tremaining: 2.46s\n",
      "444:\tlearn: 1164.6699197\ttotal: 1m 12s\tremaining: 2.29s\n",
      "445:\tlearn: 1163.5741549\ttotal: 1m 13s\tremaining: 2.13s\n",
      "446:\tlearn: 1162.7408660\ttotal: 1m 13s\tremaining: 1.97s\n",
      "447:\tlearn: 1162.1062954\ttotal: 1m 13s\tremaining: 1.8s\n",
      "448:\tlearn: 1161.2863252\ttotal: 1m 13s\tremaining: 1.64s\n",
      "449:\tlearn: 1160.4479684\ttotal: 1m 13s\tremaining: 1.48s\n",
      "450:\tlearn: 1159.9056132\ttotal: 1m 14s\tremaining: 1.31s\n",
      "451:\tlearn: 1159.0646897\ttotal: 1m 14s\tremaining: 1.15s\n",
      "452:\tlearn: 1158.0426564\ttotal: 1m 14s\tremaining: 985ms\n",
      "453:\tlearn: 1157.0107299\ttotal: 1m 14s\tremaining: 821ms\n",
      "454:\tlearn: 1156.3526588\ttotal: 1m 14s\tremaining: 657ms\n",
      "455:\tlearn: 1155.8342962\ttotal: 1m 14s\tremaining: 493ms\n",
      "456:\tlearn: 1154.1664584\ttotal: 1m 15s\tremaining: 329ms\n",
      "457:\tlearn: 1153.2466220\ttotal: 1m 15s\tremaining: 164ms\n",
      "458:\tlearn: 1152.5386425\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\tlearn: 4269.0085847\ttotal: 196ms\tremaining: 1m 29s\n",
      "1:\tlearn: 3932.1136399\ttotal: 359ms\tremaining: 1m 22s\n",
      "2:\tlearn: 3611.9785780\ttotal: 539ms\tremaining: 1m 21s\n",
      "3:\tlearn: 3339.6250292\ttotal: 722ms\tremaining: 1m 22s\n",
      "4:\tlearn: 3109.8217728\ttotal: 900ms\tremaining: 1m 21s\n",
      "5:\tlearn: 2907.9280862\ttotal: 1.1s\tremaining: 1m 23s\n",
      "6:\tlearn: 2740.0778770\ttotal: 1.29s\tremaining: 1m 23s\n",
      "7:\tlearn: 2606.9841522\ttotal: 1.47s\tremaining: 1m 22s\n",
      "8:\tlearn: 2481.7951627\ttotal: 1.64s\tremaining: 1m 22s\n",
      "9:\tlearn: 2385.6530163\ttotal: 1.82s\tremaining: 1m 21s\n",
      "10:\tlearn: 2294.6080360\ttotal: 1.99s\tremaining: 1m 21s\n",
      "11:\tlearn: 2227.9242670\ttotal: 2.18s\tremaining: 1m 21s\n",
      "12:\tlearn: 2168.6160525\ttotal: 2.36s\tremaining: 1m 20s\n",
      "13:\tlearn: 2113.2471931\ttotal: 2.54s\tremaining: 1m 20s\n",
      "14:\tlearn: 2070.7717979\ttotal: 2.73s\tremaining: 1m 20s\n",
      "15:\tlearn: 2032.2620429\ttotal: 2.92s\tremaining: 1m 20s\n",
      "16:\tlearn: 2003.9622603\ttotal: 3.08s\tremaining: 1m 20s\n",
      "17:\tlearn: 1977.0087064\ttotal: 3.27s\tremaining: 1m 20s\n",
      "18:\tlearn: 1959.1111526\ttotal: 3.41s\tremaining: 1m 18s\n",
      "19:\tlearn: 1940.7381534\ttotal: 3.58s\tremaining: 1m 18s\n",
      "20:\tlearn: 1922.2214964\ttotal: 3.74s\tremaining: 1m 18s\n",
      "21:\tlearn: 1907.9787428\ttotal: 3.93s\tremaining: 1m 18s\n",
      "22:\tlearn: 1896.7244090\ttotal: 4.1s\tremaining: 1m 17s\n",
      "23:\tlearn: 1883.5449260\ttotal: 4.28s\tremaining: 1m 17s\n",
      "24:\tlearn: 1874.7156779\ttotal: 4.46s\tremaining: 1m 17s\n",
      "25:\tlearn: 1867.0738933\ttotal: 4.64s\tremaining: 1m 17s\n",
      "26:\tlearn: 1861.9594914\ttotal: 4.81s\tremaining: 1m 16s\n",
      "27:\tlearn: 1855.0662061\ttotal: 4.98s\tremaining: 1m 16s\n",
      "28:\tlearn: 1848.0450454\ttotal: 5.15s\tremaining: 1m 16s\n",
      "29:\tlearn: 1841.5989925\ttotal: 5.32s\tremaining: 1m 16s\n",
      "30:\tlearn: 1834.3295466\ttotal: 5.5s\tremaining: 1m 15s\n",
      "31:\tlearn: 1827.3491797\ttotal: 5.67s\tremaining: 1m 15s\n",
      "32:\tlearn: 1822.3719161\ttotal: 5.82s\tremaining: 1m 15s\n",
      "33:\tlearn: 1818.8309797\ttotal: 6s\tremaining: 1m 15s\n",
      "34:\tlearn: 1814.4948775\ttotal: 6.16s\tremaining: 1m 14s\n",
      "35:\tlearn: 1812.2731412\ttotal: 6.34s\tremaining: 1m 14s\n",
      "36:\tlearn: 1806.5727575\ttotal: 6.51s\tremaining: 1m 14s\n",
      "37:\tlearn: 1802.8240803\ttotal: 6.67s\tremaining: 1m 13s\n",
      "38:\tlearn: 1801.1372818\ttotal: 6.83s\tremaining: 1m 13s\n",
      "39:\tlearn: 1796.8160075\ttotal: 6.99s\tremaining: 1m 13s\n",
      "40:\tlearn: 1794.1482802\ttotal: 7.15s\tremaining: 1m 12s\n",
      "41:\tlearn: 1791.3110373\ttotal: 7.33s\tremaining: 1m 12s\n",
      "42:\tlearn: 1789.2574362\ttotal: 7.49s\tremaining: 1m 12s\n",
      "43:\tlearn: 1786.8967978\ttotal: 7.64s\tremaining: 1m 12s\n",
      "44:\tlearn: 1786.1397180\ttotal: 7.79s\tremaining: 1m 11s\n",
      "45:\tlearn: 1784.1836140\ttotal: 7.93s\tremaining: 1m 11s\n",
      "46:\tlearn: 1780.1389726\ttotal: 8.1s\tremaining: 1m 11s\n",
      "47:\tlearn: 1778.7627855\ttotal: 8.26s\tremaining: 1m 10s\n",
      "48:\tlearn: 1774.5675503\ttotal: 8.43s\tremaining: 1m 10s\n",
      "49:\tlearn: 1773.0220702\ttotal: 8.59s\tremaining: 1m 10s\n",
      "50:\tlearn: 1771.0806193\ttotal: 8.76s\tremaining: 1m 10s\n",
      "51:\tlearn: 1769.1162230\ttotal: 8.94s\tremaining: 1m 9s\n",
      "52:\tlearn: 1767.0489514\ttotal: 9.11s\tremaining: 1m 9s\n",
      "53:\tlearn: 1765.2585858\ttotal: 9.26s\tremaining: 1m 9s\n",
      "54:\tlearn: 1763.6770153\ttotal: 9.4s\tremaining: 1m 9s\n",
      "55:\tlearn: 1761.9889701\ttotal: 9.57s\tremaining: 1m 8s\n",
      "56:\tlearn: 1759.4917966\ttotal: 9.71s\tremaining: 1m 8s\n",
      "57:\tlearn: 1758.8138105\ttotal: 9.86s\tremaining: 1m 8s\n",
      "58:\tlearn: 1757.5825869\ttotal: 10s\tremaining: 1m 7s\n",
      "59:\tlearn: 1756.4776736\ttotal: 10.2s\tremaining: 1m 7s\n",
      "60:\tlearn: 1755.0146807\ttotal: 10.3s\tremaining: 1m 7s\n",
      "61:\tlearn: 1751.4956485\ttotal: 10.5s\tremaining: 1m 7s\n",
      "62:\tlearn: 1748.9344086\ttotal: 10.6s\tremaining: 1m 6s\n",
      "63:\tlearn: 1747.7625199\ttotal: 10.8s\tremaining: 1m 6s\n",
      "64:\tlearn: 1746.2522845\ttotal: 11s\tremaining: 1m 6s\n",
      "65:\tlearn: 1744.7166542\ttotal: 11.2s\tremaining: 1m 6s\n",
      "66:\tlearn: 1743.3874372\ttotal: 11.3s\tremaining: 1m 6s\n",
      "67:\tlearn: 1740.4966617\ttotal: 11.5s\tremaining: 1m 5s\n",
      "68:\tlearn: 1738.5417437\ttotal: 11.6s\tremaining: 1m 5s\n",
      "69:\tlearn: 1737.7521973\ttotal: 11.8s\tremaining: 1m 5s\n",
      "70:\tlearn: 1736.6742943\ttotal: 11.9s\tremaining: 1m 5s\n",
      "71:\tlearn: 1734.5579879\ttotal: 12.1s\tremaining: 1m 5s\n",
      "72:\tlearn: 1733.7261790\ttotal: 12.3s\tremaining: 1m 4s\n",
      "73:\tlearn: 1732.3439720\ttotal: 12.4s\tremaining: 1m 4s\n",
      "74:\tlearn: 1731.3915259\ttotal: 12.6s\tremaining: 1m 4s\n",
      "75:\tlearn: 1728.6476348\ttotal: 12.8s\tremaining: 1m 4s\n",
      "76:\tlearn: 1727.1254320\ttotal: 12.9s\tremaining: 1m 4s\n",
      "77:\tlearn: 1725.2290056\ttotal: 13.1s\tremaining: 1m 4s\n",
      "78:\tlearn: 1724.0922921\ttotal: 13.3s\tremaining: 1m 3s\n",
      "79:\tlearn: 1723.2338040\ttotal: 13.4s\tremaining: 1m 3s\n",
      "80:\tlearn: 1721.8903458\ttotal: 13.6s\tremaining: 1m 3s\n",
      "81:\tlearn: 1720.6175312\ttotal: 13.7s\tremaining: 1m 2s\n",
      "82:\tlearn: 1719.4869156\ttotal: 13.9s\tremaining: 1m 2s\n",
      "83:\tlearn: 1717.7098187\ttotal: 14s\tremaining: 1m 2s\n",
      "84:\tlearn: 1716.0796483\ttotal: 14.2s\tremaining: 1m 2s\n",
      "85:\tlearn: 1713.8085622\ttotal: 14.3s\tremaining: 1m 2s\n",
      "86:\tlearn: 1712.5787275\ttotal: 14.5s\tremaining: 1m 1s\n",
      "87:\tlearn: 1710.9352743\ttotal: 14.7s\tremaining: 1m 1s\n",
      "88:\tlearn: 1709.6863222\ttotal: 14.8s\tremaining: 1m 1s\n",
      "89:\tlearn: 1708.5783124\ttotal: 15s\tremaining: 1m 1s\n",
      "90:\tlearn: 1705.7928269\ttotal: 15.2s\tremaining: 1m 1s\n",
      "91:\tlearn: 1702.0283612\ttotal: 15.3s\tremaining: 1m 1s\n",
      "92:\tlearn: 1700.0122878\ttotal: 15.5s\tremaining: 1m\n",
      "93:\tlearn: 1698.6287270\ttotal: 15.6s\tremaining: 1m\n",
      "94:\tlearn: 1696.6529027\ttotal: 15.8s\tremaining: 1m\n",
      "95:\tlearn: 1694.2751095\ttotal: 15.9s\tremaining: 1m\n",
      "96:\tlearn: 1688.6012267\ttotal: 16.1s\tremaining: 1m\n",
      "97:\tlearn: 1683.0303596\ttotal: 16.3s\tremaining: 59.9s\n",
      "98:\tlearn: 1679.3690322\ttotal: 16.4s\tremaining: 59.7s\n",
      "99:\tlearn: 1674.4141702\ttotal: 16.6s\tremaining: 59.6s\n",
      "100:\tlearn: 1670.7990649\ttotal: 16.8s\tremaining: 59.4s\n",
      "101:\tlearn: 1668.5988195\ttotal: 16.9s\tremaining: 59.2s\n",
      "102:\tlearn: 1662.4296390\ttotal: 17.1s\tremaining: 59.1s\n",
      "103:\tlearn: 1658.8404771\ttotal: 17.2s\tremaining: 58.9s\n",
      "104:\tlearn: 1654.8505438\ttotal: 17.4s\tremaining: 58.7s\n",
      "105:\tlearn: 1652.2820788\ttotal: 17.6s\tremaining: 58.5s\n",
      "106:\tlearn: 1647.0279918\ttotal: 17.7s\tremaining: 58.3s\n",
      "107:\tlearn: 1645.0640615\ttotal: 17.9s\tremaining: 58s\n",
      "108:\tlearn: 1641.4380325\ttotal: 18s\tremaining: 57.9s\n",
      "109:\tlearn: 1636.7757546\ttotal: 18.2s\tremaining: 57.7s\n",
      "110:\tlearn: 1632.0924480\ttotal: 18.3s\tremaining: 57.5s\n",
      "111:\tlearn: 1630.7204577\ttotal: 18.5s\tremaining: 57.3s\n",
      "112:\tlearn: 1627.9938193\ttotal: 18.6s\tremaining: 57s\n",
      "113:\tlearn: 1626.2245611\ttotal: 18.8s\tremaining: 56.8s\n",
      "114:\tlearn: 1624.0304003\ttotal: 18.9s\tremaining: 56.6s\n",
      "115:\tlearn: 1622.4713796\ttotal: 19.1s\tremaining: 56.4s\n",
      "116:\tlearn: 1620.3827034\ttotal: 19.2s\tremaining: 56.2s\n",
      "117:\tlearn: 1617.5170102\ttotal: 19.3s\tremaining: 55.9s\n",
      "118:\tlearn: 1613.5411285\ttotal: 19.5s\tremaining: 55.7s\n",
      "119:\tlearn: 1611.5828979\ttotal: 19.6s\tremaining: 55.4s\n",
      "120:\tlearn: 1607.9327171\ttotal: 19.8s\tremaining: 55.2s\n",
      "121:\tlearn: 1604.9752967\ttotal: 19.9s\tremaining: 55s\n",
      "122:\tlearn: 1601.7782614\ttotal: 20.1s\tremaining: 54.8s\n",
      "123:\tlearn: 1598.0781455\ttotal: 20.2s\tremaining: 54.6s\n",
      "124:\tlearn: 1595.3672164\ttotal: 20.4s\tremaining: 54.4s\n",
      "125:\tlearn: 1593.7506487\ttotal: 20.5s\tremaining: 54.2s\n",
      "126:\tlearn: 1591.5593641\ttotal: 20.6s\tremaining: 54s\n",
      "127:\tlearn: 1587.4351251\ttotal: 20.8s\tremaining: 53.8s\n",
      "128:\tlearn: 1585.3678260\ttotal: 20.9s\tremaining: 53.6s\n",
      "129:\tlearn: 1580.4000605\ttotal: 21.1s\tremaining: 53.5s\n",
      "130:\tlearn: 1576.4788126\ttotal: 21.3s\tremaining: 53.3s\n",
      "131:\tlearn: 1573.1031540\ttotal: 21.5s\tremaining: 53.2s\n",
      "132:\tlearn: 1569.4853718\ttotal: 21.6s\tremaining: 53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133:\tlearn: 1566.6125770\ttotal: 21.8s\tremaining: 52.9s\n",
      "134:\tlearn: 1564.7484885\ttotal: 21.9s\tremaining: 52.7s\n",
      "135:\tlearn: 1562.3279678\ttotal: 22.1s\tremaining: 52.5s\n",
      "136:\tlearn: 1561.2515256\ttotal: 22.3s\tremaining: 52.3s\n",
      "137:\tlearn: 1560.2842730\ttotal: 22.4s\tremaining: 52.1s\n",
      "138:\tlearn: 1558.7917085\ttotal: 22.5s\tremaining: 51.8s\n",
      "139:\tlearn: 1556.6528768\ttotal: 22.7s\tremaining: 51.6s\n",
      "140:\tlearn: 1550.9745222\ttotal: 22.9s\tremaining: 51.5s\n",
      "141:\tlearn: 1547.2703691\ttotal: 23s\tremaining: 51.4s\n",
      "142:\tlearn: 1545.8514775\ttotal: 23.1s\tremaining: 51.1s\n",
      "143:\tlearn: 1543.8070517\ttotal: 23.3s\tremaining: 50.9s\n",
      "144:\tlearn: 1542.2871963\ttotal: 23.4s\tremaining: 50.7s\n",
      "145:\tlearn: 1540.3165797\ttotal: 23.6s\tremaining: 50.6s\n",
      "146:\tlearn: 1536.9516317\ttotal: 23.8s\tremaining: 50.5s\n",
      "147:\tlearn: 1535.2963379\ttotal: 24s\tremaining: 50.4s\n",
      "148:\tlearn: 1533.8945618\ttotal: 24.1s\tremaining: 50.2s\n",
      "149:\tlearn: 1532.1231286\ttotal: 24.3s\tremaining: 50s\n",
      "150:\tlearn: 1530.9569860\ttotal: 24.4s\tremaining: 49.8s\n",
      "151:\tlearn: 1530.5137754\ttotal: 24.5s\tremaining: 49.5s\n",
      "152:\tlearn: 1528.9083257\ttotal: 24.7s\tremaining: 49.3s\n",
      "153:\tlearn: 1527.7548978\ttotal: 24.8s\tremaining: 49.1s\n",
      "154:\tlearn: 1524.8172167\ttotal: 25s\tremaining: 49s\n",
      "155:\tlearn: 1522.7858325\ttotal: 25.1s\tremaining: 48.8s\n",
      "156:\tlearn: 1520.7630596\ttotal: 25.3s\tremaining: 48.6s\n",
      "157:\tlearn: 1518.1115553\ttotal: 25.4s\tremaining: 48.5s\n",
      "158:\tlearn: 1517.4637286\ttotal: 25.6s\tremaining: 48.2s\n",
      "159:\tlearn: 1515.3731769\ttotal: 25.7s\tremaining: 48s\n",
      "160:\tlearn: 1514.2289034\ttotal: 25.8s\tremaining: 47.8s\n",
      "161:\tlearn: 1513.2567262\ttotal: 26s\tremaining: 47.6s\n",
      "162:\tlearn: 1510.4739256\ttotal: 26.1s\tremaining: 47.4s\n",
      "163:\tlearn: 1509.2867864\ttotal: 26.3s\tremaining: 47.2s\n",
      "164:\tlearn: 1506.5924818\ttotal: 26.4s\tremaining: 47.1s\n",
      "165:\tlearn: 1505.6948224\ttotal: 26.6s\tremaining: 46.9s\n",
      "166:\tlearn: 1502.8276556\ttotal: 26.8s\tremaining: 46.8s\n",
      "167:\tlearn: 1501.4156938\ttotal: 26.9s\tremaining: 46.6s\n",
      "168:\tlearn: 1498.1030475\ttotal: 27.1s\tremaining: 46.5s\n",
      "169:\tlearn: 1496.7089960\ttotal: 27.2s\tremaining: 46.3s\n",
      "170:\tlearn: 1492.4220359\ttotal: 27.4s\tremaining: 46.2s\n",
      "171:\tlearn: 1490.7191739\ttotal: 27.5s\tremaining: 46s\n",
      "172:\tlearn: 1489.0203970\ttotal: 27.7s\tremaining: 45.8s\n",
      "173:\tlearn: 1486.8844931\ttotal: 27.9s\tremaining: 45.6s\n",
      "174:\tlearn: 1485.5226029\ttotal: 28s\tremaining: 45.4s\n",
      "175:\tlearn: 1483.2699857\ttotal: 28.2s\tremaining: 45.3s\n",
      "176:\tlearn: 1479.7987640\ttotal: 28.4s\tremaining: 45.2s\n",
      "177:\tlearn: 1476.6567766\ttotal: 28.5s\tremaining: 45s\n",
      "178:\tlearn: 1475.6633847\ttotal: 28.7s\tremaining: 44.8s\n",
      "179:\tlearn: 1473.1617481\ttotal: 28.8s\tremaining: 44.7s\n",
      "180:\tlearn: 1471.2442775\ttotal: 29s\tremaining: 44.5s\n",
      "181:\tlearn: 1468.5442514\ttotal: 29.2s\tremaining: 44.4s\n",
      "182:\tlearn: 1465.3166160\ttotal: 29.3s\tremaining: 44.2s\n",
      "183:\tlearn: 1464.4497827\ttotal: 29.5s\tremaining: 44.1s\n",
      "184:\tlearn: 1462.6277955\ttotal: 29.6s\tremaining: 43.9s\n",
      "185:\tlearn: 1460.5253344\ttotal: 29.8s\tremaining: 43.7s\n",
      "186:\tlearn: 1459.6007783\ttotal: 29.9s\tremaining: 43.5s\n",
      "187:\tlearn: 1457.5088137\ttotal: 30.1s\tremaining: 43.4s\n",
      "188:\tlearn: 1455.9823612\ttotal: 30.2s\tremaining: 43.2s\n",
      "189:\tlearn: 1455.0156687\ttotal: 30.4s\tremaining: 43s\n",
      "190:\tlearn: 1454.1118038\ttotal: 30.5s\tremaining: 42.8s\n",
      "191:\tlearn: 1452.3810454\ttotal: 30.7s\tremaining: 42.6s\n",
      "192:\tlearn: 1451.2358194\ttotal: 30.8s\tremaining: 42.5s\n",
      "193:\tlearn: 1448.7944580\ttotal: 31s\tremaining: 42.3s\n",
      "194:\tlearn: 1448.0742497\ttotal: 31.1s\tremaining: 42.1s\n",
      "195:\tlearn: 1445.9941367\ttotal: 31.3s\tremaining: 42s\n",
      "196:\tlearn: 1444.8118343\ttotal: 31.4s\tremaining: 41.8s\n",
      "197:\tlearn: 1444.0376285\ttotal: 31.6s\tremaining: 41.6s\n",
      "198:\tlearn: 1443.3192947\ttotal: 31.7s\tremaining: 41.4s\n",
      "199:\tlearn: 1443.0701099\ttotal: 31.8s\tremaining: 41.2s\n",
      "200:\tlearn: 1440.5317181\ttotal: 32s\tremaining: 41.1s\n",
      "201:\tlearn: 1438.2550006\ttotal: 32.2s\tremaining: 41s\n",
      "202:\tlearn: 1437.4583729\ttotal: 32.3s\tremaining: 40.8s\n",
      "203:\tlearn: 1435.4609745\ttotal: 32.5s\tremaining: 40.6s\n",
      "204:\tlearn: 1434.2746814\ttotal: 32.6s\tremaining: 40.4s\n",
      "205:\tlearn: 1431.2894668\ttotal: 32.8s\tremaining: 40.3s\n",
      "206:\tlearn: 1430.1810001\ttotal: 33s\tremaining: 40.1s\n",
      "207:\tlearn: 1428.4970388\ttotal: 33.3s\tremaining: 40.1s\n",
      "208:\tlearn: 1426.3868559\ttotal: 33.4s\tremaining: 40s\n",
      "209:\tlearn: 1424.6591216\ttotal: 33.6s\tremaining: 39.8s\n",
      "210:\tlearn: 1424.2776478\ttotal: 33.7s\tremaining: 39.6s\n",
      "211:\tlearn: 1422.8748344\ttotal: 33.9s\tremaining: 39.5s\n",
      "212:\tlearn: 1422.3285981\ttotal: 34s\tremaining: 39.3s\n",
      "213:\tlearn: 1420.9399134\ttotal: 34.2s\tremaining: 39.1s\n",
      "214:\tlearn: 1419.0028883\ttotal: 34.4s\tremaining: 39s\n",
      "215:\tlearn: 1417.6262616\ttotal: 34.5s\tremaining: 38.8s\n",
      "216:\tlearn: 1416.5995978\ttotal: 34.7s\tremaining: 38.7s\n",
      "217:\tlearn: 1415.5836203\ttotal: 34.9s\tremaining: 38.5s\n",
      "218:\tlearn: 1414.5431375\ttotal: 35s\tremaining: 38.4s\n",
      "219:\tlearn: 1413.4269362\ttotal: 35.2s\tremaining: 38.2s\n",
      "220:\tlearn: 1412.4680424\ttotal: 35.3s\tremaining: 38.1s\n",
      "221:\tlearn: 1411.2910380\ttotal: 35.5s\tremaining: 37.9s\n",
      "222:\tlearn: 1409.4817689\ttotal: 35.7s\tremaining: 37.7s\n",
      "223:\tlearn: 1407.0923420\ttotal: 35.8s\tremaining: 37.6s\n",
      "224:\tlearn: 1404.3109990\ttotal: 36s\tremaining: 37.5s\n",
      "225:\tlearn: 1402.3278283\ttotal: 36.2s\tremaining: 37.3s\n",
      "226:\tlearn: 1400.6182581\ttotal: 36.4s\tremaining: 37.2s\n",
      "227:\tlearn: 1399.3497447\ttotal: 36.5s\tremaining: 37s\n",
      "228:\tlearn: 1396.8686156\ttotal: 36.7s\tremaining: 36.8s\n",
      "229:\tlearn: 1395.3859542\ttotal: 36.9s\tremaining: 36.7s\n",
      "230:\tlearn: 1393.4092927\ttotal: 37s\tremaining: 36.5s\n",
      "231:\tlearn: 1392.3682241\ttotal: 37.2s\tremaining: 36.4s\n",
      "232:\tlearn: 1391.2146540\ttotal: 37.3s\tremaining: 36.2s\n",
      "233:\tlearn: 1390.0150653\ttotal: 37.5s\tremaining: 36s\n",
      "234:\tlearn: 1389.3778345\ttotal: 37.6s\tremaining: 35.9s\n",
      "235:\tlearn: 1387.8590330\ttotal: 37.8s\tremaining: 35.7s\n",
      "236:\tlearn: 1385.7260811\ttotal: 38s\tremaining: 35.6s\n",
      "237:\tlearn: 1385.2632157\ttotal: 38.1s\tremaining: 35.4s\n",
      "238:\tlearn: 1383.9300097\ttotal: 38.3s\tremaining: 35.2s\n",
      "239:\tlearn: 1383.2484951\ttotal: 38.4s\tremaining: 35s\n",
      "240:\tlearn: 1382.2653216\ttotal: 38.6s\tremaining: 34.9s\n",
      "241:\tlearn: 1381.0220131\ttotal: 38.7s\tremaining: 34.7s\n",
      "242:\tlearn: 1380.5899348\ttotal: 38.9s\tremaining: 34.5s\n",
      "243:\tlearn: 1379.1612289\ttotal: 39s\tremaining: 34.4s\n",
      "244:\tlearn: 1377.9507765\ttotal: 39.2s\tremaining: 34.2s\n",
      "245:\tlearn: 1376.9564035\ttotal: 39.4s\tremaining: 34.1s\n",
      "246:\tlearn: 1376.4256683\ttotal: 39.5s\tremaining: 33.9s\n",
      "247:\tlearn: 1374.6728294\ttotal: 39.7s\tremaining: 33.8s\n",
      "248:\tlearn: 1373.2660866\ttotal: 39.8s\tremaining: 33.6s\n",
      "249:\tlearn: 1371.8501128\ttotal: 40s\tremaining: 33.4s\n",
      "250:\tlearn: 1370.5073345\ttotal: 40.2s\tremaining: 33.3s\n",
      "251:\tlearn: 1369.3742999\ttotal: 40.3s\tremaining: 33.1s\n",
      "252:\tlearn: 1368.4043917\ttotal: 40.4s\tremaining: 32.9s\n",
      "253:\tlearn: 1365.9533135\ttotal: 40.6s\tremaining: 32.8s\n",
      "254:\tlearn: 1365.1383297\ttotal: 40.8s\tremaining: 32.6s\n",
      "255:\tlearn: 1363.3936438\ttotal: 40.9s\tremaining: 32.5s\n",
      "256:\tlearn: 1361.0679820\ttotal: 41.1s\tremaining: 32.3s\n",
      "257:\tlearn: 1360.3279054\ttotal: 41.3s\tremaining: 32.2s\n",
      "258:\tlearn: 1359.4851955\ttotal: 41.4s\tremaining: 32s\n",
      "259:\tlearn: 1358.5515992\ttotal: 41.6s\tremaining: 31.8s\n",
      "260:\tlearn: 1356.5082784\ttotal: 41.7s\tremaining: 31.7s\n",
      "261:\tlearn: 1355.9001658\ttotal: 41.8s\tremaining: 31.5s\n",
      "262:\tlearn: 1355.4233061\ttotal: 42s\tremaining: 31.3s\n",
      "263:\tlearn: 1354.2521130\ttotal: 42.1s\tremaining: 31.1s\n",
      "264:\tlearn: 1353.3306465\ttotal: 42.3s\tremaining: 31s\n",
      "265:\tlearn: 1352.3948188\ttotal: 42.5s\tremaining: 30.8s\n",
      "266:\tlearn: 1350.7351234\ttotal: 42.6s\tremaining: 30.7s\n",
      "267:\tlearn: 1349.8668635\ttotal: 42.8s\tremaining: 30.5s\n",
      "268:\tlearn: 1348.6686001\ttotal: 42.9s\tremaining: 30.3s\n",
      "269:\tlearn: 1347.9808607\ttotal: 43.1s\tremaining: 30.2s\n",
      "270:\tlearn: 1346.8726773\ttotal: 43.2s\tremaining: 30s\n",
      "271:\tlearn: 1345.2162063\ttotal: 43.4s\tremaining: 29.9s\n",
      "272:\tlearn: 1343.7849085\ttotal: 43.6s\tremaining: 29.7s\n",
      "273:\tlearn: 1342.8450122\ttotal: 43.7s\tremaining: 29.5s\n",
      "274:\tlearn: 1341.0214988\ttotal: 43.9s\tremaining: 29.4s\n",
      "275:\tlearn: 1339.7145997\ttotal: 44.1s\tremaining: 29.2s\n",
      "276:\tlearn: 1338.5073277\ttotal: 44.3s\tremaining: 29.1s\n",
      "277:\tlearn: 1337.7998422\ttotal: 44.4s\tremaining: 28.9s\n",
      "278:\tlearn: 1337.3000448\ttotal: 44.6s\tremaining: 28.8s\n",
      "279:\tlearn: 1335.6304437\ttotal: 44.8s\tremaining: 28.6s\n",
      "280:\tlearn: 1333.3265118\ttotal: 44.9s\tremaining: 28.5s\n",
      "281:\tlearn: 1331.2734519\ttotal: 45.1s\tremaining: 28.3s\n",
      "282:\tlearn: 1330.5134247\ttotal: 45.3s\tremaining: 28.2s\n",
      "283:\tlearn: 1329.4481340\ttotal: 45.5s\tremaining: 28s\n",
      "284:\tlearn: 1328.5607201\ttotal: 45.6s\tremaining: 27.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285:\tlearn: 1326.9716254\ttotal: 45.8s\tremaining: 27.7s\n",
      "286:\tlearn: 1325.8572966\ttotal: 45.9s\tremaining: 27.5s\n",
      "287:\tlearn: 1324.8711187\ttotal: 46.1s\tremaining: 27.4s\n",
      "288:\tlearn: 1323.1621971\ttotal: 46.3s\tremaining: 27.2s\n",
      "289:\tlearn: 1321.6326190\ttotal: 46.5s\tremaining: 27.1s\n",
      "290:\tlearn: 1320.9316211\ttotal: 46.6s\tremaining: 26.9s\n",
      "291:\tlearn: 1318.5273821\ttotal: 46.8s\tremaining: 26.8s\n",
      "292:\tlearn: 1316.9957571\ttotal: 47s\tremaining: 26.6s\n",
      "293:\tlearn: 1316.0475671\ttotal: 47.2s\tremaining: 26.5s\n",
      "294:\tlearn: 1314.5162527\ttotal: 47.3s\tremaining: 26.3s\n",
      "295:\tlearn: 1313.0786723\ttotal: 47.5s\tremaining: 26.2s\n",
      "296:\tlearn: 1312.3495656\ttotal: 47.7s\tremaining: 26s\n",
      "297:\tlearn: 1310.9599499\ttotal: 47.8s\tremaining: 25.8s\n",
      "298:\tlearn: 1310.0003347\ttotal: 48s\tremaining: 25.7s\n",
      "299:\tlearn: 1308.5660178\ttotal: 48.2s\tremaining: 25.5s\n",
      "300:\tlearn: 1307.5212974\ttotal: 48.3s\tremaining: 25.3s\n",
      "301:\tlearn: 1306.4243423\ttotal: 48.5s\tremaining: 25.2s\n",
      "302:\tlearn: 1304.7929800\ttotal: 48.7s\tremaining: 25.1s\n",
      "303:\tlearn: 1303.8781621\ttotal: 48.8s\tremaining: 24.9s\n",
      "304:\tlearn: 1303.1732387\ttotal: 49s\tremaining: 24.7s\n",
      "305:\tlearn: 1302.4527092\ttotal: 49.1s\tremaining: 24.6s\n",
      "306:\tlearn: 1301.0475288\ttotal: 49.3s\tremaining: 24.4s\n",
      "307:\tlearn: 1300.1425803\ttotal: 49.5s\tremaining: 24.2s\n",
      "308:\tlearn: 1298.8324162\ttotal: 49.6s\tremaining: 24.1s\n",
      "309:\tlearn: 1297.9948465\ttotal: 49.8s\tremaining: 23.9s\n",
      "310:\tlearn: 1296.6227304\ttotal: 50s\tremaining: 23.8s\n",
      "311:\tlearn: 1296.2531156\ttotal: 50.1s\tremaining: 23.6s\n",
      "312:\tlearn: 1294.8173256\ttotal: 50.3s\tremaining: 23.5s\n",
      "313:\tlearn: 1293.8565682\ttotal: 50.5s\tremaining: 23.3s\n",
      "314:\tlearn: 1292.7670754\ttotal: 50.7s\tremaining: 23.2s\n",
      "315:\tlearn: 1291.1436238\ttotal: 50.9s\tremaining: 23s\n",
      "316:\tlearn: 1289.7139483\ttotal: 51.1s\tremaining: 22.9s\n",
      "317:\tlearn: 1288.3386343\ttotal: 51.3s\tremaining: 22.8s\n",
      "318:\tlearn: 1286.9759209\ttotal: 51.5s\tremaining: 22.6s\n",
      "319:\tlearn: 1285.8393283\ttotal: 51.8s\tremaining: 22.5s\n",
      "320:\tlearn: 1285.3292784\ttotal: 51.9s\tremaining: 22.3s\n",
      "321:\tlearn: 1284.0300487\ttotal: 52.2s\tremaining: 22.2s\n",
      "322:\tlearn: 1283.3751814\ttotal: 52.4s\tremaining: 22.1s\n",
      "323:\tlearn: 1282.6969027\ttotal: 52.6s\tremaining: 21.9s\n",
      "324:\tlearn: 1281.7271217\ttotal: 52.8s\tremaining: 21.8s\n",
      "325:\tlearn: 1280.4730696\ttotal: 53s\tremaining: 21.6s\n",
      "326:\tlearn: 1278.3930142\ttotal: 53.2s\tremaining: 21.5s\n",
      "327:\tlearn: 1277.4296982\ttotal: 53.4s\tremaining: 21.3s\n",
      "328:\tlearn: 1276.3847822\ttotal: 53.6s\tremaining: 21.2s\n",
      "329:\tlearn: 1275.4935488\ttotal: 53.8s\tremaining: 21s\n",
      "330:\tlearn: 1274.0325760\ttotal: 54s\tremaining: 20.9s\n",
      "331:\tlearn: 1273.0061342\ttotal: 54.2s\tremaining: 20.7s\n",
      "332:\tlearn: 1272.1753189\ttotal: 54.3s\tremaining: 20.6s\n",
      "333:\tlearn: 1271.0589029\ttotal: 54.5s\tremaining: 20.4s\n",
      "334:\tlearn: 1270.1919672\ttotal: 54.6s\tremaining: 20.2s\n",
      "335:\tlearn: 1268.7163647\ttotal: 54.8s\tremaining: 20.1s\n",
      "336:\tlearn: 1266.6325515\ttotal: 55.1s\tremaining: 19.9s\n",
      "337:\tlearn: 1266.1348893\ttotal: 55.2s\tremaining: 19.8s\n",
      "338:\tlearn: 1265.3270880\ttotal: 55.4s\tremaining: 19.6s\n",
      "339:\tlearn: 1264.0057764\ttotal: 55.5s\tremaining: 19.4s\n",
      "340:\tlearn: 1263.4068830\ttotal: 55.7s\tremaining: 19.3s\n",
      "341:\tlearn: 1262.0366592\ttotal: 55.9s\tremaining: 19.1s\n",
      "342:\tlearn: 1261.4603616\ttotal: 56.1s\tremaining: 19s\n",
      "343:\tlearn: 1260.0862678\ttotal: 56.4s\tremaining: 18.8s\n",
      "344:\tlearn: 1259.6061250\ttotal: 56.6s\tremaining: 18.7s\n",
      "345:\tlearn: 1258.3621457\ttotal: 56.8s\tremaining: 18.5s\n",
      "346:\tlearn: 1257.1564540\ttotal: 57s\tremaining: 18.4s\n",
      "347:\tlearn: 1256.7827822\ttotal: 57.1s\tremaining: 18.2s\n",
      "348:\tlearn: 1255.9510149\ttotal: 57.3s\tremaining: 18.1s\n",
      "349:\tlearn: 1255.3563925\ttotal: 57.4s\tremaining: 17.9s\n",
      "350:\tlearn: 1254.3625003\ttotal: 57.6s\tremaining: 17.7s\n",
      "351:\tlearn: 1253.5878500\ttotal: 57.8s\tremaining: 17.6s\n",
      "352:\tlearn: 1252.2286150\ttotal: 57.9s\tremaining: 17.4s\n",
      "353:\tlearn: 1251.5712090\ttotal: 58.1s\tremaining: 17.2s\n",
      "354:\tlearn: 1250.5185871\ttotal: 58.3s\tremaining: 17.1s\n",
      "355:\tlearn: 1249.5837646\ttotal: 58.5s\tremaining: 16.9s\n",
      "356:\tlearn: 1248.4378321\ttotal: 58.6s\tremaining: 16.8s\n",
      "357:\tlearn: 1247.7675647\ttotal: 58.8s\tremaining: 16.6s\n",
      "358:\tlearn: 1246.9620737\ttotal: 59s\tremaining: 16.4s\n",
      "359:\tlearn: 1245.8168695\ttotal: 59.2s\tremaining: 16.3s\n",
      "360:\tlearn: 1245.2064492\ttotal: 59.3s\tremaining: 16.1s\n",
      "361:\tlearn: 1244.2601954\ttotal: 59.5s\tremaining: 15.9s\n",
      "362:\tlearn: 1243.7042664\ttotal: 59.7s\tremaining: 15.8s\n",
      "363:\tlearn: 1242.9964221\ttotal: 59.8s\tremaining: 15.6s\n",
      "364:\tlearn: 1242.1408992\ttotal: 1m\tremaining: 15.5s\n",
      "365:\tlearn: 1241.1334427\ttotal: 1m\tremaining: 15.3s\n",
      "366:\tlearn: 1239.8721297\ttotal: 1m\tremaining: 15.1s\n",
      "367:\tlearn: 1239.1101767\ttotal: 1m\tremaining: 15s\n",
      "368:\tlearn: 1238.2452747\ttotal: 1m\tremaining: 14.8s\n",
      "369:\tlearn: 1237.6526888\ttotal: 1m\tremaining: 14.6s\n",
      "370:\tlearn: 1236.0281564\ttotal: 1m 1s\tremaining: 14.5s\n",
      "371:\tlearn: 1234.9000964\ttotal: 1m 1s\tremaining: 14.3s\n",
      "372:\tlearn: 1234.3608477\ttotal: 1m 1s\tremaining: 14.2s\n",
      "373:\tlearn: 1232.7692056\ttotal: 1m 1s\tremaining: 14s\n",
      "374:\tlearn: 1231.9478521\ttotal: 1m 1s\tremaining: 13.8s\n",
      "375:\tlearn: 1230.9263671\ttotal: 1m 1s\tremaining: 13.7s\n",
      "376:\tlearn: 1229.6775912\ttotal: 1m 2s\tremaining: 13.5s\n",
      "377:\tlearn: 1228.2731885\ttotal: 1m 2s\tremaining: 13.4s\n",
      "378:\tlearn: 1227.5556799\ttotal: 1m 2s\tremaining: 13.2s\n",
      "379:\tlearn: 1226.7095441\ttotal: 1m 2s\tremaining: 13s\n",
      "380:\tlearn: 1225.2011062\ttotal: 1m 2s\tremaining: 12.9s\n",
      "381:\tlearn: 1224.5072109\ttotal: 1m 3s\tremaining: 12.7s\n",
      "382:\tlearn: 1223.7853933\ttotal: 1m 3s\tremaining: 12.5s\n",
      "383:\tlearn: 1223.0001730\ttotal: 1m 3s\tremaining: 12.4s\n",
      "384:\tlearn: 1222.4957184\ttotal: 1m 3s\tremaining: 12.2s\n",
      "385:\tlearn: 1221.4962649\ttotal: 1m 3s\tremaining: 12.1s\n",
      "386:\tlearn: 1220.5321845\ttotal: 1m 3s\tremaining: 11.9s\n",
      "387:\tlearn: 1219.4394551\ttotal: 1m 4s\tremaining: 11.7s\n",
      "388:\tlearn: 1218.0976842\ttotal: 1m 4s\tremaining: 11.6s\n",
      "389:\tlearn: 1216.5961802\ttotal: 1m 4s\tremaining: 11.4s\n",
      "390:\tlearn: 1215.7389963\ttotal: 1m 4s\tremaining: 11.2s\n",
      "391:\tlearn: 1214.5734159\ttotal: 1m 4s\tremaining: 11.1s\n",
      "392:\tlearn: 1213.6064110\ttotal: 1m 5s\tremaining: 10.9s\n",
      "393:\tlearn: 1212.8644399\ttotal: 1m 5s\tremaining: 10.8s\n",
      "394:\tlearn: 1211.6496489\ttotal: 1m 5s\tremaining: 10.6s\n",
      "395:\tlearn: 1209.8164197\ttotal: 1m 5s\tremaining: 10.4s\n",
      "396:\tlearn: 1208.3217276\ttotal: 1m 5s\tremaining: 10.3s\n",
      "397:\tlearn: 1207.3536720\ttotal: 1m 5s\tremaining: 10.1s\n",
      "398:\tlearn: 1206.4306771\ttotal: 1m 6s\tremaining: 9.94s\n",
      "399:\tlearn: 1205.5513247\ttotal: 1m 6s\tremaining: 9.78s\n",
      "400:\tlearn: 1203.9041068\ttotal: 1m 6s\tremaining: 9.61s\n",
      "401:\tlearn: 1203.0134636\ttotal: 1m 6s\tremaining: 9.45s\n",
      "402:\tlearn: 1202.2625838\ttotal: 1m 6s\tremaining: 9.28s\n",
      "403:\tlearn: 1201.5746492\ttotal: 1m 6s\tremaining: 9.12s\n",
      "404:\tlearn: 1201.1088209\ttotal: 1m 7s\tremaining: 8.95s\n",
      "405:\tlearn: 1200.2558844\ttotal: 1m 7s\tremaining: 8.78s\n",
      "406:\tlearn: 1199.1496543\ttotal: 1m 7s\tremaining: 8.62s\n",
      "407:\tlearn: 1197.7215824\ttotal: 1m 7s\tremaining: 8.46s\n",
      "408:\tlearn: 1196.4962795\ttotal: 1m 7s\tremaining: 8.3s\n",
      "409:\tlearn: 1195.6929944\ttotal: 1m 8s\tremaining: 8.13s\n",
      "410:\tlearn: 1194.4531246\ttotal: 1m 8s\tremaining: 7.97s\n",
      "411:\tlearn: 1193.6528281\ttotal: 1m 8s\tremaining: 7.8s\n",
      "412:\tlearn: 1192.8851745\ttotal: 1m 8s\tremaining: 7.64s\n",
      "413:\tlearn: 1192.1466296\ttotal: 1m 8s\tremaining: 7.47s\n",
      "414:\tlearn: 1190.7602670\ttotal: 1m 8s\tremaining: 7.31s\n",
      "415:\tlearn: 1190.1376412\ttotal: 1m 9s\tremaining: 7.14s\n",
      "416:\tlearn: 1189.5159563\ttotal: 1m 9s\tremaining: 6.98s\n",
      "417:\tlearn: 1188.5105898\ttotal: 1m 9s\tremaining: 6.81s\n",
      "418:\tlearn: 1187.8819329\ttotal: 1m 9s\tremaining: 6.64s\n",
      "419:\tlearn: 1187.2016292\ttotal: 1m 9s\tremaining: 6.48s\n",
      "420:\tlearn: 1186.2252039\ttotal: 1m 9s\tremaining: 6.31s\n",
      "421:\tlearn: 1185.1478775\ttotal: 1m 10s\tremaining: 6.15s\n",
      "422:\tlearn: 1183.9756726\ttotal: 1m 10s\tremaining: 5.99s\n",
      "423:\tlearn: 1182.9148025\ttotal: 1m 10s\tremaining: 5.82s\n",
      "424:\tlearn: 1181.8302304\ttotal: 1m 10s\tremaining: 5.66s\n",
      "425:\tlearn: 1180.5267422\ttotal: 1m 10s\tremaining: 5.49s\n",
      "426:\tlearn: 1179.3904358\ttotal: 1m 11s\tremaining: 5.33s\n",
      "427:\tlearn: 1177.9322054\ttotal: 1m 11s\tremaining: 5.16s\n",
      "428:\tlearn: 1177.1496233\ttotal: 1m 11s\tremaining: 5s\n",
      "429:\tlearn: 1176.7524545\ttotal: 1m 11s\tremaining: 4.83s\n",
      "430:\tlearn: 1175.3589480\ttotal: 1m 11s\tremaining: 4.67s\n",
      "431:\tlearn: 1174.1580047\ttotal: 1m 12s\tremaining: 4.5s\n",
      "432:\tlearn: 1173.5147157\ttotal: 1m 12s\tremaining: 4.33s\n",
      "433:\tlearn: 1172.3875079\ttotal: 1m 12s\tremaining: 4.17s\n",
      "434:\tlearn: 1172.1095495\ttotal: 1m 12s\tremaining: 4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435:\tlearn: 1171.4234881\ttotal: 1m 12s\tremaining: 3.83s\n",
      "436:\tlearn: 1170.3069857\ttotal: 1m 12s\tremaining: 3.67s\n",
      "437:\tlearn: 1169.6215736\ttotal: 1m 13s\tremaining: 3.5s\n",
      "438:\tlearn: 1168.5713947\ttotal: 1m 13s\tremaining: 3.34s\n",
      "439:\tlearn: 1167.8006799\ttotal: 1m 13s\tremaining: 3.17s\n",
      "440:\tlearn: 1166.6942722\ttotal: 1m 13s\tremaining: 3s\n",
      "441:\tlearn: 1165.8601639\ttotal: 1m 13s\tremaining: 2.84s\n",
      "442:\tlearn: 1164.9348804\ttotal: 1m 13s\tremaining: 2.67s\n",
      "443:\tlearn: 1163.8855320\ttotal: 1m 14s\tremaining: 2.5s\n",
      "444:\tlearn: 1163.1463038\ttotal: 1m 14s\tremaining: 2.34s\n",
      "445:\tlearn: 1162.6123342\ttotal: 1m 14s\tremaining: 2.17s\n",
      "446:\tlearn: 1161.5512781\ttotal: 1m 14s\tremaining: 2s\n",
      "447:\tlearn: 1160.5834141\ttotal: 1m 14s\tremaining: 1.84s\n",
      "448:\tlearn: 1159.7629782\ttotal: 1m 15s\tremaining: 1.67s\n",
      "449:\tlearn: 1158.7113020\ttotal: 1m 15s\tremaining: 1.5s\n",
      "450:\tlearn: 1157.8370887\ttotal: 1m 15s\tremaining: 1.34s\n",
      "451:\tlearn: 1156.8692450\ttotal: 1m 15s\tremaining: 1.17s\n",
      "452:\tlearn: 1156.0513214\ttotal: 1m 15s\tremaining: 1s\n",
      "453:\tlearn: 1155.4899395\ttotal: 1m 15s\tremaining: 837ms\n",
      "454:\tlearn: 1155.0021007\ttotal: 1m 16s\tremaining: 670ms\n",
      "455:\tlearn: 1154.4257868\ttotal: 1m 16s\tremaining: 502ms\n",
      "456:\tlearn: 1153.4662855\ttotal: 1m 16s\tremaining: 335ms\n",
      "457:\tlearn: 1152.6314072\ttotal: 1m 16s\tremaining: 167ms\n",
      "458:\tlearn: 1151.5566183\ttotal: 1m 16s\tremaining: 0us\n",
      "Cross-Validation RMSE Scores: [1574.85029783 1576.52261921 1592.11149693 1571.85279946 1595.27289646]\n",
      "Mean Cross-Validation RMSE: 1582.122021976741\n",
      "Standard Deviation of Cross-Validation RMSE: 9.616894758271716\n",
      "0:\tlearn: 4269.2514841\ttotal: 155ms\tremaining: 1m 11s\n",
      "1:\tlearn: 3920.4949266\ttotal: 300ms\tremaining: 1m 8s\n",
      "2:\tlearn: 3607.7581430\ttotal: 437ms\tremaining: 1m 6s\n",
      "3:\tlearn: 3332.7920768\ttotal: 574ms\tremaining: 1m 5s\n",
      "4:\tlearn: 3098.2879205\ttotal: 717ms\tremaining: 1m 5s\n",
      "5:\tlearn: 2915.5611334\ttotal: 848ms\tremaining: 1m 4s\n",
      "6:\tlearn: 2740.2294284\ttotal: 984ms\tremaining: 1m 3s\n",
      "7:\tlearn: 2608.4061674\ttotal: 1.13s\tremaining: 1m 3s\n",
      "8:\tlearn: 2490.1567724\ttotal: 1.26s\tremaining: 1m 3s\n",
      "9:\tlearn: 2396.0535356\ttotal: 1.41s\tremaining: 1m 3s\n",
      "10:\tlearn: 2316.6878622\ttotal: 1.54s\tremaining: 1m 2s\n",
      "11:\tlearn: 2249.2665886\ttotal: 1.67s\tremaining: 1m 2s\n",
      "12:\tlearn: 2191.9198948\ttotal: 1.8s\tremaining: 1m 1s\n",
      "13:\tlearn: 2156.3509422\ttotal: 1.92s\tremaining: 1m 1s\n",
      "14:\tlearn: 2115.9833974\ttotal: 2.06s\tremaining: 1m\n",
      "15:\tlearn: 2079.4683912\ttotal: 2.19s\tremaining: 1m\n",
      "16:\tlearn: 2050.9441700\ttotal: 2.3s\tremaining: 59.9s\n",
      "17:\tlearn: 2022.2412831\ttotal: 2.45s\tremaining: 1m\n",
      "18:\tlearn: 1999.2361701\ttotal: 2.58s\tremaining: 59.8s\n",
      "19:\tlearn: 1982.3958720\ttotal: 2.69s\tremaining: 59.1s\n",
      "20:\tlearn: 1967.1240606\ttotal: 2.82s\tremaining: 58.8s\n",
      "21:\tlearn: 1951.3298690\ttotal: 2.94s\tremaining: 58.3s\n",
      "22:\tlearn: 1935.5994139\ttotal: 3.08s\tremaining: 58.4s\n",
      "23:\tlearn: 1924.5428829\ttotal: 3.21s\tremaining: 58.2s\n",
      "24:\tlearn: 1913.2745122\ttotal: 3.34s\tremaining: 58s\n",
      "25:\tlearn: 1903.9458922\ttotal: 3.47s\tremaining: 57.8s\n",
      "26:\tlearn: 1894.3310348\ttotal: 3.61s\tremaining: 57.7s\n",
      "27:\tlearn: 1887.2087295\ttotal: 3.74s\tremaining: 57.5s\n",
      "28:\tlearn: 1880.9428269\ttotal: 3.86s\tremaining: 57.3s\n",
      "29:\tlearn: 1873.5663276\ttotal: 4.01s\tremaining: 57.3s\n",
      "30:\tlearn: 1867.8600915\ttotal: 4.16s\tremaining: 57.4s\n",
      "31:\tlearn: 1859.8360219\ttotal: 4.29s\tremaining: 57.2s\n",
      "32:\tlearn: 1854.2022946\ttotal: 4.42s\tremaining: 57s\n",
      "33:\tlearn: 1846.6060387\ttotal: 4.54s\tremaining: 56.7s\n",
      "34:\tlearn: 1840.9944575\ttotal: 4.66s\tremaining: 56.5s\n",
      "35:\tlearn: 1834.9447833\ttotal: 4.79s\tremaining: 56.3s\n",
      "36:\tlearn: 1831.1291292\ttotal: 4.92s\tremaining: 56.1s\n",
      "37:\tlearn: 1826.9654240\ttotal: 5.04s\tremaining: 55.9s\n",
      "38:\tlearn: 1822.6759591\ttotal: 5.17s\tremaining: 55.7s\n",
      "39:\tlearn: 1820.6948359\ttotal: 5.29s\tremaining: 55.5s\n",
      "40:\tlearn: 1817.8946710\ttotal: 5.42s\tremaining: 55.2s\n",
      "41:\tlearn: 1813.3854651\ttotal: 5.55s\tremaining: 55.1s\n",
      "42:\tlearn: 1810.7517478\ttotal: 5.66s\tremaining: 54.7s\n",
      "43:\tlearn: 1806.9435954\ttotal: 5.79s\tremaining: 54.6s\n",
      "44:\tlearn: 1804.0530957\ttotal: 5.92s\tremaining: 54.5s\n",
      "45:\tlearn: 1801.8308864\ttotal: 6.03s\tremaining: 54.2s\n",
      "46:\tlearn: 1799.7182708\ttotal: 6.13s\tremaining: 53.7s\n",
      "47:\tlearn: 1797.0961951\ttotal: 6.25s\tremaining: 53.5s\n",
      "48:\tlearn: 1794.1929629\ttotal: 6.38s\tremaining: 53.4s\n",
      "49:\tlearn: 1792.4367164\ttotal: 6.5s\tremaining: 53.2s\n",
      "50:\tlearn: 1790.1393443\ttotal: 6.63s\tremaining: 53.1s\n",
      "51:\tlearn: 1787.6341162\ttotal: 6.76s\tremaining: 53s\n",
      "52:\tlearn: 1786.0026977\ttotal: 6.88s\tremaining: 52.7s\n",
      "53:\tlearn: 1784.2366768\ttotal: 6.99s\tremaining: 52.5s\n",
      "54:\tlearn: 1782.5589084\ttotal: 7.11s\tremaining: 52.2s\n",
      "55:\tlearn: 1781.4226651\ttotal: 7.23s\tremaining: 52s\n",
      "56:\tlearn: 1779.9915187\ttotal: 7.36s\tremaining: 51.9s\n",
      "57:\tlearn: 1778.0482754\ttotal: 7.5s\tremaining: 51.8s\n",
      "58:\tlearn: 1776.0627800\ttotal: 7.62s\tremaining: 51.7s\n",
      "59:\tlearn: 1774.9725938\ttotal: 7.74s\tremaining: 51.5s\n",
      "60:\tlearn: 1773.6280379\ttotal: 7.86s\tremaining: 51.3s\n",
      "61:\tlearn: 1772.6116799\ttotal: 7.97s\tremaining: 51.1s\n",
      "62:\tlearn: 1771.4040961\ttotal: 8.09s\tremaining: 50.8s\n",
      "63:\tlearn: 1770.0415645\ttotal: 8.2s\tremaining: 50.6s\n",
      "64:\tlearn: 1767.9096744\ttotal: 8.33s\tremaining: 50.5s\n",
      "65:\tlearn: 1765.7248615\ttotal: 8.44s\tremaining: 50.2s\n",
      "66:\tlearn: 1764.2982134\ttotal: 8.56s\tremaining: 50.1s\n",
      "67:\tlearn: 1762.8783747\ttotal: 8.68s\tremaining: 49.9s\n",
      "68:\tlearn: 1760.9735682\ttotal: 8.82s\tremaining: 49.9s\n",
      "69:\tlearn: 1759.2634818\ttotal: 8.94s\tremaining: 49.7s\n",
      "70:\tlearn: 1757.9813097\ttotal: 9.06s\tremaining: 49.5s\n",
      "71:\tlearn: 1755.0869517\ttotal: 9.19s\tremaining: 49.4s\n",
      "72:\tlearn: 1752.6956923\ttotal: 9.31s\tremaining: 49.2s\n",
      "73:\tlearn: 1751.2841571\ttotal: 9.44s\tremaining: 49.1s\n",
      "74:\tlearn: 1750.1228312\ttotal: 9.57s\tremaining: 49s\n",
      "75:\tlearn: 1748.6376327\ttotal: 9.68s\tremaining: 48.8s\n",
      "76:\tlearn: 1746.3466784\ttotal: 9.81s\tremaining: 48.7s\n",
      "77:\tlearn: 1744.5623402\ttotal: 9.95s\tremaining: 48.6s\n",
      "78:\tlearn: 1743.9565559\ttotal: 10s\tremaining: 48.3s\n",
      "79:\tlearn: 1742.6328385\ttotal: 10.2s\tremaining: 48.2s\n",
      "80:\tlearn: 1740.8679202\ttotal: 10.3s\tremaining: 48s\n",
      "81:\tlearn: 1739.4622565\ttotal: 10.4s\tremaining: 47.8s\n",
      "82:\tlearn: 1738.0297167\ttotal: 10.5s\tremaining: 47.6s\n",
      "83:\tlearn: 1735.5722557\ttotal: 10.6s\tremaining: 47.5s\n",
      "84:\tlearn: 1733.1250881\ttotal: 10.8s\tremaining: 47.4s\n",
      "85:\tlearn: 1730.7279311\ttotal: 10.9s\tremaining: 47.3s\n",
      "86:\tlearn: 1728.4127210\ttotal: 11s\tremaining: 47.1s\n",
      "87:\tlearn: 1725.3087738\ttotal: 11.1s\tremaining: 46.9s\n",
      "88:\tlearn: 1722.7931465\ttotal: 11.2s\tremaining: 46.7s\n",
      "89:\tlearn: 1719.5217940\ttotal: 11.4s\tremaining: 46.6s\n",
      "90:\tlearn: 1717.2595063\ttotal: 11.5s\tremaining: 46.5s\n",
      "91:\tlearn: 1715.0986713\ttotal: 11.6s\tremaining: 46.4s\n",
      "92:\tlearn: 1712.8626820\ttotal: 11.7s\tremaining: 46.1s\n",
      "93:\tlearn: 1708.7687742\ttotal: 11.9s\tremaining: 46.1s\n",
      "94:\tlearn: 1707.1777785\ttotal: 12s\tremaining: 46s\n",
      "95:\tlearn: 1704.4803549\ttotal: 12.1s\tremaining: 45.8s\n",
      "96:\tlearn: 1699.4036401\ttotal: 12.3s\tremaining: 45.7s\n",
      "97:\tlearn: 1696.1578843\ttotal: 12.4s\tremaining: 45.6s\n",
      "98:\tlearn: 1694.5605856\ttotal: 12.4s\tremaining: 45.3s\n",
      "99:\tlearn: 1690.5926512\ttotal: 12.6s\tremaining: 45.1s\n",
      "100:\tlearn: 1684.0661535\ttotal: 12.7s\tremaining: 45s\n",
      "101:\tlearn: 1678.4800340\ttotal: 12.8s\tremaining: 44.9s\n",
      "102:\tlearn: 1674.1731999\ttotal: 13s\tremaining: 44.8s\n",
      "103:\tlearn: 1668.6906186\ttotal: 13.1s\tremaining: 44.7s\n",
      "104:\tlearn: 1663.5021500\ttotal: 13.2s\tremaining: 44.6s\n",
      "105:\tlearn: 1660.3770017\ttotal: 13.3s\tremaining: 44.4s\n",
      "106:\tlearn: 1657.7598008\ttotal: 13.4s\tremaining: 44.2s\n",
      "107:\tlearn: 1652.3859680\ttotal: 13.6s\tremaining: 44.1s\n",
      "108:\tlearn: 1646.6383521\ttotal: 13.7s\tremaining: 43.9s\n",
      "109:\tlearn: 1642.0504255\ttotal: 13.8s\tremaining: 43.8s\n",
      "110:\tlearn: 1636.4450409\ttotal: 14s\tremaining: 43.7s\n",
      "111:\tlearn: 1631.9392744\ttotal: 14.1s\tremaining: 43.6s\n",
      "112:\tlearn: 1628.8475359\ttotal: 14.2s\tremaining: 43.4s\n",
      "113:\tlearn: 1625.4573763\ttotal: 14.3s\tremaining: 43.3s\n",
      "114:\tlearn: 1623.6445832\ttotal: 14.4s\tremaining: 43.1s\n",
      "115:\tlearn: 1619.4794222\ttotal: 14.5s\tremaining: 42.9s\n",
      "116:\tlearn: 1615.2109975\ttotal: 14.6s\tremaining: 42.7s\n",
      "117:\tlearn: 1612.4445058\ttotal: 14.7s\tremaining: 42.6s\n",
      "118:\tlearn: 1611.0820114\ttotal: 14.8s\tremaining: 42.4s\n",
      "119:\tlearn: 1606.0346808\ttotal: 15s\tremaining: 42.3s\n",
      "120:\tlearn: 1603.2961783\ttotal: 15.1s\tremaining: 42.2s\n",
      "121:\tlearn: 1599.7557405\ttotal: 15.2s\tremaining: 42s\n",
      "122:\tlearn: 1594.2301216\ttotal: 15.3s\tremaining: 41.9s\n",
      "123:\tlearn: 1589.7382809\ttotal: 15.5s\tremaining: 41.8s\n",
      "124:\tlearn: 1586.8613345\ttotal: 15.6s\tremaining: 41.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125:\tlearn: 1585.0016341\ttotal: 15.7s\tremaining: 41.5s\n",
      "126:\tlearn: 1584.2356984\ttotal: 15.8s\tremaining: 41.2s\n",
      "127:\tlearn: 1582.1588145\ttotal: 15.9s\tremaining: 41.1s\n",
      "128:\tlearn: 1578.9816546\ttotal: 16s\tremaining: 40.9s\n",
      "129:\tlearn: 1574.8241467\ttotal: 16.1s\tremaining: 40.8s\n",
      "130:\tlearn: 1572.0069102\ttotal: 16.3s\tremaining: 40.7s\n",
      "131:\tlearn: 1569.2234134\ttotal: 16.4s\tremaining: 40.6s\n",
      "132:\tlearn: 1567.0403703\ttotal: 16.5s\tremaining: 40.4s\n",
      "133:\tlearn: 1562.3870140\ttotal: 16.6s\tremaining: 40.3s\n",
      "134:\tlearn: 1560.6612477\ttotal: 16.7s\tremaining: 40.2s\n",
      "135:\tlearn: 1558.4671887\ttotal: 16.9s\tremaining: 40s\n",
      "136:\tlearn: 1555.3317984\ttotal: 17s\tremaining: 39.9s\n",
      "137:\tlearn: 1551.0360621\ttotal: 17.1s\tremaining: 39.8s\n",
      "138:\tlearn: 1548.8548509\ttotal: 17.2s\tremaining: 39.7s\n",
      "139:\tlearn: 1545.9293289\ttotal: 17.3s\tremaining: 39.5s\n",
      "140:\tlearn: 1540.5883646\ttotal: 17.5s\tremaining: 39.4s\n",
      "141:\tlearn: 1538.0456748\ttotal: 17.6s\tremaining: 39.3s\n",
      "142:\tlearn: 1534.5973524\ttotal: 17.7s\tremaining: 39.2s\n",
      "143:\tlearn: 1532.0756200\ttotal: 17.8s\tremaining: 39s\n",
      "144:\tlearn: 1529.9896914\ttotal: 18s\tremaining: 38.9s\n",
      "145:\tlearn: 1529.0177107\ttotal: 18.1s\tremaining: 38.7s\n",
      "146:\tlearn: 1526.3896475\ttotal: 18.2s\tremaining: 38.6s\n",
      "147:\tlearn: 1523.7869717\ttotal: 18.3s\tremaining: 38.5s\n",
      "148:\tlearn: 1522.0883487\ttotal: 18.4s\tremaining: 38.4s\n",
      "149:\tlearn: 1518.8549267\ttotal: 18.6s\tremaining: 38.3s\n",
      "150:\tlearn: 1517.9003781\ttotal: 18.7s\tremaining: 38.1s\n",
      "151:\tlearn: 1514.3333246\ttotal: 18.8s\tremaining: 38s\n",
      "152:\tlearn: 1512.9002171\ttotal: 18.9s\tremaining: 37.8s\n",
      "153:\tlearn: 1509.2802094\ttotal: 19s\tremaining: 37.7s\n",
      "154:\tlearn: 1504.5041675\ttotal: 19.2s\tremaining: 37.6s\n",
      "155:\tlearn: 1502.8015155\ttotal: 19.3s\tremaining: 37.5s\n",
      "156:\tlearn: 1499.3652440\ttotal: 19.4s\tremaining: 37.4s\n",
      "157:\tlearn: 1497.0850457\ttotal: 19.6s\tremaining: 37.3s\n",
      "158:\tlearn: 1494.8073384\ttotal: 19.7s\tremaining: 37.1s\n",
      "159:\tlearn: 1491.6191879\ttotal: 19.8s\tremaining: 37s\n",
      "160:\tlearn: 1489.5332045\ttotal: 20s\tremaining: 36.9s\n",
      "161:\tlearn: 1486.5252912\ttotal: 20.1s\tremaining: 36.8s\n",
      "162:\tlearn: 1485.0356161\ttotal: 20.2s\tremaining: 36.7s\n",
      "163:\tlearn: 1484.0843843\ttotal: 20.3s\tremaining: 36.5s\n",
      "164:\tlearn: 1482.9556177\ttotal: 20.4s\tremaining: 36.4s\n",
      "165:\tlearn: 1480.4440883\ttotal: 20.5s\tremaining: 36.2s\n",
      "166:\tlearn: 1478.5662194\ttotal: 20.6s\tremaining: 36.1s\n",
      "167:\tlearn: 1474.9544773\ttotal: 20.8s\tremaining: 36s\n",
      "168:\tlearn: 1472.2888233\ttotal: 20.9s\tremaining: 35.9s\n",
      "169:\tlearn: 1471.3532963\ttotal: 21s\tremaining: 35.7s\n",
      "170:\tlearn: 1469.3996464\ttotal: 21.1s\tremaining: 35.6s\n",
      "171:\tlearn: 1467.8500408\ttotal: 21.3s\tremaining: 35.5s\n",
      "172:\tlearn: 1466.8463720\ttotal: 21.4s\tremaining: 35.3s\n",
      "173:\tlearn: 1465.1553188\ttotal: 21.5s\tremaining: 35.2s\n",
      "174:\tlearn: 1462.4000977\ttotal: 21.6s\tremaining: 35.1s\n",
      "175:\tlearn: 1460.3377467\ttotal: 21.7s\tremaining: 35s\n",
      "176:\tlearn: 1458.6676133\ttotal: 21.9s\tremaining: 34.8s\n",
      "177:\tlearn: 1456.9215838\ttotal: 22s\tremaining: 34.7s\n",
      "178:\tlearn: 1454.4402371\ttotal: 22.1s\tremaining: 34.6s\n",
      "179:\tlearn: 1452.1039143\ttotal: 22.2s\tremaining: 34.5s\n",
      "180:\tlearn: 1451.0142193\ttotal: 22.3s\tremaining: 34.3s\n",
      "181:\tlearn: 1450.1853428\ttotal: 22.4s\tremaining: 34.1s\n",
      "182:\tlearn: 1447.9765259\ttotal: 22.6s\tremaining: 34s\n",
      "183:\tlearn: 1446.6212332\ttotal: 22.7s\tremaining: 33.9s\n",
      "184:\tlearn: 1446.2263685\ttotal: 22.8s\tremaining: 33.7s\n",
      "185:\tlearn: 1441.8054464\ttotal: 22.9s\tremaining: 33.6s\n",
      "186:\tlearn: 1440.4453648\ttotal: 23s\tremaining: 33.5s\n",
      "187:\tlearn: 1438.5008175\ttotal: 23.1s\tremaining: 33.4s\n",
      "188:\tlearn: 1437.7278621\ttotal: 23.2s\tremaining: 33.2s\n",
      "189:\tlearn: 1436.0386799\ttotal: 23.4s\tremaining: 33.1s\n",
      "190:\tlearn: 1435.4068907\ttotal: 23.5s\tremaining: 32.9s\n",
      "191:\tlearn: 1433.6952630\ttotal: 23.6s\tremaining: 32.8s\n",
      "192:\tlearn: 1431.4990201\ttotal: 23.7s\tremaining: 32.7s\n",
      "193:\tlearn: 1428.1878441\ttotal: 23.9s\tremaining: 32.6s\n",
      "194:\tlearn: 1425.9268359\ttotal: 24s\tremaining: 32.5s\n",
      "195:\tlearn: 1423.6283441\ttotal: 24.2s\tremaining: 32.4s\n",
      "196:\tlearn: 1422.2702131\ttotal: 24.3s\tremaining: 32.3s\n",
      "197:\tlearn: 1419.8099896\ttotal: 24.4s\tremaining: 32.2s\n",
      "198:\tlearn: 1417.4558121\ttotal: 24.5s\tremaining: 32.1s\n",
      "199:\tlearn: 1414.3539521\ttotal: 24.7s\tremaining: 32s\n",
      "200:\tlearn: 1412.5650149\ttotal: 24.8s\tremaining: 31.9s\n",
      "201:\tlearn: 1411.4083816\ttotal: 24.9s\tremaining: 31.7s\n",
      "202:\tlearn: 1410.6860032\ttotal: 25s\tremaining: 31.6s\n",
      "203:\tlearn: 1409.1302775\ttotal: 25.1s\tremaining: 31.4s\n",
      "204:\tlearn: 1407.2445777\ttotal: 25.3s\tremaining: 31.3s\n",
      "205:\tlearn: 1405.4224307\ttotal: 25.4s\tremaining: 31.2s\n",
      "206:\tlearn: 1404.7283148\ttotal: 25.5s\tremaining: 31.1s\n",
      "207:\tlearn: 1403.9799878\ttotal: 25.6s\tremaining: 30.9s\n",
      "208:\tlearn: 1403.1003644\ttotal: 25.7s\tremaining: 30.8s\n",
      "209:\tlearn: 1401.2942124\ttotal: 25.8s\tremaining: 30.6s\n",
      "210:\tlearn: 1400.6155110\ttotal: 25.9s\tremaining: 30.5s\n",
      "211:\tlearn: 1399.8414463\ttotal: 26s\tremaining: 30.3s\n",
      "212:\tlearn: 1398.8537115\ttotal: 26.2s\tremaining: 30.2s\n",
      "213:\tlearn: 1397.3603701\ttotal: 26.3s\tremaining: 30.1s\n",
      "214:\tlearn: 1395.6449452\ttotal: 26.4s\tremaining: 30s\n",
      "215:\tlearn: 1394.3921965\ttotal: 26.5s\tremaining: 29.8s\n",
      "216:\tlearn: 1394.0493196\ttotal: 26.6s\tremaining: 29.7s\n",
      "217:\tlearn: 1391.9821181\ttotal: 26.8s\tremaining: 29.6s\n",
      "218:\tlearn: 1390.1272598\ttotal: 26.9s\tremaining: 29.5s\n",
      "219:\tlearn: 1388.6328920\ttotal: 27.1s\tremaining: 29.4s\n",
      "220:\tlearn: 1385.8101703\ttotal: 27.2s\tremaining: 29.3s\n",
      "221:\tlearn: 1384.6976490\ttotal: 27.4s\tremaining: 29.2s\n",
      "222:\tlearn: 1383.0869254\ttotal: 27.5s\tremaining: 29.1s\n",
      "223:\tlearn: 1381.9058085\ttotal: 27.6s\tremaining: 28.9s\n",
      "224:\tlearn: 1380.2209219\ttotal: 27.7s\tremaining: 28.8s\n",
      "225:\tlearn: 1378.3527489\ttotal: 27.9s\tremaining: 28.7s\n",
      "226:\tlearn: 1376.6350625\ttotal: 28s\tremaining: 28.6s\n",
      "227:\tlearn: 1374.6241823\ttotal: 28.1s\tremaining: 28.5s\n",
      "228:\tlearn: 1373.2093772\ttotal: 28.3s\tremaining: 28.4s\n",
      "229:\tlearn: 1371.8448727\ttotal: 28.4s\tremaining: 28.3s\n",
      "230:\tlearn: 1371.0078886\ttotal: 28.5s\tremaining: 28.1s\n",
      "231:\tlearn: 1370.2835161\ttotal: 28.6s\tremaining: 28s\n",
      "232:\tlearn: 1368.6477851\ttotal: 28.7s\tremaining: 27.9s\n",
      "233:\tlearn: 1367.8803218\ttotal: 28.8s\tremaining: 27.7s\n",
      "234:\tlearn: 1366.5804878\ttotal: 29s\tremaining: 27.6s\n",
      "235:\tlearn: 1365.0103943\ttotal: 29.1s\tremaining: 27.5s\n",
      "236:\tlearn: 1363.3822529\ttotal: 29.2s\tremaining: 27.4s\n",
      "237:\tlearn: 1362.1727379\ttotal: 29.3s\tremaining: 27.2s\n",
      "238:\tlearn: 1360.6713904\ttotal: 29.5s\tremaining: 27.1s\n",
      "239:\tlearn: 1359.1043100\ttotal: 29.6s\tremaining: 27s\n",
      "240:\tlearn: 1357.3804190\ttotal: 29.7s\tremaining: 26.9s\n",
      "241:\tlearn: 1356.2584849\ttotal: 29.8s\tremaining: 26.8s\n",
      "242:\tlearn: 1355.0492555\ttotal: 30s\tremaining: 26.6s\n",
      "243:\tlearn: 1354.2044084\ttotal: 30.1s\tremaining: 26.5s\n",
      "244:\tlearn: 1353.2498636\ttotal: 30.2s\tremaining: 26.4s\n",
      "245:\tlearn: 1351.5566610\ttotal: 30.3s\tremaining: 26.2s\n",
      "246:\tlearn: 1349.2770741\ttotal: 30.4s\tremaining: 26.1s\n",
      "247:\tlearn: 1348.5251564\ttotal: 30.6s\tremaining: 26s\n",
      "248:\tlearn: 1347.8352909\ttotal: 30.7s\tremaining: 25.9s\n",
      "249:\tlearn: 1346.8950606\ttotal: 30.8s\tremaining: 25.7s\n",
      "250:\tlearn: 1345.1624558\ttotal: 30.9s\tremaining: 25.6s\n",
      "251:\tlearn: 1343.9777851\ttotal: 31s\tremaining: 25.5s\n",
      "252:\tlearn: 1342.9521304\ttotal: 31.1s\tremaining: 25.4s\n",
      "253:\tlearn: 1341.0375024\ttotal: 31.3s\tremaining: 25.2s\n",
      "254:\tlearn: 1339.7551074\ttotal: 31.4s\tremaining: 25.1s\n",
      "255:\tlearn: 1338.3706353\ttotal: 31.5s\tremaining: 25s\n",
      "256:\tlearn: 1336.4941385\ttotal: 31.7s\tremaining: 24.9s\n",
      "257:\tlearn: 1335.3857248\ttotal: 31.8s\tremaining: 24.8s\n",
      "258:\tlearn: 1333.9415325\ttotal: 32s\tremaining: 24.7s\n",
      "259:\tlearn: 1333.0861699\ttotal: 32.1s\tremaining: 24.5s\n",
      "260:\tlearn: 1331.5788842\ttotal: 32.2s\tremaining: 24.4s\n",
      "261:\tlearn: 1330.2932440\ttotal: 32.3s\tremaining: 24.3s\n",
      "262:\tlearn: 1329.4128350\ttotal: 32.4s\tremaining: 24.2s\n",
      "263:\tlearn: 1328.6243639\ttotal: 32.5s\tremaining: 24s\n",
      "264:\tlearn: 1326.1936391\ttotal: 32.6s\tremaining: 23.9s\n",
      "265:\tlearn: 1324.3557986\ttotal: 32.8s\tremaining: 23.8s\n",
      "266:\tlearn: 1323.1815891\ttotal: 32.9s\tremaining: 23.7s\n",
      "267:\tlearn: 1321.8976451\ttotal: 33s\tremaining: 23.6s\n",
      "268:\tlearn: 1320.2960738\ttotal: 33.2s\tremaining: 23.4s\n",
      "269:\tlearn: 1319.1020943\ttotal: 33.3s\tremaining: 23.3s\n",
      "270:\tlearn: 1317.0832602\ttotal: 33.4s\tremaining: 23.2s\n",
      "271:\tlearn: 1316.3252181\ttotal: 33.5s\tremaining: 23.1s\n",
      "272:\tlearn: 1315.0393874\ttotal: 33.7s\tremaining: 22.9s\n",
      "273:\tlearn: 1314.3124779\ttotal: 33.8s\tremaining: 22.8s\n",
      "274:\tlearn: 1313.2296486\ttotal: 33.9s\tremaining: 22.7s\n",
      "275:\tlearn: 1312.2230407\ttotal: 34s\tremaining: 22.6s\n",
      "276:\tlearn: 1311.1245502\ttotal: 34.1s\tremaining: 22.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277:\tlearn: 1309.3521277\ttotal: 34.3s\tremaining: 22.3s\n",
      "278:\tlearn: 1307.9007528\ttotal: 34.4s\tremaining: 22.2s\n",
      "279:\tlearn: 1305.7243073\ttotal: 34.5s\tremaining: 22.1s\n",
      "280:\tlearn: 1304.5548371\ttotal: 34.7s\tremaining: 22s\n",
      "281:\tlearn: 1303.5487275\ttotal: 34.8s\tremaining: 21.8s\n",
      "282:\tlearn: 1302.4311617\ttotal: 34.9s\tremaining: 21.7s\n",
      "283:\tlearn: 1301.0644528\ttotal: 35.1s\tremaining: 21.6s\n",
      "284:\tlearn: 1300.0099005\ttotal: 35.2s\tremaining: 21.5s\n",
      "285:\tlearn: 1298.8228774\ttotal: 35.3s\tremaining: 21.4s\n",
      "286:\tlearn: 1296.9335776\ttotal: 35.5s\tremaining: 21.3s\n",
      "287:\tlearn: 1295.8743596\ttotal: 35.6s\tremaining: 21.1s\n",
      "288:\tlearn: 1294.3555144\ttotal: 35.7s\tremaining: 21s\n",
      "289:\tlearn: 1292.9865007\ttotal: 35.8s\tremaining: 20.9s\n",
      "290:\tlearn: 1290.9914169\ttotal: 36s\tremaining: 20.8s\n",
      "291:\tlearn: 1290.6512920\ttotal: 36.1s\tremaining: 20.6s\n",
      "292:\tlearn: 1289.3782075\ttotal: 36.2s\tremaining: 20.5s\n",
      "293:\tlearn: 1288.3804798\ttotal: 36.3s\tremaining: 20.4s\n",
      "294:\tlearn: 1286.6199746\ttotal: 36.4s\tremaining: 20.3s\n",
      "295:\tlearn: 1285.8206508\ttotal: 36.6s\tremaining: 20.1s\n",
      "296:\tlearn: 1284.7942564\ttotal: 36.7s\tremaining: 20s\n",
      "297:\tlearn: 1282.0343495\ttotal: 36.8s\tremaining: 19.9s\n",
      "298:\tlearn: 1280.4805511\ttotal: 37s\tremaining: 19.8s\n",
      "299:\tlearn: 1278.9834503\ttotal: 37.1s\tremaining: 19.7s\n",
      "300:\tlearn: 1278.2147306\ttotal: 37.3s\tremaining: 19.6s\n",
      "301:\tlearn: 1277.2712236\ttotal: 37.4s\tremaining: 19.4s\n",
      "302:\tlearn: 1276.3908530\ttotal: 37.5s\tremaining: 19.3s\n",
      "303:\tlearn: 1275.2491914\ttotal: 37.6s\tremaining: 19.2s\n",
      "304:\tlearn: 1274.8544352\ttotal: 37.7s\tremaining: 19.1s\n",
      "305:\tlearn: 1274.0204674\ttotal: 37.9s\tremaining: 18.9s\n",
      "306:\tlearn: 1272.6054500\ttotal: 38s\tremaining: 18.8s\n",
      "307:\tlearn: 1270.7208487\ttotal: 38.2s\tremaining: 18.7s\n",
      "308:\tlearn: 1270.3463654\ttotal: 38.3s\tremaining: 18.6s\n",
      "309:\tlearn: 1268.9787650\ttotal: 38.4s\tremaining: 18.5s\n",
      "310:\tlearn: 1267.6152836\ttotal: 38.6s\tremaining: 18.3s\n",
      "311:\tlearn: 1266.5535851\ttotal: 38.7s\tremaining: 18.2s\n",
      "312:\tlearn: 1264.6639958\ttotal: 38.8s\tremaining: 18.1s\n",
      "313:\tlearn: 1262.7415043\ttotal: 39s\tremaining: 18s\n",
      "314:\tlearn: 1261.3909737\ttotal: 39.1s\tremaining: 17.9s\n",
      "315:\tlearn: 1260.6001328\ttotal: 39.2s\tremaining: 17.8s\n",
      "316:\tlearn: 1258.9771109\ttotal: 39.4s\tremaining: 17.6s\n",
      "317:\tlearn: 1258.1938205\ttotal: 39.5s\tremaining: 17.5s\n",
      "318:\tlearn: 1255.8829234\ttotal: 39.7s\tremaining: 17.4s\n",
      "319:\tlearn: 1255.0733784\ttotal: 39.8s\tremaining: 17.3s\n",
      "320:\tlearn: 1253.9430924\ttotal: 39.9s\tremaining: 17.2s\n",
      "321:\tlearn: 1253.3527787\ttotal: 40s\tremaining: 17s\n",
      "322:\tlearn: 1252.7895049\ttotal: 40.1s\tremaining: 16.9s\n",
      "323:\tlearn: 1251.7356215\ttotal: 40.3s\tremaining: 16.8s\n",
      "324:\tlearn: 1250.2621499\ttotal: 40.4s\tremaining: 16.7s\n",
      "325:\tlearn: 1249.3216334\ttotal: 40.5s\tremaining: 16.5s\n",
      "326:\tlearn: 1247.8608950\ttotal: 40.7s\tremaining: 16.4s\n",
      "327:\tlearn: 1246.1418194\ttotal: 40.8s\tremaining: 16.3s\n",
      "328:\tlearn: 1245.7343179\ttotal: 40.9s\tremaining: 16.2s\n",
      "329:\tlearn: 1244.0990374\ttotal: 41.1s\tremaining: 16.1s\n",
      "330:\tlearn: 1242.6492199\ttotal: 41.2s\tremaining: 15.9s\n",
      "331:\tlearn: 1241.2120583\ttotal: 41.4s\tremaining: 15.8s\n",
      "332:\tlearn: 1240.6993062\ttotal: 41.5s\tremaining: 15.7s\n",
      "333:\tlearn: 1239.6450063\ttotal: 41.6s\tremaining: 15.6s\n",
      "334:\tlearn: 1238.9299011\ttotal: 41.7s\tremaining: 15.4s\n",
      "335:\tlearn: 1237.9664002\ttotal: 41.9s\tremaining: 15.3s\n",
      "336:\tlearn: 1237.1246875\ttotal: 42s\tremaining: 15.2s\n",
      "337:\tlearn: 1236.3601227\ttotal: 42.1s\tremaining: 15.1s\n",
      "338:\tlearn: 1235.3984757\ttotal: 42.2s\tremaining: 14.9s\n",
      "339:\tlearn: 1233.5393181\ttotal: 42.4s\tremaining: 14.8s\n",
      "340:\tlearn: 1232.6468921\ttotal: 42.5s\tremaining: 14.7s\n",
      "341:\tlearn: 1231.7319330\ttotal: 42.6s\tremaining: 14.6s\n",
      "342:\tlearn: 1231.0498601\ttotal: 42.8s\tremaining: 14.5s\n",
      "343:\tlearn: 1229.8193308\ttotal: 42.9s\tremaining: 14.3s\n",
      "344:\tlearn: 1228.8609479\ttotal: 43s\tremaining: 14.2s\n",
      "345:\tlearn: 1226.9954372\ttotal: 43.2s\tremaining: 14.1s\n",
      "346:\tlearn: 1225.7557419\ttotal: 43.3s\tremaining: 14s\n",
      "347:\tlearn: 1225.3174120\ttotal: 43.4s\tremaining: 13.8s\n",
      "348:\tlearn: 1223.8125335\ttotal: 43.5s\tremaining: 13.7s\n",
      "349:\tlearn: 1222.7167586\ttotal: 43.7s\tremaining: 13.6s\n",
      "350:\tlearn: 1220.8871847\ttotal: 43.8s\tremaining: 13.5s\n",
      "351:\tlearn: 1219.7121095\ttotal: 44s\tremaining: 13.4s\n",
      "352:\tlearn: 1218.4299476\ttotal: 44.1s\tremaining: 13.2s\n",
      "353:\tlearn: 1216.5841947\ttotal: 44.3s\tremaining: 13.1s\n",
      "354:\tlearn: 1214.9730899\ttotal: 44.4s\tremaining: 13s\n",
      "355:\tlearn: 1214.0884396\ttotal: 44.6s\tremaining: 12.9s\n",
      "356:\tlearn: 1212.7090275\ttotal: 44.7s\tremaining: 12.8s\n",
      "357:\tlearn: 1212.4573763\ttotal: 44.8s\tremaining: 12.6s\n",
      "358:\tlearn: 1211.0406995\ttotal: 45s\tremaining: 12.5s\n",
      "359:\tlearn: 1209.3209039\ttotal: 45.1s\tremaining: 12.4s\n",
      "360:\tlearn: 1208.4484335\ttotal: 45.2s\tremaining: 12.3s\n",
      "361:\tlearn: 1207.5631120\ttotal: 45.4s\tremaining: 12.2s\n",
      "362:\tlearn: 1206.1251158\ttotal: 45.5s\tremaining: 12s\n",
      "363:\tlearn: 1204.4953349\ttotal: 45.7s\tremaining: 11.9s\n",
      "364:\tlearn: 1203.6479942\ttotal: 45.8s\tremaining: 11.8s\n",
      "365:\tlearn: 1202.8947025\ttotal: 45.9s\tremaining: 11.7s\n",
      "366:\tlearn: 1201.3521189\ttotal: 46.1s\tremaining: 11.6s\n",
      "367:\tlearn: 1200.3232238\ttotal: 46.2s\tremaining: 11.4s\n",
      "368:\tlearn: 1198.6898637\ttotal: 46.4s\tremaining: 11.3s\n",
      "369:\tlearn: 1197.8794898\ttotal: 46.5s\tremaining: 11.2s\n",
      "370:\tlearn: 1196.7242325\ttotal: 46.6s\tremaining: 11.1s\n",
      "371:\tlearn: 1195.5626667\ttotal: 46.8s\tremaining: 10.9s\n",
      "372:\tlearn: 1194.0626648\ttotal: 46.9s\tremaining: 10.8s\n",
      "373:\tlearn: 1192.7999241\ttotal: 47.1s\tremaining: 10.7s\n",
      "374:\tlearn: 1191.8833439\ttotal: 47.2s\tremaining: 10.6s\n",
      "375:\tlearn: 1190.9434933\ttotal: 47.3s\tremaining: 10.4s\n",
      "376:\tlearn: 1189.8720842\ttotal: 47.5s\tremaining: 10.3s\n",
      "377:\tlearn: 1188.8228226\ttotal: 47.6s\tremaining: 10.2s\n",
      "378:\tlearn: 1188.1690519\ttotal: 47.7s\tremaining: 10.1s\n",
      "379:\tlearn: 1187.1667795\ttotal: 47.9s\tremaining: 9.95s\n",
      "380:\tlearn: 1186.2179104\ttotal: 48s\tremaining: 9.83s\n",
      "381:\tlearn: 1185.3965615\ttotal: 48.1s\tremaining: 9.7s\n",
      "382:\tlearn: 1184.1910767\ttotal: 48.3s\tremaining: 9.58s\n",
      "383:\tlearn: 1183.6185417\ttotal: 48.4s\tremaining: 9.45s\n",
      "384:\tlearn: 1182.4869148\ttotal: 48.5s\tremaining: 9.33s\n",
      "385:\tlearn: 1181.2507285\ttotal: 48.7s\tremaining: 9.21s\n",
      "386:\tlearn: 1179.6824644\ttotal: 48.8s\tremaining: 9.09s\n",
      "387:\tlearn: 1179.0118597\ttotal: 49s\tremaining: 8.96s\n",
      "388:\tlearn: 1178.0618933\ttotal: 49.1s\tremaining: 8.84s\n",
      "389:\tlearn: 1177.6161492\ttotal: 49.2s\tremaining: 8.71s\n",
      "390:\tlearn: 1176.2994727\ttotal: 49.4s\tremaining: 8.59s\n",
      "391:\tlearn: 1175.5993084\ttotal: 49.5s\tremaining: 8.46s\n",
      "392:\tlearn: 1174.1641129\ttotal: 49.6s\tremaining: 8.34s\n",
      "393:\tlearn: 1173.6708270\ttotal: 49.7s\tremaining: 8.21s\n",
      "394:\tlearn: 1172.5112150\ttotal: 49.9s\tremaining: 8.08s\n",
      "395:\tlearn: 1171.0768745\ttotal: 50s\tremaining: 7.96s\n",
      "396:\tlearn: 1170.1404681\ttotal: 50.2s\tremaining: 7.83s\n",
      "397:\tlearn: 1169.2840149\ttotal: 50.3s\tremaining: 7.71s\n",
      "398:\tlearn: 1168.2788118\ttotal: 50.4s\tremaining: 7.58s\n",
      "399:\tlearn: 1167.0922488\ttotal: 50.6s\tremaining: 7.46s\n",
      "400:\tlearn: 1165.9345064\ttotal: 50.7s\tremaining: 7.33s\n",
      "401:\tlearn: 1164.8879351\ttotal: 50.8s\tremaining: 7.21s\n",
      "402:\tlearn: 1163.9361475\ttotal: 51s\tremaining: 7.08s\n",
      "403:\tlearn: 1163.2997203\ttotal: 51.1s\tremaining: 6.96s\n",
      "404:\tlearn: 1162.0503040\ttotal: 51.2s\tremaining: 6.83s\n",
      "405:\tlearn: 1161.3850933\ttotal: 51.4s\tremaining: 6.7s\n",
      "406:\tlearn: 1160.6438765\ttotal: 51.5s\tremaining: 6.58s\n",
      "407:\tlearn: 1160.0781881\ttotal: 51.6s\tremaining: 6.45s\n",
      "408:\tlearn: 1159.4141153\ttotal: 51.7s\tremaining: 6.32s\n",
      "409:\tlearn: 1158.8787237\ttotal: 51.8s\tremaining: 6.2s\n",
      "410:\tlearn: 1158.1396369\ttotal: 52s\tremaining: 6.07s\n",
      "411:\tlearn: 1156.5689831\ttotal: 52.1s\tremaining: 5.95s\n",
      "412:\tlearn: 1154.8108685\ttotal: 52.3s\tremaining: 5.82s\n",
      "413:\tlearn: 1153.3453336\ttotal: 52.4s\tremaining: 5.7s\n",
      "414:\tlearn: 1152.2699859\ttotal: 52.6s\tremaining: 5.57s\n",
      "415:\tlearn: 1151.2419146\ttotal: 52.7s\tremaining: 5.45s\n",
      "416:\tlearn: 1150.4254192\ttotal: 52.8s\tremaining: 5.32s\n",
      "417:\tlearn: 1148.7451686\ttotal: 53s\tremaining: 5.2s\n",
      "418:\tlearn: 1147.7878082\ttotal: 53.1s\tremaining: 5.07s\n",
      "419:\tlearn: 1146.6909892\ttotal: 53.3s\tremaining: 4.95s\n",
      "420:\tlearn: 1145.7513072\ttotal: 53.4s\tremaining: 4.82s\n",
      "421:\tlearn: 1144.8595914\ttotal: 53.6s\tremaining: 4.7s\n",
      "422:\tlearn: 1144.1412359\ttotal: 53.7s\tremaining: 4.57s\n",
      "423:\tlearn: 1143.0792086\ttotal: 53.8s\tremaining: 4.44s\n",
      "424:\tlearn: 1141.4335591\ttotal: 54s\tremaining: 4.32s\n",
      "425:\tlearn: 1140.4688651\ttotal: 54.1s\tremaining: 4.19s\n",
      "426:\tlearn: 1138.8887178\ttotal: 54.3s\tremaining: 4.07s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427:\tlearn: 1137.6787723\ttotal: 54.5s\tremaining: 3.94s\n",
      "428:\tlearn: 1136.4757271\ttotal: 54.6s\tremaining: 3.82s\n",
      "429:\tlearn: 1136.1592267\ttotal: 54.7s\tremaining: 3.69s\n",
      "430:\tlearn: 1135.3232547\ttotal: 54.8s\tremaining: 3.56s\n",
      "431:\tlearn: 1134.8118563\ttotal: 55s\tremaining: 3.44s\n",
      "432:\tlearn: 1134.0226057\ttotal: 55.1s\tremaining: 3.31s\n",
      "433:\tlearn: 1132.7234294\ttotal: 55.3s\tremaining: 3.18s\n",
      "434:\tlearn: 1132.3290828\ttotal: 55.4s\tremaining: 3.06s\n",
      "435:\tlearn: 1131.6247358\ttotal: 55.5s\tremaining: 2.93s\n",
      "436:\tlearn: 1130.9119032\ttotal: 55.6s\tremaining: 2.8s\n",
      "437:\tlearn: 1130.3957449\ttotal: 55.8s\tremaining: 2.67s\n",
      "438:\tlearn: 1129.5160265\ttotal: 55.9s\tremaining: 2.55s\n",
      "439:\tlearn: 1128.7255827\ttotal: 56.1s\tremaining: 2.42s\n",
      "440:\tlearn: 1127.0463310\ttotal: 56.2s\tremaining: 2.29s\n",
      "441:\tlearn: 1125.6699841\ttotal: 56.4s\tremaining: 2.17s\n",
      "442:\tlearn: 1124.9624171\ttotal: 56.5s\tremaining: 2.04s\n",
      "443:\tlearn: 1123.8182552\ttotal: 56.6s\tremaining: 1.91s\n",
      "444:\tlearn: 1123.1188139\ttotal: 56.7s\tremaining: 1.78s\n",
      "445:\tlearn: 1121.8187637\ttotal: 56.9s\tremaining: 1.66s\n",
      "446:\tlearn: 1121.0564114\ttotal: 57s\tremaining: 1.53s\n",
      "447:\tlearn: 1119.7631940\ttotal: 57.2s\tremaining: 1.4s\n",
      "448:\tlearn: 1118.3004569\ttotal: 57.3s\tremaining: 1.28s\n",
      "449:\tlearn: 1117.7309870\ttotal: 57.5s\tremaining: 1.15s\n",
      "450:\tlearn: 1116.9903943\ttotal: 57.6s\tremaining: 1.02s\n",
      "451:\tlearn: 1116.1468686\ttotal: 57.7s\tremaining: 894ms\n",
      "452:\tlearn: 1115.5019440\ttotal: 57.9s\tremaining: 766ms\n",
      "453:\tlearn: 1114.1952276\ttotal: 58s\tremaining: 639ms\n",
      "454:\tlearn: 1113.1338158\ttotal: 58.1s\tremaining: 511ms\n",
      "455:\tlearn: 1112.4698938\ttotal: 58.3s\tremaining: 383ms\n",
      "456:\tlearn: 1111.8130811\ttotal: 58.4s\tremaining: 256ms\n",
      "457:\tlearn: 1111.2167265\ttotal: 58.6s\tremaining: 128ms\n",
      "458:\tlearn: 1110.3552529\ttotal: 58.7s\tremaining: 0us\n",
      "Training time: 59.24781346321106 seconds\n",
      "Validation prediction time: 0.5297284126281738 seconds\n",
      "Validation RMSE: 1584.7459551298966\n",
      "Test prediction time: 0.5166118144989014 seconds\n",
      "Test RMSE: 1607.6692728701196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 59.24781346321106,\n",
       " 'validation_time': 0.5297284126281738,\n",
       " 'validation_rmse': 1584.7459551298966,\n",
       " 'test_prediction_time': 0.5166118144989014,\n",
       " 'test_rmse': 1607.6692728701196,\n",
       " 'cv_rmse_scores': array([1574.85029783, 1576.52261921, 1592.11149693, 1571.85279946,\n",
       "        1595.27289646]),\n",
       " 'mean_cv_rmse': 1582.122021976741,\n",
       " 'std_cv_rmse': 9.616894758271716}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_eval(CatBoostRegressor, X, y, cv_splits=5,cat_features=categorical_features, bootstrap_type= 'Bayesian',\n",
    "                             border_count= 199, depth= 10,grow_policy= 'Depthwise', iterations= 459, l2_leaf_reg= 1, \n",
    "                             learning_rate= 0.13838112223746335, min_data_in_leaf= 9, random_strength= 9, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1658.52578364 1667.46674679 1690.50061294 1671.50272237 1694.71375468]\n",
      "Mean Cross-Validation RMSE: 1676.541924086622\n",
      "Standard Deviation of Cross-Validation RMSE: 13.837587470614448\n",
      "Training time: 174.05083513259888 seconds\n",
      "Validation prediction time: 0.3653707504272461 seconds\n",
      "Validation RMSE: 1653.5819226120352\n",
      "Test prediction time: 0.4779982566833496 seconds\n",
      "Test RMSE: 1681.7635840067628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 174.05083513259888,\n",
       " 'validation_time': 0.3653707504272461,\n",
       " 'validation_rmse': 1653.5819226120352,\n",
       " 'test_prediction_time': 0.4779982566833496,\n",
       " 'test_rmse': 1681.7635840067628,\n",
       " 'cv_rmse_scores': array([1658.52578364, 1667.46674679, 1690.50061294, 1671.50272237,\n",
       "        1694.71375468]),\n",
       " 'mean_cv_rmse': 1676.541924086622,\n",
       " 'std_cv_rmse': 13.837587470614448}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_eval(XGBRegressor, x_ohe, y_ohe, cv_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[23:11:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=0.3802857225639665, learning_rate=0.14907884894416698, max_depth=7, n_estimators=202, reg_alpha=0.44583275285359114, reg_lambda=1.1999498316360058, subsample=0.7836995567863468; total time= 3.9min\n",
      "[23:15:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=0.3802857225639665, learning_rate=0.14907884894416698, max_depth=7, n_estimators=202, reg_alpha=0.44583275285359114, reg_lambda=1.1999498316360058, subsample=0.7836995567863468; total time= 3.9min\n",
      "[23:19:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=0.3802857225639665, learning_rate=0.14907884894416698, max_depth=7, n_estimators=202, reg_alpha=0.44583275285359114, reg_lambda=1.1999498316360058, subsample=0.7836995567863468; total time= 4.0min\n",
      "[23:23:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7334834444556088, gamma=0.057146727168776314, learning_rate=0.13366880986028204, max_depth=7, n_estimators=357, reg_alpha=0.7219987722668247, reg_lambda=2.8771054180315003, subsample=0.6003115063364057; total time= 8.0min\n",
      "[23:31:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7334834444556088, gamma=0.057146727168776314, learning_rate=0.13366880986028204, max_depth=7, n_estimators=357, reg_alpha=0.7219987722668247, reg_lambda=2.8771054180315003, subsample=0.6003115063364057; total time= 7.5min\n",
      "[23:39:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7334834444556088, gamma=0.057146727168776314, learning_rate=0.13366880986028204, max_depth=7, n_estimators=357, reg_alpha=0.7219987722668247, reg_lambda=2.8771054180315003, subsample=0.6003115063364057; total time= 7.4min\n",
      "[23:46:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.996884623716487, gamma=0.24699260385108662, learning_rate=0.12621410049277337, max_depth=11, n_estimators=148, reg_alpha=0.5247746602583891, reg_lambda=1.799721943430511, subsample=0.6186662652854461; total time= 6.5min\n",
      "[23:52:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.996884623716487, gamma=0.24699260385108662, learning_rate=0.12621410049277337, max_depth=11, n_estimators=148, reg_alpha=0.5247746602583891, reg_lambda=1.799721943430511, subsample=0.6186662652854461; total time= 6.5min\n",
      "[23:59:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.996884623716487, gamma=0.24699260385108662, learning_rate=0.12621410049277337, max_depth=11, n_estimators=148, reg_alpha=0.5247746602583891, reg_lambda=1.799721943430511, subsample=0.6186662652854461; total time= 6.4min\n",
      "[00:05:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9895022075365837, gamma=0.0931085361721217, learning_rate=0.02721522256123595, max_depth=5, n_estimators=463, reg_alpha=0.5142344384136116, reg_lambda=2.184829137724085, subsample=0.6185801650879991; total time= 9.0min\n",
      "[00:14:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9895022075365837, gamma=0.0931085361721217, learning_rate=0.02721522256123595, max_depth=5, n_estimators=463, reg_alpha=0.5142344384136116, reg_lambda=2.184829137724085, subsample=0.6185801650879991; total time= 9.0min\n",
      "[00:23:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9895022075365837, gamma=0.0931085361721217, learning_rate=0.02721522256123595, max_depth=5, n_estimators=463, reg_alpha=0.5142344384136116, reg_lambda=2.184829137724085, subsample=0.6185801650879991; total time= 9.0min\n",
      "[00:32:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8430179407605753, gamma=0.06820964947491662, learning_rate=0.02235980266720311, max_depth=6, n_estimators=188, reg_alpha=0.9656320330745594, reg_lambda=2.6167946962329225, subsample=0.7218455076693483; total time= 3.6min\n",
      "[00:36:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8430179407605753, gamma=0.06820964947491662, learning_rate=0.02235980266720311, max_depth=6, n_estimators=188, reg_alpha=0.9656320330745594, reg_lambda=2.6167946962329225, subsample=0.7218455076693483; total time= 3.6min\n",
      "[00:40:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8430179407605753, gamma=0.06820964947491662, learning_rate=0.02235980266720311, max_depth=6, n_estimators=188, reg_alpha=0.9656320330745594, reg_lambda=2.6167946962329225, subsample=0.7218455076693483; total time= 3.6min\n",
      "[00:43:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6390688456025535, gamma=0.2736932106048628, learning_rate=0.09362897381052425, max_depth=9, n_estimators=363, reg_alpha=0.034388521115218396, reg_lambda=2.818640804157564, subsample=0.7035119926400067; total time= 8.0min\n",
      "[00:51:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6390688456025535, gamma=0.2736932106048628, learning_rate=0.09362897381052425, max_depth=9, n_estimators=363, reg_alpha=0.034388521115218396, reg_lambda=2.818640804157564, subsample=0.7035119926400067; total time= 8.1min\n",
      "[01:00:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6390688456025535, gamma=0.2736932106048628, learning_rate=0.09362897381052425, max_depth=9, n_estimators=363, reg_alpha=0.034388521115218396, reg_lambda=2.818640804157564, subsample=0.7035119926400067; total time= 8.1min\n",
      "[01:08:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8650089137415928, gamma=0.12468443043576438, learning_rate=0.10881292402378405, max_depth=12, n_estimators=359, reg_alpha=0.18485445552552704, reg_lambda=2.939169255529117, subsample=0.9100531293444458; total time=12.6min\n",
      "[01:20:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8650089137415928, gamma=0.12468443043576438, learning_rate=0.10881292402378405, max_depth=12, n_estimators=359, reg_alpha=0.18485445552552704, reg_lambda=2.939169255529117, subsample=0.9100531293444458; total time=12.7min\n",
      "[01:33:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8650089137415928, gamma=0.12468443043576438, learning_rate=0.10881292402378405, max_depth=12, n_estimators=359, reg_alpha=0.18485445552552704, reg_lambda=2.939169255529117, subsample=0.9100531293444458; total time=12.7min\n",
      "[01:46:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9757995766256756, gamma=0.35793094017105953, learning_rate=0.12360099597410618, max_depth=10, n_estimators=314, reg_alpha=0.5208342600258237, reg_lambda=2.9223440486986982, subsample=0.9378135394712606; total time=10.1min\n",
      "[01:56:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9757995766256756, gamma=0.35793094017105953, learning_rate=0.12360099597410618, max_depth=10, n_estimators=314, reg_alpha=0.5208342600258237, reg_lambda=2.9223440486986982, subsample=0.9378135394712606; total time=10.1min\n",
      "[02:06:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9757995766256756, gamma=0.35793094017105953, learning_rate=0.12360099597410618, max_depth=10, n_estimators=314, reg_alpha=0.5208342600258237, reg_lambda=2.9223440486986982, subsample=0.9378135394712606; total time=10.2min\n",
      "[02:16:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8989280440549523, gamma=0.21587685295563191, learning_rate=0.12148272147613116, max_depth=11, n_estimators=351, reg_alpha=0.6070342476866847, reg_lambda=1.5519983640450867, subsample=0.718509402281633; total time=13.0min\n",
      "[02:29:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8989280440549523, gamma=0.21587685295563191, learning_rate=0.12148272147613116, max_depth=11, n_estimators=351, reg_alpha=0.6070342476866847, reg_lambda=1.5519983640450867, subsample=0.718509402281633; total time=13.0min\n",
      "[02:42:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8989280440549523, gamma=0.21587685295563191, learning_rate=0.12148272147613116, max_depth=11, n_estimators=351, reg_alpha=0.6070342476866847, reg_lambda=1.5519983640450867, subsample=0.718509402281633; total time=13.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:55:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6661067756252009, gamma=0.006254562696477573, learning_rate=0.09044628133421022, max_depth=3, n_estimators=235, reg_alpha=0.005522117123602399, reg_lambda=2.6309228569096685, subsample=0.8827429375390468; total time= 1.8min\n",
      "[02:57:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6661067756252009, gamma=0.006254562696477573, learning_rate=0.09044628133421022, max_depth=3, n_estimators=235, reg_alpha=0.005522117123602399, reg_lambda=2.6309228569096685, subsample=0.8827429375390468; total time= 1.8min\n",
      "[02:59:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6661067756252009, gamma=0.006254562696477573, learning_rate=0.09044628133421022, max_depth=3, n_estimators=235, reg_alpha=0.005522117123602399, reg_lambda=2.6309228569096685, subsample=0.8827429375390468; total time= 1.8min\n",
      "[03:00:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8916028672163949, gamma=0.3085081386743783, learning_rate=0.02406848382947717, max_depth=9, n_estimators=140, reg_alpha=0.9149596755437808, reg_lambda=2.7000771555795984, subsample=0.7797802696552814; total time= 4.3min\n",
      "[03:05:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8916028672163949, gamma=0.3085081386743783, learning_rate=0.02406848382947717, max_depth=9, n_estimators=140, reg_alpha=0.9149596755437808, reg_lambda=2.7000771555795984, subsample=0.7797802696552814; total time= 4.3min\n",
      "[03:09:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8916028672163949, gamma=0.3085081386743783, learning_rate=0.02406848382947717, max_depth=9, n_estimators=140, reg_alpha=0.9149596755437808, reg_lambda=2.7000771555795984, subsample=0.7797802696552814; total time= 4.3min\n",
      "[03:13:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6381640465961645, gamma=0.14832730087930654, learning_rate=0.1370798380060854, max_depth=7, n_estimators=198, reg_alpha=0.5912977877077271, reg_lambda=1.5494435859801283, subsample=0.8244973703390804; total time= 3.2min\n",
      "[03:17:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6381640465961645, gamma=0.14832730087930654, learning_rate=0.1370798380060854, max_depth=7, n_estimators=198, reg_alpha=0.5912977877077271, reg_lambda=1.5494435859801283, subsample=0.8244973703390804; total time= 3.3min\n",
      "[03:20:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6381640465961645, gamma=0.14832730087930654, learning_rate=0.1370798380060854, max_depth=7, n_estimators=198, reg_alpha=0.5912977877077271, reg_lambda=1.5494435859801283, subsample=0.8244973703390804; total time= 3.2min\n",
      "[03:23:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7531707499015159, gamma=0.38868483815564153, learning_rate=0.17129362661055594, max_depth=7, n_estimators=317, reg_alpha=0.23598491974895575, reg_lambda=1.512136645522648, subsample=0.6161734358153725; total time= 6.8min\n",
      "[03:30:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7531707499015159, gamma=0.38868483815564153, learning_rate=0.17129362661055594, max_depth=7, n_estimators=317, reg_alpha=0.23598491974895575, reg_lambda=1.512136645522648, subsample=0.6161734358153725; total time= 6.8min\n",
      "[03:37:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7531707499015159, gamma=0.38868483815564153, learning_rate=0.17129362661055594, max_depth=7, n_estimators=317, reg_alpha=0.23598491974895575, reg_lambda=1.512136645522648, subsample=0.6161734358153725; total time= 6.8min\n",
      "[03:43:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8842651558743149, gamma=0.04435632832473253, learning_rate=0.09347393535449632, max_depth=5, n_estimators=162, reg_alpha=0.8957635956735194, reg_lambda=1.9507404463642235, subsample=0.8253102287905535; total time= 2.6min\n",
      "[03:46:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8842651558743149, gamma=0.04435632832473253, learning_rate=0.09347393535449632, max_depth=5, n_estimators=162, reg_alpha=0.8957635956735194, reg_lambda=1.9507404463642235, subsample=0.8253102287905535; total time= 2.6min\n",
      "[03:49:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8842651558743149, gamma=0.04435632832473253, learning_rate=0.09347393535449632, max_depth=5, n_estimators=162, reg_alpha=0.8957635956735194, reg_lambda=1.9507404463642235, subsample=0.8253102287905535; total time= 2.6min\n",
      "[03:51:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.878206434570451, gamma=0.055732581762350276, learning_rate=0.12483930206278528, max_depth=6, n_estimators=112, reg_alpha=0.07697990982879299, reg_lambda=1.579502905827536, subsample=0.6644885149016018; total time= 2.4min\n",
      "[03:54:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.878206434570451, gamma=0.055732581762350276, learning_rate=0.12483930206278528, max_depth=6, n_estimators=112, reg_alpha=0.07697990982879299, reg_lambda=1.579502905827536, subsample=0.6644885149016018; total time= 2.3min\n",
      "[03:56:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.878206434570451, gamma=0.055732581762350276, learning_rate=0.12483930206278528, max_depth=6, n_estimators=112, reg_alpha=0.07697990982879299, reg_lambda=1.579502905827536, subsample=0.6644885149016018; total time= 2.3min\n",
      "[03:58:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9718790609370292, gamma=0.3232481518257668, learning_rate=0.13034671373698045, max_depth=8, n_estimators=383, reg_alpha=0.8036720768991145, reg_lambda=1.3731401177720717, subsample=0.9570235993959911; total time= 9.6min\n",
      "[04:08:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9718790609370292, gamma=0.3232481518257668, learning_rate=0.13034671373698045, max_depth=8, n_estimators=383, reg_alpha=0.8036720768991145, reg_lambda=1.3731401177720717, subsample=0.9570235993959911; total time= 9.7min\n",
      "[04:17:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9718790609370292, gamma=0.3232481518257668, learning_rate=0.13034671373698045, max_depth=8, n_estimators=383, reg_alpha=0.8036720768991145, reg_lambda=1.3731401177720717, subsample=0.9570235993959911; total time= 9.6min\n",
      "[04:27:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8157368967662603, gamma=0.322976062065625, learning_rate=0.18025734698546372, max_depth=9, n_estimators=289, reg_alpha=0.11005192452767676, reg_lambda=1.4558703250838834, subsample=0.7708431154505025; total time= 7.6min\n",
      "[04:35:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8157368967662603, gamma=0.322976062065625, learning_rate=0.18025734698546372, max_depth=9, n_estimators=289, reg_alpha=0.11005192452767676, reg_lambda=1.4558703250838834, subsample=0.7708431154505025; total time= 7.6min\n",
      "[04:42:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8157368967662603, gamma=0.322976062065625, learning_rate=0.18025734698546372, max_depth=9, n_estimators=289, reg_alpha=0.11005192452767676, reg_lambda=1.4558703250838834, subsample=0.7708431154505025; total time= 7.6min\n",
      "[04:50:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9272059063689972, gamma=0.3442922333025374, learning_rate=0.011320904800926235, max_depth=10, n_estimators=236, reg_alpha=0.4848299713589832, reg_lambda=2.3848720657805407, subsample=0.7077649335194086; total time= 8.9min\n",
      "[04:59:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9272059063689972, gamma=0.3442922333025374, learning_rate=0.011320904800926235, max_depth=10, n_estimators=236, reg_alpha=0.4848299713589832, reg_lambda=2.3848720657805407, subsample=0.7077649335194086; total time= 8.8min\n",
      "[05:08:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9272059063689972, gamma=0.3442922333025374, learning_rate=0.011320904800926235, max_depth=10, n_estimators=236, reg_alpha=0.4848299713589832, reg_lambda=2.3848720657805407, subsample=0.7077649335194086; total time= 8.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6976502088991097, gamma=0.06731641686917222, learning_rate=0.05156520171888335, max_depth=10, n_estimators=332, reg_alpha=0.4038361710580408, reg_lambda=1.1297844942179631, subsample=0.7015661655737379; total time= 9.1min\n",
      "[05:26:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6976502088991097, gamma=0.06731641686917222, learning_rate=0.05156520171888335, max_depth=10, n_estimators=332, reg_alpha=0.4038361710580408, reg_lambda=1.1297844942179631, subsample=0.7015661655737379; total time= 9.0min\n",
      "[05:35:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6976502088991097, gamma=0.06731641686917222, learning_rate=0.05156520171888335, max_depth=10, n_estimators=332, reg_alpha=0.4038361710580408, reg_lambda=1.1297844942179631, subsample=0.7015661655737379; total time= 9.7min\n",
      "[05:44:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6987504251354405, gamma=0.27852170913591534, learning_rate=0.14533141208564399, max_depth=7, n_estimators=212, reg_alpha=0.9977404850489419, reg_lambda=1.53356202855057, subsample=0.9906459823330611; total time= 3.5min\n",
      "[05:48:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6987504251354405, gamma=0.27852170913591534, learning_rate=0.14533141208564399, max_depth=7, n_estimators=212, reg_alpha=0.9977404850489419, reg_lambda=1.53356202855057, subsample=0.9906459823330611; total time= 3.5min\n",
      "[05:51:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6987504251354405, gamma=0.27852170913591534, learning_rate=0.14533141208564399, max_depth=7, n_estimators=212, reg_alpha=0.9977404850489419, reg_lambda=1.53356202855057, subsample=0.9906459823330611; total time= 3.5min\n",
      "[05:55:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7644148053272926, gamma=0.013220293160219354, learning_rate=0.07556353712506976, max_depth=3, n_estimators=225, reg_alpha=0.1448948720912231, reg_lambda=1.978905520555126, subsample=0.9942601816442402; total time= 1.8min\n",
      "[05:57:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7644148053272926, gamma=0.013220293160219354, learning_rate=0.07556353712506976, max_depth=3, n_estimators=225, reg_alpha=0.1448948720912231, reg_lambda=1.978905520555126, subsample=0.9942601816442402; total time= 1.8min\n",
      "[05:58:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7644148053272926, gamma=0.013220293160219354, learning_rate=0.07556353712506976, max_depth=3, n_estimators=225, reg_alpha=0.1448948720912231, reg_lambda=1.978905520555126, subsample=0.9942601816442402; total time= 1.8min\n",
      "[06:00:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6968221086046001, gamma=0.26885421896235145, learning_rate=0.15470772691245635, max_depth=3, n_estimators=354, reg_alpha=0.8031397563798959, reg_lambda=1.9406012688920768, subsample=0.9933692563579372; total time= 2.7min\n",
      "[06:03:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6968221086046001, gamma=0.26885421896235145, learning_rate=0.15470772691245635, max_depth=3, n_estimators=354, reg_alpha=0.8031397563798959, reg_lambda=1.9406012688920768, subsample=0.9933692563579372; total time= 2.7min\n",
      "[06:06:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6968221086046001, gamma=0.26885421896235145, learning_rate=0.15470772691245635, max_depth=3, n_estimators=354, reg_alpha=0.8031397563798959, reg_lambda=1.9406012688920768, subsample=0.9933692563579372; total time= 2.8min\n",
      "[06:08:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7595297769778212, gamma=0.3265727492877536, learning_rate=0.16168557374706471, max_depth=11, n_estimators=223, reg_alpha=0.5081987767407187, reg_lambda=2.3916256135817635, subsample=0.943343521925488; total time= 6.3min\n",
      "[06:15:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7595297769778212, gamma=0.3265727492877536, learning_rate=0.16168557374706471, max_depth=11, n_estimators=223, reg_alpha=0.5081987767407187, reg_lambda=2.3916256135817635, subsample=0.943343521925488; total time= 6.2min\n",
      "[06:21:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7595297769778212, gamma=0.3265727492877536, learning_rate=0.16168557374706471, max_depth=11, n_estimators=223, reg_alpha=0.5081987767407187, reg_lambda=2.3916256135817635, subsample=0.943343521925488; total time= 6.4min\n",
      "[06:27:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.730383562080754, gamma=0.08809641902621933, learning_rate=0.14511841116322338, max_depth=5, n_estimators=247, reg_alpha=0.6451727904094499, reg_lambda=1.3487328580099829, subsample=0.8763750952409863; total time= 3.2min\n",
      "[06:31:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.730383562080754, gamma=0.08809641902621933, learning_rate=0.14511841116322338, max_depth=5, n_estimators=247, reg_alpha=0.6451727904094499, reg_lambda=1.3487328580099829, subsample=0.8763750952409863; total time= 3.2min\n",
      "[06:34:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.730383562080754, gamma=0.08809641902621933, learning_rate=0.14511841116322338, max_depth=5, n_estimators=247, reg_alpha=0.6451727904094499, reg_lambda=1.3487328580099829, subsample=0.8763750952409863; total time= 3.2min\n",
      "[06:37:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7546941385202149, gamma=0.37469199549469384, learning_rate=0.03612897938773872, max_depth=11, n_estimators=250, reg_alpha=0.5414479738275658, reg_lambda=2.391568798690164, subsample=0.6914200087189198; total time= 8.3min\n",
      "[06:45:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7546941385202149, gamma=0.37469199549469384, learning_rate=0.03612897938773872, max_depth=11, n_estimators=250, reg_alpha=0.5414479738275658, reg_lambda=2.391568798690164, subsample=0.6914200087189198; total time= 8.8min\n",
      "[06:54:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7546941385202149, gamma=0.37469199549469384, learning_rate=0.03612897938773872, max_depth=11, n_estimators=250, reg_alpha=0.5414479738275658, reg_lambda=2.391568798690164, subsample=0.6914200087189198; total time= 8.3min\n",
      "[07:02:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6699819708383744, gamma=0.39286733733177426, learning_rate=0.10816081934149271, max_depth=3, n_estimators=101, reg_alpha=0.9962536997579243, reg_lambda=2.9308387025775873, subsample=0.8233173814428391; total time=  49.4s\n",
      "[07:03:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6699819708383744, gamma=0.39286733733177426, learning_rate=0.10816081934149271, max_depth=3, n_estimators=101, reg_alpha=0.9962536997579243, reg_lambda=2.9308387025775873, subsample=0.8233173814428391; total time=  49.4s\n",
      "[07:04:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6699819708383744, gamma=0.39286733733177426, learning_rate=0.10816081934149271, max_depth=3, n_estimators=101, reg_alpha=0.9962536997579243, reg_lambda=2.9308387025775873, subsample=0.8233173814428391; total time=  49.7s\n",
      "[07:05:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9530545372757359, gamma=0.07548284333655175, learning_rate=0.06298555699251455, max_depth=5, n_estimators=403, reg_alpha=0.8466611422383059, reg_lambda=2.712648583756185, subsample=0.761803250848876; total time= 7.0min\n",
      "[07:12:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9530545372757359, gamma=0.07548284333655175, learning_rate=0.06298555699251455, max_depth=5, n_estimators=403, reg_alpha=0.8466611422383059, reg_lambda=2.712648583756185, subsample=0.761803250848876; total time= 7.0min\n",
      "[07:19:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9530545372757359, gamma=0.07548284333655175, learning_rate=0.06298555699251455, max_depth=5, n_estimators=403, reg_alpha=0.8466611422383059, reg_lambda=2.712648583756185, subsample=0.761803250848876; total time= 7.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:26:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9551080395043839, gamma=0.34037137950700513, learning_rate=0.18777064890198003, max_depth=6, n_estimators=203, reg_alpha=0.6064290596595899, reg_lambda=1.0183941032332593, subsample=0.6405886171464128; total time= 4.5min\n",
      "[07:30:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9551080395043839, gamma=0.34037137950700513, learning_rate=0.18777064890198003, max_depth=6, n_estimators=203, reg_alpha=0.6064290596595899, reg_lambda=1.0183941032332593, subsample=0.6405886171464128; total time= 4.5min\n",
      "[07:35:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9551080395043839, gamma=0.34037137950700513, learning_rate=0.18777064890198003, max_depth=6, n_estimators=203, reg_alpha=0.6064290596595899, reg_lambda=1.0183941032332593, subsample=0.6405886171464128; total time= 4.5min\n",
      "[07:39:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8654007076432223, gamma=0.0020246335384874747, learning_rate=0.04055352976932475, max_depth=4, n_estimators=293, reg_alpha=0.6918951976926933, reg_lambda=2.303922519005201, subsample=0.689707723784224; total time= 4.0min\n",
      "[07:43:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8654007076432223, gamma=0.0020246335384874747, learning_rate=0.04055352976932475, max_depth=4, n_estimators=293, reg_alpha=0.6918951976926933, reg_lambda=2.303922519005201, subsample=0.689707723784224; total time= 4.0min\n",
      "[07:47:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8654007076432223, gamma=0.0020246335384874747, learning_rate=0.04055352976932475, max_depth=4, n_estimators=293, reg_alpha=0.6918951976926933, reg_lambda=2.303922519005201, subsample=0.689707723784224; total time= 4.0min\n",
      "[07:51:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8848716885390143, gamma=0.09489963499872003, learning_rate=0.07182594265026086, max_depth=6, n_estimators=483, reg_alpha=0.7441705230565623, reg_lambda=2.4418798485042585, subsample=0.7232243167409557; total time= 9.6min\n",
      "[08:01:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8848716885390143, gamma=0.09489963499872003, learning_rate=0.07182594265026086, max_depth=6, n_estimators=483, reg_alpha=0.7441705230565623, reg_lambda=2.4418798485042585, subsample=0.7232243167409557; total time= 9.6min\n",
      "[08:10:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8848716885390143, gamma=0.09489963499872003, learning_rate=0.07182594265026086, max_depth=6, n_estimators=483, reg_alpha=0.7441705230565623, reg_lambda=2.4418798485042585, subsample=0.7232243167409557; total time= 9.5min\n",
      "[08:20:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8170160922219597, gamma=0.203525630735504, learning_rate=0.1309031974553201, max_depth=8, n_estimators=337, reg_alpha=0.5898708475605439, reg_lambda=2.957785716550018, subsample=0.794696861183782; total time= 7.8min\n",
      "[08:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8170160922219597, gamma=0.203525630735504, learning_rate=0.1309031974553201, max_depth=8, n_estimators=337, reg_alpha=0.5898708475605439, reg_lambda=2.957785716550018, subsample=0.794696861183782; total time= 7.8min\n",
      "[08:35:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8170160922219597, gamma=0.203525630735504, learning_rate=0.1309031974553201, max_depth=8, n_estimators=337, reg_alpha=0.5898708475605439, reg_lambda=2.957785716550018, subsample=0.794696861183782; total time= 7.7min\n",
      "[08:43:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9624395150874216, gamma=0.17375774620417148, learning_rate=0.07651489746198838, max_depth=3, n_estimators=383, reg_alpha=0.6689240596630996, reg_lambda=2.7283351301438064, subsample=0.6920741072966221; total time= 4.4min\n",
      "[08:48:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9624395150874216, gamma=0.17375774620417148, learning_rate=0.07651489746198838, max_depth=3, n_estimators=383, reg_alpha=0.6689240596630996, reg_lambda=2.7283351301438064, subsample=0.6920741072966221; total time= 4.4min\n",
      "[08:52:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9624395150874216, gamma=0.17375774620417148, learning_rate=0.07651489746198838, max_depth=3, n_estimators=383, reg_alpha=0.6689240596630996, reg_lambda=2.7283351301438064, subsample=0.6920741072966221; total time= 4.4min\n",
      "[08:56:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7996773519539009, gamma=0.22880167968367326, learning_rate=0.15602526271819872, max_depth=3, n_estimators=271, reg_alpha=0.9404585843529143, reg_lambda=2.9078571540051747, subsample=0.9659457560881795; total time= 2.3min\n",
      "[08:59:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7996773519539009, gamma=0.22880167968367326, learning_rate=0.15602526271819872, max_depth=3, n_estimators=271, reg_alpha=0.9404585843529143, reg_lambda=2.9078571540051747, subsample=0.9659457560881795; total time= 2.3min\n",
      "[09:01:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7996773519539009, gamma=0.22880167968367326, learning_rate=0.15602526271819872, max_depth=3, n_estimators=271, reg_alpha=0.9404585843529143, reg_lambda=2.9078571540051747, subsample=0.9659457560881795; total time= 2.3min\n",
      "[09:03:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7480634801021777, gamma=0.006182646611546972, learning_rate=0.18638052689166784, max_depth=3, n_estimators=401, reg_alpha=0.9666548190436696, reg_lambda=2.9272399541785057, subsample=0.941203782186944; total time= 3.3min\n",
      "[09:07:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7480634801021777, gamma=0.006182646611546972, learning_rate=0.18638052689166784, max_depth=3, n_estimators=401, reg_alpha=0.9666548190436696, reg_lambda=2.9272399541785057, subsample=0.941203782186944; total time= 3.3min\n",
      "[09:10:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7480634801021777, gamma=0.006182646611546972, learning_rate=0.18638052689166784, max_depth=3, n_estimators=401, reg_alpha=0.9666548190436696, reg_lambda=2.9272399541785057, subsample=0.941203782186944; total time= 3.3min\n",
      "[09:13:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7177795568278342, gamma=0.1540390914407701, learning_rate=0.17171596758820282, max_depth=5, n_estimators=227, reg_alpha=0.3726868670940493, reg_lambda=1.7893829336189444, subsample=0.9376852562905246; total time= 2.9min\n",
      "[09:16:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7177795568278342, gamma=0.1540390914407701, learning_rate=0.17171596758820282, max_depth=5, n_estimators=227, reg_alpha=0.3726868670940493, reg_lambda=1.7893829336189444, subsample=0.9376852562905246; total time= 2.8min\n",
      "[09:19:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7177795568278342, gamma=0.1540390914407701, learning_rate=0.17171596758820282, max_depth=5, n_estimators=227, reg_alpha=0.3726868670940493, reg_lambda=1.7893829336189444, subsample=0.9376852562905246; total time= 2.8min\n",
      "[09:22:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9720067339243328, gamma=0.02816645233981756, learning_rate=0.04969455634691844, max_depth=8, n_estimators=250, reg_alpha=0.14008401523652403, reg_lambda=2.0366593047274737, subsample=0.9509492287711822; total time= 6.3min\n",
      "[09:28:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9720067339243328, gamma=0.02816645233981756, learning_rate=0.04969455634691844, max_depth=8, n_estimators=250, reg_alpha=0.14008401523652403, reg_lambda=2.0366593047274737, subsample=0.9509492287711822; total time= 6.3min\n",
      "[09:34:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9720067339243328, gamma=0.02816645233981756, learning_rate=0.04969455634691844, max_depth=8, n_estimators=250, reg_alpha=0.14008401523652403, reg_lambda=2.0366593047274737, subsample=0.9509492287711822; total time= 6.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:41:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8963074471016818, gamma=0.2788062963981072, learning_rate=0.14347197595755076, max_depth=9, n_estimators=269, reg_alpha=0.8093611554785136, reg_lambda=2.6202267893583615, subsample=0.9468289274320415; total time= 7.1min\n",
      "[09:48:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8963074471016818, gamma=0.2788062963981072, learning_rate=0.14347197595755076, max_depth=9, n_estimators=269, reg_alpha=0.8093611554785136, reg_lambda=2.6202267893583615, subsample=0.9468289274320415; total time= 7.1min\n",
      "[09:55:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8963074471016818, gamma=0.2788062963981072, learning_rate=0.14347197595755076, max_depth=9, n_estimators=269, reg_alpha=0.8093611554785136, reg_lambda=2.6202267893583615, subsample=0.9468289274320415; total time= 7.1min\n",
      "[10:02:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9652962210225885, gamma=0.20453695954437512, learning_rate=0.10528809599056792, max_depth=6, n_estimators=420, reg_alpha=0.07094091699992766, reg_lambda=1.7935676544277768, subsample=0.6203074124157587; total time= 9.4min\n",
      "[10:11:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9652962210225885, gamma=0.20453695954437512, learning_rate=0.10528809599056792, max_depth=6, n_estimators=420, reg_alpha=0.07094091699992766, reg_lambda=1.7935676544277768, subsample=0.6203074124157587; total time= 9.5min\n",
      "[10:21:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9652962210225885, gamma=0.20453695954437512, learning_rate=0.10528809599056792, max_depth=6, n_estimators=420, reg_alpha=0.07094091699992766, reg_lambda=1.7935676544277768, subsample=0.6203074124157587; total time= 9.4min\n",
      "[10:30:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.954646859580264, gamma=0.011046708749481882, learning_rate=0.11998433014643616, max_depth=9, n_estimators=441, reg_alpha=0.32815266747473193, reg_lambda=1.3100832334554884, subsample=0.9927363553242124; total time=12.1min\n",
      "[10:42:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.954646859580264, gamma=0.011046708749481882, learning_rate=0.11998433014643616, max_depth=9, n_estimators=441, reg_alpha=0.32815266747473193, reg_lambda=1.3100832334554884, subsample=0.9927363553242124; total time=12.2min\n",
      "[10:54:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.954646859580264, gamma=0.011046708749481882, learning_rate=0.11998433014643616, max_depth=9, n_estimators=441, reg_alpha=0.32815266747473193, reg_lambda=1.3100832334554884, subsample=0.9927363553242124; total time=12.1min\n",
      "[11:07:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9355734008277453, gamma=0.34416184732467014, learning_rate=0.05754775849801417, max_depth=12, n_estimators=425, reg_alpha=0.3032655146732228, reg_lambda=2.074164854393311, subsample=0.7306604967184164; total time=17.7min\n",
      "[11:24:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9355734008277453, gamma=0.34416184732467014, learning_rate=0.05754775849801417, max_depth=12, n_estimators=425, reg_alpha=0.3032655146732228, reg_lambda=2.074164854393311, subsample=0.7306604967184164; total time=17.8min\n",
      "[11:42:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9355734008277453, gamma=0.34416184732467014, learning_rate=0.05754775849801417, max_depth=12, n_estimators=425, reg_alpha=0.3032655146732228, reg_lambda=2.074164854393311, subsample=0.7306604967184164; total time=17.8min\n",
      "[12:00:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9311476015150355, gamma=0.10861716632789675, learning_rate=0.19339784777424626, max_depth=9, n_estimators=295, reg_alpha=0.8420230750119814, reg_lambda=1.388760067989746, subsample=0.7645415620226714; total time= 8.9min\n",
      "[12:09:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9311476015150355, gamma=0.10861716632789675, learning_rate=0.19339784777424626, max_depth=9, n_estimators=295, reg_alpha=0.8420230750119814, reg_lambda=1.388760067989746, subsample=0.7645415620226714; total time= 8.9min\n",
      "[12:18:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9311476015150355, gamma=0.10861716632789675, learning_rate=0.19339784777424626, max_depth=9, n_estimators=295, reg_alpha=0.8420230750119814, reg_lambda=1.388760067989746, subsample=0.7645415620226714; total time= 8.9min\n",
      "[12:27:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8798048843068775, gamma=0.055341236967120545, learning_rate=0.035221630226164265, max_depth=4, n_estimators=223, reg_alpha=0.7145951041799521, reg_lambda=1.0821350335357516, subsample=0.7595283605779178; total time= 2.9min\n",
      "[12:30:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8798048843068775, gamma=0.055341236967120545, learning_rate=0.035221630226164265, max_depth=4, n_estimators=223, reg_alpha=0.7145951041799521, reg_lambda=1.0821350335357516, subsample=0.7595283605779178; total time= 3.0min\n",
      "[12:32:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8798048843068775, gamma=0.055341236967120545, learning_rate=0.035221630226164265, max_depth=4, n_estimators=223, reg_alpha=0.7145951041799521, reg_lambda=1.0821350335357516, subsample=0.7595283605779178; total time= 2.9min\n",
      "[12:35:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7734082950322968, gamma=0.29761705719964615, learning_rate=0.05766350019586563, max_depth=12, n_estimators=216, reg_alpha=0.08087296661719767, reg_lambda=1.8566289498802155, subsample=0.8753999603061465; total time= 7.3min\n",
      "[12:43:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7734082950322968, gamma=0.29761705719964615, learning_rate=0.05766350019586563, max_depth=12, n_estimators=216, reg_alpha=0.08087296661719767, reg_lambda=1.8566289498802155, subsample=0.8753999603061465; total time= 7.2min\n",
      "[12:50:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7734082950322968, gamma=0.29761705719964615, learning_rate=0.05766350019586563, max_depth=12, n_estimators=216, reg_alpha=0.08087296661719767, reg_lambda=1.8566289498802155, subsample=0.8753999603061465; total time= 7.2min\n",
      "[12:57:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6232774382033774, gamma=0.3660854910505922, learning_rate=0.09404692364890983, max_depth=8, n_estimators=147, reg_alpha=0.18286599710730733, reg_lambda=2.8692279946794192, subsample=0.8553082375373402; total time= 2.7min\n",
      "[13:00:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6232774382033774, gamma=0.3660854910505922, learning_rate=0.09404692364890983, max_depth=8, n_estimators=147, reg_alpha=0.18286599710730733, reg_lambda=2.8692279946794192, subsample=0.8553082375373402; total time= 2.7min\n",
      "[13:03:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6232774382033774, gamma=0.3660854910505922, learning_rate=0.09404692364890983, max_depth=8, n_estimators=147, reg_alpha=0.18286599710730733, reg_lambda=2.8692279946794192, subsample=0.8553082375373402; total time= 2.7min\n",
      "[13:05:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8066785029706267, gamma=0.26284453140006675, learning_rate=0.0927778507487993, max_depth=9, n_estimators=175, reg_alpha=0.5660372104940763, reg_lambda=1.317292895284982, subsample=0.6480658591222569; total time= 5.0min\n",
      "[13:10:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8066785029706267, gamma=0.26284453140006675, learning_rate=0.0927778507487993, max_depth=9, n_estimators=175, reg_alpha=0.5660372104940763, reg_lambda=1.317292895284982, subsample=0.6480658591222569; total time= 5.0min\n",
      "[13:15:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.8066785029706267, gamma=0.26284453140006675, learning_rate=0.0927778507487993, max_depth=9, n_estimators=175, reg_alpha=0.5660372104940763, reg_lambda=1.317292895284982, subsample=0.6480658591222569; total time= 5.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:20:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7367518666865607, gamma=0.03671962632537675, learning_rate=0.027889827771026422, max_depth=6, n_estimators=303, reg_alpha=0.017161101831750236, reg_lambda=2.526728846007822, subsample=0.9227651908203118; total time= 4.6min\n",
      "[13:25:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7367518666865607, gamma=0.03671962632537675, learning_rate=0.027889827771026422, max_depth=6, n_estimators=303, reg_alpha=0.017161101831750236, reg_lambda=2.526728846007822, subsample=0.9227651908203118; total time= 4.6min\n",
      "[13:29:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7367518666865607, gamma=0.03671962632537675, learning_rate=0.027889827771026422, max_depth=6, n_estimators=303, reg_alpha=0.017161101831750236, reg_lambda=2.526728846007822, subsample=0.9227651908203118; total time= 4.6min\n",
      "[13:34:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7385217284357604, gamma=0.18586952517584457, learning_rate=0.13345699970212505, max_depth=12, n_estimators=109, reg_alpha=0.9491457315913859, reg_lambda=2.773360774596095, subsample=0.7043574493366855; total time= 3.8min\n",
      "[13:38:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7385217284357604, gamma=0.18586952517584457, learning_rate=0.13345699970212505, max_depth=12, n_estimators=109, reg_alpha=0.9491457315913859, reg_lambda=2.773360774596095, subsample=0.7043574493366855; total time= 3.8min\n",
      "[13:42:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.7385217284357604, gamma=0.18586952517584457, learning_rate=0.13345699970212505, max_depth=12, n_estimators=109, reg_alpha=0.9491457315913859, reg_lambda=2.773360774596095, subsample=0.7043574493366855; total time= 3.8min\n",
      "[13:45:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6061218161161539, gamma=0.3733745232317932, learning_rate=0.10519757794389925, max_depth=10, n_estimators=424, reg_alpha=0.6839637693981411, reg_lambda=2.2317023287798277, subsample=0.9775566418243029; total time= 8.6min\n",
      "[13:54:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6061218161161539, gamma=0.3733745232317932, learning_rate=0.10519757794389925, max_depth=10, n_estimators=424, reg_alpha=0.6839637693981411, reg_lambda=2.2317023287798277, subsample=0.9775566418243029; total time= 8.6min\n",
      "[14:03:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.6061218161161539, gamma=0.3733745232317932, learning_rate=0.10519757794389925, max_depth=10, n_estimators=424, reg_alpha=0.6839637693981411, reg_lambda=2.2317023287798277, subsample=0.9775566418243029; total time=10.2min\n",
      "[14:13:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.977700638850067, gamma=0.34687957342200154, learning_rate=0.13091668351474214, max_depth=6, n_estimators=251, reg_alpha=0.6771683423829817, reg_lambda=2.1467340833438664, subsample=0.651400141293564; total time= 6.6min\n",
      "[14:19:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.977700638850067, gamma=0.34687957342200154, learning_rate=0.13091668351474214, max_depth=6, n_estimators=251, reg_alpha=0.6771683423829817, reg_lambda=2.1467340833438664, subsample=0.651400141293564; total time= 6.9min\n",
      "[14:26:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.977700638850067, gamma=0.34687957342200154, learning_rate=0.13091668351474214, max_depth=6, n_estimators=251, reg_alpha=0.6771683423829817, reg_lambda=2.1467340833438664, subsample=0.651400141293564; total time= 5.6min\n",
      "[14:32:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9244816706944012, gamma=0.3282557902975822, learning_rate=0.12892853731929885, max_depth=3, n_estimators=267, reg_alpha=0.9053506419560637, reg_lambda=1.3915822695785929, subsample=0.6277445203500661; total time= 3.1min\n",
      "[14:35:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9244816706944012, gamma=0.3282557902975822, learning_rate=0.12892853731929885, max_depth=3, n_estimators=267, reg_alpha=0.9053506419560637, reg_lambda=1.3915822695785929, subsample=0.6277445203500661; total time= 3.1min\n",
      "[14:38:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV] END colsample_bytree=0.9244816706944012, gamma=0.3282557902975822, learning_rate=0.12892853731929885, max_depth=3, n_estimators=267, reg_alpha=0.9053506419560637, reg_lambda=1.3915822695785929, subsample=0.6277445203500661; total time= 3.1min\n",
      "[14:41:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Best parameters found:  {'colsample_bytree': 0.9355734008277453, 'gamma': 0.34416184732467014, 'learning_rate': 0.05754775849801417, 'max_depth': 12, 'n_estimators': 425, 'reg_alpha': 0.3032655146732228, 'reg_lambda': 2.074164854393311, 'subsample': 0.7306604967184164}\n",
      "Best Score: -1611.1292\n"
     ]
    }
   ],
   "source": [
    "# define the XGBRegressor model\n",
    "xgb_model = XGBRegressor(random_state=42, early_stopping_rounds=10)\n",
    "\n",
    "# define the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 501),\n",
    "    'max_depth': randint(3, 13),\n",
    "    'learning_rate': uniform(0.01, 0.19),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'gamma': uniform(0, 0.4),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(1, 2)\n",
    "}\n",
    "\n",
    "# set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50, \n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "random_search.fit(x_train_array_ohe, y_train_array_ohe)\n",
    "\n",
    "# best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(f\"Best Score: {random_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [1533.8972715  1539.39468102 1564.12217632 1537.82334636 1561.99302103]\n",
      "Mean Cross-Validation RMSE: 1547.446099245668\n",
      "Standard Deviation of Cross-Validation RMSE: 12.889514510566135\n",
      "Training time: 1595.166897058487 seconds\n",
      "Validation prediction time: 1.9100613594055176 seconds\n",
      "Validation RMSE: 1551.5367204024178\n",
      "Test prediction time: 1.8989830017089844 seconds\n",
      "Test RMSE: 1570.282256272423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'training_time': 1595.166897058487,\n",
       " 'validation_time': 1.9100613594055176,\n",
       " 'validation_rmse': 1551.5367204024178,\n",
       " 'test_prediction_time': 1.8989830017089844,\n",
       " 'test_rmse': 1570.282256272423,\n",
       " 'cv_rmse_scores': array([1533.8972715 , 1539.39468102, 1564.12217632, 1537.82334636,\n",
       "        1561.99302103]),\n",
       " 'mean_cv_rmse': 1547.446099245668,\n",
       " 'std_cv_rmse': 12.889514510566135}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_eval(XGBRegressor, x_ohe, y_ohe, cv_splits=5, \n",
    "                              colsample_bytree= 0.9355734008277453, gamma= 0.34416184732467014,\n",
    "                              learning_rate= 0.05754775849801417, max_depth= 12, n_estimators= 425,\n",
    "                              reg_alpha= 0.3032655146732228, reg_lambda= 2.074164854393311, subsample= 0.7306604967184164, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78/1762413361.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train[col] = x_train[col].astype('category')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training time: 198.02 seconds\n",
      "XGBoost training time: 1620.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 915\n",
      "[LightGBM] [Info] Number of data points in the train set: 147340, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 5134.128363\n",
      "LightGBM training time: 4.43 seconds\n",
      "CatBoost training time: 54.47 seconds\n",
      "Meta-learner training time: 1.06 seconds\n",
      "Validation prediction time: 0.01 seconds\n",
      "Validation RMSE: 1705.9689\n",
      "Test prediction time: 0.01 seconds\n",
      "Test RMSE: 1718.5146\n"
     ]
    }
   ],
   "source": [
    "# convert categorical features to 'category' dtype for LightGBM\n",
    "for col in categorical_features:\n",
    "    x_train[col] = x_train[col].astype('category')\n",
    "    x_valid[col] = x_valid[col].astype('category')\n",
    "    x_test[col] = x_test[col].astype('category')\n",
    "\n",
    "# convert training set to LightGBM dataset\n",
    "lgb_train_data = lgb.Dataset(x_train, label=y_train, categorical_feature=categorical_features)\n",
    "\n",
    "# define base models\n",
    "rf_model = RandomForestRegressor(min_samples_leaf=1, min_samples_split=5, n_estimators=107, random_state=42)\n",
    "xgb_model = XGBRegressor(colsample_bytree=0.9355734008277453, gamma=0.34416184732467014,\n",
    "                         learning_rate=0.05754775849801417, max_depth=12, n_estimators=425,\n",
    "                         reg_alpha=0.3032655146732228, reg_lambda=2.074164854393311, subsample=0.7306604967184164, random_state=42)\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'colsample_bytree': 0.791609158103318,\n",
    "    'learning_rate': 0.10712275071724532,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 257,\n",
    "    'num_leaves': 48,\n",
    "    'reg_alpha': 0.22426930946055978,\n",
    "    'reg_lambda': 0.7121792213475359,\n",
    "    'subsample': 0.7711747262490399,\n",
    "    'random_state': 42,\n",
    "}\n",
    "cat_model = CatBoostRegressor(cat_features=categorical_features, bootstrap_type='Bayesian',\n",
    "                              border_count=199, depth=10, grow_policy='Depthwise', iterations=459, \n",
    "                              l2_leaf_reg=1, learning_rate=0.13838112223746335, min_data_in_leaf=9, \n",
    "                              random_strength=9, random_state=42, silent=True)\n",
    "\n",
    "# track training time for each base model\n",
    "start_time = time.time()\n",
    "rf_model.fit(x_train_ohe, y_train_ohe)\n",
    "rf_training_time = time.time() - start_time\n",
    "print(f\"Random Forest training time: {rf_training_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_model.fit(x_train_ohe, y_train_ohe)\n",
    "xgb_training_time = time.time() - start_time\n",
    "print(f\"XGBoost training time: {xgb_training_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "lgb_model = lgb.train(lgb_params, lgb_train_data)\n",
    "lgb_training_time = time.time() - start_time\n",
    "print(f\"LightGBM training time: {lgb_training_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "cat_model.fit(x_train, y_train)\n",
    "cat_training_time = time.time() - start_time\n",
    "print(f\"CatBoost training time: {cat_training_time:.2f} seconds\")\n",
    "\n",
    "# get predictions from base models on training data\n",
    "rf_pred_train = rf_model.predict(x_train_ohe)\n",
    "xgb_pred_train = xgb_model.predict(x_train_ohe)\n",
    "lgb_pred_train = lgb_model.predict(x_train)\n",
    "cat_pred_train = cat_model.predict(x_train)\n",
    "\n",
    "# stack the predictions along with original features to create a new training set for the meta-model\n",
    "X_meta_train = np.column_stack((rf_pred_train, xgb_pred_train, lgb_pred_train, cat_pred_train, x_train_ohe))\n",
    "\n",
    "# define and train the meta-learner\n",
    "meta_learner = Ridge(alpha=1.0)\n",
    "start_time = time.time()\n",
    "meta_learner.fit(X_meta_train, y_train)\n",
    "meta_training_time = time.time() - start_time\n",
    "print(f\"Meta-learner training time: {meta_training_time:.2f} seconds\")\n",
    "\n",
    "# get predictions from base models on validation data\n",
    "rf_pred_val = rf_model.predict(x_valid_ohe)\n",
    "xgb_pred_val = xgb_model.predict(x_valid_ohe)\n",
    "lgb_pred_val = lgb_model.predict(x_valid)\n",
    "cat_pred_val = cat_model.predict(x_valid)\n",
    "\n",
    "# stack the validation predictions\n",
    "X_meta_val = np.column_stack((rf_pred_val, xgb_pred_val, lgb_pred_val, cat_pred_val, x_valid_ohe))\n",
    "\n",
    "# measure prediction time on validation set\n",
    "start_time = time.time()\n",
    "y_pred_val = meta_learner.predict(X_meta_val)\n",
    "validation_time = time.time() - start_time\n",
    "print(f\"Validation prediction time: {validation_time:.2f} seconds\")\n",
    "\n",
    "# calculate RMSE for validation\n",
    "rmse_val = np.sqrt(mean_squared_error(y_valid_ohe, y_pred_val))\n",
    "print(f\"Validation RMSE: {rmse_val:.4f}\")\n",
    "\n",
    "# get predictions from base models on test data\n",
    "rf_pred_test = rf_model.predict(x_test_ohe)\n",
    "xgb_pred_test = xgb_model.predict(x_test_ohe)\n",
    "lgb_pred_test = lgb_model.predict(x_test)\n",
    "cat_pred_test = cat_model.predict(x_test)\n",
    "\n",
    "# stack the test predictions\n",
    "X_meta_test = np.column_stack((rf_pred_test, xgb_pred_test, lgb_pred_test, cat_pred_test, x_test_ohe))\n",
    "\n",
    "# measure prediction time on test set\n",
    "start_time = time.time()\n",
    "y_pred_test = meta_learner.predict(X_meta_test)\n",
    "test_prediction_time = time.time() - start_time\n",
    "print(f\"Test prediction time: {test_prediction_time:.2f} seconds\")\n",
    "\n",
    "# calculate RMSE for test\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print(f\"Test RMSE: {rmse_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - the model metrics referenced in the conclusion below are all after tuning is done\n",
    " \n",
    "After training & making predictions with the various prior models, it seems that each model is unique with its training time and prediction quality. With respect to training time, there appears that 3 distinct classes were formed, one class that incorporates 3 models (LR & LGBM) that are towards the lower range, another that incorporates 3 models (RF, XGB & Stacked) that seems to hang around the 2 to 5 minute mark & 1 model (CB) that resides in the middle (around 1 min). Now, solely using the LR as a reference (sanity check), the only model that outperformed it is the LGBM in terms of time . \n",
    "\n",
    "Looking towards the prediction timing, no models outperformed the LR model for both validation and testing except for the stacked regressor. However, for prediction quality, all of the models did better than the base model, with the XGBoost model being the most accurate. Overall, there's a trend in the RMSE score across all models, the score increases after the validation prediction, which usually indicates overfitting; overfitting regularizers were used in tuning.\n",
    "\n",
    "For considering a model to use, if time is a high importance, I think the LGBM would be the best given that the sum time for training and prediction is low. If prediction quality is imperative, then either XGBoost or CatBoost is a great pick. It seems that the CatBoost model is an ideal pick that balances prediction quality with time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [x]  Code is error free\n",
    "- [x]  The cells with the code have been arranged in order of execution\n",
    "- [x]  The data has been downloaded and prepared\n",
    "- [x]  The models have been trained\n",
    "- [x]  The analysis of speed and quality of the models has been performed"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2564,
    "start_time": "2024-12-23T00:34:13.003Z"
   },
   {
    "duration": 462,
    "start_time": "2024-12-23T00:36:09.217Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-23T00:36:33.952Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-23T00:37:00.255Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-23T00:39:49.234Z"
   },
   {
    "duration": 162,
    "start_time": "2024-12-23T18:08:10.800Z"
   },
   {
    "duration": 2891,
    "start_time": "2024-12-23T18:08:17.978Z"
   },
   {
    "duration": 486,
    "start_time": "2024-12-23T18:08:23.308Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-23T18:08:26.669Z"
   },
   {
    "duration": 96,
    "start_time": "2024-12-23T18:08:27.832Z"
   },
   {
    "duration": 76,
    "start_time": "2024-12-23T18:08:29.061Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-23T18:08:32.701Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-23T18:08:38.854Z"
   },
   {
    "duration": 261,
    "start_time": "2024-12-23T18:09:34.334Z"
   },
   {
    "duration": 345,
    "start_time": "2024-12-23T18:09:40.408Z"
   },
   {
    "duration": 240,
    "start_time": "2024-12-23T18:09:50.745Z"
   },
   {
    "duration": 247,
    "start_time": "2024-12-23T18:09:59.983Z"
   },
   {
    "duration": 258,
    "start_time": "2024-12-23T18:10:06.813Z"
   },
   {
    "duration": 255,
    "start_time": "2024-12-23T18:10:13.693Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-23T18:12:10.023Z"
   },
   {
    "duration": 154,
    "start_time": "2024-12-23T19:18:59.655Z"
   },
   {
    "duration": 2570,
    "start_time": "2024-12-23T19:19:13.889Z"
   },
   {
    "duration": 447,
    "start_time": "2024-12-23T19:19:18.789Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-23T19:19:21.550Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-23T19:19:24.265Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-23T19:19:25.969Z"
   },
   {
    "duration": 212,
    "start_time": "2024-12-23T19:19:28.683Z"
   },
   {
    "duration": 453,
    "start_time": "2024-12-23T19:19:31.559Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-23T19:35:35.319Z"
   },
   {
    "duration": 29,
    "start_time": "2024-12-23T19:37:52.380Z"
   },
   {
    "duration": 957,
    "start_time": "2024-12-23T19:39:10.438Z"
   },
   {
    "duration": 397,
    "start_time": "2024-12-23T19:39:12.743Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-23T19:39:14.945Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-23T19:39:16.800Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-23T19:39:18.531Z"
   },
   {
    "duration": 216,
    "start_time": "2024-12-23T19:39:22.831Z"
   },
   {
    "duration": 474,
    "start_time": "2024-12-23T19:39:24.359Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-23T19:39:26.049Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-23T19:39:27.538Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-23T19:44:55.385Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-23T19:45:05.628Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-23T19:45:17.164Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-23T19:45:30.835Z"
   },
   {
    "duration": 946,
    "start_time": "2024-12-23T20:00:33.710Z"
   },
   {
    "duration": 416,
    "start_time": "2024-12-23T20:00:34.658Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-23T20:00:35.076Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-23T20:00:35.092Z"
   },
   {
    "duration": 70,
    "start_time": "2024-12-23T20:00:35.195Z"
   },
   {
    "duration": 236,
    "start_time": "2024-12-23T20:00:35.267Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-23T20:00:35.512Z"
   },
   {
    "duration": 1,
    "start_time": "2024-12-23T20:00:35.512Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-23T20:00:35.514Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-23T20:00:35.515Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-23T20:00:35.516Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-23T20:00:35.517Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-23T20:00:46.967Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-23T20:00:50.580Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-23T20:00:53.026Z"
   },
   {
    "duration": 89,
    "start_time": "2024-12-23T20:00:56.128Z"
   },
   {
    "duration": 935,
    "start_time": "2024-12-23T20:03:57.128Z"
   },
   {
    "duration": 399,
    "start_time": "2024-12-23T20:03:58.065Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-23T20:03:58.466Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-23T20:03:58.481Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-23T20:03:58.584Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-23T20:03:58.650Z"
   },
   {
    "duration": 230,
    "start_time": "2024-12-23T20:03:58.675Z"
   },
   {
    "duration": 472,
    "start_time": "2024-12-23T20:03:58.912Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-23T20:03:59.386Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-23T20:03:59.478Z"
   },
   {
    "duration": 35,
    "start_time": "2024-12-23T20:03:59.490Z"
   },
   {
    "duration": 98,
    "start_time": "2024-12-23T20:03:59.527Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-23T20:06:35.469Z"
   },
   {
    "duration": 60,
    "start_time": "2024-12-23T20:07:07.024Z"
   },
   {
    "duration": 196,
    "start_time": "2024-12-23T20:07:52.491Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-23T20:09:28.799Z"
   },
   {
    "duration": 209,
    "start_time": "2024-12-23T20:09:40.804Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-23T20:10:51.113Z"
   },
   {
    "duration": 120,
    "start_time": "2024-12-23T20:10:58.864Z"
   },
   {
    "duration": 960,
    "start_time": "2024-12-23T20:15:33.790Z"
   },
   {
    "duration": 402,
    "start_time": "2024-12-23T20:15:34.753Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-23T20:15:35.157Z"
   },
   {
    "duration": 102,
    "start_time": "2024-12-23T20:15:35.172Z"
   },
   {
    "duration": 72,
    "start_time": "2024-12-23T20:15:35.277Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-23T20:15:35.352Z"
   },
   {
    "duration": 229,
    "start_time": "2024-12-23T20:15:35.376Z"
   },
   {
    "duration": 455,
    "start_time": "2024-12-23T20:15:35.611Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-23T20:15:36.068Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-23T20:15:36.160Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-23T20:15:36.172Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-23T20:15:36.189Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-23T20:15:36.221Z"
   },
   {
    "duration": 134,
    "start_time": "2024-12-23T20:15:36.231Z"
   },
   {
    "duration": 941,
    "start_time": "2024-12-23T20:17:50.830Z"
   },
   {
    "duration": 398,
    "start_time": "2024-12-23T20:17:51.773Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-23T20:17:52.172Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-23T20:17:52.188Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-23T20:17:52.292Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-23T20:17:52.357Z"
   },
   {
    "duration": 239,
    "start_time": "2024-12-23T20:17:52.381Z"
   },
   {
    "duration": 473,
    "start_time": "2024-12-23T20:17:52.622Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-23T20:17:53.098Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-23T20:17:53.192Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-23T20:17:53.213Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-23T20:17:53.238Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-23T20:17:53.245Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-23T20:17:53.251Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-23T20:20:39.756Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-23T20:22:26.611Z"
   },
   {
    "duration": 147,
    "start_time": "2024-12-23T20:24:01.273Z"
   },
   {
    "duration": 948,
    "start_time": "2024-12-23T20:42:32.615Z"
   },
   {
    "duration": 391,
    "start_time": "2024-12-23T20:42:33.566Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-23T20:42:33.960Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-23T20:42:33.975Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-23T20:42:34.078Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-23T20:42:34.144Z"
   },
   {
    "duration": 235,
    "start_time": "2024-12-23T20:42:34.168Z"
   },
   {
    "duration": 489,
    "start_time": "2024-12-23T20:42:34.405Z"
   },
   {
    "duration": 88,
    "start_time": "2024-12-23T20:42:34.898Z"
   },
   {
    "duration": 129,
    "start_time": "2024-12-23T20:42:34.989Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-23T20:42:35.119Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-23T20:42:35.133Z"
   },
   {
    "duration": 42,
    "start_time": "2024-12-23T20:42:35.151Z"
   },
   {
    "duration": 62,
    "start_time": "2024-12-23T20:42:35.194Z"
   },
   {
    "duration": 121,
    "start_time": "2024-12-23T20:42:35.258Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-23T20:42:35.380Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-23T20:42:35.384Z"
   },
   {
    "duration": 957,
    "start_time": "2024-12-23T20:50:45.934Z"
   },
   {
    "duration": 400,
    "start_time": "2024-12-23T20:50:46.893Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-23T20:50:47.294Z"
   },
   {
    "duration": 89,
    "start_time": "2024-12-23T20:50:47.313Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-23T20:50:47.404Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-23T20:50:47.466Z"
   },
   {
    "duration": 234,
    "start_time": "2024-12-23T20:50:47.492Z"
   },
   {
    "duration": 469,
    "start_time": "2024-12-23T20:50:47.728Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-23T20:50:48.199Z"
   },
   {
    "duration": 181,
    "start_time": "2024-12-23T20:50:48.294Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-23T20:50:48.477Z"
   },
   {
    "duration": 29,
    "start_time": "2024-12-23T20:50:48.489Z"
   },
   {
    "duration": 41,
    "start_time": "2024-12-23T20:50:48.519Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-23T20:50:48.562Z"
   },
   {
    "duration": 114,
    "start_time": "2024-12-23T20:50:48.620Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-23T20:50:48.736Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-23T20:50:48.741Z"
   },
   {
    "duration": 5752,
    "start_time": "2024-12-23T21:01:13.717Z"
   },
   {
    "duration": 157,
    "start_time": "2024-12-24T01:02:55.958Z"
   },
   {
    "duration": 2576,
    "start_time": "2024-12-24T01:03:13.384Z"
   },
   {
    "duration": 471,
    "start_time": "2024-12-24T01:03:17.379Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-24T01:03:19.671Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-24T01:03:21.077Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-24T01:03:22.456Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-24T01:03:23.113Z"
   },
   {
    "duration": 229,
    "start_time": "2024-12-24T01:03:25.314Z"
   },
   {
    "duration": 492,
    "start_time": "2024-12-24T01:03:27.219Z"
   },
   {
    "duration": 87,
    "start_time": "2024-12-24T01:03:30.249Z"
   },
   {
    "duration": 178,
    "start_time": "2024-12-24T01:03:32.668Z"
   },
   {
    "duration": 16179,
    "start_time": "2024-12-24T01:03:35.606Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-24T01:06:58.509Z"
   },
   {
    "duration": 288,
    "start_time": "2024-12-24T01:07:07.953Z"
   },
   {
    "duration": 46,
    "start_time": "2024-12-24T01:16:00.679Z"
   },
   {
    "duration": 387,
    "start_time": "2024-12-24T01:16:40.219Z"
   },
   {
    "duration": 974,
    "start_time": "2024-12-24T01:17:39.318Z"
   },
   {
    "duration": 409,
    "start_time": "2024-12-24T01:17:40.294Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-24T01:17:40.704Z"
   },
   {
    "duration": 99,
    "start_time": "2024-12-24T01:17:40.722Z"
   },
   {
    "duration": 55,
    "start_time": "2024-12-24T01:17:40.822Z"
   },
   {
    "duration": 39,
    "start_time": "2024-12-24T01:17:40.879Z"
   },
   {
    "duration": 245,
    "start_time": "2024-12-24T01:17:40.920Z"
   },
   {
    "duration": 491,
    "start_time": "2024-12-24T01:17:41.167Z"
   },
   {
    "duration": 89,
    "start_time": "2024-12-24T01:17:41.660Z"
   },
   {
    "duration": 191,
    "start_time": "2024-12-24T01:17:41.751Z"
   },
   {
    "duration": 309,
    "start_time": "2024-12-24T01:17:41.944Z"
   },
   {
    "duration": 377,
    "start_time": "2024-12-24T01:17:42.255Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-24T01:17:42.634Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-24T01:17:42.647Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-24T01:17:42.661Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-24T01:17:42.665Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-24T01:22:29.965Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-24T01:22:47.651Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-24T01:27:24.313Z"
   },
   {
    "duration": 240,
    "start_time": "2024-12-24T01:30:39.231Z"
   },
   {
    "duration": 231,
    "start_time": "2024-12-24T01:30:56.387Z"
   },
   {
    "duration": 989,
    "start_time": "2024-12-24T01:34:00.585Z"
   },
   {
    "duration": 534,
    "start_time": "2024-12-24T01:34:01.578Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-24T01:34:02.114Z"
   },
   {
    "duration": 120,
    "start_time": "2024-12-24T01:34:02.133Z"
   },
   {
    "duration": 69,
    "start_time": "2024-12-24T01:34:02.255Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-24T01:34:02.326Z"
   },
   {
    "duration": 294,
    "start_time": "2024-12-24T01:34:02.357Z"
   },
   {
    "duration": 503,
    "start_time": "2024-12-24T01:34:02.654Z"
   },
   {
    "duration": 108,
    "start_time": "2024-12-24T01:34:03.159Z"
   },
   {
    "duration": 245,
    "start_time": "2024-12-24T01:34:03.271Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-24T01:34:03.517Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-24T01:34:03.531Z"
   },
   {
    "duration": 269,
    "start_time": "2024-12-24T01:34:03.556Z"
   },
   {
    "duration": 234,
    "start_time": "2024-12-24T01:34:03.828Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-24T01:34:04.065Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-24T01:34:04.070Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-24T01:34:04.074Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-24T01:34:04.109Z"
   },
   {
    "duration": 451,
    "start_time": "2024-12-24T01:36:07.301Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-24T01:37:47.570Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-24T01:39:24.885Z"
   },
   {
    "duration": 99,
    "start_time": "2024-12-24T01:40:10.494Z"
   },
   {
    "duration": 137,
    "start_time": "2024-12-24T01:40:51.252Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-24T01:46:46.535Z"
   },
   {
    "duration": 230,
    "start_time": "2024-12-24T02:12:01.105Z"
   },
   {
    "duration": 436,
    "start_time": "2024-12-24T02:22:25.162Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-24T02:32:28.685Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-24T20:51:17.596Z"
   },
   {
    "duration": 155,
    "start_time": "2024-12-24T20:51:21.448Z"
   },
   {
    "duration": 2656,
    "start_time": "2024-12-24T20:53:50.115Z"
   },
   {
    "duration": 455,
    "start_time": "2024-12-24T20:53:52.773Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-24T20:53:53.230Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-24T20:53:53.245Z"
   },
   {
    "duration": 67,
    "start_time": "2024-12-24T20:53:53.351Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-24T20:53:53.420Z"
   },
   {
    "duration": 235,
    "start_time": "2024-12-24T20:53:53.447Z"
   },
   {
    "duration": 464,
    "start_time": "2024-12-24T20:53:53.685Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-24T20:53:54.151Z"
   },
   {
    "duration": 181,
    "start_time": "2024-12-24T20:53:54.247Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-24T20:53:54.430Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-24T20:53:54.443Z"
   },
   {
    "duration": 237,
    "start_time": "2024-12-24T20:53:54.458Z"
   },
   {
    "duration": 113,
    "start_time": "2024-12-24T20:53:54.697Z"
   },
   {
    "duration": 110,
    "start_time": "2024-12-24T20:53:54.812Z"
   },
   {
    "duration": 197,
    "start_time": "2024-12-24T20:53:54.924Z"
   },
   {
    "duration": 224,
    "start_time": "2024-12-24T20:53:55.123Z"
   },
   {
    "duration": 456,
    "start_time": "2024-12-24T20:53:55.349Z"
   },
   {
    "duration": 55,
    "start_time": "2024-12-24T20:53:55.810Z"
   },
   {
    "duration": 6069,
    "start_time": "2024-12-24T20:53:55.867Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-24T20:54:02.009Z"
   },
   {
    "duration": 316,
    "start_time": "2024-12-24T20:54:02.014Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-24T20:54:27.686Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-24T20:54:35.909Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-24T20:55:49.871Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-24T20:55:51.342Z"
   },
   {
    "duration": 2661,
    "start_time": "2024-12-24T23:41:34.129Z"
   },
   {
    "duration": 457,
    "start_time": "2024-12-24T23:41:36.792Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-24T23:41:37.253Z"
   },
   {
    "duration": 97,
    "start_time": "2024-12-24T23:41:37.273Z"
   },
   {
    "duration": 58,
    "start_time": "2024-12-24T23:41:37.372Z"
   },
   {
    "duration": 39,
    "start_time": "2024-12-24T23:41:37.432Z"
   },
   {
    "duration": 225,
    "start_time": "2024-12-24T23:41:37.473Z"
   },
   {
    "duration": 463,
    "start_time": "2024-12-24T23:41:37.699Z"
   },
   {
    "duration": 89,
    "start_time": "2024-12-24T23:41:38.164Z"
   },
   {
    "duration": 167,
    "start_time": "2024-12-24T23:41:38.270Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-24T23:41:38.439Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-24T23:41:38.451Z"
   },
   {
    "duration": 219,
    "start_time": "2024-12-24T23:41:38.479Z"
   },
   {
    "duration": 111,
    "start_time": "2024-12-24T23:41:38.699Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-24T23:41:38.812Z"
   },
   {
    "duration": 150,
    "start_time": "2024-12-24T23:41:38.921Z"
   },
   {
    "duration": 219,
    "start_time": "2024-12-24T23:41:39.073Z"
   },
   {
    "duration": 450,
    "start_time": "2024-12-24T23:41:39.294Z"
   },
   {
    "duration": 113,
    "start_time": "2024-12-24T23:41:39.746Z"
   },
   {
    "duration": 6036,
    "start_time": "2024-12-24T23:41:39.861Z"
   },
   {
    "duration": 76,
    "start_time": "2024-12-24T23:41:45.899Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-24T23:41:45.978Z"
   },
   {
    "duration": 1016,
    "start_time": "2024-12-25T00:02:32.835Z"
   },
   {
    "duration": 447,
    "start_time": "2024-12-25T00:02:33.853Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-25T00:02:34.301Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-25T00:02:34.319Z"
   },
   {
    "duration": 77,
    "start_time": "2024-12-25T00:02:34.428Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-25T00:02:34.507Z"
   },
   {
    "duration": 276,
    "start_time": "2024-12-25T00:02:34.535Z"
   },
   {
    "duration": 532,
    "start_time": "2024-12-25T00:02:34.813Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-25T00:02:35.347Z"
   },
   {
    "duration": 196,
    "start_time": "2024-12-25T00:02:35.456Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-25T00:02:35.654Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-25T00:02:35.681Z"
   },
   {
    "duration": 249,
    "start_time": "2024-12-25T00:02:35.705Z"
   },
   {
    "duration": 145,
    "start_time": "2024-12-25T00:02:35.956Z"
   },
   {
    "duration": 127,
    "start_time": "2024-12-25T00:02:36.103Z"
   },
   {
    "duration": 159,
    "start_time": "2024-12-25T00:02:36.233Z"
   },
   {
    "duration": 247,
    "start_time": "2024-12-25T00:02:36.394Z"
   },
   {
    "duration": 476,
    "start_time": "2024-12-25T00:02:36.643Z"
   },
   {
    "duration": 80,
    "start_time": "2024-12-25T00:02:37.121Z"
   },
   {
    "duration": 6871,
    "start_time": "2024-12-25T00:02:37.203Z"
   },
   {
    "duration": 109965,
    "start_time": "2024-12-25T00:02:44.076Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T00:04:34.044Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T00:04:34.045Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T00:04:34.047Z"
   },
   {
    "duration": 1033,
    "start_time": "2024-12-25T00:23:37.119Z"
   },
   {
    "duration": 479,
    "start_time": "2024-12-25T00:23:38.154Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-25T00:23:38.635Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-25T00:23:38.651Z"
   },
   {
    "duration": 77,
    "start_time": "2024-12-25T00:23:38.746Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-25T00:23:38.825Z"
   },
   {
    "duration": 256,
    "start_time": "2024-12-25T00:23:38.855Z"
   },
   {
    "duration": 597,
    "start_time": "2024-12-25T00:23:39.113Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-25T00:23:39.711Z"
   },
   {
    "duration": 203,
    "start_time": "2024-12-25T00:23:39.819Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-25T00:23:40.023Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-25T00:23:40.036Z"
   },
   {
    "duration": 252,
    "start_time": "2024-12-25T00:23:40.056Z"
   },
   {
    "duration": 135,
    "start_time": "2024-12-25T00:23:40.310Z"
   },
   {
    "duration": 118,
    "start_time": "2024-12-25T00:23:40.446Z"
   },
   {
    "duration": 177,
    "start_time": "2024-12-25T00:23:40.573Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-25T00:23:40.752Z"
   },
   {
    "duration": 466,
    "start_time": "2024-12-25T00:23:40.997Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-25T00:23:41.466Z"
   },
   {
    "duration": 9412,
    "start_time": "2024-12-25T00:23:41.560Z"
   },
   {
    "duration": 190796,
    "start_time": "2024-12-25T00:23:50.974Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T00:27:01.772Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T00:27:01.778Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T00:27:01.783Z"
   },
   {
    "duration": 230,
    "start_time": "2024-12-25T01:45:52.178Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-25T01:46:42.133Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T01:46:48.979Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T01:49:01.498Z"
   },
   {
    "duration": 4790,
    "start_time": "2024-12-25T01:49:02.788Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T01:49:30.858Z"
   },
   {
    "duration": 990,
    "start_time": "2024-12-25T02:03:37.917Z"
   },
   {
    "duration": 405,
    "start_time": "2024-12-25T02:03:38.909Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-25T02:03:39.316Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-25T02:03:39.333Z"
   },
   {
    "duration": 68,
    "start_time": "2024-12-25T02:03:39.438Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-25T02:03:39.507Z"
   },
   {
    "duration": 242,
    "start_time": "2024-12-25T02:03:39.532Z"
   },
   {
    "duration": 474,
    "start_time": "2024-12-25T02:03:39.776Z"
   },
   {
    "duration": 99,
    "start_time": "2024-12-25T02:03:40.251Z"
   },
   {
    "duration": 191,
    "start_time": "2024-12-25T02:03:40.354Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-25T02:03:40.547Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-25T02:03:40.559Z"
   },
   {
    "duration": 235,
    "start_time": "2024-12-25T02:03:40.586Z"
   },
   {
    "duration": 116,
    "start_time": "2024-12-25T02:03:40.823Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-25T02:03:40.941Z"
   },
   {
    "duration": 149,
    "start_time": "2024-12-25T02:03:41.046Z"
   },
   {
    "duration": 427,
    "start_time": "2024-12-25T02:03:41.197Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.626Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.628Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.629Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.631Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.632Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.633Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.634Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.635Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.636Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.637Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T02:03:41.638Z"
   },
   {
    "duration": 108,
    "start_time": "2024-12-25T02:04:13.387Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T02:04:18.167Z"
   },
   {
    "duration": 412,
    "start_time": "2024-12-25T02:04:30.673Z"
   },
   {
    "duration": 53,
    "start_time": "2024-12-25T02:04:35.384Z"
   },
   {
    "duration": 6019,
    "start_time": "2024-12-25T02:04:40.352Z"
   },
   {
    "duration": 190818,
    "start_time": "2024-12-25T02:04:49.253Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-25T02:08:16.872Z"
   },
   {
    "duration": 923,
    "start_time": "2024-12-25T02:53:20.644Z"
   },
   {
    "duration": 419,
    "start_time": "2024-12-25T02:53:21.571Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T02:53:21.992Z"
   },
   {
    "duration": 98,
    "start_time": "2024-12-25T02:53:22.008Z"
   },
   {
    "duration": 66,
    "start_time": "2024-12-25T02:53:22.108Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-25T02:53:22.176Z"
   },
   {
    "duration": 242,
    "start_time": "2024-12-25T02:53:22.203Z"
   },
   {
    "duration": 471,
    "start_time": "2024-12-25T02:53:22.446Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-25T02:53:22.919Z"
   },
   {
    "duration": 175,
    "start_time": "2024-12-25T02:53:23.016Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-25T02:53:23.193Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T02:53:23.206Z"
   },
   {
    "duration": 231,
    "start_time": "2024-12-25T02:53:23.221Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-25T02:53:23.454Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-25T02:53:23.569Z"
   },
   {
    "duration": 148,
    "start_time": "2024-12-25T02:53:23.675Z"
   },
   {
    "duration": 217,
    "start_time": "2024-12-25T02:53:23.825Z"
   },
   {
    "duration": 439,
    "start_time": "2024-12-25T02:53:24.043Z"
   },
   {
    "duration": 54,
    "start_time": "2024-12-25T02:53:24.483Z"
   },
   {
    "duration": 6056,
    "start_time": "2024-12-25T02:53:24.540Z"
   },
   {
    "duration": 189653,
    "start_time": "2024-12-25T02:53:30.598Z"
   },
   {
    "duration": 937,
    "start_time": "2024-12-25T03:04:21.613Z"
   },
   {
    "duration": 400,
    "start_time": "2024-12-25T03:04:22.552Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-25T03:04:22.954Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-25T03:04:22.974Z"
   },
   {
    "duration": 96,
    "start_time": "2024-12-25T03:04:23.077Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-25T03:04:23.176Z"
   },
   {
    "duration": 248,
    "start_time": "2024-12-25T03:04:23.202Z"
   },
   {
    "duration": 488,
    "start_time": "2024-12-25T03:04:23.451Z"
   },
   {
    "duration": 93,
    "start_time": "2024-12-25T03:04:23.941Z"
   },
   {
    "duration": 184,
    "start_time": "2024-12-25T03:04:24.038Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-25T03:04:24.224Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-25T03:04:24.237Z"
   },
   {
    "duration": 233,
    "start_time": "2024-12-25T03:04:24.270Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-25T03:04:24.505Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-25T03:04:24.619Z"
   },
   {
    "duration": 144,
    "start_time": "2024-12-25T03:04:24.727Z"
   },
   {
    "duration": 219,
    "start_time": "2024-12-25T03:04:24.874Z"
   },
   {
    "duration": 445,
    "start_time": "2024-12-25T03:04:25.095Z"
   },
   {
    "duration": 60,
    "start_time": "2024-12-25T03:04:25.541Z"
   },
   {
    "duration": 6076,
    "start_time": "2024-12-25T03:04:25.602Z"
   },
   {
    "duration": 189104,
    "start_time": "2024-12-25T03:04:31.680Z"
   },
   {
    "duration": 996,
    "start_time": "2024-12-25T03:14:27.995Z"
   },
   {
    "duration": 409,
    "start_time": "2024-12-25T03:14:28.993Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T03:14:29.403Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-25T03:14:29.419Z"
   },
   {
    "duration": 66,
    "start_time": "2024-12-25T03:14:29.525Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-25T03:14:29.592Z"
   },
   {
    "duration": 246,
    "start_time": "2024-12-25T03:14:29.617Z"
   },
   {
    "duration": 475,
    "start_time": "2024-12-25T03:14:29.865Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-25T03:14:30.341Z"
   },
   {
    "duration": 186,
    "start_time": "2024-12-25T03:14:30.438Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-25T03:14:30.627Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-25T03:14:30.639Z"
   },
   {
    "duration": 229,
    "start_time": "2024-12-25T03:14:30.672Z"
   },
   {
    "duration": 111,
    "start_time": "2024-12-25T03:14:30.904Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-25T03:14:31.017Z"
   },
   {
    "duration": 160,
    "start_time": "2024-12-25T03:14:31.131Z"
   },
   {
    "duration": 234,
    "start_time": "2024-12-25T03:14:31.293Z"
   },
   {
    "duration": 520,
    "start_time": "2024-12-25T03:14:31.529Z"
   },
   {
    "duration": 62,
    "start_time": "2024-12-25T03:14:32.051Z"
   },
   {
    "duration": 6165,
    "start_time": "2024-12-25T03:14:32.115Z"
   },
   {
    "duration": 188746,
    "start_time": "2024-12-25T03:14:38.282Z"
   },
   {
    "duration": 947,
    "start_time": "2024-12-25T03:23:44.507Z"
   },
   {
    "duration": 397,
    "start_time": "2024-12-25T03:23:45.456Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-25T03:23:45.855Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-25T03:23:45.874Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-25T03:23:45.976Z"
   },
   {
    "duration": 38,
    "start_time": "2024-12-25T03:23:46.035Z"
   },
   {
    "duration": 228,
    "start_time": "2024-12-25T03:23:46.075Z"
   },
   {
    "duration": 495,
    "start_time": "2024-12-25T03:23:46.305Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-25T03:23:46.802Z"
   },
   {
    "duration": 181,
    "start_time": "2024-12-25T03:23:46.898Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-25T03:23:47.081Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T03:23:47.094Z"
   },
   {
    "duration": 234,
    "start_time": "2024-12-25T03:23:47.110Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-25T03:23:47.347Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-25T03:23:47.458Z"
   },
   {
    "duration": 145,
    "start_time": "2024-12-25T03:23:47.572Z"
   },
   {
    "duration": 218,
    "start_time": "2024-12-25T03:23:47.718Z"
   },
   {
    "duration": 449,
    "start_time": "2024-12-25T03:23:47.938Z"
   },
   {
    "duration": 54,
    "start_time": "2024-12-25T03:23:48.388Z"
   },
   {
    "duration": 6028,
    "start_time": "2024-12-25T03:23:48.445Z"
   },
   {
    "duration": 189845,
    "start_time": "2024-12-25T03:23:54.476Z"
   },
   {
    "duration": 950,
    "start_time": "2024-12-25T04:05:09.165Z"
   },
   {
    "duration": 409,
    "start_time": "2024-12-25T04:05:10.118Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T04:05:10.529Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-25T04:05:10.545Z"
   },
   {
    "duration": 66,
    "start_time": "2024-12-25T04:05:10.652Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-25T04:05:10.719Z"
   },
   {
    "duration": 240,
    "start_time": "2024-12-25T04:05:10.747Z"
   },
   {
    "duration": 474,
    "start_time": "2024-12-25T04:05:10.989Z"
   },
   {
    "duration": 85,
    "start_time": "2024-12-25T04:05:11.471Z"
   },
   {
    "duration": 182,
    "start_time": "2024-12-25T04:05:11.558Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-25T04:05:11.742Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-25T04:05:11.754Z"
   },
   {
    "duration": 233,
    "start_time": "2024-12-25T04:05:11.778Z"
   },
   {
    "duration": 113,
    "start_time": "2024-12-25T04:05:12.016Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-25T04:05:12.131Z"
   },
   {
    "duration": 143,
    "start_time": "2024-12-25T04:05:12.239Z"
   },
   {
    "duration": 225,
    "start_time": "2024-12-25T04:05:12.384Z"
   },
   {
    "duration": 439,
    "start_time": "2024-12-25T04:05:12.612Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-25T04:05:13.052Z"
   },
   {
    "duration": 6155,
    "start_time": "2024-12-25T04:05:13.117Z"
   },
   {
    "duration": 189878,
    "start_time": "2024-12-25T04:05:19.273Z"
   },
   {
    "duration": 937,
    "start_time": "2024-12-25T04:43:03.070Z"
   },
   {
    "duration": 401,
    "start_time": "2024-12-25T04:43:04.009Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T04:43:04.412Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-25T04:43:04.429Z"
   },
   {
    "duration": 67,
    "start_time": "2024-12-25T04:43:04.536Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-25T04:43:04.605Z"
   },
   {
    "duration": 253,
    "start_time": "2024-12-25T04:43:04.632Z"
   },
   {
    "duration": 491,
    "start_time": "2024-12-25T04:43:04.887Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-25T04:43:05.380Z"
   },
   {
    "duration": 197,
    "start_time": "2024-12-25T04:43:05.474Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-25T04:43:05.672Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T04:43:05.684Z"
   },
   {
    "duration": 241,
    "start_time": "2024-12-25T04:43:05.700Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-25T04:43:05.943Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-25T04:43:06.054Z"
   },
   {
    "duration": 153,
    "start_time": "2024-12-25T04:43:06.162Z"
   },
   {
    "duration": 244,
    "start_time": "2024-12-25T04:43:06.316Z"
   },
   {
    "duration": 448,
    "start_time": "2024-12-25T04:43:06.562Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-25T04:43:07.011Z"
   },
   {
    "duration": 6019,
    "start_time": "2024-12-25T04:43:07.077Z"
   },
   {
    "duration": 191330,
    "start_time": "2024-12-25T04:43:13.171Z"
   },
   {
    "duration": 948,
    "start_time": "2024-12-25T04:47:00.524Z"
   },
   {
    "duration": 416,
    "start_time": "2024-12-25T04:47:01.473Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-25T04:47:01.892Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-25T04:47:01.908Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-25T04:47:02.013Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-25T04:47:02.106Z"
   },
   {
    "duration": 252,
    "start_time": "2024-12-25T04:47:02.131Z"
   },
   {
    "duration": 488,
    "start_time": "2024-12-25T04:47:02.385Z"
   },
   {
    "duration": 96,
    "start_time": "2024-12-25T04:47:02.875Z"
   },
   {
    "duration": 182,
    "start_time": "2024-12-25T04:47:02.975Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-25T04:47:03.159Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-25T04:47:03.176Z"
   },
   {
    "duration": 241,
    "start_time": "2024-12-25T04:47:03.197Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-25T04:47:03.439Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-25T04:47:03.550Z"
   },
   {
    "duration": 153,
    "start_time": "2024-12-25T04:47:03.658Z"
   },
   {
    "duration": 221,
    "start_time": "2024-12-25T04:47:03.813Z"
   },
   {
    "duration": 442,
    "start_time": "2024-12-25T04:47:04.037Z"
   },
   {
    "duration": 55,
    "start_time": "2024-12-25T04:47:04.481Z"
   },
   {
    "duration": 6246,
    "start_time": "2024-12-25T04:47:04.538Z"
   },
   {
    "duration": 190132,
    "start_time": "2024-12-25T04:47:10.786Z"
   },
   {
    "duration": 155,
    "start_time": "2024-12-25T12:40:33.990Z"
   },
   {
    "duration": 950,
    "start_time": "2024-12-25T12:40:39.966Z"
   },
   {
    "duration": 402,
    "start_time": "2024-12-25T12:40:42.698Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-25T12:40:44.581Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-25T12:40:46.347Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-25T12:40:48.004Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-25T12:40:49.012Z"
   },
   {
    "duration": 229,
    "start_time": "2024-12-25T12:40:51.831Z"
   },
   {
    "duration": 472,
    "start_time": "2024-12-25T12:40:54.648Z"
   },
   {
    "duration": 85,
    "start_time": "2024-12-25T12:40:58.371Z"
   },
   {
    "duration": 179,
    "start_time": "2024-12-25T12:41:36.637Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-25T12:41:44.206Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-25T12:41:46.759Z"
   },
   {
    "duration": 222,
    "start_time": "2024-12-25T12:44:44.312Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-25T12:44:45.416Z"
   },
   {
    "duration": 97,
    "start_time": "2024-12-25T12:44:46.004Z"
   },
   {
    "duration": 138,
    "start_time": "2024-12-25T12:44:47.024Z"
   },
   {
    "duration": 210,
    "start_time": "2024-12-25T12:45:00.175Z"
   },
   {
    "duration": 427,
    "start_time": "2024-12-25T12:45:12.267Z"
   },
   {
    "duration": 54,
    "start_time": "2024-12-25T12:45:18.500Z"
   },
   {
    "duration": 7334,
    "start_time": "2024-12-25T12:45:25.939Z"
   },
   {
    "duration": 189639,
    "start_time": "2024-12-25T12:45:46.849Z"
   },
   {
    "duration": 46,
    "start_time": "2024-12-25T12:59:23.453Z"
   },
   {
    "duration": 990,
    "start_time": "2024-12-25T13:24:19.701Z"
   },
   {
    "duration": 399,
    "start_time": "2024-12-25T13:24:20.693Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-25T13:24:21.094Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-25T13:24:21.110Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-25T13:24:21.218Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-25T13:24:21.284Z"
   },
   {
    "duration": 248,
    "start_time": "2024-12-25T13:24:21.308Z"
   },
   {
    "duration": 486,
    "start_time": "2024-12-25T13:24:21.558Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-25T13:24:22.046Z"
   },
   {
    "duration": 186,
    "start_time": "2024-12-25T13:24:22.149Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-25T13:24:22.337Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-25T13:24:22.349Z"
   },
   {
    "duration": 226,
    "start_time": "2024-12-25T13:24:22.381Z"
   },
   {
    "duration": 116,
    "start_time": "2024-12-25T13:24:22.609Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-25T13:24:22.727Z"
   },
   {
    "duration": 149,
    "start_time": "2024-12-25T13:24:22.836Z"
   },
   {
    "duration": 218,
    "start_time": "2024-12-25T13:24:22.987Z"
   },
   {
    "duration": 439,
    "start_time": "2024-12-25T13:24:23.207Z"
   },
   {
    "duration": 58,
    "start_time": "2024-12-25T13:24:23.648Z"
   },
   {
    "duration": 6072,
    "start_time": "2024-12-25T13:24:23.708Z"
   },
   {
    "duration": 136,
    "start_time": "2024-12-25T13:24:29.782Z"
   },
   {
    "duration": 76,
    "start_time": "2024-12-25T13:24:29.920Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-25T13:24:29.997Z"
   },
   {
    "duration": 78210,
    "start_time": "2024-12-25T13:24:30.016Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T13:25:48.228Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T13:25:48.230Z"
   },
   {
    "duration": 1,
    "start_time": "2024-12-25T13:25:48.231Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T13:25:48.233Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T13:25:48.234Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T13:25:48.235Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T13:25:48.237Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T13:25:48.238Z"
   },
   {
    "duration": 10576,
    "start_time": "2024-12-25T13:26:25.980Z"
   },
   {
    "duration": 954,
    "start_time": "2024-12-25T13:46:51.362Z"
   },
   {
    "duration": 400,
    "start_time": "2024-12-25T13:46:52.318Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T13:46:52.720Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-25T13:46:52.736Z"
   },
   {
    "duration": 66,
    "start_time": "2024-12-25T13:46:52.841Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-25T13:46:52.909Z"
   },
   {
    "duration": 234,
    "start_time": "2024-12-25T13:46:52.937Z"
   },
   {
    "duration": 457,
    "start_time": "2024-12-25T13:46:53.173Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-25T13:46:53.632Z"
   },
   {
    "duration": 179,
    "start_time": "2024-12-25T13:46:53.730Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-25T13:46:53.911Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-25T13:46:53.923Z"
   },
   {
    "duration": 245,
    "start_time": "2024-12-25T13:46:53.945Z"
   },
   {
    "duration": 114,
    "start_time": "2024-12-25T13:46:54.191Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-25T13:46:54.307Z"
   },
   {
    "duration": 143,
    "start_time": "2024-12-25T13:46:54.415Z"
   },
   {
    "duration": 218,
    "start_time": "2024-12-25T13:46:54.560Z"
   },
   {
    "duration": 444,
    "start_time": "2024-12-25T13:46:54.779Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-25T13:46:55.224Z"
   },
   {
    "duration": 6091,
    "start_time": "2024-12-25T13:46:55.290Z"
   },
   {
    "duration": 129,
    "start_time": "2024-12-25T13:47:01.383Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-25T13:47:01.514Z"
   },
   {
    "duration": 40,
    "start_time": "2024-12-25T13:47:01.538Z"
   },
   {
    "duration": 4296,
    "start_time": "2024-12-25T13:47:01.580Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T13:47:05.877Z"
   },
   {
    "duration": 569758,
    "start_time": "2024-12-25T13:47:05.882Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T13:56:35.642Z"
   },
   {
    "duration": 4724,
    "start_time": "2024-12-25T13:56:35.649Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T13:56:40.377Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T13:56:40.382Z"
   },
   {
    "duration": 405,
    "start_time": "2024-12-25T13:56:40.387Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T13:56:40.794Z"
   },
   {
    "duration": 39,
    "start_time": "2024-12-25T13:57:58.277Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T13:58:15.520Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T13:58:22.749Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T13:58:27.177Z"
   },
   {
    "duration": 251,
    "start_time": "2024-12-25T14:02:59.325Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T14:03:13.568Z"
   },
   {
    "duration": 381,
    "start_time": "2024-12-25T14:05:45.501Z"
   },
   {
    "duration": 45,
    "start_time": "2024-12-25T14:05:55.513Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T14:06:12.187Z"
   },
   {
    "duration": 4291,
    "start_time": "2024-12-25T14:10:58.466Z"
   },
   {
    "duration": 952,
    "start_time": "2024-12-25T14:13:20.330Z"
   },
   {
    "duration": 415,
    "start_time": "2024-12-25T14:13:21.284Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-25T14:13:21.701Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-25T14:13:21.716Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-25T14:13:21.818Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-25T14:13:21.915Z"
   },
   {
    "duration": 247,
    "start_time": "2024-12-25T14:13:21.939Z"
   },
   {
    "duration": 490,
    "start_time": "2024-12-25T14:13:22.188Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-25T14:13:22.680Z"
   },
   {
    "duration": 176,
    "start_time": "2024-12-25T14:13:22.776Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-25T14:13:22.955Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-25T14:13:22.976Z"
   },
   {
    "duration": 249,
    "start_time": "2024-12-25T14:13:22.995Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-25T14:13:23.247Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-25T14:13:23.358Z"
   },
   {
    "duration": 143,
    "start_time": "2024-12-25T14:13:23.470Z"
   },
   {
    "duration": 218,
    "start_time": "2024-12-25T14:13:23.615Z"
   },
   {
    "duration": 435,
    "start_time": "2024-12-25T14:13:23.835Z"
   },
   {
    "duration": 54,
    "start_time": "2024-12-25T14:13:24.272Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-25T14:13:24.328Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-25T14:13:24.393Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T14:13:24.413Z"
   },
   {
    "duration": 354,
    "start_time": "2024-12-25T14:13:24.429Z"
   },
   {
    "duration": 4767,
    "start_time": "2024-12-25T14:13:24.785Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T14:13:29.554Z"
   },
   {
    "duration": 569445,
    "start_time": "2024-12-25T14:13:29.558Z"
   },
   {
    "duration": 4266,
    "start_time": "2024-12-25T14:22:59.005Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T14:23:03.272Z"
   },
   {
    "duration": 413,
    "start_time": "2024-12-25T14:23:03.277Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T14:23:03.771Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T14:23:03.775Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T14:23:03.780Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T14:23:03.785Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T14:23:03.790Z"
   },
   {
    "duration": 573,
    "start_time": "2024-12-25T15:02:36.310Z"
   },
   {
    "duration": 54,
    "start_time": "2024-12-25T15:02:40.623Z"
   },
   {
    "duration": 50,
    "start_time": "2024-12-25T15:02:45.998Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-25T15:02:47.415Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-25T15:02:48.697Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T15:02:53.229Z"
   },
   {
    "duration": 279,
    "start_time": "2024-12-25T15:02:55.291Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T15:02:57.475Z"
   },
   {
    "duration": 960,
    "start_time": "2024-12-25T15:04:15.296Z"
   },
   {
    "duration": 451,
    "start_time": "2024-12-25T15:04:16.258Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T15:04:16.710Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-25T15:04:16.726Z"
   },
   {
    "duration": 74,
    "start_time": "2024-12-25T15:04:16.831Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-25T15:04:16.907Z"
   },
   {
    "duration": 242,
    "start_time": "2024-12-25T15:04:16.934Z"
   },
   {
    "duration": 467,
    "start_time": "2024-12-25T15:04:17.181Z"
   },
   {
    "duration": 88,
    "start_time": "2024-12-25T15:04:17.649Z"
   },
   {
    "duration": 179,
    "start_time": "2024-12-25T15:04:17.741Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-25T15:04:17.922Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T15:04:17.935Z"
   },
   {
    "duration": 226,
    "start_time": "2024-12-25T15:04:17.951Z"
   },
   {
    "duration": 114,
    "start_time": "2024-12-25T15:04:18.179Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-25T15:04:18.295Z"
   },
   {
    "duration": 148,
    "start_time": "2024-12-25T15:04:18.402Z"
   },
   {
    "duration": 226,
    "start_time": "2024-12-25T15:04:18.552Z"
   },
   {
    "duration": 576,
    "start_time": "2024-12-25T15:04:18.780Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-25T15:04:19.357Z"
   },
   {
    "duration": 62,
    "start_time": "2024-12-25T15:04:19.419Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-25T15:04:19.484Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T15:04:19.511Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T15:04:19.528Z"
   },
   {
    "duration": 261,
    "start_time": "2024-12-25T15:04:19.531Z"
   },
   {
    "duration": 77,
    "start_time": "2024-12-25T15:04:19.794Z"
   },
   {
    "duration": 3423,
    "start_time": "2024-12-25T15:04:19.874Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T15:04:23.299Z"
   },
   {
    "duration": 137828,
    "start_time": "2024-12-25T15:04:23.306Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T15:06:41.137Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T15:06:41.138Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T15:06:41.139Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T15:06:41.140Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T15:06:41.141Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T15:06:41.142Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T15:06:41.143Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T15:09:12.285Z"
   },
   {
    "duration": 262,
    "start_time": "2024-12-25T15:09:13.109Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T15:09:14.664Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T15:10:32.422Z"
   },
   {
    "duration": 4702,
    "start_time": "2024-12-25T15:10:33.287Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T15:10:40.153Z"
   },
   {
    "duration": 4666,
    "start_time": "2024-12-25T15:10:53.205Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T15:12:39.179Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T15:13:31.721Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T15:13:52.314Z"
   },
   {
    "duration": 4557,
    "start_time": "2024-12-25T15:14:38.025Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T15:14:44.637Z"
   },
   {
    "duration": 144286,
    "start_time": "2024-12-25T15:17:21.793Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T15:20:06.127Z"
   },
   {
    "duration": 450882,
    "start_time": "2024-12-25T15:21:22.367Z"
   },
   {
    "duration": 284981,
    "start_time": "2024-12-25T15:32:49.512Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-25T15:37:37.797Z"
   },
   {
    "duration": 281118,
    "start_time": "2024-12-25T15:45:22.131Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T15:50:08.762Z"
   },
   {
    "duration": 1032,
    "start_time": "2024-12-25T15:52:00.489Z"
   },
   {
    "duration": 401,
    "start_time": "2024-12-25T15:52:01.524Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-25T15:52:01.927Z"
   },
   {
    "duration": 98,
    "start_time": "2024-12-25T15:52:01.944Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-25T15:52:02.045Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-25T15:52:02.112Z"
   },
   {
    "duration": 233,
    "start_time": "2024-12-25T15:52:02.138Z"
   },
   {
    "duration": 456,
    "start_time": "2024-12-25T15:52:02.372Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-25T15:52:02.830Z"
   },
   {
    "duration": 186,
    "start_time": "2024-12-25T15:52:02.927Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-25T15:52:03.115Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-25T15:52:03.127Z"
   },
   {
    "duration": 237,
    "start_time": "2024-12-25T15:52:03.148Z"
   },
   {
    "duration": 114,
    "start_time": "2024-12-25T15:52:03.389Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-25T15:52:03.505Z"
   },
   {
    "duration": 145,
    "start_time": "2024-12-25T15:52:03.613Z"
   },
   {
    "duration": 218,
    "start_time": "2024-12-25T15:52:03.761Z"
   },
   {
    "duration": 578,
    "start_time": "2024-12-25T15:52:03.981Z"
   },
   {
    "duration": 60,
    "start_time": "2024-12-25T15:52:04.561Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-25T15:52:04.623Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-25T15:52:04.684Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-25T15:52:04.711Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T15:52:04.729Z"
   },
   {
    "duration": 4839,
    "start_time": "2024-12-25T15:52:04.733Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-25T15:52:09.574Z"
   },
   {
    "duration": 4597,
    "start_time": "2024-12-25T15:52:09.584Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-25T15:52:14.187Z"
   },
   {
    "duration": 144553,
    "start_time": "2024-12-25T15:52:14.195Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T15:54:38.750Z"
   },
   {
    "duration": 144403,
    "start_time": "2024-12-25T15:54:38.756Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T15:57:03.161Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T15:57:03.170Z"
   },
   {
    "duration": 448518,
    "start_time": "2024-12-25T15:57:03.174Z"
   },
   {
    "duration": 1005,
    "start_time": "2024-12-25T16:06:59.798Z"
   },
   {
    "duration": 410,
    "start_time": "2024-12-25T16:07:00.805Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T16:07:01.217Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-25T16:07:01.234Z"
   },
   {
    "duration": 70,
    "start_time": "2024-12-25T16:07:01.341Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-25T16:07:01.412Z"
   },
   {
    "duration": 247,
    "start_time": "2024-12-25T16:07:01.443Z"
   },
   {
    "duration": 479,
    "start_time": "2024-12-25T16:07:01.691Z"
   },
   {
    "duration": 85,
    "start_time": "2024-12-25T16:07:02.172Z"
   },
   {
    "duration": 176,
    "start_time": "2024-12-25T16:07:02.269Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-25T16:07:02.447Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T16:07:02.471Z"
   },
   {
    "duration": 232,
    "start_time": "2024-12-25T16:07:02.487Z"
   },
   {
    "duration": 114,
    "start_time": "2024-12-25T16:07:02.720Z"
   },
   {
    "duration": 108,
    "start_time": "2024-12-25T16:07:02.836Z"
   },
   {
    "duration": 143,
    "start_time": "2024-12-25T16:07:02.945Z"
   },
   {
    "duration": 221,
    "start_time": "2024-12-25T16:07:03.090Z"
   },
   {
    "duration": 593,
    "start_time": "2024-12-25T16:07:03.313Z"
   },
   {
    "duration": 64,
    "start_time": "2024-12-25T16:07:03.907Z"
   },
   {
    "duration": 53,
    "start_time": "2024-12-25T16:07:03.973Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-25T16:07:04.028Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-25T16:07:04.055Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T16:07:04.084Z"
   },
   {
    "duration": 4607,
    "start_time": "2024-12-25T16:07:04.088Z"
   },
   {
    "duration": 76,
    "start_time": "2024-12-25T16:07:08.696Z"
   },
   {
    "duration": 4609,
    "start_time": "2024-12-25T16:07:08.774Z"
   },
   {
    "duration": 81,
    "start_time": "2024-12-25T16:07:13.389Z"
   },
   {
    "duration": 144214,
    "start_time": "2024-12-25T16:07:13.475Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T16:09:37.692Z"
   },
   {
    "duration": 145202,
    "start_time": "2024-12-25T16:09:37.697Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T16:12:02.901Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T16:12:02.907Z"
   },
   {
    "duration": 1008289,
    "start_time": "2024-12-25T16:12:02.911Z"
   },
   {
    "duration": 24308,
    "start_time": "2024-12-25T16:28:51.202Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.513Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.515Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.516Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.518Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.519Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.520Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.522Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.523Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-25T16:29:15.525Z"
   },
   {
    "duration": 141051,
    "start_time": "2024-12-25T16:29:18.840Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T16:33:14.988Z"
   },
   {
    "duration": 140431,
    "start_time": "2024-12-25T16:33:19.815Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T16:35:42.279Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T16:35:54.884Z"
   },
   {
    "duration": 400,
    "start_time": "2024-12-25T16:35:56.489Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T16:38:17.288Z"
   },
   {
    "duration": 3857,
    "start_time": "2024-12-25T16:38:21.020Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T16:38:40.061Z"
   },
   {
    "duration": 3892,
    "start_time": "2024-12-25T16:42:13.589Z"
   },
   {
    "duration": 3828,
    "start_time": "2024-12-25T16:42:30.961Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T16:42:59.893Z"
   },
   {
    "duration": 2394,
    "start_time": "2024-12-25T16:57:23.396Z"
   },
   {
    "duration": 2840,
    "start_time": "2024-12-25T16:57:30.445Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T16:58:41.988Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-25T16:59:22.518Z"
   },
   {
    "duration": 2746,
    "start_time": "2024-12-25T17:00:18.844Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T17:00:21.879Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-25T17:00:31.023Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-25T17:02:59.892Z"
   },
   {
    "duration": 2792,
    "start_time": "2024-12-25T17:03:00.889Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-25T17:03:04.164Z"
   },
   {
    "duration": 2704,
    "start_time": "2024-12-26T00:20:14.507Z"
   },
   {
    "duration": 469,
    "start_time": "2024-12-26T00:20:17.215Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-26T00:20:17.686Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-26T00:20:17.701Z"
   },
   {
    "duration": 73,
    "start_time": "2024-12-26T00:20:17.804Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-26T00:20:17.879Z"
   },
   {
    "duration": 248,
    "start_time": "2024-12-26T00:20:17.905Z"
   },
   {
    "duration": 507,
    "start_time": "2024-12-26T00:20:18.154Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-26T00:20:18.663Z"
   },
   {
    "duration": 188,
    "start_time": "2024-12-26T00:20:18.756Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-26T00:20:18.945Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-26T00:20:18.958Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-26T00:20:18.974Z"
   },
   {
    "duration": 116,
    "start_time": "2024-12-26T00:20:19.219Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-26T00:20:19.337Z"
   },
   {
    "duration": 151,
    "start_time": "2024-12-26T00:20:19.448Z"
   },
   {
    "duration": 231,
    "start_time": "2024-12-26T00:20:19.601Z"
   },
   {
    "duration": 588,
    "start_time": "2024-12-26T00:20:19.833Z"
   },
   {
    "duration": 121,
    "start_time": "2024-12-26T00:20:20.422Z"
   },
   {
    "duration": 50,
    "start_time": "2024-12-26T00:20:20.545Z"
   },
   {
    "duration": 39,
    "start_time": "2024-12-26T00:20:20.597Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-26T00:20:20.638Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T00:20:20.655Z"
   },
   {
    "duration": 4893,
    "start_time": "2024-12-26T00:20:20.659Z"
   },
   {
    "duration": 80,
    "start_time": "2024-12-26T00:20:25.556Z"
   },
   {
    "duration": 5091,
    "start_time": "2024-12-26T00:20:25.641Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T00:20:30.735Z"
   },
   {
    "duration": 154036,
    "start_time": "2024-12-26T00:20:30.745Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T00:23:04.783Z"
   },
   {
    "duration": 153062,
    "start_time": "2024-12-26T00:23:04.789Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T00:25:37.853Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-26T00:25:37.859Z"
   },
   {
    "duration": 2716,
    "start_time": "2024-12-26T01:08:10.410Z"
   },
   {
    "duration": 502,
    "start_time": "2024-12-26T01:08:13.129Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-26T01:08:13.633Z"
   },
   {
    "duration": 98,
    "start_time": "2024-12-26T01:08:13.651Z"
   },
   {
    "duration": 70,
    "start_time": "2024-12-26T01:08:13.751Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-26T01:08:13.823Z"
   },
   {
    "duration": 248,
    "start_time": "2024-12-26T01:08:13.848Z"
   },
   {
    "duration": 517,
    "start_time": "2024-12-26T01:08:14.100Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-26T01:08:14.619Z"
   },
   {
    "duration": 193,
    "start_time": "2024-12-26T01:08:14.717Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-26T01:08:14.912Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-26T01:08:14.929Z"
   },
   {
    "duration": 244,
    "start_time": "2024-12-26T01:08:14.954Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-26T01:08:15.208Z"
   },
   {
    "duration": 166,
    "start_time": "2024-12-26T01:08:15.317Z"
   },
   {
    "duration": 156,
    "start_time": "2024-12-26T01:08:15.485Z"
   },
   {
    "duration": 265,
    "start_time": "2024-12-26T01:08:15.644Z"
   },
   {
    "duration": 590,
    "start_time": "2024-12-26T01:08:15.911Z"
   },
   {
    "duration": 69,
    "start_time": "2024-12-26T01:08:16.505Z"
   },
   {
    "duration": 60,
    "start_time": "2024-12-26T01:08:16.576Z"
   },
   {
    "duration": 50,
    "start_time": "2024-12-26T01:08:16.638Z"
   },
   {
    "duration": 28,
    "start_time": "2024-12-26T01:08:16.690Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-26T01:08:16.720Z"
   },
   {
    "duration": 6297,
    "start_time": "2024-12-26T01:08:16.724Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-26T01:08:23.026Z"
   },
   {
    "duration": 5478,
    "start_time": "2024-12-26T01:08:23.036Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-26T01:08:28.516Z"
   },
   {
    "duration": 152761,
    "start_time": "2024-12-26T01:08:28.527Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T01:11:01.289Z"
   },
   {
    "duration": 150463,
    "start_time": "2024-12-26T01:11:01.295Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T01:13:31.760Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-26T01:13:31.766Z"
   },
   {
    "duration": 977,
    "start_time": "2024-12-26T01:50:47.655Z"
   },
   {
    "duration": 403,
    "start_time": "2024-12-26T01:50:48.634Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-26T01:50:49.039Z"
   },
   {
    "duration": 97,
    "start_time": "2024-12-26T01:50:49.054Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-26T01:50:49.153Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-26T01:50:49.218Z"
   },
   {
    "duration": 244,
    "start_time": "2024-12-26T01:50:49.242Z"
   },
   {
    "duration": 460,
    "start_time": "2024-12-26T01:50:49.489Z"
   },
   {
    "duration": 93,
    "start_time": "2024-12-26T01:50:49.951Z"
   },
   {
    "duration": 186,
    "start_time": "2024-12-26T01:50:50.048Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-26T01:50:50.236Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-26T01:50:50.248Z"
   },
   {
    "duration": 246,
    "start_time": "2024-12-26T01:50:50.266Z"
   },
   {
    "duration": 111,
    "start_time": "2024-12-26T01:50:50.513Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-26T01:50:50.626Z"
   },
   {
    "duration": 148,
    "start_time": "2024-12-26T01:50:50.734Z"
   },
   {
    "duration": 225,
    "start_time": "2024-12-26T01:50:50.884Z"
   },
   {
    "duration": 583,
    "start_time": "2024-12-26T01:50:51.110Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-26T01:50:51.695Z"
   },
   {
    "duration": 62,
    "start_time": "2024-12-26T01:50:51.756Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-26T01:50:51.819Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-26T01:50:51.847Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-26T01:50:51.863Z"
   },
   {
    "duration": 5347,
    "start_time": "2024-12-26T01:50:51.866Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-26T01:50:57.217Z"
   },
   {
    "duration": 6027,
    "start_time": "2024-12-26T01:50:57.226Z"
   },
   {
    "duration": 55,
    "start_time": "2024-12-26T01:51:03.255Z"
   },
   {
    "duration": 153565,
    "start_time": "2024-12-26T01:51:03.318Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T01:53:36.884Z"
   },
   {
    "duration": 150045,
    "start_time": "2024-12-26T01:53:36.890Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T01:56:06.936Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T01:56:06.942Z"
   },
   {
    "duration": 952,
    "start_time": "2024-12-26T01:58:12.142Z"
   },
   {
    "duration": 416,
    "start_time": "2024-12-26T01:58:13.096Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-26T01:58:13.514Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-26T01:58:13.530Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-26T01:58:13.638Z"
   },
   {
    "duration": 34,
    "start_time": "2024-12-26T01:58:13.696Z"
   },
   {
    "duration": 238,
    "start_time": "2024-12-26T01:58:13.732Z"
   },
   {
    "duration": 480,
    "start_time": "2024-12-26T01:58:13.972Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-26T01:58:14.455Z"
   },
   {
    "duration": 189,
    "start_time": "2024-12-26T01:58:14.550Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-26T01:58:14.741Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-26T01:58:14.754Z"
   },
   {
    "duration": 235,
    "start_time": "2024-12-26T01:58:14.775Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-26T01:58:15.012Z"
   },
   {
    "duration": 106,
    "start_time": "2024-12-26T01:58:15.125Z"
   },
   {
    "duration": 148,
    "start_time": "2024-12-26T01:58:15.232Z"
   },
   {
    "duration": 226,
    "start_time": "2024-12-26T01:58:15.383Z"
   },
   {
    "duration": 589,
    "start_time": "2024-12-26T01:58:15.611Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-26T01:58:16.202Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-26T01:58:16.263Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-26T01:58:16.287Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-26T01:58:16.314Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T01:58:16.331Z"
   },
   {
    "duration": 4682,
    "start_time": "2024-12-26T01:58:16.335Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T01:58:21.019Z"
   },
   {
    "duration": 4589,
    "start_time": "2024-12-26T01:58:21.024Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-26T01:58:25.614Z"
   },
   {
    "duration": 149910,
    "start_time": "2024-12-26T01:58:25.628Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T02:00:55.540Z"
   },
   {
    "duration": 149769,
    "start_time": "2024-12-26T02:00:55.546Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T02:03:25.318Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-26T02:03:25.323Z"
   },
   {
    "duration": 192745,
    "start_time": "2024-12-26T02:03:25.327Z"
   },
   {
    "duration": 58440,
    "start_time": "2024-12-26T02:06:38.074Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-26T02:07:36.516Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-26T02:07:36.519Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-26T02:07:36.520Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-26T02:07:36.521Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-26T02:07:36.523Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-26T02:07:36.524Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-26T02:07:36.525Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-26T02:07:36.526Z"
   },
   {
    "duration": 279887,
    "start_time": "2024-12-26T02:07:49.980Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T02:13:04.972Z"
   },
   {
    "duration": 280390,
    "start_time": "2024-12-26T02:13:13.559Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T02:18:32.748Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-26T02:18:43.094Z"
   },
   {
    "duration": 2772,
    "start_time": "2024-12-26T02:18:44.041Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T02:18:47.811Z"
   },
   {
    "duration": 3806,
    "start_time": "2024-12-26T02:18:51.924Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T02:18:58.622Z"
   },
   {
    "duration": 943,
    "start_time": "2024-12-26T02:45:03.714Z"
   },
   {
    "duration": 397,
    "start_time": "2024-12-26T02:45:04.660Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-26T02:45:05.059Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-26T02:45:05.077Z"
   },
   {
    "duration": 68,
    "start_time": "2024-12-26T02:45:05.178Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-26T02:45:05.248Z"
   },
   {
    "duration": 247,
    "start_time": "2024-12-26T02:45:05.273Z"
   },
   {
    "duration": 478,
    "start_time": "2024-12-26T02:45:05.522Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-26T02:45:06.009Z"
   },
   {
    "duration": 182,
    "start_time": "2024-12-26T02:45:06.114Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-26T02:45:06.298Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-26T02:45:06.315Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-26T02:45:06.334Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-26T02:45:06.579Z"
   },
   {
    "duration": 110,
    "start_time": "2024-12-26T02:45:06.685Z"
   },
   {
    "duration": 142,
    "start_time": "2024-12-26T02:45:06.797Z"
   },
   {
    "duration": 230,
    "start_time": "2024-12-26T02:45:06.941Z"
   },
   {
    "duration": 640,
    "start_time": "2024-12-26T02:45:07.173Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-26T02:45:07.815Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-26T02:45:07.873Z"
   },
   {
    "duration": 81,
    "start_time": "2024-12-26T02:45:07.968Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-26T02:45:08.051Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T02:45:08.071Z"
   },
   {
    "duration": 4445,
    "start_time": "2024-12-26T02:45:08.076Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-26T02:45:12.523Z"
   },
   {
    "duration": 4500,
    "start_time": "2024-12-26T02:45:12.533Z"
   },
   {
    "duration": 75,
    "start_time": "2024-12-26T02:45:17.035Z"
   },
   {
    "duration": 152124,
    "start_time": "2024-12-26T02:45:17.115Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T02:47:49.241Z"
   },
   {
    "duration": 151371,
    "start_time": "2024-12-26T02:47:49.246Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T02:50:20.619Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-26T02:50:20.625Z"
   },
   {
    "duration": 3699563,
    "start_time": "2024-12-26T02:50:20.629Z"
   },
   {
    "duration": 279048,
    "start_time": "2024-12-26T03:52:00.194Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T03:56:39.244Z"
   },
   {
    "duration": 278996,
    "start_time": "2024-12-26T03:56:39.249Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T04:01:18.247Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-26T04:01:18.253Z"
   },
   {
    "duration": 2762,
    "start_time": "2024-12-26T04:01:18.257Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-26T04:01:21.021Z"
   },
   {
    "duration": 3801,
    "start_time": "2024-12-26T04:01:21.027Z"
   },
   {
    "duration": 79,
    "start_time": "2024-12-26T04:01:24.830Z"
   },
   {
    "duration": 2603,
    "start_time": "2024-12-27T00:11:54.099Z"
   },
   {
    "duration": 442,
    "start_time": "2024-12-27T00:11:56.704Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T00:11:57.147Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-27T00:11:57.163Z"
   },
   {
    "duration": 97,
    "start_time": "2024-12-27T00:11:57.270Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-27T00:11:57.369Z"
   },
   {
    "duration": 248,
    "start_time": "2024-12-27T00:11:57.394Z"
   },
   {
    "duration": 473,
    "start_time": "2024-12-27T00:11:57.644Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-27T00:11:58.119Z"
   },
   {
    "duration": 177,
    "start_time": "2024-12-27T00:11:58.215Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-27T00:11:58.394Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-27T00:11:58.414Z"
   },
   {
    "duration": 242,
    "start_time": "2024-12-27T00:11:58.435Z"
   },
   {
    "duration": 168,
    "start_time": "2024-12-27T00:11:58.680Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-27T00:11:58.850Z"
   },
   {
    "duration": 143,
    "start_time": "2024-12-27T00:11:58.964Z"
   },
   {
    "duration": 216,
    "start_time": "2024-12-27T00:11:59.109Z"
   },
   {
    "duration": 586,
    "start_time": "2024-12-27T00:11:59.327Z"
   },
   {
    "duration": 55,
    "start_time": "2024-12-27T00:11:59.915Z"
   },
   {
    "duration": 53,
    "start_time": "2024-12-27T00:11:59.972Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T00:12:00.026Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-27T00:12:00.042Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T00:12:00.057Z"
   },
   {
    "duration": 4948,
    "start_time": "2024-12-27T00:12:00.061Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T00:12:05.011Z"
   },
   {
    "duration": 4895,
    "start_time": "2024-12-27T00:12:05.017Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T00:12:09.914Z"
   },
   {
    "duration": 147144,
    "start_time": "2024-12-27T00:12:09.921Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T00:14:37.067Z"
   },
   {
    "duration": 146008,
    "start_time": "2024-12-27T00:14:37.073Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T00:17:03.083Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T00:17:03.088Z"
   },
   {
    "duration": 981,
    "start_time": "2024-12-27T00:20:27.530Z"
   },
   {
    "duration": 406,
    "start_time": "2024-12-27T00:20:28.513Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-27T00:20:28.921Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-27T00:20:28.937Z"
   },
   {
    "duration": 67,
    "start_time": "2024-12-27T00:20:29.039Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-27T00:20:29.108Z"
   },
   {
    "duration": 246,
    "start_time": "2024-12-27T00:20:29.140Z"
   },
   {
    "duration": 488,
    "start_time": "2024-12-27T00:20:29.388Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-27T00:20:29.878Z"
   },
   {
    "duration": 181,
    "start_time": "2024-12-27T00:20:29.975Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-27T00:20:30.158Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-27T00:20:30.169Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-27T00:20:30.184Z"
   },
   {
    "duration": 114,
    "start_time": "2024-12-27T00:20:30.429Z"
   },
   {
    "duration": 108,
    "start_time": "2024-12-27T00:20:30.544Z"
   },
   {
    "duration": 149,
    "start_time": "2024-12-27T00:20:30.653Z"
   },
   {
    "duration": 213,
    "start_time": "2024-12-27T00:20:30.805Z"
   },
   {
    "duration": 592,
    "start_time": "2024-12-27T00:20:31.020Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-27T00:20:31.614Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-27T00:20:31.672Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-27T00:20:31.704Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-27T00:20:31.714Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-27T00:20:31.728Z"
   },
   {
    "duration": 4794,
    "start_time": "2024-12-27T00:20:31.731Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-27T00:20:36.527Z"
   },
   {
    "duration": 4893,
    "start_time": "2024-12-27T00:20:36.535Z"
   },
   {
    "duration": 80,
    "start_time": "2024-12-27T00:20:41.429Z"
   },
   {
    "duration": 146944,
    "start_time": "2024-12-27T00:20:41.518Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T00:23:08.463Z"
   },
   {
    "duration": 146592,
    "start_time": "2024-12-27T00:23:08.468Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T00:25:35.062Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-27T00:25:35.068Z"
   },
   {
    "duration": 86175,
    "start_time": "2024-12-27T00:25:35.072Z"
   },
   {
    "duration": 54660,
    "start_time": "2024-12-27T00:27:01.249Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.911Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.912Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.913Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.914Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.915Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.917Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.918Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.919Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T00:27:55.920Z"
   },
   {
    "duration": 189720,
    "start_time": "2024-12-27T00:27:59.029Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T00:31:21.551Z"
   },
   {
    "duration": 188882,
    "start_time": "2024-12-27T00:31:22.580Z"
   },
   {
    "duration": 1015192,
    "start_time": "2024-12-27T00:41:10.987Z"
   },
   {
    "duration": 621268,
    "start_time": "2024-12-27T00:58:48.324Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T01:11:22.059Z"
   },
   {
    "duration": 29080,
    "start_time": "2024-12-27T01:11:28.630Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T01:12:02.636Z"
   },
   {
    "duration": 28893,
    "start_time": "2024-12-27T01:12:16.741Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T01:12:53.084Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-27T01:13:03.731Z"
   },
   {
    "duration": 2864,
    "start_time": "2024-12-27T01:13:04.544Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T01:13:09.442Z"
   },
   {
    "duration": 3996,
    "start_time": "2024-12-27T01:13:11.814Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T01:13:22.464Z"
   },
   {
    "duration": 952,
    "start_time": "2024-12-27T01:44:27.398Z"
   },
   {
    "duration": 399,
    "start_time": "2024-12-27T01:44:28.352Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-27T01:44:28.753Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-27T01:44:28.768Z"
   },
   {
    "duration": 72,
    "start_time": "2024-12-27T01:44:28.870Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-27T01:44:28.943Z"
   },
   {
    "duration": 233,
    "start_time": "2024-12-27T01:44:28.970Z"
   },
   {
    "duration": 478,
    "start_time": "2024-12-27T01:44:29.205Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-27T01:44:29.685Z"
   },
   {
    "duration": 184,
    "start_time": "2024-12-27T01:44:29.778Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-27T01:44:29.964Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-27T01:44:29.976Z"
   },
   {
    "duration": 231,
    "start_time": "2024-12-27T01:44:30.008Z"
   },
   {
    "duration": 114,
    "start_time": "2024-12-27T01:44:30.241Z"
   },
   {
    "duration": 110,
    "start_time": "2024-12-27T01:44:30.357Z"
   },
   {
    "duration": 150,
    "start_time": "2024-12-27T01:44:30.469Z"
   },
   {
    "duration": 214,
    "start_time": "2024-12-27T01:44:30.623Z"
   },
   {
    "duration": 602,
    "start_time": "2024-12-27T01:44:30.839Z"
   },
   {
    "duration": 53,
    "start_time": "2024-12-27T01:44:31.442Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-27T01:44:31.497Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-27T01:44:31.517Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-27T01:44:31.527Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T01:44:31.544Z"
   },
   {
    "duration": 4865,
    "start_time": "2024-12-27T01:44:31.549Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T01:44:36.417Z"
   },
   {
    "duration": 4696,
    "start_time": "2024-12-27T01:44:36.424Z"
   },
   {
    "duration": 79,
    "start_time": "2024-12-27T01:44:41.126Z"
   },
   {
    "duration": 146913,
    "start_time": "2024-12-27T01:44:41.210Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T01:47:08.125Z"
   },
   {
    "duration": 146602,
    "start_time": "2024-12-27T01:47:08.131Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T01:49:34.735Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T01:49:34.743Z"
   },
   {
    "duration": 606659,
    "start_time": "2024-12-27T01:49:34.748Z"
   },
   {
    "duration": 27926,
    "start_time": "2024-12-27T01:59:41.410Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T02:00:09.338Z"
   },
   {
    "duration": 27964,
    "start_time": "2024-12-27T02:00:09.344Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T02:00:37.312Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T02:00:37.317Z"
   },
   {
    "duration": 2812,
    "start_time": "2024-12-27T02:00:37.321Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T02:00:40.204Z"
   },
   {
    "duration": 4011,
    "start_time": "2024-12-27T02:00:40.210Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T02:00:44.225Z"
   },
   {
    "duration": 384083,
    "start_time": "2024-12-27T02:00:44.230Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T02:07:08.315Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-27T02:07:23.657Z"
   },
   {
    "duration": 40680,
    "start_time": "2024-12-27T02:10:40.159Z"
   },
   {
    "duration": 257029,
    "start_time": "2024-12-27T02:16:03.798Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T02:20:34.026Z"
   },
   {
    "duration": 256003,
    "start_time": "2024-12-27T02:20:55.031Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T02:25:31.358Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-27T02:27:43.950Z"
   },
   {
    "duration": 2873,
    "start_time": "2024-12-27T02:27:44.746Z"
   },
   {
    "duration": 4062,
    "start_time": "2024-12-27T02:27:51.955Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T02:28:00.931Z"
   },
   {
    "duration": 50591,
    "start_time": "2024-12-27T02:28:04.314Z"
   },
   {
    "duration": 2563,
    "start_time": "2024-12-27T16:42:13.324Z"
   },
   {
    "duration": 474,
    "start_time": "2024-12-27T16:42:15.889Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T16:42:16.365Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-27T16:42:16.380Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-27T16:42:16.490Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-27T16:42:16.555Z"
   },
   {
    "duration": 232,
    "start_time": "2024-12-27T16:42:16.580Z"
   },
   {
    "duration": 481,
    "start_time": "2024-12-27T16:42:16.814Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-27T16:42:17.297Z"
   },
   {
    "duration": 189,
    "start_time": "2024-12-27T16:42:17.389Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-27T16:42:17.579Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T16:42:17.591Z"
   },
   {
    "duration": 242,
    "start_time": "2024-12-27T16:42:17.607Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-27T16:42:17.852Z"
   },
   {
    "duration": 157,
    "start_time": "2024-12-27T16:42:17.963Z"
   },
   {
    "duration": 150,
    "start_time": "2024-12-27T16:42:18.121Z"
   },
   {
    "duration": 218,
    "start_time": "2024-12-27T16:42:18.273Z"
   },
   {
    "duration": 583,
    "start_time": "2024-12-27T16:42:18.493Z"
   },
   {
    "duration": 72,
    "start_time": "2024-12-27T16:42:19.079Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-27T16:42:19.153Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-27T16:42:19.168Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-27T16:42:19.177Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T16:42:19.190Z"
   },
   {
    "duration": 4649,
    "start_time": "2024-12-27T16:42:19.194Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T16:42:23.845Z"
   },
   {
    "duration": 4594,
    "start_time": "2024-12-27T16:42:23.852Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T16:42:28.448Z"
   },
   {
    "duration": 143598,
    "start_time": "2024-12-27T16:42:28.453Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T16:44:52.053Z"
   },
   {
    "duration": 142520,
    "start_time": "2024-12-27T16:44:52.058Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T16:47:14.580Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T16:47:14.585Z"
   },
   {
    "duration": 40013,
    "start_time": "2024-12-27T16:47:14.589Z"
   },
   {
    "duration": 252159,
    "start_time": "2024-12-27T16:47:54.604Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T16:52:06.765Z"
   },
   {
    "duration": 251991,
    "start_time": "2024-12-27T16:52:06.772Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T16:56:18.765Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T16:56:18.770Z"
   },
   {
    "duration": 2895,
    "start_time": "2024-12-27T16:56:18.774Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-27T16:56:21.743Z"
   },
   {
    "duration": 3890,
    "start_time": "2024-12-27T16:56:21.756Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T16:56:25.648Z"
   },
   {
    "duration": 49499,
    "start_time": "2024-12-27T16:56:25.654Z"
   },
   {
    "duration": 665,
    "start_time": "2024-12-27T17:05:13.242Z"
   },
   {
    "duration": 2779,
    "start_time": "2024-12-27T17:11:06.464Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T17:12:11.820Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T17:15:08.025Z"
   },
   {
    "duration": 2894,
    "start_time": "2024-12-27T17:15:15.174Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-27T17:15:19.812Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T17:15:33.236Z"
   },
   {
    "duration": 69,
    "start_time": "2024-12-27T17:35:49.298Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T17:44:39.578Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-27T17:44:53.800Z"
   },
   {
    "duration": 7857,
    "start_time": "2024-12-27T17:45:01.726Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T17:45:14.196Z"
   },
   {
    "duration": 134854,
    "start_time": "2024-12-27T17:50:22.357Z"
   },
   {
    "duration": 199429,
    "start_time": "2024-12-27T17:57:22.168Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-27T18:07:37.289Z"
   },
   {
    "duration": 4933,
    "start_time": "2024-12-27T18:07:44.279Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T18:07:52.067Z"
   },
   {
    "duration": 7793,
    "start_time": "2024-12-27T18:10:47.444Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T18:10:58.514Z"
   },
   {
    "duration": 4990,
    "start_time": "2024-12-27T18:12:41.453Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T18:12:48.774Z"
   },
   {
    "duration": 2696,
    "start_time": "2024-12-27T20:10:09.586Z"
   },
   {
    "duration": 464,
    "start_time": "2024-12-27T20:10:12.285Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-27T20:10:12.751Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-27T20:10:12.768Z"
   },
   {
    "duration": 68,
    "start_time": "2024-12-27T20:10:12.879Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-27T20:10:12.949Z"
   },
   {
    "duration": 237,
    "start_time": "2024-12-27T20:10:12.975Z"
   },
   {
    "duration": 499,
    "start_time": "2024-12-27T20:10:13.214Z"
   },
   {
    "duration": 96,
    "start_time": "2024-12-27T20:10:13.716Z"
   },
   {
    "duration": 180,
    "start_time": "2024-12-27T20:10:13.816Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-27T20:10:13.998Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T20:10:14.018Z"
   },
   {
    "duration": 240,
    "start_time": "2024-12-27T20:10:14.034Z"
   },
   {
    "duration": 167,
    "start_time": "2024-12-27T20:10:14.276Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-27T20:10:14.445Z"
   },
   {
    "duration": 151,
    "start_time": "2024-12-27T20:10:14.554Z"
   },
   {
    "duration": 239,
    "start_time": "2024-12-27T20:10:14.710Z"
   },
   {
    "duration": 586,
    "start_time": "2024-12-27T20:10:14.951Z"
   },
   {
    "duration": 55,
    "start_time": "2024-12-27T20:10:15.539Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-27T20:10:15.608Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-27T20:10:15.628Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T20:10:15.640Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T20:10:15.655Z"
   },
   {
    "duration": 4569,
    "start_time": "2024-12-27T20:10:15.660Z"
   },
   {
    "duration": 78,
    "start_time": "2024-12-27T20:10:20.231Z"
   },
   {
    "duration": 4501,
    "start_time": "2024-12-27T20:10:20.311Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T20:10:24.816Z"
   },
   {
    "duration": 151873,
    "start_time": "2024-12-27T20:10:24.828Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-27T20:12:56.703Z"
   },
   {
    "duration": 150021,
    "start_time": "2024-12-27T20:12:56.711Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T20:15:26.734Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T20:15:26.740Z"
   },
   {
    "duration": 40565,
    "start_time": "2024-12-27T20:15:26.745Z"
   },
   {
    "duration": 265967,
    "start_time": "2024-12-27T20:16:07.313Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T20:20:33.282Z"
   },
   {
    "duration": 266174,
    "start_time": "2024-12-27T20:20:33.288Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T20:24:59.464Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-27T20:24:59.470Z"
   },
   {
    "duration": 3037,
    "start_time": "2024-12-27T20:24:59.474Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T20:25:02.513Z"
   },
   {
    "duration": 3803,
    "start_time": "2024-12-27T20:25:02.518Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T20:25:06.323Z"
   },
   {
    "duration": 48681,
    "start_time": "2024-12-27T20:25:06.329Z"
   },
   {
    "duration": 2809,
    "start_time": "2024-12-27T20:25:55.012Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T20:25:57.824Z"
   },
   {
    "duration": 2886,
    "start_time": "2024-12-27T20:25:57.830Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T20:26:00.717Z"
   },
   {
    "duration": 595,
    "start_time": "2024-12-27T20:26:00.723Z"
   },
   {
    "duration": 7988,
    "start_time": "2024-12-27T20:26:01.320Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T20:26:09.310Z"
   },
   {
    "duration": 7803,
    "start_time": "2024-12-27T20:26:09.317Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T20:26:17.122Z"
   },
   {
    "duration": 201260,
    "start_time": "2024-12-27T20:26:17.127Z"
   },
   {
    "duration": 4920,
    "start_time": "2024-12-27T20:29:38.389Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T20:29:43.311Z"
   },
   {
    "duration": 5036,
    "start_time": "2024-12-27T20:29:43.317Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T20:29:48.355Z"
   },
   {
    "duration": 46,
    "start_time": "2024-12-27T20:41:02.363Z"
   },
   {
    "duration": 20451,
    "start_time": "2024-12-27T20:41:12.163Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T20:41:43.301Z"
   },
   {
    "duration": 20328,
    "start_time": "2024-12-27T20:43:22.402Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T20:43:44.707Z"
   },
   {
    "duration": 294,
    "start_time": "2024-12-27T20:47:08.426Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-27T20:47:59.442Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T20:48:23.136Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-27T20:48:32.649Z"
   },
   {
    "duration": 2044563,
    "start_time": "2024-12-27T20:48:41.860Z"
   },
   {
    "duration": 1248,
    "start_time": "2024-12-27T21:33:10.830Z"
   },
   {
    "duration": 1118,
    "start_time": "2024-12-27T21:34:02.301Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T21:34:58.114Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T21:35:23.210Z"
   },
   {
    "duration": 360327,
    "start_time": "2024-12-27T21:35:56.718Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-27T21:42:04.563Z"
   },
   {
    "duration": 369009,
    "start_time": "2024-12-27T21:42:15.913Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T21:48:34.787Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-27T22:17:10.767Z"
   },
   {
    "duration": 1130,
    "start_time": "2024-12-27T22:17:31.623Z"
   },
   {
    "duration": 427,
    "start_time": "2024-12-27T22:17:35.201Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-27T22:17:37.545Z"
   },
   {
    "duration": 102,
    "start_time": "2024-12-27T22:17:39.479Z"
   },
   {
    "duration": 69,
    "start_time": "2024-12-27T22:17:41.080Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-27T22:17:41.836Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-27T22:17:44.269Z"
   },
   {
    "duration": 500,
    "start_time": "2024-12-27T22:17:46.054Z"
   },
   {
    "duration": 93,
    "start_time": "2024-12-27T22:17:48.663Z"
   },
   {
    "duration": 181,
    "start_time": "2024-12-27T22:17:51.328Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-27T22:17:56.005Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T22:18:17.864Z"
   },
   {
    "duration": 223,
    "start_time": "2024-12-27T22:18:25.864Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T22:18:33.830Z"
   },
   {
    "duration": 1046,
    "start_time": "2024-12-27T22:35:23.797Z"
   },
   {
    "duration": 436,
    "start_time": "2024-12-27T22:35:24.845Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-27T22:35:25.283Z"
   },
   {
    "duration": 102,
    "start_time": "2024-12-27T22:35:25.309Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-27T22:35:25.413Z"
   },
   {
    "duration": 38,
    "start_time": "2024-12-27T22:35:25.476Z"
   },
   {
    "duration": 239,
    "start_time": "2024-12-27T22:35:25.515Z"
   },
   {
    "duration": 496,
    "start_time": "2024-12-27T22:35:25.756Z"
   },
   {
    "duration": 97,
    "start_time": "2024-12-27T22:35:26.254Z"
   },
   {
    "duration": 182,
    "start_time": "2024-12-27T22:35:26.355Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-27T22:35:26.539Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T22:35:26.551Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-27T22:35:26.567Z"
   },
   {
    "duration": 111,
    "start_time": "2024-12-27T22:35:26.812Z"
   },
   {
    "duration": 115,
    "start_time": "2024-12-27T22:35:26.925Z"
   },
   {
    "duration": 162,
    "start_time": "2024-12-27T22:35:27.041Z"
   },
   {
    "duration": 240,
    "start_time": "2024-12-27T22:35:27.205Z"
   },
   {
    "duration": 616,
    "start_time": "2024-12-27T22:35:27.446Z"
   },
   {
    "duration": 72,
    "start_time": "2024-12-27T22:35:28.064Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T22:35:28.138Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-27T22:35:28.153Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-27T22:35:28.164Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T22:35:28.179Z"
   },
   {
    "duration": 689,
    "start_time": "2024-12-27T22:35:28.184Z"
   },
   {
    "duration": 4934,
    "start_time": "2024-12-27T22:35:28.876Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T22:35:33.812Z"
   },
   {
    "duration": 4919,
    "start_time": "2024-12-27T22:35:33.819Z"
   },
   {
    "duration": 68,
    "start_time": "2024-12-27T22:35:38.744Z"
   },
   {
    "duration": 157630,
    "start_time": "2024-12-27T22:35:38.817Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T22:38:16.449Z"
   },
   {
    "duration": 157981,
    "start_time": "2024-12-27T22:38:16.454Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T22:40:54.437Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-27T22:40:54.443Z"
   },
   {
    "duration": 41312,
    "start_time": "2024-12-27T22:40:54.448Z"
   },
   {
    "duration": 273547,
    "start_time": "2024-12-27T22:41:35.762Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-27T22:46:09.310Z"
   },
   {
    "duration": 321,
    "start_time": "2024-12-27T22:46:09.317Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.640Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.641Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.643Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.644Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.645Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.646Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.647Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.648Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.649Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.650Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.651Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.652Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.653Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.654Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.655Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.656Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.657Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.658Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.659Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.661Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.662Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.663Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.664Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.665Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.667Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.709Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.710Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.711Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.712Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.713Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.714Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.715Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.716Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.718Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-27T22:46:09.719Z"
   },
   {
    "duration": 274999,
    "start_time": "2024-12-27T22:46:53.433Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T22:51:37.068Z"
   },
   {
    "duration": 84,
    "start_time": "2024-12-27T22:51:46.180Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-27T22:51:48.078Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-27T22:51:49.290Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-27T22:51:50.573Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-27T22:51:51.300Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-27T22:51:52.177Z"
   },
   {
    "duration": 471,
    "start_time": "2024-12-27T22:51:53.373Z"
   },
   {
    "duration": 2735,
    "start_time": "2024-12-28T02:23:02.241Z"
   },
   {
    "duration": 459,
    "start_time": "2024-12-28T02:23:04.978Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T02:23:05.439Z"
   },
   {
    "duration": 102,
    "start_time": "2024-12-28T02:23:05.454Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-28T02:23:05.558Z"
   },
   {
    "duration": 32,
    "start_time": "2024-12-28T02:23:05.650Z"
   },
   {
    "duration": 235,
    "start_time": "2024-12-28T02:23:05.684Z"
   },
   {
    "duration": 486,
    "start_time": "2024-12-28T02:23:05.920Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-28T02:23:06.408Z"
   },
   {
    "duration": 197,
    "start_time": "2024-12-28T02:23:06.505Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-28T02:23:06.704Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-28T02:23:06.716Z"
   },
   {
    "duration": 251,
    "start_time": "2024-12-28T02:23:06.736Z"
   },
   {
    "duration": 111,
    "start_time": "2024-12-28T02:23:06.989Z"
   },
   {
    "duration": 114,
    "start_time": "2024-12-28T02:23:07.102Z"
   },
   {
    "duration": 144,
    "start_time": "2024-12-28T02:23:07.218Z"
   },
   {
    "duration": 217,
    "start_time": "2024-12-28T02:23:07.364Z"
   },
   {
    "duration": 578,
    "start_time": "2024-12-28T02:23:07.583Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-28T02:23:08.163Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T02:23:08.226Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-28T02:23:08.241Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-28T02:23:08.251Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T02:23:08.283Z"
   },
   {
    "duration": 578,
    "start_time": "2024-12-28T02:23:08.287Z"
   },
   {
    "duration": 4706,
    "start_time": "2024-12-28T02:23:08.869Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-28T02:23:13.580Z"
   },
   {
    "duration": 4782,
    "start_time": "2024-12-28T02:23:13.590Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-28T02:23:18.378Z"
   },
   {
    "duration": 145645,
    "start_time": "2024-12-28T02:23:18.385Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:25:44.032Z"
   },
   {
    "duration": 145108,
    "start_time": "2024-12-28T02:25:44.037Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:28:09.147Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T02:28:09.152Z"
   },
   {
    "duration": 40669,
    "start_time": "2024-12-28T02:28:09.156Z"
   },
   {
    "duration": 256243,
    "start_time": "2024-12-28T02:28:49.827Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:33:06.072Z"
   },
   {
    "duration": 258440,
    "start_time": "2024-12-28T02:33:06.077Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:37:24.519Z"
   },
   {
    "duration": 84,
    "start_time": "2024-12-28T02:37:24.525Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-28T02:37:24.611Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T02:37:24.672Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-28T02:37:24.681Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-28T02:37:24.691Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T02:37:24.705Z"
   },
   {
    "duration": 686,
    "start_time": "2024-12-28T02:37:24.709Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.397Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.398Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.399Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.401Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.402Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.403Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.404Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.405Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.406Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.407Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.408Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.409Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.410Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.411Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.412Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.413Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.414Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.415Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.416Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.418Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.418Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.419Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.420Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.421Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.423Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.470Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T02:37:25.471Z"
   },
   {
    "duration": 96,
    "start_time": "2024-12-28T02:43:35.243Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T02:46:40.953Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-28T02:46:47.240Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T02:48:52.536Z"
   },
   {
    "duration": 166,
    "start_time": "2024-12-28T02:49:09.764Z"
   },
   {
    "duration": 2791,
    "start_time": "2024-12-28T02:51:06.785Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:51:17.667Z"
   },
   {
    "duration": 2791,
    "start_time": "2024-12-28T02:51:36.686Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T02:52:01.331Z"
   },
   {
    "duration": 48754,
    "start_time": "2024-12-28T02:52:18.317Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-28T02:54:00.908Z"
   },
   {
    "duration": 2725,
    "start_time": "2024-12-28T02:54:20.954Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:54:31.524Z"
   },
   {
    "duration": 2689,
    "start_time": "2024-12-28T02:54:54.500Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:55:01.159Z"
   },
   {
    "duration": 398,
    "start_time": "2024-12-28T02:55:12.542Z"
   },
   {
    "duration": 14638,
    "start_time": "2024-12-28T02:55:46.512Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:56:30.814Z"
   },
   {
    "duration": 14574,
    "start_time": "2024-12-28T02:56:46.167Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T02:57:12.775Z"
   },
   {
    "duration": 201187,
    "start_time": "2024-12-28T02:57:36.883Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-28T03:01:47.336Z"
   },
   {
    "duration": 4993,
    "start_time": "2024-12-28T03:02:01.189Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T03:02:07.782Z"
   },
   {
    "duration": 5041,
    "start_time": "2024-12-28T03:02:30.979Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T03:02:43.013Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T03:02:50.520Z"
   },
   {
    "duration": 172929,
    "start_time": "2024-12-28T03:03:49.252Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T03:09:21.552Z"
   },
   {
    "duration": 171528,
    "start_time": "2024-12-28T03:09:24.055Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T03:13:46.565Z"
   },
   {
    "duration": 1066,
    "start_time": "2024-12-28T03:56:51.730Z"
   },
   {
    "duration": 413,
    "start_time": "2024-12-28T03:56:52.798Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T03:56:53.213Z"
   },
   {
    "duration": 102,
    "start_time": "2024-12-28T03:56:53.229Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-28T03:56:53.333Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-28T03:56:53.401Z"
   },
   {
    "duration": 236,
    "start_time": "2024-12-28T03:56:53.428Z"
   },
   {
    "duration": 458,
    "start_time": "2024-12-28T03:56:53.665Z"
   },
   {
    "duration": 89,
    "start_time": "2024-12-28T03:56:54.126Z"
   },
   {
    "duration": 184,
    "start_time": "2024-12-28T03:56:54.218Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-28T03:56:54.404Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-28T03:56:54.416Z"
   },
   {
    "duration": 318,
    "start_time": "2024-12-28T03:56:54.435Z"
   },
   {
    "duration": 108,
    "start_time": "2024-12-28T03:56:54.755Z"
   },
   {
    "duration": 102,
    "start_time": "2024-12-28T03:56:54.869Z"
   },
   {
    "duration": 149,
    "start_time": "2024-12-28T03:56:54.973Z"
   },
   {
    "duration": 238,
    "start_time": "2024-12-28T03:56:55.124Z"
   },
   {
    "duration": 596,
    "start_time": "2024-12-28T03:56:55.363Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-28T03:56:55.969Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T03:56:56.027Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-28T03:56:56.042Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-28T03:56:56.051Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-28T03:56:56.083Z"
   },
   {
    "duration": 622,
    "start_time": "2024-12-28T03:56:56.087Z"
   },
   {
    "duration": 4972,
    "start_time": "2024-12-28T03:56:56.710Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T03:57:01.684Z"
   },
   {
    "duration": 4906,
    "start_time": "2024-12-28T03:57:01.689Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T03:57:06.601Z"
   },
   {
    "duration": 175123,
    "start_time": "2024-12-28T03:57:06.607Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T04:00:01.732Z"
   },
   {
    "duration": 173454,
    "start_time": "2024-12-28T04:00:01.737Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T04:02:55.193Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:02:55.198Z"
   },
   {
    "duration": 44275,
    "start_time": "2024-12-28T04:02:55.203Z"
   },
   {
    "duration": 206812,
    "start_time": "2024-12-28T04:03:39.480Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.294Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.295Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.297Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.298Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.300Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.301Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.303Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.304Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.306Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.307Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.309Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.310Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.311Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.313Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.315Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.316Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.317Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.319Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.320Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.322Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.323Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.325Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.326Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.371Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.372Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.373Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.374Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.376Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.377Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.378Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.380Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.381Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.381Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.383Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.384Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.385Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:07:06.386Z"
   },
   {
    "duration": 290262,
    "start_time": "2024-12-28T04:07:53.819Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:12:51.846Z"
   },
   {
    "duration": 1034,
    "start_time": "2024-12-28T04:22:02.661Z"
   },
   {
    "duration": 418,
    "start_time": "2024-12-28T04:22:03.697Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T04:22:04.117Z"
   },
   {
    "duration": 99,
    "start_time": "2024-12-28T04:22:04.132Z"
   },
   {
    "duration": 70,
    "start_time": "2024-12-28T04:22:04.232Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-28T04:22:04.303Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-28T04:22:04.332Z"
   },
   {
    "duration": 494,
    "start_time": "2024-12-28T04:22:04.577Z"
   },
   {
    "duration": 85,
    "start_time": "2024-12-28T04:22:05.073Z"
   },
   {
    "duration": 178,
    "start_time": "2024-12-28T04:22:05.173Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-28T04:22:05.353Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-28T04:22:05.374Z"
   },
   {
    "duration": 307,
    "start_time": "2024-12-28T04:22:05.397Z"
   },
   {
    "duration": 115,
    "start_time": "2024-12-28T04:22:05.706Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-28T04:22:05.823Z"
   },
   {
    "duration": 147,
    "start_time": "2024-12-28T04:22:05.930Z"
   },
   {
    "duration": 235,
    "start_time": "2024-12-28T04:22:06.079Z"
   },
   {
    "duration": 615,
    "start_time": "2024-12-28T04:22:06.316Z"
   },
   {
    "duration": 72,
    "start_time": "2024-12-28T04:22:06.932Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T04:22:07.007Z"
   },
   {
    "duration": 309,
    "start_time": "2024-12-28T04:22:07.022Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.334Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.335Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.337Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.338Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.339Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.340Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.341Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.342Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.343Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.344Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.345Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.346Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.370Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.372Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.374Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.376Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.377Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.378Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.379Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.380Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.382Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.383Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.384Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.385Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.386Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.387Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.388Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.391Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.392Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.394Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.396Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.397Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.399Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.401Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.402Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.403Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.404Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.406Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.407Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.408Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.409Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.410Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.411Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:22:07.413Z"
   },
   {
    "duration": 1167,
    "start_time": "2024-12-28T04:22:55.603Z"
   },
   {
    "duration": 472,
    "start_time": "2024-12-28T04:22:56.772Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T04:22:57.246Z"
   },
   {
    "duration": 139,
    "start_time": "2024-12-28T04:22:57.270Z"
   },
   {
    "duration": 79,
    "start_time": "2024-12-28T04:22:57.412Z"
   },
   {
    "duration": 29,
    "start_time": "2024-12-28T04:22:57.493Z"
   },
   {
    "duration": 279,
    "start_time": "2024-12-28T04:22:57.524Z"
   },
   {
    "duration": 496,
    "start_time": "2024-12-28T04:22:57.805Z"
   },
   {
    "duration": 93,
    "start_time": "2024-12-28T04:22:58.303Z"
   },
   {
    "duration": 207,
    "start_time": "2024-12-28T04:22:58.398Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-28T04:22:58.607Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-28T04:22:58.627Z"
   },
   {
    "duration": 325,
    "start_time": "2024-12-28T04:22:58.653Z"
   },
   {
    "duration": 116,
    "start_time": "2024-12-28T04:22:58.983Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-28T04:22:59.101Z"
   },
   {
    "duration": 159,
    "start_time": "2024-12-28T04:22:59.215Z"
   },
   {
    "duration": 241,
    "start_time": "2024-12-28T04:22:59.376Z"
   },
   {
    "duration": 614,
    "start_time": "2024-12-28T04:22:59.619Z"
   },
   {
    "duration": 67,
    "start_time": "2024-12-28T04:23:00.235Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T04:23:00.304Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T04:23:00.319Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T04:23:00.328Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-28T04:23:00.344Z"
   },
   {
    "duration": 5611,
    "start_time": "2024-12-28T04:23:00.372Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T04:23:05.986Z"
   },
   {
    "duration": 6090,
    "start_time": "2024-12-28T04:23:05.993Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T04:23:12.090Z"
   },
   {
    "duration": 180856,
    "start_time": "2024-12-28T04:23:12.101Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T04:26:12.959Z"
   },
   {
    "duration": 182006,
    "start_time": "2024-12-28T04:26:12.964Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:29:14.972Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T04:29:14.977Z"
   },
   {
    "duration": 45888,
    "start_time": "2024-12-28T04:29:14.982Z"
   },
   {
    "duration": 288211,
    "start_time": "2024-12-28T04:30:00.872Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:34:49.084Z"
   },
   {
    "duration": 290924,
    "start_time": "2024-12-28T04:34:49.091Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:39:40.016Z"
   },
   {
    "duration": 3060,
    "start_time": "2024-12-28T04:39:40.022Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T04:39:43.084Z"
   },
   {
    "duration": 3288,
    "start_time": "2024-12-28T04:39:43.090Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T04:39:46.384Z"
   },
   {
    "duration": 58588,
    "start_time": "2024-12-28T04:39:46.389Z"
   },
   {
    "duration": 3809,
    "start_time": "2024-12-28T04:40:44.979Z"
   },
   {
    "duration": 363,
    "start_time": "2024-12-28T04:40:48.790Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.155Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.157Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.158Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.170Z"
   },
   {
    "duration": 1,
    "start_time": "2024-12-28T04:40:49.171Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.173Z"
   },
   {
    "duration": 1,
    "start_time": "2024-12-28T04:40:49.174Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.176Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.177Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.178Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.179Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.181Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.183Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.184Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.185Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.186Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.187Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.189Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.189Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.191Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T04:40:49.192Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T04:42:37.330Z"
   },
   {
    "duration": 3244,
    "start_time": "2024-12-28T04:42:42.457Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T04:42:48.868Z"
   },
   {
    "duration": 15894,
    "start_time": "2024-12-28T04:42:54.495Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:47:26.311Z"
   },
   {
    "duration": 15698,
    "start_time": "2024-12-28T04:47:27.193Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:47:55.364Z"
   },
   {
    "duration": 254069,
    "start_time": "2024-12-28T04:47:58.739Z"
   },
   {
    "duration": 13642,
    "start_time": "2024-12-28T04:54:08.945Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:54:32.807Z"
   },
   {
    "duration": 13821,
    "start_time": "2024-12-28T04:54:37.106Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:54:53.745Z"
   },
   {
    "duration": 174824,
    "start_time": "2024-12-28T04:54:58.767Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T04:58:16.435Z"
   },
   {
    "duration": 173372,
    "start_time": "2024-12-28T04:58:18.402Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T05:01:38.456Z"
   },
   {
    "duration": 2090760,
    "start_time": "2024-12-28T05:01:42.928Z"
   },
   {
    "duration": 287743,
    "start_time": "2024-12-28T05:37:31.244Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T05:42:24.239Z"
   },
   {
    "duration": 286621,
    "start_time": "2024-12-28T05:42:28.164Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T05:47:17.207Z"
   },
   {
    "duration": 5018,
    "start_time": "2024-12-28T05:55:27.674Z"
   },
   {
    "duration": 28,
    "start_time": "2024-12-28T05:55:40.287Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-28T05:55:46.263Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T05:56:19.753Z"
   },
   {
    "duration": 5028,
    "start_time": "2024-12-28T05:56:29.258Z"
   },
   {
    "duration": 40,
    "start_time": "2024-12-28T05:57:07.159Z"
   },
   {
    "duration": 29,
    "start_time": "2024-12-28T05:57:20.273Z"
   },
   {
    "duration": 28,
    "start_time": "2024-12-28T05:58:04.093Z"
   },
   {
    "duration": 174430,
    "start_time": "2024-12-28T06:00:08.954Z"
   },
   {
    "duration": 1950,
    "start_time": "2024-12-28T06:03:55.522Z"
   },
   {
    "duration": 1909,
    "start_time": "2024-12-28T06:04:12.234Z"
   },
   {
    "duration": 1923,
    "start_time": "2024-12-28T06:04:18.249Z"
   },
   {
    "duration": 1883,
    "start_time": "2024-12-28T06:04:39.447Z"
   },
   {
    "duration": 291412,
    "start_time": "2024-12-28T06:07:07.887Z"
   },
   {
    "duration": 2105,
    "start_time": "2024-12-28T06:12:08.333Z"
   },
   {
    "duration": 2042,
    "start_time": "2024-12-28T06:12:14.216Z"
   },
   {
    "duration": 1110,
    "start_time": "2024-12-28T06:14:29.192Z"
   },
   {
    "duration": 470,
    "start_time": "2024-12-28T06:14:30.305Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T06:14:30.776Z"
   },
   {
    "duration": 110,
    "start_time": "2024-12-28T06:14:30.792Z"
   },
   {
    "duration": 66,
    "start_time": "2024-12-28T06:14:30.905Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-28T06:14:30.973Z"
   },
   {
    "duration": 246,
    "start_time": "2024-12-28T06:14:31.002Z"
   },
   {
    "duration": 478,
    "start_time": "2024-12-28T06:14:31.250Z"
   },
   {
    "duration": 89,
    "start_time": "2024-12-28T06:14:31.729Z"
   },
   {
    "duration": 185,
    "start_time": "2024-12-28T06:14:31.821Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-28T06:14:32.008Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-28T06:14:32.020Z"
   },
   {
    "duration": 312,
    "start_time": "2024-12-28T06:14:32.041Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-28T06:14:32.355Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-28T06:14:32.470Z"
   },
   {
    "duration": 143,
    "start_time": "2024-12-28T06:14:32.579Z"
   },
   {
    "duration": 240,
    "start_time": "2024-12-28T06:14:32.724Z"
   },
   {
    "duration": 600,
    "start_time": "2024-12-28T06:14:32.966Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-28T06:14:33.570Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T06:14:33.629Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-28T06:14:33.643Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-28T06:14:33.671Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T06:14:33.685Z"
   },
   {
    "duration": 4980,
    "start_time": "2024-12-28T06:14:33.690Z"
   },
   {
    "duration": 97,
    "start_time": "2024-12-28T06:14:38.674Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-28T06:14:38.776Z"
   },
   {
    "duration": 172751,
    "start_time": "2024-12-28T06:14:38.888Z"
   },
   {
    "duration": 1891,
    "start_time": "2024-12-28T06:17:31.644Z"
   },
   {
    "duration": 1881,
    "start_time": "2024-12-28T06:17:33.536Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T06:17:35.419Z"
   },
   {
    "duration": 44024,
    "start_time": "2024-12-28T06:17:35.424Z"
   },
   {
    "duration": 291910,
    "start_time": "2024-12-28T06:18:19.450Z"
   },
   {
    "duration": 1991,
    "start_time": "2024-12-28T06:23:11.362Z"
   },
   {
    "duration": 1979,
    "start_time": "2024-12-28T06:23:13.355Z"
   },
   {
    "duration": 2757,
    "start_time": "2024-12-28T06:23:15.335Z"
   },
   {
    "duration": 392,
    "start_time": "2024-12-28T06:23:18.094Z"
   },
   {
    "duration": 397,
    "start_time": "2024-12-28T06:23:18.488Z"
   },
   {
    "duration": 26523,
    "start_time": "2024-12-28T06:23:18.887Z"
   },
   {
    "duration": 1,
    "start_time": "2024-12-28T06:23:45.412Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.414Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.416Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.417Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.417Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.419Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.420Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.421Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.422Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.423Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.424Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.425Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.426Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.427Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.428Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.430Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.431Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.431Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.432Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.433Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.434Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.435Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T06:23:45.470Z"
   },
   {
    "duration": 2804,
    "start_time": "2024-12-28T06:25:10.785Z"
   },
   {
    "duration": 355,
    "start_time": "2024-12-28T06:25:19.327Z"
   },
   {
    "duration": 337,
    "start_time": "2024-12-28T06:25:21.453Z"
   },
   {
    "duration": 15594,
    "start_time": "2024-12-28T06:26:51.044Z"
   },
   {
    "duration": 66,
    "start_time": "2024-12-28T06:27:21.344Z"
   },
   {
    "duration": 62,
    "start_time": "2024-12-28T06:27:23.868Z"
   },
   {
    "duration": 253359,
    "start_time": "2024-12-28T06:27:27.523Z"
   },
   {
    "duration": 50,
    "start_time": "2024-12-28T06:32:47.210Z"
   },
   {
    "duration": 13272,
    "start_time": "2024-12-28T06:32:54.834Z"
   },
   {
    "duration": 347,
    "start_time": "2024-12-28T06:33:19.954Z"
   },
   {
    "duration": 345,
    "start_time": "2024-12-28T06:33:21.994Z"
   },
   {
    "duration": 172978,
    "start_time": "2024-12-28T06:33:25.620Z"
   },
   {
    "duration": 420,
    "start_time": "2024-12-28T06:37:26.470Z"
   },
   {
    "duration": 374,
    "start_time": "2024-12-28T06:37:28.611Z"
   },
   {
    "duration": 11578,
    "start_time": "2024-12-28T06:37:32.233Z"
   },
   {
    "duration": 284203,
    "start_time": "2024-12-28T06:37:48.831Z"
   },
   {
    "duration": 405,
    "start_time": "2024-12-28T06:42:44.983Z"
   },
   {
    "duration": 373,
    "start_time": "2024-12-28T06:42:47.511Z"
   },
   {
    "duration": 13483,
    "start_time": "2024-12-28T06:50:42.675Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T06:51:20.837Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T06:51:31.493Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-28T06:56:23.643Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-28T06:58:21.255Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T06:59:48.065Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-28T07:01:17.093Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T07:04:32.495Z"
   },
   {
    "duration": 599,
    "start_time": "2024-12-28T07:08:14.798Z"
   },
   {
    "duration": 52,
    "start_time": "2024-12-28T07:11:30.895Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T07:12:09.845Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T07:12:41.868Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T07:13:30.926Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T07:14:31.190Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T07:15:06.088Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T07:15:36.308Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T07:15:52.219Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T07:16:16.363Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T07:16:17.874Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T07:18:38.436Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T07:19:12.211Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T07:19:34.413Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T07:19:48.624Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T07:19:56.682Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T07:19:58.369Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-28T07:20:07.367Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T07:20:09.422Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-28T07:25:32.223Z"
   },
   {
    "duration": 1133,
    "start_time": "2024-12-28T07:42:25.790Z"
   },
   {
    "duration": 463,
    "start_time": "2024-12-28T07:42:29.133Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T07:42:31.564Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-28T07:42:35.091Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-28T07:42:39.339Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-28T07:42:41.376Z"
   },
   {
    "duration": 229,
    "start_time": "2024-12-28T07:42:45.050Z"
   },
   {
    "duration": 468,
    "start_time": "2024-12-28T07:42:46.850Z"
   },
   {
    "duration": 85,
    "start_time": "2024-12-28T07:42:54.049Z"
   },
   {
    "duration": 174,
    "start_time": "2024-12-28T07:43:32.271Z"
   },
   {
    "duration": 2779,
    "start_time": "2024-12-28T16:48:26.922Z"
   },
   {
    "duration": 480,
    "start_time": "2024-12-28T16:48:29.703Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-28T16:48:30.184Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-28T16:48:30.201Z"
   },
   {
    "duration": 70,
    "start_time": "2024-12-28T16:48:30.307Z"
   },
   {
    "duration": 32,
    "start_time": "2024-12-28T16:48:30.380Z"
   },
   {
    "duration": 252,
    "start_time": "2024-12-28T16:48:30.414Z"
   },
   {
    "duration": 485,
    "start_time": "2024-12-28T16:48:30.668Z"
   },
   {
    "duration": 93,
    "start_time": "2024-12-28T16:48:31.155Z"
   },
   {
    "duration": 186,
    "start_time": "2024-12-28T16:48:31.251Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-28T16:48:31.439Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T16:48:31.451Z"
   },
   {
    "duration": 374,
    "start_time": "2024-12-28T16:48:31.468Z"
   },
   {
    "duration": 115,
    "start_time": "2024-12-28T16:48:31.844Z"
   },
   {
    "duration": 115,
    "start_time": "2024-12-28T16:48:31.961Z"
   },
   {
    "duration": 156,
    "start_time": "2024-12-28T16:48:32.078Z"
   },
   {
    "duration": 238,
    "start_time": "2024-12-28T16:48:32.237Z"
   },
   {
    "duration": 600,
    "start_time": "2024-12-28T16:48:32.477Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-28T16:48:33.079Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T16:48:33.144Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-28T16:48:33.162Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-28T16:48:33.174Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-28T16:48:33.191Z"
   },
   {
    "duration": 5142,
    "start_time": "2024-12-28T16:48:33.195Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-28T16:48:38.339Z"
   },
   {
    "duration": 113,
    "start_time": "2024-12-28T16:48:38.437Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T16:48:38.554Z"
   },
   {
    "duration": 178207,
    "start_time": "2024-12-28T16:48:38.637Z"
   },
   {
    "duration": 1985,
    "start_time": "2024-12-28T16:51:36.847Z"
   },
   {
    "duration": 1934,
    "start_time": "2024-12-28T16:51:38.834Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T16:51:40.770Z"
   },
   {
    "duration": 44947,
    "start_time": "2024-12-28T16:51:40.774Z"
   },
   {
    "duration": 306254,
    "start_time": "2024-12-28T16:52:25.723Z"
   },
   {
    "duration": 2153,
    "start_time": "2024-12-28T16:57:31.980Z"
   },
   {
    "duration": 2172,
    "start_time": "2024-12-28T16:57:34.135Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T16:57:36.309Z"
   },
   {
    "duration": 2639,
    "start_time": "2024-12-28T16:57:36.314Z"
   },
   {
    "duration": 323,
    "start_time": "2024-12-28T16:57:39.032Z"
   },
   {
    "duration": 321,
    "start_time": "2024-12-28T16:57:39.430Z"
   },
   {
    "duration": 56978,
    "start_time": "2024-12-28T16:57:39.754Z"
   },
   {
    "duration": 3010,
    "start_time": "2024-12-28T16:58:36.734Z"
   },
   {
    "duration": 399,
    "start_time": "2024-12-28T16:58:39.745Z"
   },
   {
    "duration": 396,
    "start_time": "2024-12-28T16:58:40.147Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T16:58:40.545Z"
   },
   {
    "duration": 16032,
    "start_time": "2024-12-28T16:58:40.550Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-28T16:58:56.584Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-28T16:58:56.687Z"
   },
   {
    "duration": 257563,
    "start_time": "2024-12-28T16:58:56.793Z"
   },
   {
    "duration": 13569,
    "start_time": "2024-12-28T17:03:14.358Z"
   },
   {
    "duration": 355,
    "start_time": "2024-12-28T17:03:27.929Z"
   },
   {
    "duration": 359,
    "start_time": "2024-12-28T17:03:28.286Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T17:03:28.647Z"
   },
   {
    "duration": 172946,
    "start_time": "2024-12-28T17:03:28.652Z"
   },
   {
    "duration": 453,
    "start_time": "2024-12-28T17:06:21.601Z"
   },
   {
    "duration": 398,
    "start_time": "2024-12-28T17:06:22.058Z"
   },
   {
    "duration": 1062089,
    "start_time": "2024-12-28T17:06:22.457Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T17:24:04.548Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T17:24:04.550Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T17:24:04.551Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T17:24:04.552Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T17:24:04.554Z"
   },
   {
    "duration": 281901,
    "start_time": "2024-12-28T17:24:08.983Z"
   },
   {
    "duration": 363,
    "start_time": "2024-12-28T17:36:06.884Z"
   },
   {
    "duration": 353,
    "start_time": "2024-12-28T17:36:08.195Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T17:36:19.429Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-28T17:36:22.054Z"
   },
   {
    "duration": 273,
    "start_time": "2024-12-28T17:50:15.781Z"
   },
   {
    "duration": 1141,
    "start_time": "2024-12-28T17:50:39.940Z"
   },
   {
    "duration": 438,
    "start_time": "2024-12-28T17:50:41.497Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T17:50:43.111Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-28T17:50:44.932Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-28T17:50:46.711Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-28T17:50:47.380Z"
   },
   {
    "duration": 236,
    "start_time": "2024-12-28T17:50:49.171Z"
   },
   {
    "duration": 484,
    "start_time": "2024-12-28T17:50:50.625Z"
   },
   {
    "duration": 87,
    "start_time": "2024-12-28T17:50:52.931Z"
   },
   {
    "duration": 175,
    "start_time": "2024-12-28T17:50:54.810Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T17:51:03.520Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T17:51:04.502Z"
   },
   {
    "duration": 291,
    "start_time": "2024-12-28T17:51:09.314Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-28T17:51:09.769Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-28T17:51:10.217Z"
   },
   {
    "duration": 151,
    "start_time": "2024-12-28T17:51:10.694Z"
   },
   {
    "duration": 241,
    "start_time": "2024-12-28T17:51:15.045Z"
   },
   {
    "duration": 657,
    "start_time": "2024-12-28T17:51:23.962Z"
   },
   {
    "duration": 1078,
    "start_time": "2024-12-28T17:52:30.114Z"
   },
   {
    "duration": 418,
    "start_time": "2024-12-28T17:52:32.222Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T17:52:33.241Z"
   },
   {
    "duration": 98,
    "start_time": "2024-12-28T17:52:34.688Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-28T17:52:35.846Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-28T17:52:36.498Z"
   },
   {
    "duration": 242,
    "start_time": "2024-12-28T17:52:38.246Z"
   },
   {
    "duration": 491,
    "start_time": "2024-12-28T17:52:39.464Z"
   },
   {
    "duration": 89,
    "start_time": "2024-12-28T17:52:40.788Z"
   },
   {
    "duration": 182,
    "start_time": "2024-12-28T17:52:41.949Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-28T17:52:44.762Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-28T17:52:45.405Z"
   },
   {
    "duration": 303,
    "start_time": "2024-12-28T17:52:47.504Z"
   },
   {
    "duration": 108,
    "start_time": "2024-12-28T17:52:48.100Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-28T17:52:48.756Z"
   },
   {
    "duration": 147,
    "start_time": "2024-12-28T17:52:49.624Z"
   },
   {
    "duration": 719,
    "start_time": "2024-12-28T17:52:52.163Z"
   },
   {
    "duration": 231,
    "start_time": "2024-12-28T17:53:11.205Z"
   },
   {
    "duration": 1154,
    "start_time": "2024-12-28T17:55:59.487Z"
   },
   {
    "duration": 460,
    "start_time": "2024-12-28T17:56:01.934Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T17:56:02.998Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-28T17:56:04.271Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-28T17:56:05.405Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-28T17:56:05.951Z"
   },
   {
    "duration": 220,
    "start_time": "2024-12-28T17:56:08.707Z"
   },
   {
    "duration": 479,
    "start_time": "2024-12-28T17:56:10.006Z"
   },
   {
    "duration": 86,
    "start_time": "2024-12-28T17:56:11.251Z"
   },
   {
    "duration": 177,
    "start_time": "2024-12-28T17:56:12.363Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-28T17:56:14.116Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T17:56:14.815Z"
   },
   {
    "duration": 314,
    "start_time": "2024-12-28T17:56:17.675Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-28T17:56:18.424Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-28T17:56:18.942Z"
   },
   {
    "duration": 139,
    "start_time": "2024-12-28T17:56:19.112Z"
   },
   {
    "duration": 169,
    "start_time": "2024-12-28T17:56:37.256Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-28T17:56:56.813Z"
   },
   {
    "duration": 1144,
    "start_time": "2024-12-28T17:57:13.153Z"
   },
   {
    "duration": 487,
    "start_time": "2024-12-28T17:57:15.265Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-28T17:57:16.407Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-28T17:57:17.525Z"
   },
   {
    "duration": 62,
    "start_time": "2024-12-28T17:57:18.646Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-28T17:57:19.270Z"
   },
   {
    "duration": 244,
    "start_time": "2024-12-28T17:57:21.152Z"
   },
   {
    "duration": 487,
    "start_time": "2024-12-28T17:57:22.390Z"
   },
   {
    "duration": 87,
    "start_time": "2024-12-28T17:57:23.869Z"
   },
   {
    "duration": 174,
    "start_time": "2024-12-28T17:57:25.201Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-28T17:57:26.923Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T17:57:27.563Z"
   },
   {
    "duration": 299,
    "start_time": "2024-12-28T17:57:29.903Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-28T17:57:30.567Z"
   },
   {
    "duration": 98,
    "start_time": "2024-12-28T17:57:31.106Z"
   },
   {
    "duration": 139,
    "start_time": "2024-12-28T17:57:31.676Z"
   },
   {
    "duration": 238,
    "start_time": "2024-12-28T17:57:33.931Z"
   },
   {
    "duration": 587,
    "start_time": "2024-12-28T17:57:43.310Z"
   },
   {
    "duration": 152,
    "start_time": "2024-12-28T18:00:52.785Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T18:00:57.846Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-28T18:00:58.640Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-28T18:01:32.313Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T18:01:35.964Z"
   },
   {
    "duration": 5159,
    "start_time": "2024-12-28T18:01:36.976Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-28T18:01:43.036Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-28T18:01:46.948Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T18:01:49.040Z"
   },
   {
    "duration": 156,
    "start_time": "2024-12-28T18:03:50.396Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T18:07:02.121Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:07:22.194Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:07:37.698Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T18:07:47.855Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:09:44.700Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T18:12:35.162Z"
   },
   {
    "duration": 8317,
    "start_time": "2024-12-28T18:13:04.622Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:14:10.316Z"
   },
   {
    "duration": 7692,
    "start_time": "2024-12-28T18:14:11.048Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:15:10.503Z"
   },
   {
    "duration": 8004,
    "start_time": "2024-12-28T18:15:13.145Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:22:36.830Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:23:03.993Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:23:33.213Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T18:23:37.934Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T18:23:51.906Z"
   },
   {
    "duration": 667,
    "start_time": "2024-12-28T18:25:00.664Z"
   },
   {
    "duration": 5289,
    "start_time": "2024-12-28T18:25:18.753Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:41:14.738Z"
   },
   {
    "duration": 645,
    "start_time": "2024-12-28T18:41:16.705Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-28T18:41:21.967Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-28T18:41:24.062Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T18:46:44.733Z"
   },
   {
    "duration": 5253,
    "start_time": "2024-12-28T18:48:59.077Z"
   },
   {
    "duration": 185257,
    "start_time": "2024-12-28T18:51:09.306Z"
   },
   {
    "duration": 53,
    "start_time": "2024-12-28T18:54:33.695Z"
   },
   {
    "duration": 180900,
    "start_time": "2024-12-28T18:54:39.337Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T18:57:40.239Z"
   },
   {
    "duration": 1102,
    "start_time": "2024-12-28T19:04:40.093Z"
   },
   {
    "duration": 437,
    "start_time": "2024-12-28T19:04:41.197Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-28T19:04:41.636Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-28T19:04:41.651Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-28T19:04:41.752Z"
   },
   {
    "duration": 40,
    "start_time": "2024-12-28T19:04:41.814Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-28T19:04:41.856Z"
   },
   {
    "duration": 481,
    "start_time": "2024-12-28T19:04:42.101Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-28T19:04:42.584Z"
   },
   {
    "duration": 186,
    "start_time": "2024-12-28T19:04:42.679Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-28T19:04:42.867Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-28T19:04:42.880Z"
   },
   {
    "duration": 335,
    "start_time": "2024-12-28T19:04:42.905Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-28T19:04:43.242Z"
   },
   {
    "duration": 120,
    "start_time": "2024-12-28T19:04:43.356Z"
   },
   {
    "duration": 146,
    "start_time": "2024-12-28T19:04:43.478Z"
   },
   {
    "duration": 240,
    "start_time": "2024-12-28T19:04:43.626Z"
   },
   {
    "duration": 87,
    "start_time": "2024-12-28T19:04:43.868Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T19:04:43.957Z"
   },
   {
    "duration": 690,
    "start_time": "2024-12-28T19:04:43.962Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T19:04:44.654Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-28T19:04:44.660Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-28T19:04:44.677Z"
   },
   {
    "duration": 5444,
    "start_time": "2024-12-28T19:04:44.698Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T19:04:50.144Z"
   },
   {
    "duration": 186865,
    "start_time": "2024-12-28T19:04:50.148Z"
   },
   {
    "duration": 323,
    "start_time": "2024-12-28T19:07:57.015Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.341Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.342Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.343Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.345Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.346Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.347Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.348Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.350Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.351Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.353Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.354Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.356Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.357Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.360Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.362Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T19:07:57.363Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T19:08:41.387Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-28T19:08:44.681Z"
   },
   {
    "duration": 44730,
    "start_time": "2024-12-28T19:09:59.261Z"
   },
   {
    "duration": 312331,
    "start_time": "2024-12-28T19:11:16.634Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T19:17:06.077Z"
   },
   {
    "duration": 3472,
    "start_time": "2024-12-28T19:17:09.075Z"
   },
   {
    "duration": 59143,
    "start_time": "2024-12-28T19:17:25.097Z"
   },
   {
    "duration": 4161,
    "start_time": "2024-12-28T19:20:04.778Z"
   },
   {
    "duration": 16129,
    "start_time": "2024-12-28T19:20:29.865Z"
   },
   {
    "duration": 254790,
    "start_time": "2024-12-28T19:20:53.304Z"
   },
   {
    "duration": 14358,
    "start_time": "2024-12-28T19:25:42.707Z"
   },
   {
    "duration": 172424,
    "start_time": "2024-12-28T19:26:26.808Z"
   },
   {
    "duration": 2085146,
    "start_time": "2024-12-28T19:29:28.685Z"
   },
   {
    "duration": 144035,
    "start_time": "2024-12-28T20:08:13.800Z"
   },
   {
    "duration": 5177,
    "start_time": "2024-12-28T20:13:00.859Z"
   },
   {
    "duration": 1169,
    "start_time": "2024-12-28T20:17:42.041Z"
   },
   {
    "duration": 419,
    "start_time": "2024-12-28T20:17:43.212Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T20:17:43.633Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-28T20:17:43.650Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-28T20:17:43.755Z"
   },
   {
    "duration": 42,
    "start_time": "2024-12-28T20:17:43.814Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-28T20:17:43.857Z"
   },
   {
    "duration": 494,
    "start_time": "2024-12-28T20:17:44.102Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-28T20:17:44.598Z"
   },
   {
    "duration": 181,
    "start_time": "2024-12-28T20:17:44.697Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-28T20:17:44.880Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-28T20:17:44.893Z"
   },
   {
    "duration": 305,
    "start_time": "2024-12-28T20:17:44.930Z"
   },
   {
    "duration": 113,
    "start_time": "2024-12-28T20:17:45.237Z"
   },
   {
    "duration": 119,
    "start_time": "2024-12-28T20:17:45.352Z"
   },
   {
    "duration": 153,
    "start_time": "2024-12-28T20:17:45.473Z"
   },
   {
    "duration": 251,
    "start_time": "2024-12-28T20:17:45.631Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-28T20:17:45.884Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T20:17:45.978Z"
   },
   {
    "duration": 694,
    "start_time": "2024-12-28T20:17:45.984Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T20:17:46.680Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-28T20:17:46.687Z"
   },
   {
    "duration": 40,
    "start_time": "2024-12-28T20:17:46.704Z"
   },
   {
    "duration": 5393,
    "start_time": "2024-12-28T20:17:46.745Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T20:17:52.140Z"
   },
   {
    "duration": 24373,
    "start_time": "2024-12-28T20:17:52.145Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.520Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.521Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.531Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.532Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.533Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.534Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.535Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.536Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.537Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.540Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.541Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.543Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.544Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.546Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.547Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.549Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-28T20:18:16.552Z"
   },
   {
    "duration": 68296,
    "start_time": "2024-12-28T20:18:22.720Z"
   },
   {
    "duration": 4186,
    "start_time": "2024-12-28T20:19:38.952Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-28T20:19:58.542Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-28T20:20:03.364Z"
   },
   {
    "duration": 5212,
    "start_time": "2024-12-28T20:20:19.620Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T20:20:33.261Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T20:20:48.291Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T20:21:30.021Z"
   },
   {
    "duration": 313423,
    "start_time": "2024-12-28T20:23:02.368Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T20:28:30.601Z"
   },
   {
    "duration": 14448,
    "start_time": "2024-12-28T20:28:39.623Z"
   },
   {
    "duration": 145830,
    "start_time": "2024-12-28T20:29:07.626Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-28T20:31:37.724Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-28T20:31:40.524Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-28T20:33:53.611Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T20:33:56.668Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T20:33:58.317Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T20:34:11.253Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-28T20:38:28.901Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-28T20:38:42.746Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-28T20:40:23.744Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-28T20:40:26.249Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-29T01:47:13.391Z"
   },
   {
    "duration": 2675,
    "start_time": "2024-12-29T02:22:06.057Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-29T02:40:14.777Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-29T02:41:39.860Z"
   },
   {
    "duration": 298,
    "start_time": "2024-12-29T02:44:00.748Z"
   },
   {
    "duration": 1195,
    "start_time": "2024-12-29T02:44:25.626Z"
   },
   {
    "duration": 453,
    "start_time": "2024-12-29T02:44:29.298Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-29T02:44:31.342Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-29T02:44:34.571Z"
   },
   {
    "duration": 58,
    "start_time": "2024-12-29T02:44:42.857Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-29T02:44:44.893Z"
   },
   {
    "duration": 230,
    "start_time": "2024-12-29T02:44:48.326Z"
   },
   {
    "duration": 483,
    "start_time": "2024-12-29T02:44:50.308Z"
   },
   {
    "duration": 87,
    "start_time": "2024-12-29T02:44:52.123Z"
   },
   {
    "duration": 172,
    "start_time": "2024-12-29T02:44:53.158Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-29T02:44:55.378Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-29T02:44:56.049Z"
   },
   {
    "duration": 291,
    "start_time": "2024-12-29T02:44:57.879Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-29T02:44:58.359Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-29T02:44:59.100Z"
   },
   {
    "duration": 161,
    "start_time": "2024-12-29T02:45:00.656Z"
   },
   {
    "duration": 231,
    "start_time": "2024-12-29T02:45:03.493Z"
   },
   {
    "duration": 78,
    "start_time": "2024-12-29T02:45:07.221Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-29T02:45:09.943Z"
   },
   {
    "duration": 657,
    "start_time": "2024-12-29T02:45:18.948Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-29T02:45:33.520Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-29T02:45:34.874Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-29T02:45:35.490Z"
   },
   {
    "duration": 348,
    "start_time": "2024-12-29T02:45:38.953Z"
   },
   {
    "duration": 42349,
    "start_time": "2024-12-29T02:49:19.062Z"
   },
   {
    "duration": 1464762,
    "start_time": "2024-12-29T02:51:25.218Z"
   },
   {
    "duration": 157,
    "start_time": "2024-12-29T03:42:22.470Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-29T03:42:42.665Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-29T03:42:51.157Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-29T03:42:57.815Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-29T03:43:07.044Z"
   },
   {
    "duration": 1121,
    "start_time": "2024-12-29T03:43:24.203Z"
   },
   {
    "duration": 412,
    "start_time": "2024-12-29T03:43:26.466Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-29T03:43:27.689Z"
   },
   {
    "duration": 96,
    "start_time": "2024-12-29T03:43:29.171Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-29T03:43:30.992Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-29T03:43:31.710Z"
   },
   {
    "duration": 245,
    "start_time": "2024-12-29T03:43:33.542Z"
   },
   {
    "duration": 491,
    "start_time": "2024-12-29T03:43:35.010Z"
   },
   {
    "duration": 85,
    "start_time": "2024-12-29T03:43:36.553Z"
   },
   {
    "duration": 188,
    "start_time": "2024-12-29T03:43:37.748Z"
   },
   {
    "duration": 34,
    "start_time": "2024-12-29T03:44:39.496Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-29T03:48:24.615Z"
   },
   {
    "duration": 211,
    "start_time": "2024-12-29T03:48:45.545Z"
   },
   {
    "duration": 35669,
    "start_time": "2024-12-29T03:49:08.453Z"
   },
   {
    "duration": 76,
    "start_time": "2024-12-29T03:51:18.899Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-29T03:51:20.275Z"
   },
   {
    "duration": 1063,
    "start_time": "2024-12-29T03:51:21.851Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-29T03:51:33.424Z"
   },
   {
    "duration": 583,
    "start_time": "2024-12-29T03:51:36.940Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-29T03:51:40.368Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-29T03:51:41.305Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-29T03:51:42.047Z"
   },
   {
    "duration": 40982,
    "start_time": "2024-12-29T03:51:44.913Z"
   },
   {
    "duration": 1160048,
    "start_time": "2024-12-29T03:52:34.980Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-29T04:14:43.411Z"
   },
   {
    "duration": 88299,
    "start_time": "2024-12-29T04:14:44.553Z"
   },
   {
    "duration": 1053,
    "start_time": "2024-12-31T02:24:23.399Z"
   },
   {
    "duration": 418,
    "start_time": "2024-12-31T02:24:24.455Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-31T02:24:24.874Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-31T02:24:24.891Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-31T02:24:25.002Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-31T02:24:25.065Z"
   },
   {
    "duration": 252,
    "start_time": "2024-12-31T02:24:25.090Z"
   },
   {
    "duration": 490,
    "start_time": "2024-12-31T02:24:25.344Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-31T02:24:25.836Z"
   },
   {
    "duration": 180,
    "start_time": "2024-12-31T02:24:25.929Z"
   },
   {
    "duration": 36,
    "start_time": "2024-12-31T02:24:26.112Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-31T02:24:26.150Z"
   },
   {
    "duration": 258,
    "start_time": "2024-12-31T02:24:26.170Z"
   },
   {
    "duration": 122,
    "start_time": "2024-12-31T02:24:26.430Z"
   },
   {
    "duration": 107,
    "start_time": "2024-12-31T02:24:26.554Z"
   },
   {
    "duration": 149,
    "start_time": "2024-12-31T02:24:26.663Z"
   },
   {
    "duration": 229,
    "start_time": "2024-12-31T02:24:26.814Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-31T02:24:27.044Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-31T02:24:27.053Z"
   },
   {
    "duration": 180,
    "start_time": "2024-12-31T02:24:27.060Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T02:24:27.242Z"
   },
   {
    "duration": 40,
    "start_time": "2024-12-31T02:24:27.250Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-31T02:24:27.308Z"
   },
   {
    "duration": 481,
    "start_time": "2024-12-31T02:24:27.329Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.813Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.814Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.816Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.817Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.818Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.821Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.822Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.823Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.825Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.827Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.828Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.829Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.831Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.833Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.834Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.836Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.837Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:24:27.839Z"
   },
   {
    "duration": 1114,
    "start_time": "2024-12-31T02:27:03.432Z"
   },
   {
    "duration": 419,
    "start_time": "2024-12-31T02:27:04.548Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-31T02:27:04.969Z"
   },
   {
    "duration": 110,
    "start_time": "2024-12-31T02:27:04.985Z"
   },
   {
    "duration": 66,
    "start_time": "2024-12-31T02:27:05.097Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-31T02:27:05.165Z"
   },
   {
    "duration": 249,
    "start_time": "2024-12-31T02:27:05.193Z"
   },
   {
    "duration": 483,
    "start_time": "2024-12-31T02:27:05.444Z"
   },
   {
    "duration": 93,
    "start_time": "2024-12-31T02:27:05.929Z"
   },
   {
    "duration": 195,
    "start_time": "2024-12-31T02:27:06.025Z"
   },
   {
    "duration": 33,
    "start_time": "2024-12-31T02:27:06.222Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-31T02:27:06.257Z"
   },
   {
    "duration": 308,
    "start_time": "2024-12-31T02:27:06.279Z"
   },
   {
    "duration": 108,
    "start_time": "2024-12-31T02:27:06.589Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-31T02:27:06.699Z"
   },
   {
    "duration": 147,
    "start_time": "2024-12-31T02:27:06.814Z"
   },
   {
    "duration": 246,
    "start_time": "2024-12-31T02:27:06.963Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-31T02:27:07.211Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T02:27:07.309Z"
   },
   {
    "duration": 632,
    "start_time": "2024-12-31T02:27:07.316Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T02:27:07.952Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-31T02:27:07.960Z"
   },
   {
    "duration": 39,
    "start_time": "2024-12-31T02:27:07.983Z"
   },
   {
    "duration": 43098,
    "start_time": "2024-12-31T02:27:08.024Z"
   },
   {
    "duration": 1521822,
    "start_time": "2024-12-31T02:27:51.124Z"
   },
   {
    "duration": 299,
    "start_time": "2024-12-31T02:53:12.948Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.249Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.250Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.251Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.253Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.253Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.255Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.256Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.257Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.259Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.260Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.261Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.262Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.263Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.264Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.265Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T02:53:13.266Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-31T02:56:13.095Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T02:56:21.728Z"
   },
   {
    "duration": 95110,
    "start_time": "2024-12-31T02:56:23.351Z"
   },
   {
    "duration": 2556892,
    "start_time": "2024-12-31T02:59:29.840Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T03:43:35.726Z"
   },
   {
    "duration": 1090,
    "start_time": "2024-12-31T03:59:54.136Z"
   },
   {
    "duration": 404,
    "start_time": "2024-12-31T03:59:55.229Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-31T03:59:55.635Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-31T03:59:55.651Z"
   },
   {
    "duration": 68,
    "start_time": "2024-12-31T03:59:55.754Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-31T03:59:55.824Z"
   },
   {
    "duration": 243,
    "start_time": "2024-12-31T03:59:55.848Z"
   },
   {
    "duration": 470,
    "start_time": "2024-12-31T03:59:56.097Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-31T03:59:56.569Z"
   },
   {
    "duration": 183,
    "start_time": "2024-12-31T03:59:56.665Z"
   },
   {
    "duration": 36,
    "start_time": "2024-12-31T03:59:56.850Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-31T03:59:56.888Z"
   },
   {
    "duration": 303,
    "start_time": "2024-12-31T03:59:56.921Z"
   },
   {
    "duration": 127,
    "start_time": "2024-12-31T03:59:57.226Z"
   },
   {
    "duration": 121,
    "start_time": "2024-12-31T03:59:57.356Z"
   },
   {
    "duration": 144,
    "start_time": "2024-12-31T03:59:57.479Z"
   },
   {
    "duration": 242,
    "start_time": "2024-12-31T03:59:57.625Z"
   },
   {
    "duration": 80,
    "start_time": "2024-12-31T03:59:57.870Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T03:59:57.952Z"
   },
   {
    "duration": 621,
    "start_time": "2024-12-31T03:59:57.958Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T03:59:58.581Z"
   },
   {
    "duration": 28,
    "start_time": "2024-12-31T03:59:58.589Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-31T03:59:58.618Z"
   },
   {
    "duration": 41204,
    "start_time": "2024-12-31T03:59:58.635Z"
   },
   {
    "duration": 1507952,
    "start_time": "2024-12-31T04:00:39.841Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T04:25:47.795Z"
   },
   {
    "duration": 94617,
    "start_time": "2024-12-31T04:25:47.809Z"
   },
   {
    "duration": 335,
    "start_time": "2024-12-31T04:42:56.919Z"
   },
   {
    "duration": 2135,
    "start_time": "2024-12-31T04:43:08.881Z"
   },
   {
    "duration": 891,
    "start_time": "2024-12-31T04:43:11.018Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-31T04:43:13.449Z"
   },
   {
    "duration": 172,
    "start_time": "2024-12-31T04:43:14.777Z"
   },
   {
    "duration": 129,
    "start_time": "2024-12-31T04:43:15.887Z"
   },
   {
    "duration": 60,
    "start_time": "2024-12-31T04:43:16.449Z"
   },
   {
    "duration": 485,
    "start_time": "2024-12-31T04:43:18.261Z"
   },
   {
    "duration": 1042,
    "start_time": "2024-12-31T04:43:19.309Z"
   },
   {
    "duration": 172,
    "start_time": "2024-12-31T04:43:20.438Z"
   },
   {
    "duration": 322,
    "start_time": "2024-12-31T04:43:22.325Z"
   },
   {
    "duration": 76,
    "start_time": "2024-12-31T04:43:27.641Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-31T04:43:28.217Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-31T04:43:43.515Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-31T04:44:39.722Z"
   },
   {
    "duration": 152,
    "start_time": "2024-12-31T04:45:07.891Z"
   },
   {
    "duration": 515,
    "start_time": "2024-12-31T04:45:12.224Z"
   },
   {
    "duration": 1070,
    "start_time": "2024-12-31T04:45:16.877Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T04:45:34.512Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-31T04:49:24.842Z"
   },
   {
    "duration": 29,
    "start_time": "2024-12-31T04:49:33.297Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T04:52:00.976Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T04:52:39.267Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-31T04:54:15.149Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-31T04:54:16.316Z"
   },
   {
    "duration": 721,
    "start_time": "2024-12-31T04:56:58.411Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-31T05:02:01.994Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-31T05:02:04.822Z"
   },
   {
    "duration": 93,
    "start_time": "2024-12-31T05:02:36.743Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-31T05:03:31.766Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-31T05:04:27.887Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T05:04:36.710Z"
   },
   {
    "duration": 130,
    "start_time": "2024-12-31T05:08:08.283Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-31T05:24:33.324Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T05:25:05.782Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-31T05:25:09.025Z"
   },
   {
    "duration": 65,
    "start_time": "2024-12-31T05:25:21.289Z"
   },
   {
    "duration": 1043,
    "start_time": "2024-12-31T05:50:13.610Z"
   },
   {
    "duration": 406,
    "start_time": "2024-12-31T05:50:15.713Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T05:50:17.324Z"
   },
   {
    "duration": 92,
    "start_time": "2024-12-31T05:50:19.210Z"
   },
   {
    "duration": 58,
    "start_time": "2024-12-31T05:50:20.689Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-31T05:50:21.287Z"
   },
   {
    "duration": 248,
    "start_time": "2024-12-31T05:50:23.265Z"
   },
   {
    "duration": 676,
    "start_time": "2024-12-31T05:50:24.785Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-31T05:50:27.287Z"
   },
   {
    "duration": 187,
    "start_time": "2024-12-31T05:50:29.009Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-31T05:50:31.449Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-31T05:50:32.252Z"
   },
   {
    "duration": 1052,
    "start_time": "2024-12-31T05:50:43.713Z"
   },
   {
    "duration": 479,
    "start_time": "2024-12-31T05:50:44.770Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-31T05:50:45.250Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-31T05:50:45.271Z"
   },
   {
    "duration": 82,
    "start_time": "2024-12-31T05:50:45.375Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-31T05:50:45.458Z"
   },
   {
    "duration": 244,
    "start_time": "2024-12-31T05:50:45.485Z"
   },
   {
    "duration": 485,
    "start_time": "2024-12-31T05:50:45.731Z"
   },
   {
    "duration": 96,
    "start_time": "2024-12-31T05:50:46.217Z"
   },
   {
    "duration": 202,
    "start_time": "2024-12-31T05:50:46.317Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T05:50:46.521Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T05:50:46.526Z"
   },
   {
    "duration": 1066,
    "start_time": "2024-12-31T05:50:57.972Z"
   },
   {
    "duration": 544,
    "start_time": "2024-12-31T05:50:59.041Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T05:50:59.586Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-31T05:50:59.609Z"
   },
   {
    "duration": 75,
    "start_time": "2024-12-31T05:50:59.720Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-31T05:50:59.797Z"
   },
   {
    "duration": 234,
    "start_time": "2024-12-31T05:50:59.826Z"
   },
   {
    "duration": 492,
    "start_time": "2024-12-31T05:51:00.062Z"
   },
   {
    "duration": 97,
    "start_time": "2024-12-31T05:51:00.556Z"
   },
   {
    "duration": 182,
    "start_time": "2024-12-31T05:51:00.656Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T05:51:00.840Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T05:51:00.846Z"
   },
   {
    "duration": 1322,
    "start_time": "2024-12-31T05:52:59.898Z"
   },
   {
    "duration": 452,
    "start_time": "2024-12-31T05:53:01.222Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-31T05:53:01.676Z"
   },
   {
    "duration": 117,
    "start_time": "2024-12-31T05:53:01.692Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-31T05:53:01.810Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-31T05:53:01.868Z"
   },
   {
    "duration": 234,
    "start_time": "2024-12-31T05:53:01.909Z"
   },
   {
    "duration": 479,
    "start_time": "2024-12-31T05:53:02.146Z"
   },
   {
    "duration": 93,
    "start_time": "2024-12-31T05:53:02.627Z"
   },
   {
    "duration": 196,
    "start_time": "2024-12-31T05:53:02.723Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T05:53:02.921Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T05:53:02.926Z"
   },
   {
    "duration": 1073,
    "start_time": "2024-12-31T05:57:35.569Z"
   },
   {
    "duration": 456,
    "start_time": "2024-12-31T05:57:36.645Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-31T05:57:37.102Z"
   },
   {
    "duration": 112,
    "start_time": "2024-12-31T05:57:37.123Z"
   },
   {
    "duration": 79,
    "start_time": "2024-12-31T05:57:37.238Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-31T05:57:37.318Z"
   },
   {
    "duration": 246,
    "start_time": "2024-12-31T05:57:37.345Z"
   },
   {
    "duration": 492,
    "start_time": "2024-12-31T05:57:37.593Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-31T05:57:38.086Z"
   },
   {
    "duration": 221,
    "start_time": "2024-12-31T05:57:38.180Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T05:57:38.409Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T05:57:38.415Z"
   },
   {
    "duration": 1101,
    "start_time": "2024-12-31T06:10:30.362Z"
   },
   {
    "duration": 441,
    "start_time": "2024-12-31T06:10:31.465Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-31T06:10:31.909Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-31T06:10:31.924Z"
   },
   {
    "duration": 56,
    "start_time": "2024-12-31T06:10:32.027Z"
   },
   {
    "duration": 35,
    "start_time": "2024-12-31T06:10:32.084Z"
   },
   {
    "duration": 231,
    "start_time": "2024-12-31T06:10:32.121Z"
   },
   {
    "duration": 473,
    "start_time": "2024-12-31T06:10:32.355Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-31T06:10:32.830Z"
   },
   {
    "duration": 180,
    "start_time": "2024-12-31T06:10:32.922Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T06:10:33.104Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T06:10:33.112Z"
   },
   {
    "duration": 1104,
    "start_time": "2024-12-31T06:11:11.839Z"
   },
   {
    "duration": 453,
    "start_time": "2024-12-31T06:11:12.945Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-31T06:11:13.400Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-31T06:11:13.415Z"
   },
   {
    "duration": 81,
    "start_time": "2024-12-31T06:11:13.518Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-31T06:11:13.601Z"
   },
   {
    "duration": 245,
    "start_time": "2024-12-31T06:11:13.629Z"
   },
   {
    "duration": 479,
    "start_time": "2024-12-31T06:11:13.876Z"
   },
   {
    "duration": 94,
    "start_time": "2024-12-31T06:11:14.357Z"
   },
   {
    "duration": 178,
    "start_time": "2024-12-31T06:11:14.456Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T06:11:14.636Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T06:11:14.641Z"
   },
   {
    "duration": 1053,
    "start_time": "2024-12-31T07:26:24.300Z"
   },
   {
    "duration": 225,
    "start_time": "2024-12-31T07:26:29.455Z"
   },
   {
    "duration": 463,
    "start_time": "2024-12-31T07:26:34.891Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-31T07:26:36.506Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-31T07:26:39.040Z"
   },
   {
    "duration": 57,
    "start_time": "2024-12-31T07:26:40.724Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-31T07:26:41.416Z"
   },
   {
    "duration": 229,
    "start_time": "2024-12-31T07:26:43.182Z"
   },
   {
    "duration": 477,
    "start_time": "2024-12-31T07:26:44.564Z"
   },
   {
    "duration": 88,
    "start_time": "2024-12-31T07:26:45.700Z"
   },
   {
    "duration": 179,
    "start_time": "2024-12-31T07:26:48.621Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T07:27:15.864Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T07:27:16.702Z"
   },
   {
    "duration": 162,
    "start_time": "2024-12-31T07:30:46.234Z"
   },
   {
    "duration": 1119,
    "start_time": "2024-12-31T07:31:00.922Z"
   },
   {
    "duration": 449,
    "start_time": "2024-12-31T07:31:03.076Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-31T07:31:05.226Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-31T07:31:06.488Z"
   },
   {
    "duration": 63,
    "start_time": "2024-12-31T07:31:07.673Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-31T07:31:08.306Z"
   },
   {
    "duration": 235,
    "start_time": "2024-12-31T07:31:09.937Z"
   },
   {
    "duration": 486,
    "start_time": "2024-12-31T07:31:11.523Z"
   },
   {
    "duration": 87,
    "start_time": "2024-12-31T07:31:12.596Z"
   },
   {
    "duration": 179,
    "start_time": "2024-12-31T07:31:13.928Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T07:31:15.562Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T07:31:16.870Z"
   },
   {
    "duration": 273,
    "start_time": "2024-12-31T07:31:20.904Z"
   },
   {
    "duration": 308,
    "start_time": "2024-12-31T07:31:41.527Z"
   },
   {
    "duration": 2889,
    "start_time": "2024-12-31T17:15:29.348Z"
   },
   {
    "duration": 535,
    "start_time": "2024-12-31T17:15:32.239Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-31T17:15:32.776Z"
   },
   {
    "duration": 102,
    "start_time": "2024-12-31T17:15:32.802Z"
   },
   {
    "duration": 62,
    "start_time": "2024-12-31T17:15:32.906Z"
   },
   {
    "duration": 38,
    "start_time": "2024-12-31T17:15:32.969Z"
   },
   {
    "duration": 269,
    "start_time": "2024-12-31T17:15:33.009Z"
   },
   {
    "duration": 491,
    "start_time": "2024-12-31T17:15:33.280Z"
   },
   {
    "duration": 101,
    "start_time": "2024-12-31T17:15:33.773Z"
   },
   {
    "duration": 199,
    "start_time": "2024-12-31T17:15:33.877Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-31T17:15:34.077Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T17:15:34.089Z"
   },
   {
    "duration": 1101,
    "start_time": "2024-12-31T17:16:36.481Z"
   },
   {
    "duration": 471,
    "start_time": "2024-12-31T17:16:37.585Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T17:16:38.057Z"
   },
   {
    "duration": 113,
    "start_time": "2024-12-31T17:16:38.074Z"
   },
   {
    "duration": 60,
    "start_time": "2024-12-31T17:16:38.188Z"
   },
   {
    "duration": 40,
    "start_time": "2024-12-31T17:16:38.250Z"
   },
   {
    "duration": 247,
    "start_time": "2024-12-31T17:16:38.292Z"
   },
   {
    "duration": 508,
    "start_time": "2024-12-31T17:16:38.541Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-31T17:16:39.051Z"
   },
   {
    "duration": 182,
    "start_time": "2024-12-31T17:16:39.157Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T17:16:39.341Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T17:16:39.346Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-31T17:16:39.351Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T17:16:39.355Z"
   },
   {
    "duration": 526,
    "start_time": "2024-12-31T17:16:39.359Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.888Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.889Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.890Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.891Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.892Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.892Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.894Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.896Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.898Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.900Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.902Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.903Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.905Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.906Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.908Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.909Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.911Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.912Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.914Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.916Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.917Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.919Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.920Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.922Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.923Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.925Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.927Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.986Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.988Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.989Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.991Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.992Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.994Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.996Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.997Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:16:39.998Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T17:17:12.086Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-31T17:17:13.153Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-31T17:17:23.493Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T17:17:53.490Z"
   },
   {
    "duration": 1076,
    "start_time": "2024-12-31T17:38:00.183Z"
   },
   {
    "duration": 445,
    "start_time": "2024-12-31T17:38:01.263Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-31T17:38:01.709Z"
   },
   {
    "duration": 105,
    "start_time": "2024-12-31T17:38:01.726Z"
   },
   {
    "duration": 70,
    "start_time": "2024-12-31T17:38:01.833Z"
   },
   {
    "duration": 29,
    "start_time": "2024-12-31T17:38:01.905Z"
   },
   {
    "duration": 252,
    "start_time": "2024-12-31T17:38:01.936Z"
   },
   {
    "duration": 506,
    "start_time": "2024-12-31T17:38:02.190Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-31T17:38:02.698Z"
   },
   {
    "duration": 181,
    "start_time": "2024-12-31T17:38:02.796Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-31T17:38:02.979Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T17:38:02.990Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-31T17:38:02.995Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-31T17:38:02.999Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-31T17:38:03.003Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-31T17:38:03.008Z"
   },
   {
    "duration": 82,
    "start_time": "2024-12-31T17:38:03.011Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-31T17:38:03.095Z"
   },
   {
    "duration": 326,
    "start_time": "2024-12-31T17:38:03.123Z"
   },
   {
    "duration": 237,
    "start_time": "2024-12-31T17:38:03.451Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-31T17:38:03.691Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-31T17:38:03.709Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-31T17:38:03.814Z"
   },
   {
    "duration": 1136,
    "start_time": "2024-12-31T17:38:03.824Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.962Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.963Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.965Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.966Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.967Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.968Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.969Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.970Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.973Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.986Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.988Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.990Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.991Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.993Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.994Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.996Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.997Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.998Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:04.999Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:05.000Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:05.002Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:38:05.003Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T17:38:32.017Z"
   },
   {
    "duration": 589,
    "start_time": "2024-12-31T17:38:32.755Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T17:38:38.292Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T17:39:19.682Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-31T17:39:20.283Z"
   },
   {
    "duration": 7828,
    "start_time": "2024-12-31T17:39:23.460Z"
   },
   {
    "duration": 1106,
    "start_time": "2024-12-31T17:40:40.253Z"
   },
   {
    "duration": 425,
    "start_time": "2024-12-31T17:40:41.361Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-31T17:40:41.788Z"
   },
   {
    "duration": 103,
    "start_time": "2024-12-31T17:40:41.804Z"
   },
   {
    "duration": 104,
    "start_time": "2024-12-31T17:40:41.909Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-31T17:40:42.015Z"
   },
   {
    "duration": 262,
    "start_time": "2024-12-31T17:40:42.040Z"
   },
   {
    "duration": 507,
    "start_time": "2024-12-31T17:40:42.304Z"
   },
   {
    "duration": 95,
    "start_time": "2024-12-31T17:40:42.812Z"
   },
   {
    "duration": 191,
    "start_time": "2024-12-31T17:40:42.910Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-31T17:40:43.105Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-31T17:40:43.114Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T17:40:43.121Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T17:40:43.126Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-31T17:40:43.131Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T17:40:43.136Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-31T17:40:43.143Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-31T17:40:43.236Z"
   },
   {
    "duration": 322,
    "start_time": "2024-12-31T17:40:43.260Z"
   },
   {
    "duration": 242,
    "start_time": "2024-12-31T17:40:43.587Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T17:40:43.831Z"
   },
   {
    "duration": 102,
    "start_time": "2024-12-31T17:40:43.848Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T17:40:43.952Z"
   },
   {
    "duration": 585,
    "start_time": "2024-12-31T17:40:43.958Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T17:40:44.545Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-31T17:40:44.553Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-31T17:40:44.570Z"
   },
   {
    "duration": 3208,
    "start_time": "2024-12-31T17:40:44.604Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.814Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.817Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.818Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.820Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.821Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.822Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.824Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.826Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.827Z"
   },
   {
    "duration": 1,
    "start_time": "2024-12-31T17:40:47.828Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.829Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.831Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.832Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.833Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.834Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.835Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.836Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-31T17:40:47.837Z"
   },
   {
    "duration": 32,
    "start_time": "2024-12-31T17:41:29.969Z"
   },
   {
    "duration": 50,
    "start_time": "2024-12-31T17:41:36.507Z"
   },
   {
    "duration": 59,
    "start_time": "2024-12-31T17:41:45.389Z"
   },
   {
    "duration": 1128,
    "start_time": "2024-12-31T17:44:30.643Z"
   },
   {
    "duration": 424,
    "start_time": "2024-12-31T17:44:33.601Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-31T17:44:35.202Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-31T17:44:37.089Z"
   },
   {
    "duration": 60,
    "start_time": "2024-12-31T17:44:39.123Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-31T17:44:39.529Z"
   },
   {
    "duration": 244,
    "start_time": "2024-12-31T17:44:42.649Z"
   },
   {
    "duration": 508,
    "start_time": "2024-12-31T17:44:44.597Z"
   },
   {
    "duration": 87,
    "start_time": "2024-12-31T17:44:47.181Z"
   },
   {
    "duration": 180,
    "start_time": "2024-12-31T17:44:52.346Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T17:44:55.991Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T17:44:56.444Z"
   },
   {
    "duration": 28,
    "start_time": "2024-12-31T17:45:01.243Z"
   },
   {
    "duration": 227,
    "start_time": "2024-12-31T17:45:08.930Z"
   },
   {
    "duration": 81,
    "start_time": "2024-12-31T17:45:22.687Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T17:45:27.205Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-31T17:45:29.080Z"
   },
   {
    "duration": 231,
    "start_time": "2024-12-31T17:45:30.497Z"
   },
   {
    "duration": 2902,
    "start_time": "2024-12-31T17:45:35.181Z"
   },
   {
    "duration": 1089,
    "start_time": "2024-12-31T18:01:13.448Z"
   },
   {
    "duration": 409,
    "start_time": "2024-12-31T18:01:16.096Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-31T18:01:17.669Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-31T18:01:19.130Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-31T18:01:20.860Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-31T18:01:21.593Z"
   },
   {
    "duration": 225,
    "start_time": "2024-12-31T18:01:25.089Z"
   },
   {
    "duration": 512,
    "start_time": "2024-12-31T18:01:33.081Z"
   },
   {
    "duration": 87,
    "start_time": "2024-12-31T18:01:35.567Z"
   },
   {
    "duration": 183,
    "start_time": "2024-12-31T18:01:37.749Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T18:01:39.363Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T18:01:40.896Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-31T18:01:41.567Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-31T18:01:47.904Z"
   },
   {
    "duration": 230,
    "start_time": "2024-12-31T18:01:57.902Z"
   },
   {
    "duration": 48,
    "start_time": "2024-12-31T18:02:00.877Z"
   },
   {
    "duration": 81,
    "start_time": "2024-12-31T18:02:06.537Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T18:02:11.386Z"
   },
   {
    "duration": 3113,
    "start_time": "2024-12-31T18:02:14.361Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-31T18:02:56.383Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T18:02:58.125Z"
   },
   {
    "duration": 574,
    "start_time": "2024-12-31T18:02:58.864Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-31T18:03:04.883Z"
   },
   {
    "duration": 2944,
    "start_time": "2024-12-31T18:03:08.578Z"
   },
   {
    "duration": 3012,
    "start_time": "2024-12-31T18:03:45.542Z"
   },
   {
    "duration": 1115,
    "start_time": "2024-12-31T18:35:45.880Z"
   },
   {
    "duration": 417,
    "start_time": "2024-12-31T18:35:49.902Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-31T18:35:51.731Z"
   },
   {
    "duration": 91,
    "start_time": "2024-12-31T18:35:54.064Z"
   },
   {
    "duration": 61,
    "start_time": "2024-12-31T18:35:56.612Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-31T18:35:57.055Z"
   },
   {
    "duration": 232,
    "start_time": "2024-12-31T18:35:59.398Z"
   },
   {
    "duration": 480,
    "start_time": "2024-12-31T18:36:01.480Z"
   },
   {
    "duration": 90,
    "start_time": "2024-12-31T18:36:04.304Z"
   },
   {
    "duration": 188,
    "start_time": "2024-12-31T18:36:06.911Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-31T18:39:13.488Z"
   },
   {
    "duration": 251,
    "start_time": "2024-12-31T18:39:33.037Z"
   },
   {
    "duration": 55,
    "start_time": "2024-12-31T18:39:33.846Z"
   },
   {
    "duration": 80,
    "start_time": "2024-12-31T18:39:35.876Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-31T18:39:37.597Z"
   },
   {
    "duration": 590,
    "start_time": "2024-12-31T18:39:38.160Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-31T18:39:42.579Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-31T18:39:43.369Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-31T18:39:43.876Z"
   },
   {
    "duration": 44914,
    "start_time": "2024-12-31T18:39:46.889Z"
   },
   {
    "duration": 1516821,
    "start_time": "2024-12-31T18:44:52.569Z"
   },
   {
    "duration": 42,
    "start_time": "2024-12-31T19:12:21.907Z"
   },
   {
    "duration": 4622055,
    "start_time": "2024-12-31T19:12:24.647Z"
   },
   {
    "duration": 18869002,
    "start_time": "2024-12-31T20:32:56.620Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-01T01:47:25.626Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-01T01:47:33.291Z"
   },
   {
    "duration": 4779172,
    "start_time": "2025-01-01T01:47:41.487Z"
   },
   {
    "duration": 3018,
    "start_time": "2025-01-01T04:05:18.725Z"
   },
   {
    "duration": 1105,
    "start_time": "2025-01-01T04:06:14.720Z"
   },
   {
    "duration": 412,
    "start_time": "2025-01-01T04:06:17.032Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-01T04:06:18.859Z"
   },
   {
    "duration": 93,
    "start_time": "2025-01-01T04:06:20.036Z"
   },
   {
    "duration": 61,
    "start_time": "2025-01-01T04:06:21.415Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-01T04:06:21.986Z"
   },
   {
    "duration": 237,
    "start_time": "2025-01-01T04:06:23.917Z"
   },
   {
    "duration": 482,
    "start_time": "2025-01-01T04:06:25.355Z"
   },
   {
    "duration": 85,
    "start_time": "2025-01-01T04:06:26.931Z"
   },
   {
    "duration": 175,
    "start_time": "2025-01-01T04:06:29.228Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-01T04:06:36.056Z"
   },
   {
    "duration": 228,
    "start_time": "2025-01-01T04:07:10.378Z"
   },
   {
    "duration": 47,
    "start_time": "2025-01-01T04:07:24.831Z"
   },
   {
    "duration": 80,
    "start_time": "2025-01-01T04:07:26.523Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-01T04:07:28.210Z"
   },
   {
    "duration": 573,
    "start_time": "2025-01-01T04:07:30.469Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-01T04:07:34.590Z"
   },
   {
    "duration": 3463,
    "start_time": "2025-01-01T04:07:43.804Z"
   },
   {
    "duration": 240,
    "start_time": "2025-01-01T04:14:39.825Z"
   },
   {
    "duration": 77,
    "start_time": "2025-01-01T04:14:53.970Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-01T04:14:54.647Z"
   },
   {
    "duration": 555,
    "start_time": "2025-01-01T04:14:55.518Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-01T04:14:59.118Z"
   },
   {
    "duration": 3000,
    "start_time": "2025-01-01T04:15:03.780Z"
   },
   {
    "duration": 8127,
    "start_time": "2025-01-01T04:15:43.438Z"
   },
   {
    "duration": 26408,
    "start_time": "2025-01-01T04:16:10.481Z"
   },
   {
    "duration": 239,
    "start_time": "2025-01-01T04:17:23.263Z"
   },
   {
    "duration": 223,
    "start_time": "2025-01-01T04:17:39.695Z"
   },
   {
    "duration": 95,
    "start_time": "2025-01-01T04:17:53.147Z"
   },
   {
    "duration": 558,
    "start_time": "2025-01-01T04:18:17.255Z"
   },
   {
    "duration": 1448435,
    "start_time": "2025-01-01T04:18:27.477Z"
   },
   {
    "duration": 43793,
    "start_time": "2025-01-01T04:43:02.815Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-01T04:45:38.226Z"
   },
   {
    "duration": 21,
    "start_time": "2025-01-01T04:46:20.989Z"
   },
   {
    "duration": 1319914,
    "start_time": "2025-01-01T04:46:30.991Z"
   },
   {
    "duration": 21,
    "start_time": "2025-01-01T05:34:46.448Z"
   },
   {
    "duration": 39,
    "start_time": "2025-01-01T05:35:43.723Z"
   },
   {
    "duration": 56546015,
    "start_time": "2025-01-01T05:35:50.661Z"
   },
   {
    "duration": 1115,
    "start_time": "2025-01-02T02:16:21.218Z"
   },
   {
    "duration": 471,
    "start_time": "2025-01-02T02:16:22.784Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-02T02:16:24.285Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-02T02:16:26.219Z"
   },
   {
    "duration": 57,
    "start_time": "2025-01-02T02:16:27.249Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-02T02:16:27.812Z"
   },
   {
    "duration": 237,
    "start_time": "2025-01-02T02:16:29.468Z"
   },
   {
    "duration": 480,
    "start_time": "2025-01-02T02:16:30.756Z"
   },
   {
    "duration": 88,
    "start_time": "2025-01-02T02:16:31.881Z"
   },
   {
    "duration": 181,
    "start_time": "2025-01-02T02:16:33.216Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-02T02:16:38.630Z"
   },
   {
    "duration": 230,
    "start_time": "2025-01-02T02:16:42.535Z"
   },
   {
    "duration": 76,
    "start_time": "2025-01-02T02:16:48.961Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-02T02:16:53.909Z"
   },
   {
    "duration": 581,
    "start_time": "2025-01-02T02:16:54.637Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-02T02:17:00.541Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-02T02:17:10.613Z"
   },
   {
    "duration": 2844,
    "start_time": "2025-01-02T06:30:49.818Z"
   },
   {
    "duration": 467,
    "start_time": "2025-01-02T06:30:55.566Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-02T06:30:58.358Z"
   },
   {
    "duration": 104,
    "start_time": "2025-01-02T06:31:03.014Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-02T06:31:07.307Z"
   },
   {
    "duration": 237,
    "start_time": "2025-01-02T06:31:09.081Z"
   },
   {
    "duration": 492,
    "start_time": "2025-01-02T06:31:10.988Z"
   },
   {
    "duration": 87,
    "start_time": "2025-01-02T06:31:12.920Z"
   },
   {
    "duration": 179,
    "start_time": "2025-01-02T06:31:15.319Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-02T06:31:19.774Z"
   },
   {
    "duration": 217,
    "start_time": "2025-01-02T06:31:23.101Z"
   },
   {
    "duration": 47,
    "start_time": "2025-01-02T06:31:28.089Z"
   },
   {
    "duration": 78,
    "start_time": "2025-01-02T06:31:30.039Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-02T06:31:30.939Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-02T06:31:33.290Z"
   },
   {
    "duration": 12188693,
    "start_time": "2025-01-02T06:31:45.044Z"
   },
   {
    "duration": 284,
    "start_time": "2025-01-02T16:55:28.432Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-02T16:55:40.787Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-02T16:58:11.788Z"
   },
   {
    "duration": 119,
    "start_time": "2025-01-02T16:59:02.981Z"
   },
   {
    "duration": 82,
    "start_time": "2025-01-02T16:59:25.959Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T16:59:30.124Z"
   },
   {
    "duration": 17375,
    "start_time": "2025-01-02T16:59:34.237Z"
   },
   {
    "duration": 266,
    "start_time": "2025-01-02T17:02:18.470Z"
   },
   {
    "duration": 1634,
    "start_time": "2025-01-02T17:03:07.302Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-02T17:07:50.202Z"
   },
   {
    "duration": 51,
    "start_time": "2025-01-02T17:08:21.704Z"
   },
   {
    "duration": 1203,
    "start_time": "2025-01-02T17:10:09.344Z"
   },
   {
    "duration": 41,
    "start_time": "2025-01-02T17:18:34.925Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-02T17:19:05.714Z"
   },
   {
    "duration": 1118,
    "start_time": "2025-01-02T17:19:42.488Z"
   },
   {
    "duration": 1105,
    "start_time": "2025-01-02T17:51:02.979Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-02T17:51:18.707Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T17:51:19.608Z"
   },
   {
    "duration": 16893,
    "start_time": "2025-01-02T17:51:20.225Z"
   },
   {
    "duration": 1082,
    "start_time": "2025-01-02T17:52:04.978Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-02T18:27:26.092Z"
   },
   {
    "duration": 3726,
    "start_time": "2025-01-02T18:27:43.084Z"
   },
   {
    "duration": 190,
    "start_time": "2025-01-02T18:30:28.666Z"
   },
   {
    "duration": 124,
    "start_time": "2025-01-02T18:31:21.371Z"
   },
   {
    "duration": 176,
    "start_time": "2025-01-02T18:31:35.299Z"
   },
   {
    "duration": 1109,
    "start_time": "2025-01-02T18:32:52.640Z"
   },
   {
    "duration": 408,
    "start_time": "2025-01-02T18:32:53.751Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-02T18:32:54.161Z"
   },
   {
    "duration": 100,
    "start_time": "2025-01-02T18:32:54.177Z"
   },
   {
    "duration": 70,
    "start_time": "2025-01-02T18:32:54.279Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-02T18:32:54.350Z"
   },
   {
    "duration": 249,
    "start_time": "2025-01-02T18:32:54.376Z"
   },
   {
    "duration": 470,
    "start_time": "2025-01-02T18:32:54.626Z"
   },
   {
    "duration": 92,
    "start_time": "2025-01-02T18:32:55.099Z"
   },
   {
    "duration": 186,
    "start_time": "2025-01-02T18:32:55.194Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T18:32:55.382Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T18:32:55.386Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-02T18:32:55.390Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T18:32:55.407Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T18:32:55.410Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T18:32:55.414Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T18:32:55.420Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-02T18:32:55.425Z"
   },
   {
    "duration": 49,
    "start_time": "2025-01-02T18:32:55.464Z"
   },
   {
    "duration": 268,
    "start_time": "2025-01-02T18:32:55.515Z"
   },
   {
    "duration": 223,
    "start_time": "2025-01-02T18:32:55.785Z"
   },
   {
    "duration": 48,
    "start_time": "2025-01-02T18:32:56.009Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-02T18:32:56.059Z"
   },
   {
    "duration": 100,
    "start_time": "2025-01-02T18:32:56.070Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-02T18:32:56.172Z"
   },
   {
    "duration": 134,
    "start_time": "2025-01-02T18:32:56.177Z"
   },
   {
    "duration": 587,
    "start_time": "2025-01-02T18:32:56.312Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-02T18:32:56.907Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-02T18:32:56.915Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-02T18:32:56.930Z"
   },
   {
    "duration": 42792,
    "start_time": "2025-01-02T18:32:56.947Z"
   },
   {
    "duration": 8603,
    "start_time": "2025-01-02T18:33:39.806Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.411Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.413Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.414Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.415Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.416Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.417Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.418Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.419Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.419Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.420Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.421Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.422Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.423Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.423Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.424Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.425Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-02T18:33:48.426Z"
   },
   {
    "duration": 470,
    "start_time": "2025-01-02T18:34:33.949Z"
   },
   {
    "duration": 262,
    "start_time": "2025-01-02T18:35:11.185Z"
   },
   {
    "duration": 3705,
    "start_time": "2025-01-02T18:35:34.221Z"
   },
   {
    "duration": 3710,
    "start_time": "2025-01-02T18:36:33.113Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-02T19:04:17.834Z"
   },
   {
    "duration": 19281,
    "start_time": "2025-01-02T19:05:30.035Z"
   },
   {
    "duration": 41646,
    "start_time": "2025-01-02T19:08:12.571Z"
   },
   {
    "duration": 743780,
    "start_time": "2025-01-02T19:18:30.341Z"
   },
   {
    "duration": 44913,
    "start_time": "2025-01-02T19:34:49.407Z"
   },
   {
    "duration": 683785,
    "start_time": "2025-01-02T19:35:51.680Z"
   },
   {
    "duration": 109916,
    "start_time": "2025-01-02T20:04:07.880Z"
   },
   {
    "duration": 5362962,
    "start_time": "2025-01-02T20:06:06.038Z"
   },
   {
    "duration": 301,
    "start_time": "2025-01-02T21:57:13.639Z"
   },
   {
    "duration": 417201,
    "start_time": "2025-01-02T21:59:11.255Z"
   },
   {
    "duration": 2767,
    "start_time": "2025-01-02T23:34:32.179Z"
   },
   {
    "duration": 286,
    "start_time": "2025-01-02T23:41:38.582Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T23:41:47.537Z"
   },
   {
    "duration": 447,
    "start_time": "2025-01-02T23:41:48.974Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-02T23:41:50.690Z"
   },
   {
    "duration": 96,
    "start_time": "2025-01-02T23:41:51.532Z"
   },
   {
    "duration": 63,
    "start_time": "2025-01-02T23:41:52.364Z"
   },
   {
    "duration": 28,
    "start_time": "2025-01-02T23:41:52.814Z"
   },
   {
    "duration": 256,
    "start_time": "2025-01-02T23:41:54.020Z"
   },
   {
    "duration": 468,
    "start_time": "2025-01-02T23:41:54.879Z"
   },
   {
    "duration": 88,
    "start_time": "2025-01-02T23:41:55.751Z"
   },
   {
    "duration": 178,
    "start_time": "2025-01-02T23:41:56.728Z"
   },
   {
    "duration": 28,
    "start_time": "2025-01-02T23:42:02.393Z"
   },
   {
    "duration": 219,
    "start_time": "2025-01-02T23:42:07.124Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-02T23:42:13.116Z"
   },
   {
    "duration": 73,
    "start_time": "2025-01-02T23:42:13.509Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-02T23:42:14.774Z"
   },
   {
    "duration": 183,
    "start_time": "2025-01-02T23:42:15.871Z"
   },
   {
    "duration": 567,
    "start_time": "2025-01-02T23:42:17.925Z"
   },
   {
    "duration": 1096,
    "start_time": "2025-01-02T23:42:45.495Z"
   },
   {
    "duration": 451,
    "start_time": "2025-01-02T23:42:46.593Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-02T23:42:47.046Z"
   },
   {
    "duration": 103,
    "start_time": "2025-01-02T23:42:47.061Z"
   },
   {
    "duration": 65,
    "start_time": "2025-01-02T23:42:47.166Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-02T23:42:47.232Z"
   },
   {
    "duration": 235,
    "start_time": "2025-01-02T23:42:47.257Z"
   },
   {
    "duration": 462,
    "start_time": "2025-01-02T23:42:47.494Z"
   },
   {
    "duration": 111,
    "start_time": "2025-01-02T23:42:47.958Z"
   },
   {
    "duration": 181,
    "start_time": "2025-01-02T23:42:48.072Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T23:42:48.254Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T23:42:48.258Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:42:48.263Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:42:48.267Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:42:48.271Z"
   },
   {
    "duration": 31,
    "start_time": "2025-01-02T23:42:48.275Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T23:42:48.307Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-02T23:42:48.312Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-02T23:42:48.351Z"
   },
   {
    "duration": 291,
    "start_time": "2025-01-02T23:42:48.371Z"
   },
   {
    "duration": 215,
    "start_time": "2025-01-02T23:42:48.664Z"
   },
   {
    "duration": 55,
    "start_time": "2025-01-02T23:42:48.880Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-02T23:42:48.938Z"
   },
   {
    "duration": 84,
    "start_time": "2025-01-02T23:42:48.948Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-02T23:42:49.033Z"
   },
   {
    "duration": 129,
    "start_time": "2025-01-02T23:42:49.039Z"
   },
   {
    "duration": 572,
    "start_time": "2025-01-02T23:42:49.171Z"
   },
   {
    "duration": 1121,
    "start_time": "2025-01-02T23:47:30.037Z"
   },
   {
    "duration": 460,
    "start_time": "2025-01-02T23:47:31.160Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-02T23:47:31.623Z"
   },
   {
    "duration": 104,
    "start_time": "2025-01-02T23:47:31.640Z"
   },
   {
    "duration": 63,
    "start_time": "2025-01-02T23:47:31.746Z"
   },
   {
    "duration": 22,
    "start_time": "2025-01-02T23:47:31.812Z"
   },
   {
    "duration": 237,
    "start_time": "2025-01-02T23:47:31.836Z"
   },
   {
    "duration": 480,
    "start_time": "2025-01-02T23:47:32.075Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-02T23:47:32.557Z"
   },
   {
    "duration": 187,
    "start_time": "2025-01-02T23:47:32.652Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:47:32.840Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T23:47:32.844Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:47:32.849Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:47:32.853Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:47:32.857Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:47:32.861Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-02T23:47:32.865Z"
   },
   {
    "duration": 58,
    "start_time": "2025-01-02T23:47:32.869Z"
   },
   {
    "duration": 288,
    "start_time": "2025-01-02T23:47:32.929Z"
   },
   {
    "duration": 224,
    "start_time": "2025-01-02T23:47:33.219Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-02T23:47:33.445Z"
   },
   {
    "duration": 88,
    "start_time": "2025-01-02T23:47:33.455Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-02T23:47:33.546Z"
   },
   {
    "duration": 129,
    "start_time": "2025-01-02T23:47:33.551Z"
   },
   {
    "duration": 573,
    "start_time": "2025-01-02T23:47:33.682Z"
   },
   {
    "duration": 1100,
    "start_time": "2025-01-03T00:04:56.132Z"
   },
   {
    "duration": 450,
    "start_time": "2025-01-03T00:04:57.234Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-03T00:04:57.686Z"
   },
   {
    "duration": 101,
    "start_time": "2025-01-03T00:04:57.706Z"
   },
   {
    "duration": 61,
    "start_time": "2025-01-03T00:04:57.808Z"
   },
   {
    "duration": 41,
    "start_time": "2025-01-03T00:04:57.871Z"
   },
   {
    "duration": 230,
    "start_time": "2025-01-03T00:04:57.913Z"
   },
   {
    "duration": 491,
    "start_time": "2025-01-03T00:04:58.144Z"
   },
   {
    "duration": 95,
    "start_time": "2025-01-03T00:04:58.636Z"
   },
   {
    "duration": 189,
    "start_time": "2025-01-03T00:04:58.733Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T00:04:58.924Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T00:04:58.928Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T00:04:58.931Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T00:04:58.936Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T00:04:58.940Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T00:04:58.944Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T00:04:58.948Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-03T00:04:58.952Z"
   },
   {
    "duration": 269,
    "start_time": "2025-01-03T00:04:59.006Z"
   },
   {
    "duration": 214,
    "start_time": "2025-01-03T00:04:59.276Z"
   },
   {
    "duration": 20,
    "start_time": "2025-01-03T00:04:59.491Z"
   },
   {
    "duration": 75,
    "start_time": "2025-01-03T00:04:59.513Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-03T00:04:59.591Z"
   },
   {
    "duration": 142,
    "start_time": "2025-01-03T00:04:59.608Z"
   },
   {
    "duration": 568,
    "start_time": "2025-01-03T00:04:59.751Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-03T00:05:00.321Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-03T00:05:00.329Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-03T00:05:00.343Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-03T00:05:00.359Z"
   },
   {
    "duration": 43244,
    "start_time": "2025-01-03T00:05:00.375Z"
   },
   {
    "duration": 64400,
    "start_time": "2025-01-03T00:05:43.621Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.023Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.024Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.024Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.026Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.027Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.028Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.029Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.030Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.031Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.032Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.033Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T00:06:48.034Z"
   },
   {
    "duration": 180,
    "start_time": "2025-01-03T00:16:00.722Z"
   },
   {
    "duration": 168,
    "start_time": "2025-01-03T00:17:46.019Z"
   },
   {
    "duration": 1727378,
    "start_time": "2025-01-03T00:18:06.661Z"
   },
   {
    "duration": 5413,
    "start_time": "2025-01-03T03:53:16.515Z"
   },
   {
    "duration": 114,
    "start_time": "2025-01-03T03:53:37.606Z"
   },
   {
    "duration": 706,
    "start_time": "2025-01-03T03:53:46.507Z"
   },
   {
    "duration": 1811,
    "start_time": "2025-01-03T03:53:49.707Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-03T03:53:52.606Z"
   },
   {
    "duration": 328,
    "start_time": "2025-01-03T03:53:55.306Z"
   },
   {
    "duration": 210,
    "start_time": "2025-01-03T03:53:57.506Z"
   },
   {
    "duration": 96,
    "start_time": "2025-01-03T03:53:58.525Z"
   },
   {
    "duration": 902,
    "start_time": "2025-01-03T03:54:00.608Z"
   },
   {
    "duration": 2104,
    "start_time": "2025-01-03T03:54:02.506Z"
   },
   {
    "duration": 323,
    "start_time": "2025-01-03T03:54:05.906Z"
   },
   {
    "duration": 717,
    "start_time": "2025-01-03T03:54:08.020Z"
   },
   {
    "duration": 104,
    "start_time": "2025-01-03T03:54:17.213Z"
   },
   {
    "duration": 1015,
    "start_time": "2025-01-03T03:54:21.629Z"
   },
   {
    "duration": 20,
    "start_time": "2025-01-03T03:54:25.006Z"
   },
   {
    "duration": 294,
    "start_time": "2025-01-03T03:54:25.610Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-03T03:54:26.406Z"
   },
   {
    "duration": 430,
    "start_time": "2025-01-03T03:54:27.006Z"
   },
   {
    "duration": 2523,
    "start_time": "2025-01-03T03:54:27.605Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-03T03:54:30.210Z"
   },
   {
    "duration": 388,
    "start_time": "2025-01-03T03:54:30.224Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-03T03:54:30.706Z"
   },
   {
    "duration": 795,
    "start_time": "2025-01-03T03:54:42.033Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-03T04:24:08.025Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-03T04:24:44.139Z"
   },
   {
    "duration": 1141,
    "start_time": "2025-01-03T04:40:40.017Z"
   },
   {
    "duration": 1033,
    "start_time": "2025-01-03T04:58:15.106Z"
   },
   {
    "duration": 435,
    "start_time": "2025-01-03T04:58:16.141Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-03T04:58:16.578Z"
   },
   {
    "duration": 99,
    "start_time": "2025-01-03T04:58:16.592Z"
   },
   {
    "duration": 66,
    "start_time": "2025-01-03T04:58:16.694Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-03T04:58:16.761Z"
   },
   {
    "duration": 238,
    "start_time": "2025-01-03T04:58:16.807Z"
   },
   {
    "duration": 475,
    "start_time": "2025-01-03T04:58:17.047Z"
   },
   {
    "duration": 92,
    "start_time": "2025-01-03T04:58:17.523Z"
   },
   {
    "duration": 181,
    "start_time": "2025-01-03T04:58:17.617Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-03T04:58:17.800Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T04:58:17.808Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T04:58:17.814Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T04:58:17.820Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T04:58:17.825Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T04:58:17.829Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T04:58:17.833Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-03T04:58:17.838Z"
   },
   {
    "duration": 304,
    "start_time": "2025-01-03T04:58:17.859Z"
   },
   {
    "duration": 228,
    "start_time": "2025-01-03T04:58:18.164Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-03T04:58:18.394Z"
   },
   {
    "duration": 74,
    "start_time": "2025-01-03T04:58:18.412Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-03T04:58:18.488Z"
   },
   {
    "duration": 234,
    "start_time": "2025-01-03T04:58:18.505Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.740Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.742Z"
   },
   {
    "duration": 1,
    "start_time": "2025-01-03T04:58:18.742Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.744Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.745Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.746Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.747Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.748Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.749Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.750Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.751Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.751Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.752Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.754Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.755Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.756Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.757Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T04:58:18.758Z"
   },
   {
    "duration": 411,
    "start_time": "2025-01-03T04:58:29.566Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-03T04:59:01.712Z"
   },
   {
    "duration": 132,
    "start_time": "2025-01-03T04:59:09.700Z"
   },
   {
    "duration": 577,
    "start_time": "2025-01-03T04:59:13.967Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-03T04:59:16.146Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-03T04:59:16.830Z"
   },
   {
    "duration": 7482,
    "start_time": "2025-01-03T04:59:17.825Z"
   },
   {
    "duration": 42845,
    "start_time": "2025-01-03T04:59:30.068Z"
   },
   {
    "duration": 492193,
    "start_time": "2025-01-03T05:00:58.263Z"
   },
   {
    "duration": 1114,
    "start_time": "2025-01-03T05:09:59.353Z"
   },
   {
    "duration": 472,
    "start_time": "2025-01-03T05:10:00.470Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-03T05:10:00.944Z"
   },
   {
    "duration": 99,
    "start_time": "2025-01-03T05:10:00.959Z"
   },
   {
    "duration": 68,
    "start_time": "2025-01-03T05:10:01.061Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-03T05:10:01.131Z"
   },
   {
    "duration": 271,
    "start_time": "2025-01-03T05:10:01.156Z"
   },
   {
    "duration": 490,
    "start_time": "2025-01-03T05:10:01.428Z"
   },
   {
    "duration": 92,
    "start_time": "2025-01-03T05:10:01.919Z"
   },
   {
    "duration": 184,
    "start_time": "2025-01-03T05:10:02.013Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T05:10:02.204Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T05:10:02.209Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T05:10:02.213Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T05:10:02.219Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T05:10:02.223Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T05:10:02.227Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-03T05:10:02.231Z"
   },
   {
    "duration": 30,
    "start_time": "2025-01-03T05:10:02.236Z"
   },
   {
    "duration": 315,
    "start_time": "2025-01-03T05:10:02.268Z"
   },
   {
    "duration": 223,
    "start_time": "2025-01-03T05:10:02.585Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-03T05:10:02.809Z"
   },
   {
    "duration": 90,
    "start_time": "2025-01-03T05:10:02.822Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T05:10:02.914Z"
   },
   {
    "duration": 137,
    "start_time": "2025-01-03T05:10:02.919Z"
   },
   {
    "duration": 587,
    "start_time": "2025-01-03T05:10:03.057Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-03T05:10:03.646Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-03T05:10:03.654Z"
   },
   {
    "duration": 43076,
    "start_time": "2025-01-03T05:10:03.664Z"
   },
   {
    "duration": 1387274,
    "start_time": "2025-01-03T05:10:46.742Z"
   },
   {
    "duration": 40,
    "start_time": "2025-01-03T05:33:54.018Z"
   },
   {
    "duration": 150483,
    "start_time": "2025-01-03T05:33:54.060Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.546Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.547Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.549Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.550Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.552Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.553Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.555Z"
   },
   {
    "duration": 1,
    "start_time": "2025-01-03T05:36:24.556Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.558Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.559Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T05:36:24.560Z"
   },
   {
    "duration": 8306,
    "start_time": "2025-01-03T05:36:42.283Z"
   },
   {
    "duration": 20302,
    "start_time": "2025-01-03T05:36:55.828Z"
   },
   {
    "duration": 45588,
    "start_time": "2025-01-03T05:37:49.917Z"
   },
   {
    "duration": 343114,
    "start_time": "2025-01-03T05:50:00.051Z"
   },
   {
    "duration": 371812,
    "start_time": "2025-01-03T05:56:58.235Z"
   },
   {
    "duration": 371545,
    "start_time": "2025-01-03T06:04:13.335Z"
   },
   {
    "duration": 6340,
    "start_time": "2025-01-03T06:13:57.602Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-03T06:16:22.758Z"
   },
   {
    "duration": 62,
    "start_time": "2025-01-03T06:16:30.729Z"
   },
   {
    "duration": 63498,
    "start_time": "2025-01-03T06:16:50.041Z"
   },
   {
    "duration": 1149,
    "start_time": "2025-01-03T06:20:44.167Z"
   },
   {
    "duration": 500,
    "start_time": "2025-01-03T06:20:45.319Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-03T06:20:45.822Z"
   },
   {
    "duration": 111,
    "start_time": "2025-01-03T06:20:45.838Z"
   },
   {
    "duration": 82,
    "start_time": "2025-01-03T06:20:45.952Z"
   },
   {
    "duration": 30,
    "start_time": "2025-01-03T06:20:46.037Z"
   },
   {
    "duration": 286,
    "start_time": "2025-01-03T06:20:46.069Z"
   },
   {
    "duration": 519,
    "start_time": "2025-01-03T06:20:46.357Z"
   },
   {
    "duration": 94,
    "start_time": "2025-01-03T06:20:46.878Z"
   },
   {
    "duration": 181,
    "start_time": "2025-01-03T06:20:46.976Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T06:20:47.159Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T06:20:47.163Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T06:20:47.168Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T06:20:47.174Z"
   },
   {
    "duration": 27,
    "start_time": "2025-01-03T06:20:47.179Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T06:20:47.208Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-03T06:20:47.213Z"
   },
   {
    "duration": 22,
    "start_time": "2025-01-03T06:20:47.217Z"
   },
   {
    "duration": 301,
    "start_time": "2025-01-03T06:20:47.241Z"
   },
   {
    "duration": 247,
    "start_time": "2025-01-03T06:20:47.544Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-03T06:20:47.793Z"
   },
   {
    "duration": 101,
    "start_time": "2025-01-03T06:20:47.808Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-03T06:20:47.911Z"
   },
   {
    "duration": 146,
    "start_time": "2025-01-03T06:20:47.918Z"
   },
   {
    "duration": 614,
    "start_time": "2025-01-03T06:20:48.067Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-03T06:20:48.683Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-03T06:20:48.691Z"
   },
   {
    "duration": 49718,
    "start_time": "2025-01-03T06:20:48.713Z"
   },
   {
    "duration": 65108,
    "start_time": "2025-01-03T06:21:38.435Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.545Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.546Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.547Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.549Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.550Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.552Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.553Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.554Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.555Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.557Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.558Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.559Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-03T06:22:43.560Z"
   },
   {
    "duration": 2487760,
    "start_time": "2025-01-03T06:22:53.553Z"
   },
   {
    "duration": 2677,
    "start_time": "2025-01-03T16:44:42.951Z"
   },
   {
    "duration": 518,
    "start_time": "2025-01-03T16:44:48.964Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-03T16:44:50.671Z"
   },
   {
    "duration": 101,
    "start_time": "2025-01-03T16:44:51.686Z"
   },
   {
    "duration": 60,
    "start_time": "2025-01-03T16:44:52.536Z"
   },
   {
    "duration": 26,
    "start_time": "2025-01-03T16:44:52.966Z"
   },
   {
    "duration": 231,
    "start_time": "2025-01-03T16:44:54.199Z"
   },
   {
    "duration": 481,
    "start_time": "2025-01-03T16:44:55.130Z"
   },
   {
    "duration": 88,
    "start_time": "2025-01-03T16:44:56.003Z"
   },
   {
    "duration": 170,
    "start_time": "2025-01-03T16:44:57.163Z"
   },
   {
    "duration": 27,
    "start_time": "2025-01-03T16:45:03.684Z"
   },
   {
    "duration": 218,
    "start_time": "2025-01-03T16:45:09.532Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-03T16:45:13.363Z"
   },
   {
    "duration": 76,
    "start_time": "2025-01-03T16:45:15.411Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-03T16:45:17.526Z"
   },
   {
    "duration": 127,
    "start_time": "2025-01-03T16:45:18.378Z"
   },
   {
    "duration": 579,
    "start_time": "2025-01-03T16:45:18.982Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-03T16:45:21.610Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-03T16:45:22.396Z"
   },
   {
    "duration": 1717591,
    "start_time": "2025-01-03T16:46:18.350Z"
   },
   {
    "duration": 1450042,
    "start_time": "2025-01-03T17:15:30.717Z"
   },
   {
    "duration": 1411528,
    "start_time": "2025-01-03T17:40:49.386Z"
   },
   {
    "duration": 20078,
    "start_time": "2025-01-03T18:10:11.618Z"
   },
   {
    "duration": 46033,
    "start_time": "2025-01-03T18:10:46.188Z"
   },
   {
    "duration": 685378,
    "start_time": "2025-01-03T18:12:06.002Z"
   },
   {
    "duration": 413224,
    "start_time": "2025-01-03T18:23:49.167Z"
   },
   {
    "duration": 1328851,
    "start_time": "2025-01-03T18:34:59.451Z"
   },
   {
    "duration": 14167130,
    "start_time": "2025-01-03T18:58:20.185Z"
   },
   {
    "duration": 26130,
    "start_time": "2025-01-03T23:36:59.445Z"
   },
   {
    "duration": 1719442,
    "start_time": "2025-01-03T23:37:52.978Z"
   },
   {
    "duration": 1120,
    "start_time": "2025-01-04T00:39:27.104Z"
   },
   {
    "duration": 480,
    "start_time": "2025-01-04T00:39:28.226Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-04T00:39:28.707Z"
   },
   {
    "duration": 100,
    "start_time": "2025-01-04T00:39:28.724Z"
   },
   {
    "duration": 69,
    "start_time": "2025-01-04T00:39:28.826Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-04T00:39:28.897Z"
   },
   {
    "duration": 235,
    "start_time": "2025-01-04T00:39:28.923Z"
   },
   {
    "duration": 478,
    "start_time": "2025-01-04T00:39:29.160Z"
   },
   {
    "duration": 94,
    "start_time": "2025-01-04T00:39:29.640Z"
   },
   {
    "duration": 180,
    "start_time": "2025-01-04T00:39:29.737Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-04T00:39:29.919Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-04T00:39:29.923Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-04T00:39:29.928Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-04T00:39:29.932Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-04T00:39:29.936Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-04T00:39:29.942Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-04T00:39:29.947Z"
   },
   {
    "duration": 56,
    "start_time": "2025-01-04T00:39:29.950Z"
   },
   {
    "duration": 283,
    "start_time": "2025-01-04T00:39:30.008Z"
   },
   {
    "duration": 226,
    "start_time": "2025-01-04T00:39:30.292Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-04T00:39:30.522Z"
   },
   {
    "duration": 85,
    "start_time": "2025-01-04T00:39:30.532Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-04T00:39:30.619Z"
   },
   {
    "duration": 140,
    "start_time": "2025-01-04T00:39:30.624Z"
   },
   {
    "duration": 591,
    "start_time": "2025-01-04T00:39:30.766Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-04T00:39:31.360Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-04T00:39:31.370Z"
   },
   {
    "duration": 7803,
    "start_time": "2025-01-04T00:39:31.398Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.205Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.206Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.210Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.211Z"
   },
   {
    "duration": 1,
    "start_time": "2025-01-04T00:39:39.212Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.214Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.215Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.215Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.217Z"
   },
   {
    "duration": 1,
    "start_time": "2025-01-04T00:39:39.217Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.218Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.219Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.220Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T00:39:39.221Z"
   },
   {
    "duration": 22,
    "start_time": "2025-01-04T00:40:02.227Z"
   },
   {
    "duration": 19725,
    "start_time": "2025-01-04T00:40:41.582Z"
   },
   {
    "duration": 359195,
    "start_time": "2025-01-04T00:41:32.698Z"
   },
   {
    "duration": 1134,
    "start_time": "2025-01-04T01:23:21.600Z"
   },
   {
    "duration": 488,
    "start_time": "2025-01-04T01:23:22.737Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-04T01:23:23.227Z"
   },
   {
    "duration": 104,
    "start_time": "2025-01-04T01:23:23.243Z"
   },
   {
    "duration": 102,
    "start_time": "2025-01-04T01:23:23.349Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-04T01:23:23.453Z"
   },
   {
    "duration": 258,
    "start_time": "2025-01-04T01:23:23.489Z"
   },
   {
    "duration": 509,
    "start_time": "2025-01-04T01:23:23.749Z"
   },
   {
    "duration": 93,
    "start_time": "2025-01-04T01:23:24.260Z"
   },
   {
    "duration": 184,
    "start_time": "2025-01-04T01:23:24.355Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-04T01:23:24.541Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-04T01:23:24.546Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-04T01:23:24.551Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-04T01:23:24.557Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-04T01:23:24.561Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-04T01:23:24.565Z"
   },
   {
    "duration": 2,
    "start_time": "2025-01-04T01:23:24.591Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-04T01:23:24.595Z"
   },
   {
    "duration": 292,
    "start_time": "2025-01-04T01:23:24.622Z"
   },
   {
    "duration": 239,
    "start_time": "2025-01-04T01:23:24.916Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-04T01:23:25.157Z"
   },
   {
    "duration": 93,
    "start_time": "2025-01-04T01:23:25.167Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-04T01:23:25.262Z"
   },
   {
    "duration": 132,
    "start_time": "2025-01-04T01:23:25.269Z"
   },
   {
    "duration": 591,
    "start_time": "2025-01-04T01:23:25.403Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-04T01:23:25.996Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-04T01:23:26.006Z"
   },
   {
    "duration": 15322,
    "start_time": "2025-01-04T01:23:26.018Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.342Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.343Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.345Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.346Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.347Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.348Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.349Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.350Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.351Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.352Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.353Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.354Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.355Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-04T01:23:41.386Z"
   },
   {
    "duration": 43,
    "start_time": "2025-01-04T01:23:47.863Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-04T01:25:12.946Z"
   },
   {
    "duration": 19874,
    "start_time": "2025-01-04T01:25:28.117Z"
   },
   {
    "duration": 1834967,
    "start_time": "2025-01-04T01:28:24.266Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-04T02:04:19.752Z"
   },
   {
    "duration": 29,
    "start_time": "2025-01-04T02:04:40.081Z"
   },
   {
    "duration": 29,
    "start_time": "2025-01-04T02:05:01.808Z"
   },
   {
    "duration": 1770428,
    "start_time": "2025-01-04T02:45:55.766Z"
   },
   {
    "duration": 1770723,
    "start_time": "2025-01-04T03:35:00.949Z"
   },
   {
    "duration": 1852706,
    "start_time": "2025-01-04T04:17:11.742Z"
   },
   {
    "duration": 2658,
    "start_time": "2025-01-04T23:17:07.124Z"
   },
   {
    "duration": 725,
    "start_time": "2025-01-04T23:17:09.784Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-04T23:17:10.511Z"
   },
   {
    "duration": 102,
    "start_time": "2025-01-04T23:17:10.526Z"
   },
   {
    "duration": 56,
    "start_time": "2025-01-04T23:17:10.642Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-04T23:17:10.699Z"
   },
   {
    "duration": 253,
    "start_time": "2025-01-04T23:17:10.724Z"
   },
   {
    "duration": 490,
    "start_time": "2025-01-04T23:17:10.979Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-04T23:17:11.471Z"
   },
   {
    "duration": 182,
    "start_time": "2025-01-04T23:17:11.564Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-04T23:17:11.748Z"
   },
   {
    "duration": 280,
    "start_time": "2025-01-04T23:17:11.774Z"
   },
   {
    "duration": 221,
    "start_time": "2025-01-04T23:17:12.056Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-04T23:17:12.281Z"
   },
   {
    "duration": 92,
    "start_time": "2025-01-04T23:17:12.291Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-04T23:17:12.385Z"
   },
   {
    "duration": 130,
    "start_time": "2025-01-04T23:17:12.392Z"
   },
   {
    "duration": 584,
    "start_time": "2025-01-04T23:17:12.524Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-04T23:17:13.110Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-04T23:17:13.119Z"
   },
   {
    "duration": 40753,
    "start_time": "2025-01-04T23:17:13.128Z"
   },
   {
    "duration": 1409037,
    "start_time": "2025-01-04T23:17:53.946Z"
   },
   {
    "duration": 39,
    "start_time": "2025-01-04T23:41:22.986Z"
   },
   {
    "duration": 4484473,
    "start_time": "2025-01-04T23:41:23.027Z"
   },
   {
    "duration": 1383365,
    "start_time": "2025-01-05T00:56:07.501Z"
   },
   {
    "duration": 19600,
    "start_time": "2025-01-05T01:19:10.868Z"
   },
   {
    "duration": 324,
    "start_time": "2025-01-05T01:19:30.470Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T01:19:30.795Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T01:19:30.796Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T01:19:30.797Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T01:19:30.798Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T01:19:30.799Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T01:19:30.800Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T01:19:30.800Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T01:19:30.801Z"
   },
   {
    "duration": 3270,
    "start_time": "2025-01-05T01:20:21.824Z"
   },
   {
    "duration": 2897,
    "start_time": "2025-01-05T01:22:49.994Z"
   },
   {
    "duration": 1098254,
    "start_time": "2025-01-05T01:25:47.996Z"
   },
   {
    "duration": 44553,
    "start_time": "2025-01-05T01:52:30.910Z"
   },
   {
    "duration": 678959,
    "start_time": "2025-01-05T02:02:36.883Z"
   },
   {
    "duration": 64805,
    "start_time": "2025-01-05T02:14:47.550Z"
   },
   {
    "duration": 409659,
    "start_time": "2025-01-05T02:15:56.571Z"
   },
   {
    "duration": 1315301,
    "start_time": "2025-01-05T02:24:09.154Z"
   },
   {
    "duration": 12823,
    "start_time": "2025-01-05T02:46:12.580Z"
   },
   {
    "duration": 154,
    "start_time": "2025-01-05T03:28:22.014Z"
   },
   {
    "duration": 1071,
    "start_time": "2025-01-05T03:34:04.136Z"
   },
   {
    "duration": 451,
    "start_time": "2025-01-05T03:34:05.209Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-05T03:34:05.662Z"
   },
   {
    "duration": 98,
    "start_time": "2025-01-05T03:34:05.682Z"
   },
   {
    "duration": 63,
    "start_time": "2025-01-05T03:34:05.782Z"
   },
   {
    "duration": 22,
    "start_time": "2025-01-05T03:34:05.847Z"
   },
   {
    "duration": 244,
    "start_time": "2025-01-05T03:34:05.871Z"
   },
   {
    "duration": 467,
    "start_time": "2025-01-05T03:34:06.117Z"
   },
   {
    "duration": 99,
    "start_time": "2025-01-05T03:34:06.586Z"
   },
   {
    "duration": 184,
    "start_time": "2025-01-05T03:34:06.687Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-05T03:34:06.873Z"
   },
   {
    "duration": 286,
    "start_time": "2025-01-05T03:34:06.899Z"
   },
   {
    "duration": 255,
    "start_time": "2025-01-05T03:34:07.187Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-05T03:34:07.444Z"
   },
   {
    "duration": 74,
    "start_time": "2025-01-05T03:34:07.455Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-05T03:34:07.543Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-05T03:34:07.550Z"
   },
   {
    "duration": 40502,
    "start_time": "2025-01-05T03:34:07.560Z"
   },
   {
    "duration": 1438264,
    "start_time": "2025-01-05T03:34:48.064Z"
   },
   {
    "duration": 233,
    "start_time": "2025-01-05T03:58:46.330Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.566Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.566Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.567Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.569Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.570Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.573Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.575Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.576Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.577Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.578Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.579Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T03:58:46.580Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-05T04:13:23.829Z"
   },
   {
    "duration": 76,
    "start_time": "2025-01-05T04:13:34.887Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-05T04:13:36.921Z"
   },
   {
    "duration": 508,
    "start_time": "2025-01-05T04:13:53.149Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-05T04:13:54.231Z"
   },
   {
    "duration": 492,
    "start_time": "2025-01-05T04:14:17.336Z"
   },
   {
    "duration": 38,
    "start_time": "2025-01-05T04:14:18.263Z"
   },
   {
    "duration": 70875,
    "start_time": "2025-01-05T04:14:29.162Z"
   },
   {
    "duration": 1449976,
    "start_time": "2025-01-05T04:15:50.960Z"
   },
   {
    "duration": 19722,
    "start_time": "2025-01-05T04:40:18.124Z"
   },
   {
    "duration": 5986,
    "start_time": "2025-01-05T04:42:52.427Z"
   },
   {
    "duration": 44695,
    "start_time": "2025-01-05T04:43:05.371Z"
   },
   {
    "duration": 679974,
    "start_time": "2025-01-05T04:44:27.845Z"
   },
   {
    "duration": 20,
    "start_time": "2025-01-05T05:00:36.113Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-05T05:01:37.111Z"
   },
   {
    "duration": 31,
    "start_time": "2025-01-05T05:01:44.533Z"
   },
   {
    "duration": 4478,
    "start_time": "2025-01-05T05:01:54.902Z"
   },
   {
    "duration": 409041,
    "start_time": "2025-01-05T05:02:04.087Z"
   },
   {
    "duration": 1317002,
    "start_time": "2025-01-05T05:15:29.448Z"
   },
   {
    "duration": 6969,
    "start_time": "2025-01-05T05:37:32.673Z"
   },
   {
    "duration": 2711,
    "start_time": "2025-01-05T15:07:50.059Z"
   },
   {
    "duration": 490,
    "start_time": "2025-01-05T15:07:52.772Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-05T15:07:53.263Z"
   },
   {
    "duration": 105,
    "start_time": "2025-01-05T15:07:53.279Z"
   },
   {
    "duration": 67,
    "start_time": "2025-01-05T15:07:53.386Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-05T15:07:53.455Z"
   },
   {
    "duration": 228,
    "start_time": "2025-01-05T15:07:53.481Z"
   },
   {
    "duration": 454,
    "start_time": "2025-01-05T15:07:53.711Z"
   },
   {
    "duration": 90,
    "start_time": "2025-01-05T15:07:54.167Z"
   },
   {
    "duration": 185,
    "start_time": "2025-01-05T15:07:54.260Z"
   },
   {
    "duration": 22,
    "start_time": "2025-01-05T15:07:54.446Z"
   },
   {
    "duration": 275,
    "start_time": "2025-01-05T15:07:54.469Z"
   },
   {
    "duration": 228,
    "start_time": "2025-01-05T15:07:54.747Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-05T15:07:54.977Z"
   },
   {
    "duration": 85,
    "start_time": "2025-01-05T15:07:54.986Z"
   },
   {
    "duration": 235,
    "start_time": "2025-01-05T15:07:55.073Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.310Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.323Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.325Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.326Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.327Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.329Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.330Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.331Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.332Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.333Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.335Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.337Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.338Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.339Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.341Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.342Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.343Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.344Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:07:55.345Z"
   },
   {
    "duration": 1030,
    "start_time": "2025-01-05T15:08:22.801Z"
   },
   {
    "duration": 415,
    "start_time": "2025-01-05T15:08:23.833Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-05T15:08:24.252Z"
   },
   {
    "duration": 96,
    "start_time": "2025-01-05T15:08:24.272Z"
   },
   {
    "duration": 65,
    "start_time": "2025-01-05T15:08:24.372Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-05T15:08:24.439Z"
   },
   {
    "duration": 239,
    "start_time": "2025-01-05T15:08:24.464Z"
   },
   {
    "duration": 473,
    "start_time": "2025-01-05T15:08:24.705Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-05T15:08:25.180Z"
   },
   {
    "duration": 184,
    "start_time": "2025-01-05T15:08:25.273Z"
   },
   {
    "duration": 22,
    "start_time": "2025-01-05T15:08:25.459Z"
   },
   {
    "duration": 280,
    "start_time": "2025-01-05T15:08:25.482Z"
   },
   {
    "duration": 224,
    "start_time": "2025-01-05T15:08:25.764Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-05T15:08:25.993Z"
   },
   {
    "duration": 91,
    "start_time": "2025-01-05T15:08:26.003Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-05T15:08:26.095Z"
   },
   {
    "duration": 21,
    "start_time": "2025-01-05T15:08:26.103Z"
   },
   {
    "duration": 41830,
    "start_time": "2025-01-05T15:08:26.126Z"
   },
   {
    "duration": 1422708,
    "start_time": "2025-01-05T15:09:08.025Z"
   },
   {
    "duration": 520,
    "start_time": "2025-01-05T15:32:50.735Z"
   },
   {
    "duration": 78,
    "start_time": "2025-01-05T15:32:51.256Z"
   },
   {
    "duration": 38,
    "start_time": "2025-01-05T15:32:51.336Z"
   },
   {
    "duration": 86474,
    "start_time": "2025-01-05T15:32:51.376Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.852Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.853Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.855Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.857Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.857Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.859Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.860Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.861Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.862Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.863Z"
   },
   {
    "duration": 0,
    "start_time": "2025-01-05T15:34:17.864Z"
   },
   {
    "duration": 1440521,
    "start_time": "2025-01-05T15:34:26.736Z"
   },
   {
    "duration": 20162,
    "start_time": "2025-01-05T16:12:34.181Z"
   },
   {
    "duration": 4212,
    "start_time": "2025-01-05T16:15:48.604Z"
   },
   {
    "duration": 44022,
    "start_time": "2025-01-05T16:15:59.813Z"
   },
   {
    "duration": 681457,
    "start_time": "2025-01-05T16:20:33.971Z"
   },
   {
    "duration": 3964,
    "start_time": "2025-01-05T16:32:41.197Z"
   },
   {
    "duration": 6806,
    "start_time": "2025-01-05T16:32:47.920Z"
   },
   {
    "duration": 2752,
    "start_time": "2025-01-05T17:16:40.290Z"
   },
   {
    "duration": 513,
    "start_time": "2025-01-05T17:16:43.044Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-05T17:16:43.559Z"
   },
   {
    "duration": 102,
    "start_time": "2025-01-05T17:16:43.575Z"
   },
   {
    "duration": 69,
    "start_time": "2025-01-05T17:16:43.679Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-05T17:16:43.751Z"
   },
   {
    "duration": 254,
    "start_time": "2025-01-05T17:16:43.775Z"
   },
   {
    "duration": 487,
    "start_time": "2025-01-05T17:16:44.031Z"
   },
   {
    "duration": 90,
    "start_time": "2025-01-05T17:16:44.519Z"
   },
   {
    "duration": 179,
    "start_time": "2025-01-05T17:16:44.612Z"
   },
   {
    "duration": 31,
    "start_time": "2025-01-05T17:16:44.793Z"
   },
   {
    "duration": 278,
    "start_time": "2025-01-05T17:16:44.825Z"
   },
   {
    "duration": 224,
    "start_time": "2025-01-05T17:16:45.105Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-05T17:16:45.330Z"
   },
   {
    "duration": 86,
    "start_time": "2025-01-05T17:16:45.341Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-05T17:16:45.429Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-05T17:16:45.437Z"
   },
   {
    "duration": 44473,
    "start_time": "2025-01-05T17:16:45.446Z"
   },
   {
    "duration": 1178,
    "start_time": "2025-01-05T18:23:20.627Z"
   },
   {
    "duration": 831,
    "start_time": "2025-01-05T18:23:21.807Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-05T18:23:22.639Z"
   },
   {
    "duration": 126,
    "start_time": "2025-01-05T18:23:22.654Z"
   },
   {
    "duration": 101,
    "start_time": "2025-01-05T18:23:22.781Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-05T18:23:22.884Z"
   },
   {
    "duration": 248,
    "start_time": "2025-01-05T18:23:22.928Z"
   },
   {
    "duration": 502,
    "start_time": "2025-01-05T18:23:23.178Z"
   },
   {
    "duration": 96,
    "start_time": "2025-01-05T18:23:23.682Z"
   },
   {
    "duration": 179,
    "start_time": "2025-01-05T18:23:23.781Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-05T18:23:23.962Z"
   },
   {
    "duration": 303,
    "start_time": "2025-01-05T18:23:23.989Z"
   },
   {
    "duration": 212,
    "start_time": "2025-01-05T18:23:24.294Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-05T18:23:24.508Z"
   },
   {
    "duration": 88,
    "start_time": "2025-01-05T18:23:24.517Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-05T18:23:24.607Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-05T18:23:24.616Z"
   },
   {
    "duration": 42391,
    "start_time": "2025-01-05T18:23:24.625Z"
   },
   {
    "duration": 1450090,
    "start_time": "2025-01-05T18:24:07.017Z"
   },
   {
    "duration": 464,
    "start_time": "2025-01-05T18:48:17.108Z"
   },
   {
    "duration": 63,
    "start_time": "2025-01-05T18:48:17.574Z"
   },
   {
    "duration": 20,
    "start_time": "2025-01-05T18:48:17.639Z"
   },
   {
    "duration": 5011835,
    "start_time": "2025-01-05T18:48:17.661Z"
   },
   {
    "duration": 1418267,
    "start_time": "2025-01-05T20:11:49.506Z"
   },
   {
    "duration": 20749,
    "start_time": "2025-01-05T20:35:27.775Z"
   },
   {
    "duration": 1131900,
    "start_time": "2025-01-05T20:35:48.526Z"
   },
   {
    "duration": 47402,
    "start_time": "2025-01-05T20:54:40.428Z"
   },
   {
    "duration": 703247,
    "start_time": "2025-01-05T20:55:27.834Z"
   },
   {
    "duration": 5432043,
    "start_time": "2025-01-05T21:07:11.083Z"
   },
   {
    "duration": 432797,
    "start_time": "2025-01-05T22:37:43.128Z"
   },
   {
    "duration": 1611293,
    "start_time": "2025-01-05T22:44:55.927Z"
   },
   {
    "duration": 57394461,
    "start_time": "2025-01-05T23:11:47.222Z"
   },
   {
    "duration": 12604950,
    "start_time": "2025-01-06T15:08:21.686Z"
   },
   {
    "duration": 337,
    "start_time": "2025-01-06T18:38:26.705Z"
   },
   {
    "duration": 33,
    "start_time": "2025-01-06T22:29:14.756Z"
   },
   {
    "duration": 1849343,
    "start_time": "2025-01-06T22:29:35.764Z"
   },
   {
    "duration": 478,
    "start_time": "2025-01-07T00:48:09.351Z"
   },
   {
    "duration": 1904958,
    "start_time": "2025-01-07T00:49:08.608Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
